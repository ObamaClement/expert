=== Fichier: ./test_api.py ===

import requests
import json
from datetime import datetime
import time

# Configuration
BASE_URL = "https://expert-cmck.onrender.com"
API_BASE = f"{BASE_URL}/api/v1"
OUTPUT_FILE = f"test_api_complet_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    END = '\033[0m'

class APITester:
    def __init__(self, filename):
        self.filename = filename
        self.file = open(filename, 'w', encoding='utf-8')
        self.test_count = 0
        self.success_count = 0
        self.fail_count = 0
        self.created_ids = {}
        
    def write(self, message, color=None):
        """Ã‰crit dans le fichier et affiche Ã  l'Ã©cran"""
        self.file.write(message + '\n')
        self.file.flush()
        
        if color:
            print(f"{color}{message}{Colors.END}")
        else:
            print(message)
    
    def section(self, title):
        separator = '='*100
        self.write(f"\n{separator}")
        self.write(f"  {title}")
        self.write(separator)
    
    def test_header(self, method, endpoint, description):
        self.test_count += 1
        header = f"\n{'â”€'*100}\nTEST #{self.test_count}: {method} {endpoint}\nDescription: {description}\n{'â”€'*100}"
        self.write(header, Colors.CYAN)
    
    def log_request(self, method, url, data=None, params=None):
        self.write(f"\nğŸ“¤ REQUÃŠTE:", Colors.BLUE)
        self.write(f"   MÃ©thode: {method}")
        self.write(f"   URL: {url}")
        if params:
            self.write(f"   ParamÃ¨tres: {json.dumps(params, indent=6, ensure_ascii=False)}")
        if data:
            self.write(f"   DonnÃ©es envoyÃ©es:")
            self.write(json.dumps(data, indent=6, ensure_ascii=False))
    
    def log_response(self, response, show_full=True):
        self.write(f"\nğŸ“¥ RÃ‰PONSE:", Colors.BLUE)
        self.write(f"   Status Code: {response.status_code}")
        self.write(f"   Temps de rÃ©ponse: {response.elapsed.total_seconds():.2f}s")
        
        try:
            data = response.json()
            if show_full:
                self.write(f"   DonnÃ©es reÃ§ues:")
                self.write(json.dumps(data, indent=6, ensure_ascii=False))
            else:
                if isinstance(data, list):
                    self.write(f"   Type: Liste de {len(data)} Ã©lÃ©ments")
                    if len(data) > 0:
                        self.write(f"   Premier Ã©lÃ©ment:")
                        self.write(json.dumps(data[0], indent=6, ensure_ascii=False))
                else:
                    self.write(f"   DonnÃ©es reÃ§ues:")
                    self.write(json.dumps(data, indent=6, ensure_ascii=False))
        except:
            self.write(f"   RÃ©ponse texte: {response.text[:500]}")
    
    def mark_success(self, message=""):
        self.success_count += 1
        self.write(f"\nâœ… SUCCÃˆS: {message}", Colors.GREEN)
    
    def mark_failure(self, message=""):
        self.fail_count += 1
        self.write(f"\nâŒ Ã‰CHEC: {message}", Colors.RED)
    
    def summary(self):
        self.section("RÃ‰SUMÃ‰ DES TESTS")
        self.write(f"Total de tests: {self.test_count}")
        self.write(f"SuccÃ¨s: {self.success_count}", Colors.GREEN)
        self.write(f"Ã‰checs: {self.fail_count}", Colors.RED)
        self.write(f"Taux de rÃ©ussite: {(self.success_count/self.test_count*100):.1f}%" if self.test_count > 0 else "N/A")
        
        if self.created_ids:
            self.write("\nğŸ“ IDs crÃ©Ã©s pendant les tests:")
            for key, value in self.created_ids.items():
                self.write(f"   {key}: {value}")
    
    def close(self):
        self.file.close()
    
    def wait_for_user(self):
        """Attend que l'utilisateur appuie sur EntrÃ©e"""
        input(f"\n{Colors.YELLOW}â¸  Appuyez sur EntrÃ©e pour continuer...{Colors.END}")

# Instance globale
tester = None

# =============================================================================
# TESTS SYMPTOMS
# =============================================================================

def test_symptoms_create():
    tester.test_header("POST", "/api/v1/symptoms/", "CrÃ©er un nouveau symptÃ´me")
    
    data = {
        "nom": "CÃ©phalÃ©e Test API",
        "nom_local": "Mal de tÃªte (Ewondo)",
        "categorie": "Neurologique",
        "type_symptome": "Subjectif",
        "description": "Douleur au niveau de la tÃªte",
        "questions_anamnese": {
            "localisation": "OÃ¹ se situe la douleur ?",
            "intensite": "Sur une Ã©chelle de 1 Ã  10 ?",
            "caractere": "Pulsatile, constrictive ?"
        },
        "signes_alarme": True
    }
    
    tester.log_request("POST", f"{API_BASE}/symptoms/", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/symptoms/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            result = response.json()
            tester.created_ids['symptom'] = result['id']
            tester.mark_success(f"SymptÃ´me crÃ©Ã© avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_symptoms_list():
    tester.test_header("GET", "/api/v1/symptoms/", "RÃ©cupÃ©rer la liste des symptÃ´mes")
    
    params = {"skip": 0, "limit": 10}
    tester.log_request("GET", f"{API_BASE}/symptoms/", params=params)
    
    try:
        response = requests.get(f"{API_BASE}/symptoms/", params=params, timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} symptÃ´mes")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_symptoms_read():
    if 'symptom' not in tester.created_ids:
        tester.write("âš ï¸  Aucun symptÃ´me crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    symptom_id = tester.created_ids['symptom']
    tester.test_header("GET", f"/api/v1/symptoms/{symptom_id}", "RÃ©cupÃ©rer un symptÃ´me par ID")
    
    tester.log_request("GET", f"{API_BASE}/symptoms/{symptom_id}")
    
    try:
        response = requests.get(f"{API_BASE}/symptoms/{symptom_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("SymptÃ´me rÃ©cupÃ©rÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_symptoms_update():
    if 'symptom' not in tester.created_ids:
        tester.write("âš ï¸  Aucun symptÃ´me crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    symptom_id = tester.created_ids['symptom']
    tester.test_header("PATCH", f"/api/v1/symptoms/{symptom_id}", "Mettre Ã  jour un symptÃ´me")
    
    data = {
        "description": "Description mise Ã  jour - Douleur cÃ©phalique modÃ©rÃ©e Ã  sÃ©vÃ¨re",
        "signes_alarme": False
    }
    
    tester.log_request("PATCH", f"{API_BASE}/symptoms/{symptom_id}", data=data)
    
    try:
        response = requests.patch(f"{API_BASE}/symptoms/{symptom_id}", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("SymptÃ´me mis Ã  jour")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS DISEASES
# =============================================================================

def test_diseases_create():
    tester.test_header("POST", "/api/v1/diseases/", "CrÃ©er une nouvelle pathologie")
    
    data = {
        "nom_fr": "MÃ©ningite Test API",
        "code_icd10": "G03.9",
        "nom_en": "Meningitis Test",
        "nom_local": "Inflammation cerveau (Bulu)",
        "categorie": "Infectiologie",
        "prevalence_cameroun": 5.2,
        "niveau_gravite": 4,
        "description": "Inflammation des mÃ©ninges",
        "physiopathologie": "Infection bactÃ©rienne ou virale des mÃ©ninges",
        "evolution_naturelle": "Urgence mÃ©dicale nÃ©cessitant un traitement rapide",
        "complications": {
            "neurologiques": ["SÃ©quelles neurologiques", "DÃ©cÃ¨s"],
            "autres": ["SepticÃ©mie"]
        },
        "facteurs_risque": {
            "age": ["Nourrissons", "Jeunes adultes"],
            "immunitaires": ["ImmunodÃ©pression"]
        },
        "prevention": "Vaccination, hygiÃ¨ne"
    }
    
    tester.log_request("POST", f"{API_BASE}/diseases/", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/diseases/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            result = response.json()
            tester.created_ids['disease'] = result['id']
            tester.mark_success(f"Pathologie crÃ©Ã©e avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_diseases_list():
    tester.test_header("GET", "/api/v1/diseases/", "RÃ©cupÃ©rer la liste des pathologies")
    
    params = {"skip": 0, "limit": 10}
    tester.log_request("GET", f"{API_BASE}/diseases/", params=params)
    
    try:
        response = requests.get(f"{API_BASE}/diseases/", params=params, timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} pathologies")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_diseases_read():
    if 'disease' not in tester.created_ids:
        tester.write("âš ï¸  Aucune pathologie crÃ©Ã©e, test ignorÃ©", Colors.YELLOW)
        return False
    
    disease_id = tester.created_ids['disease']
    tester.test_header("GET", f"/api/v1/diseases/{disease_id}", "RÃ©cupÃ©rer une pathologie par ID")
    
    tester.log_request("GET", f"{API_BASE}/diseases/{disease_id}")
    
    try:
        response = requests.get(f"{API_BASE}/diseases/{disease_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Pathologie rÃ©cupÃ©rÃ©e")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS MEDICATIONS
# =============================================================================

def test_medications_create():
    tester.test_header("POST", "/api/v1/medications/", "CrÃ©er un nouveau mÃ©dicament")
    
    data = {
        "dci": "Amoxicilline Test API",
        "nom_commercial": "Clamoxyl Test",
        "classe_therapeutique": "Antibiotique - PÃ©nicilline",
        "forme_galenique": "GÃ©lule",
        "dosage": "1g",
        "voie_administration": "Orale",
        "mecanisme_action": "Inhibition de la synthÃ¨se de la paroi bactÃ©rienne",
        "indications": {
            "principales": ["Infections respiratoires", "Infections ORL"]
        },
        "contre_indications": {
            "absolues": ["Allergie aux pÃ©nicillines"]
        },
        "effets_secondaires": {
            "digestifs": ["DiarrhÃ©e", "NausÃ©es"]
        },
        "interactions_medicamenteuses": {
            "attention": ["MÃ©thotrexate"]
        },
        "precautions_emploi": "Surveiller fonction rÃ©nale",
        "posologie_standard": {
            "adulte": "1g x 3/jour"
        },
        "disponibilite_cameroun": "Disponible",
        "cout_moyen_fcfa": 2500,
        "statut_prescription": "Sur ordonnance"
    }
    
    tester.log_request("POST", f"{API_BASE}/medications/", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/medications/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            result = response.json()
            tester.created_ids['medication'] = result['id']
            tester.mark_success(f"MÃ©dicament crÃ©Ã© avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_medications_list():
    tester.test_header("GET", "/api/v1/medications/", "RÃ©cupÃ©rer la liste des mÃ©dicaments")
    
    params = {"skip": 0, "limit": 10}
    tester.log_request("GET", f"{API_BASE}/medications/", params=params)
    
    try:
        response = requests.get(f"{API_BASE}/medications/", params=params, timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} mÃ©dicaments")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_medications_read():
    if 'medication' not in tester.created_ids:
        tester.write("âš ï¸  Aucun mÃ©dicament crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    medication_id = tester.created_ids['medication']
    tester.test_header("GET", f"/api/v1/medications/{medication_id}", "RÃ©cupÃ©rer un mÃ©dicament par ID")
    
    tester.log_request("GET", f"{API_BASE}/medications/{medication_id}")
    
    try:
        response = requests.get(f"{API_BASE}/medications/{medication_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("MÃ©dicament rÃ©cupÃ©rÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS RELATIONS
# =============================================================================

def test_add_symptom_to_disease():
    if 'disease' not in tester.created_ids or 'symptom' not in tester.created_ids:
        tester.write("âš ï¸  Pathologie ou symptÃ´me manquant, test ignorÃ©", Colors.YELLOW)
        return False
    
    disease_id = tester.created_ids['disease']
    tester.test_header("POST", f"/api/v1/diseases/{disease_id}/symptoms", 
                      "Associer un symptÃ´me Ã  une pathologie")
    
    data = {
        "pathologie_id": disease_id,
        "symptome_id": tester.created_ids['symptom'],
        "probabilite": 0.90,
        "sensibilite": 0.85,
        "specificite": 0.75,
        "phase_maladie": "Initiale",
        "frequence": "TrÃ¨s frÃ©quent",
        "est_pathognomonique": False,
        "importance_diagnostique": 9
    }
    
    tester.log_request("POST", f"{API_BASE}/diseases/{disease_id}/symptoms", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/diseases/{disease_id}/symptoms", 
                               json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            tester.mark_success("SymptÃ´me associÃ© Ã  la pathologie")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_get_symptoms_for_disease():
    if 'disease' not in tester.created_ids:
        tester.write("âš ï¸  Aucune pathologie crÃ©Ã©e, test ignorÃ©", Colors.YELLOW)
        return False
    
    disease_id = tester.created_ids['disease']
    tester.test_header("GET", f"/api/v1/diseases/{disease_id}/symptoms", 
                      "RÃ©cupÃ©rer les symptÃ´mes d'une pathologie")
    
    tester.log_request("GET", f"{API_BASE}/diseases/{disease_id}/symptoms")
    
    try:
        response = requests.get(f"{API_BASE}/diseases/{disease_id}/symptoms", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"{len(data)} symptÃ´mes trouvÃ©s")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_add_treatment_to_disease():
    if 'disease' not in tester.created_ids or 'medication' not in tester.created_ids:
        tester.write("âš ï¸  Pathologie ou mÃ©dicament manquant, test ignorÃ©", Colors.YELLOW)
        return False
    
    disease_id = tester.created_ids['disease']
    tester.test_header("POST", f"/api/v1/diseases/{disease_id}/treatments", 
                      "Associer un traitement Ã  une pathologie")
    
    data = {
        "pathologie_id": disease_id,
        "medicament_id": tester.created_ids['medication'],
        "type_traitement": "Curatif",
        "ligne_traitement": 1,
        "indication_precise": "Traitement de premiÃ¨re intention",
        "efficacite_taux": 92.5,
        "duree_traitement_jours": 10,
        "posologie_detaillee": {
            "dose": "1g x 3/jour",
            "duree": "10 jours"
        },
        "niveau_preuve": "A",
        "guidelines_source": "OMS 2024",
        "rang_preference": 1
    }
    
    tester.log_request("POST", f"{API_BASE}/diseases/{disease_id}/treatments", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/diseases/{disease_id}/treatments", 
                               json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            tester.mark_success("Traitement associÃ© Ã  la pathologie")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS CLINICAL CASES
# =============================================================================

def test_clinical_cases_create():
    if 'disease' not in tester.created_ids:
        tester.write("âš ï¸  Aucune pathologie crÃ©Ã©e, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", "/api/v1/clinical-cases/", "CrÃ©er un cas clinique")
    
    data = {
        "code_fultang": f"TEST_API_{int(time.time())}",
        "pathologie_principale_id": tester.created_ids['disease'],
        "pathologies_secondaires_ids": [],
        "presentation_clinique": {
            "histoire_maladie": "Patient de 28 ans consultant pour cÃ©phalÃ©es intenses",
            "symptomes_patient": [
                {
                    "symptome_id": tester.created_ids.get('symptom', 1),
                    "details": "CÃ©phalÃ©e intense"
                }
            ],
            "antecedents": {
                "medicaux": ["RAS"]
            }
        },
        "donnees_paracliniques": {},
        "evolution_patient": "AmÃ©lioration",
        "images_associees_ids": [],
        "sons_associes_ids": [],
        "medicaments_prescrits": [],
        "niveau_difficulte": 3,
        "duree_estimee_resolution_min": 45,
        "objectifs_apprentissage": ["Diagnostic"],
        "competences_requises": {}
    }
    
    tester.log_request("POST", f"{API_BASE}/clinical-cases/", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/clinical-cases/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            result = response.json()
            tester.created_ids['clinical_case'] = result['id']
            tester.mark_success(f"Cas clinique crÃ©Ã© avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_clinical_cases_list():
    tester.test_header("GET", "/api/v1/clinical-cases/", "RÃ©cupÃ©rer la liste des cas cliniques")
    
    params = {"skip": 0, "limit": 5}
    tester.log_request("GET", f"{API_BASE}/clinical-cases/", params=params)
    
    try:
        response = requests.get(f"{API_BASE}/clinical-cases/", params=params, timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} cas cliniques")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# NETTOYAGE
# =============================================================================

def cleanup_test_data():
    """Supprime les donnÃ©es de test crÃ©Ã©es"""
    tester.section("NETTOYAGE DES DONNÃ‰ES DE TEST")
    
    cleanup_order = [
        ('clinical_case', 'clinical-cases', 'Cas clinique'),
        ('symptom', 'symptoms', 'SymptÃ´me'),
        ('medication', 'medications', 'MÃ©dicament'),
        ('disease', 'diseases', 'Pathologie'),
    ]
    
    for key, endpoint, name in cleanup_order:
        if key in tester.created_ids:
            item_id = tester.created_ids[key]
            tester.write(f"\nğŸ—‘ï¸  Suppression {name} ID {item_id}...", Colors.YELLOW)
            
            try:
                response = requests.delete(f"{API_BASE}/{endpoint}/{item_id}", timeout=30)
                if response.status_code == 200:
                    tester.write(f"âœ… {name} supprimÃ©", Colors.GREEN)
                else:
                    tester.write(f"âš ï¸  Erreur {response.status_code}", Colors.YELLOW)
            except Exception as e:
                tester.write(f"âŒ Exception: {str(e)}", Colors.RED)

# =============================================================================
# FONCTION PRINCIPALE
# =============================================================================

def main():
    global tester
    tester = APITester(OUTPUT_FILE)
    
    tester.section("TEST SYSTÃ‰MATIQUE COMPLET DE L'API STI MEDICAL EXPERT")
    tester.write(f"URL: {BASE_URL}")
    tester.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    tester.write(f"Fichier de sortie: {OUTPUT_FILE}")
    
    print(f"\n{Colors.CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"â•‘  TEST AUTOMATIQUE DE TOUTES LES ROUTES DE L'API              â•‘")
    print(f"â•‘  Chaque test s'exÃ©cutera et attendra votre validation        â•‘")
    print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.END}\n")
    
    try:
        # =====================================================================
        # MODULE 1: SYMPTOMS
        # =====================================================================
        tester.section("MODULE 1: SYMPTOMS - Tests CRUD complets")
        
        # 1.1 CrÃ©er un symptÃ´me
        test_symptoms_create()
        tester.wait_for_user()
        
        # 1.2 Lister les symptÃ´mes
        test_symptoms_list()
        tester.wait_for_user()
        
        # 1.3 RÃ©cupÃ©rer un symptÃ´me spÃ©cifique
        test_symptoms_read()
        tester.wait_for_user()
        
        # 1.4 Mettre Ã  jour le symptÃ´me
        test_symptoms_update()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 2: DISEASES
        # =====================================================================
        tester.section("MODULE 2: DISEASES - Tests CRUD complets")
        
        # 2.1 CrÃ©er une pathologie
        test_diseases_create()
        tester.wait_for_user()
        
        # 2.2 Lister les pathologies
        test_diseases_list()
        tester.wait_for_user()
        
        # 2.3 RÃ©cupÃ©rer une pathologie spÃ©cifique
        test_diseases_read()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 3: MEDICATIONS
        # =====================================================================
        tester.section("MODULE 3: MEDICATIONS - Tests CRUD complets")
        
        # 3.1 CrÃ©er un mÃ©dicament
        test_medications_create()
        tester.wait_for_user()
        
        # 3.2 Lister les mÃ©dicaments
        test_medications_list()
        tester.wait_for_user()
        
        # 3.3 RÃ©cupÃ©rer un mÃ©dicament spÃ©cifique
        test_medications_read()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 4: RELATIONS SYMPTÃ”MES-PATHOLOGIES
        # =====================================================================
        tester.section("MODULE 4: RELATIONS SYMPTÃ”MES-PATHOLOGIES")
        
        # 4.1 Associer un symptÃ´me Ã  une pathologie
        test_add_symptom_to_disease()
        tester.wait_for_user()
        
        # 4.2 RÃ©cupÃ©rer les symptÃ´mes d'une pathologie
        test_get_symptoms_for_disease()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 5: RELATIONS TRAITEMENTS-PATHOLOGIES
        # =====================================================================
        tester.section("MODULE 5: RELATIONS TRAITEMENTS-PATHOLOGIES")
        
        # 5.1 Associer un traitement Ã  une pathologie
        test_add_treatment_to_disease()
        tester.wait_for_user()
        
        # 5.2 RÃ©cupÃ©rer les traitements d'une pathologie (nouveau test)
        test_get_treatments_for_disease()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 6: RELATIONS TRAITEMENTS-SYMPTÃ”MES
        # =====================================================================
        tester.section("MODULE 6: RELATIONS TRAITEMENTS SYMPTOMATIQUES")
        
        # 6.1 Associer un traitement Ã  un symptÃ´me
        test_add_treatment_to_symptom()
        tester.wait_for_user()
        
        # 6.2 RÃ©cupÃ©rer les traitements d'un symptÃ´me
        test_get_treatments_for_symptom()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 7: CLINICAL CASES
        # =====================================================================
        tester.section("MODULE 7: CLINICAL CASES - Cas cliniques")
        
        # 7.1 CrÃ©er un cas clinique
        test_clinical_cases_create()
        tester.wait_for_user()
        
        # 7.2 Lister les cas cliniques
        test_clinical_cases_list()
        tester.wait_for_user()
        
        # 7.3 RÃ©cupÃ©rer un cas clinique complet
        test_clinical_cases_read()
        tester.wait_for_user()
        
        # 7.4 RÃ©cupÃ©rer un cas clinique simplifiÃ©
        test_clinical_cases_read_simple()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 8: EXPERT STRATEGIES
        # =====================================================================
        tester.section("MODULE 8: EXPERT STRATEGIES - RÃ¨gles expertes")
        
        # 8.1 CrÃ©er une rÃ¨gle experte
        test_expert_strategies_create()
        tester.wait_for_user()
        
        # 8.2 Lister les rÃ¨gles expertes
        test_expert_strategies_list()
        tester.wait_for_user()
        
        # 8.3 RÃ©cupÃ©rer une rÃ¨gle experte
        test_expert_strategies_read()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 9: DIAGNOSTIC ENGINE
        # =====================================================================
        tester.section("MODULE 9: DIAGNOSTIC ENGINE - Moteur de diagnostic")
        
        # 9.1 ExÃ©cuter le moteur de diagnostic
        test_diagnostic_engine_run()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 10: MEDIA (IMAGES)
        # =====================================================================
        tester.section("MODULE 10: MEDIA - Gestion des images mÃ©dicales")
        
        # 10.1 CrÃ©er une image fictive et l'uploader
        test_media_upload_image()
        tester.wait_for_user()
        
        # 10.2 Lister les images
        test_media_list_images()
        tester.wait_for_user()
        
        # 10.3 RÃ©cupÃ©rer une image spÃ©cifique
        test_media_read_image()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 11: CHAT
        # =====================================================================
        tester.section("MODULE 11: CHAT - SystÃ¨me de messagerie")
        
        # 11.1 CrÃ©er une session de chat et envoyer des messages
        test_chat_send_message()
        tester.wait_for_user()
        
        # 11.2 RÃ©cupÃ©rer l'historique du chat
        test_chat_get_history()
        tester.wait_for_user()
        
        # =====================================================================
        # RÃ‰SUMÃ‰ FINAL
        # =====================================================================
        tester.summary()
        
        # =====================================================================
        # NETTOYAGE OPTIONNEL
        # =====================================================================
        print(f"\n{Colors.YELLOW}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"â•‘  NETTOYAGE DES DONNÃ‰ES DE TEST                                â•‘")
        print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.END}\n")
        print(f"{Colors.YELLOW}Voulez-vous supprimer les donnÃ©es de test crÃ©Ã©es? (o/n): {Colors.END}", end='')
        
        if input().lower() == 'o':
            cleanup_test_data()
        else:
            tester.write("\nâš ï¸  DonnÃ©es de test conservÃ©es", Colors.YELLOW)
            tester.write("IDs conservÃ©s pour rÃ©fÃ©rence future:")
            for key, value in tester.created_ids.items():
                tester.write(f"   - {key}: {value}")
        
    except KeyboardInterrupt:
        tester.write("\n\nâš ï¸  Tests interrompus par l'utilisateur", Colors.YELLOW)
        tester.summary()
    except Exception as e:
        tester.write(f"\n\nâŒ ERREUR CRITIQUE: {str(e)}", Colors.RED)
        import traceback
        tester.write(traceback.format_exc())
        tester.summary()
    finally:
        tester.close()
        print(f"\n{Colors.GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"â•‘  TESTS TERMINÃ‰S                                               â•‘")
        print(f"â•‘  RÃ©sultats sauvegardÃ©s dans: {OUTPUT_FILE:31s} â•‘")
        print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.END}\n")


# =====================================================================
# FONCTIONS DE TEST SUPPLÃ‰MENTAIRES
# =====================================================================

def test_get_treatments_for_disease():
    """RÃ©cupÃ¨re les traitements d'une pathologie"""
    if 'disease' not in tester.created_ids:
        tester.write("âš ï¸  Aucune pathologie crÃ©Ã©e, test ignorÃ©", Colors.YELLOW)
        return False
    
    disease_id = tester.created_ids['disease']
    tester.test_header("GET", f"/api/v1/diseases/{disease_id}/treatments", 
                      "RÃ©cupÃ©rer les traitements d'une pathologie")
    
    tester.log_request("GET", f"{API_BASE}/diseases/{disease_id}/treatments")
    
    try:
        response = requests.get(f"{API_BASE}/diseases/{disease_id}/treatments", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"{len(data)} traitements trouvÃ©s")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_add_treatment_to_symptom():
    """Associe un traitement Ã  un symptÃ´me"""
    if 'symptom' not in tester.created_ids or 'medication' not in tester.created_ids:
        tester.write("âš ï¸  SymptÃ´me ou mÃ©dicament manquant, test ignorÃ©", Colors.YELLOW)
        return False
    
    symptom_id = tester.created_ids['symptom']
    tester.test_header("POST", f"/api/v1/symptoms/{symptom_id}/treatments", 
                      "Associer un traitement symptomatique")
    
    data = {
        "symptome_id": symptom_id,
        "medicament_id": tester.created_ids['medication'],
        "efficacite": "Bonne",
        "rapidite_action": "15-30 minutes",
        "posologie_recommandee": "1g toutes les 6h si besoin",
        "rang_preference": 1
    }
    
    tester.log_request("POST", f"{API_BASE}/symptoms/{symptom_id}/treatments", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/symptoms/{symptom_id}/treatments", 
                               json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            tester.mark_success("Traitement symptomatique associÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_get_treatments_for_symptom():
    """RÃ©cupÃ¨re les traitements d'un symptÃ´me"""
    if 'symptom' not in tester.created_ids:
        tester.write("âš ï¸  Aucun symptÃ´me crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    symptom_id = tester.created_ids['symptom']
    tester.test_header("GET", f"/api/v1/symptoms/{symptom_id}/treatments", 
                      "RÃ©cupÃ©rer les traitements symptomatiques")
    
    tester.log_request("GET", f"{API_BASE}/symptoms/{symptom_id}/treatments")
    
    try:
        response = requests.get(f"{API_BASE}/symptoms/{symptom_id}/treatments", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"{len(data)} traitements trouvÃ©s")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_clinical_cases_read():
    """RÃ©cupÃ¨re un cas clinique complet"""
    if 'clinical_case' not in tester.created_ids:
        tester.write("âš ï¸  Aucun cas clinique crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    case_id = tester.created_ids['clinical_case']
    tester.test_header("GET", f"/api/v1/clinical-cases/{case_id}", 
                      "RÃ©cupÃ©rer un cas clinique complet")
    
    tester.log_request("GET", f"{API_BASE}/clinical-cases/{case_id}")
    
    try:
        response = requests.get(f"{API_BASE}/clinical-cases/{case_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Cas clinique complet rÃ©cupÃ©rÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_clinical_cases_read_simple():
    """RÃ©cupÃ¨re un cas clinique en version simplifiÃ©e"""
    if 'clinical_case' not in tester.created_ids:
        tester.write("âš ï¸  Aucun cas clinique crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    case_id = tester.created_ids['clinical_case']
    tester.test_header("GET", f"/api/v1/clinical-cases/{case_id}/simple", 
                      "RÃ©cupÃ©rer un cas clinique simplifiÃ©")
    
    tester.log_request("GET", f"{API_BASE}/clinical-cases/{case_id}/simple")
    
    try:
        response = requests.get(f"{API_BASE}/clinical-cases/{case_id}/simple", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Cas clinique simplifiÃ© rÃ©cupÃ©rÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_expert_strategies_create():
    """CrÃ©e une rÃ¨gle experte"""
    tester.test_header("POST", "/api/v1/expert-strategies/", "CrÃ©er une rÃ¨gle experte")
    
    data = {
        "code_regle": f"RULE_TEST_{int(time.time())}",
        "categorie": "Diagnostic",
        "priorite": 8,
        "conditions": {
            "symptomes": ["fiÃ¨vre", "cÃ©phalÃ©e", "raideur nuque"],
            "age_min": 0
        },
        "actions": [
            {"type": "alerte", "message": "Suspicion de mÃ©ningite - Urgence"},
            {"type": "examen", "nom": "Ponction lombaire"}
        ],
        "description_naturelle": "Si fiÃ¨vre + cÃ©phalÃ©e + raideur de nuque â†’ suspecter mÃ©ningite",
        "justification_medicale": "Triade classique de la mÃ©ningite",
        "expert_auteur": "Dr. Test API",
        "date_validation": "2025-01-17",
        "est_active": True
    }
    
    tester.log_request("POST", f"{API_BASE}/expert-strategies/", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/expert-strategies/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            result = response.json()
            tester.created_ids['expert_strategy'] = result['id']
            tester.mark_success(f"RÃ¨gle experte crÃ©Ã©e avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_expert_strategies_list():
    """Liste les rÃ¨gles expertes"""
    tester.test_header("GET", "/api/v1/expert-strategies/", "Lister les rÃ¨gles expertes")
    
    params = {"skip": 0, "limit": 10}
    tester.log_request("GET", f"{API_BASE}/expert-strategies/", params=params)
    
    try:
        response = requests.get(f"{API_BASE}/expert-strategies/", params=params, timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} rÃ¨gles")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_expert_strategies_read():
    """RÃ©cupÃ¨re une rÃ¨gle experte"""
    if 'expert_strategy' not in tester.created_ids:
        tester.write("âš ï¸  Aucune rÃ¨gle experte crÃ©Ã©e, test ignorÃ©", Colors.YELLOW)
        return False
    
    strategy_id = tester.created_ids['expert_strategy']
    tester.test_header("GET", f"/api/v1/expert-strategies/{strategy_id}", 
                      "RÃ©cupÃ©rer une rÃ¨gle experte")
    
    tester.log_request("GET", f"{API_BASE}/expert-strategies/{strategy_id}")
    
    try:
        response = requests.get(f"{API_BASE}/expert-strategies/{strategy_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("RÃ¨gle experte rÃ©cupÃ©rÃ©e")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_diagnostic_engine_run():
    """ExÃ©cute le moteur de diagnostic"""
    tester.test_header("POST", "/api/v1/diagnostic-engine/run", 
                      "ExÃ©cuter le moteur de diagnostic")
    
    data = {
        "symptoms": ["fiÃ¨vre", "cÃ©phalÃ©e intense", "raideur de nuque"],
        "context": ["adulte jeune", "dÃ©but brutal"],
        "age": 25
    }
    
    tester.log_request("POST", f"{API_BASE}/diagnostic-engine/run", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/diagnostic-engine/run", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Moteur de diagnostic exÃ©cutÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_media_upload_image():
    """Upload une image mÃ©dicale fictive"""
    tester.test_header("POST", "/api/v1/media/images/upload", "Upload d'une image mÃ©dicale")
    
    # CrÃ©er une image fictive (pixel blanc 1x1)
    import io
    from PIL import Image
    
    img = Image.new('RGB', (100, 100), color='white')
    img_byte_arr = io.BytesIO()
    img.save(img_byte_arr, format='PNG')
    img_byte_arr.seek(0)
    
    files = {'file': ('test_image.png', img_byte_arr, 'image/png')}
    data = {
        'type_examen': 'Radiographie',
        'sous_type': 'Thorax',
        'description': 'Image de test API'
    }
    
    if 'disease' in tester.created_ids:
        data['pathologie_id'] = tester.created_ids['disease']
    
    tester.log_request("POST", f"{API_BASE}/media/images/upload", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/media/images/upload", 
                               files=files, data=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            result = response.json()
            tester.created_ids['image'] = result['id']
            tester.mark_success(f"Image uploadÃ©e avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_media_list_images():
    """Liste les images mÃ©dicales"""
    tester.test_header("GET", "/api/v1/media/images", "Lister les images mÃ©dicales")
    
    params = {"skip": 0, "limit": 10}
    tester.log_request("GET", f"{API_BASE}/media/images", params=params)
    
    try:
        response = requests.get(f"{API_BASE}/media/images", params=params, timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} images")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_media_read_image():
    """RÃ©cupÃ¨re les mÃ©tadonnÃ©es d'une image"""
    if 'image' not in tester.created_ids:
        tester.write("âš ï¸  Aucune image crÃ©Ã©e, test ignorÃ©", Colors.YELLOW)
        return False
    
    image_id = tester.created_ids['image']
    tester.test_header("GET", f"/api/v1/media/images/{image_id}", 
                      "RÃ©cupÃ©rer les mÃ©tadonnÃ©es d'une image")
    
    tester.log_request("GET", f"{API_BASE}/media/images/{image_id}")
    
    try:
        response = requests.get(f"{API_BASE}/media/images/{image_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("MÃ©tadonnÃ©es image rÃ©cupÃ©rÃ©es")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_chat_send_message():
    """Envoie un message dans une session de chat"""
    import uuid
    
    session_id = str(uuid.uuid4())
    tester.created_ids['chat_session'] = session_id
    
    tester.test_header("POST", f"/api/v1/chat/sessions/{session_id}/messages", 
                      "Envoyer un message dans le chat")
    
    data = {
        "sender": "Etudiant",
        "content": "Bonjour, je souhaite discuter de ce cas clinique",
        "message_metadata": {"type": "question"}
    }
    
    tester.log_request("POST", f"{API_BASE}/chat/sessions/{session_id}/messages", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                               json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 201:
            tester.mark_success("Message envoyÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_chat_get_history():
    """RÃ©cupÃ¨re l'historique d'une session de chat"""
    if 'chat_session' not in tester.created_ids:
        tester.write("âš ï¸  Aucune session de chat crÃ©Ã©e, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.created_ids['chat_session']
    tester.test_header("GET", f"/api/v1/chat/sessions/{session_id}/messages", 
                      "RÃ©cupÃ©rer l'historique du chat")
    
    tester.log_request("GET", f"{API_BASE}/chat/sessions/{session_id}/messages")
    
    try:
        response = requests.get(f"{API_BASE}/chat/sessions/{session_id}/messages", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Historique rÃ©cupÃ©rÃ©: {len(data)} messages")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


# =====================================================================
# POINT D'ENTRÃ‰E
# =====================================================================

if __name__ == "__main__":
    main()

=== Fichier: ./app/main.py ===

from fastapi import FastAPI
from .api.v1 import (
    symptoms, diseases, medications, media, clinical_cases, 
    expert_strategies, diagnostic, chat, simulation
)
# --- AJOUT ---
from .utils.logging import setup_logging

# Configurer le logging dÃ¨s le dÃ©marrage
setup_logging()
# --- FIN AJOUT ---

app = FastAPI(
    title="STI Medical Expert Module",
    description="Base de connaissances et moteur de raisonnement pour le STI mÃ©dical.",
    version="0.1.0"
)

# ... (le reste de vos `app.include_router` reste identique)
app.include_router(symptoms.router, prefix="/api/v1")
app.include_router(diseases.router, prefix="/api/v1")
app.include_router(medications.router, prefix="/api/v1")
app.include_router(media.router, prefix="/api/v1")
app.include_router(clinical_cases.router, prefix="/api/v1")
app.include_router(expert_strategies.router, prefix="/api/v1")
app.include_router(diagnostic.router, prefix="/api/v1")
app.include_router(chat.router, prefix="/api/v1")
app.include_router(simulation.router, prefix="/api/v1")

@app.get("/")
def read_root():
    return {"status": "Service is running"}

=== Fichier: ./app/core/cognitive_diagnosis.py ===



=== Fichier: ./app/core/prerequisite_graph.py ===



=== Fichier: ./app/core/prompts/exam_prompts.py ===

#=== Fichier: ./app/core/prompts/exam_prompts.py ===

import logging
import json
import datetime
from typing import Dict, Any, Optional, List

# ==============================================================================
# CONFIGURATION DU LOGGER SPÃ‰CIFIQUE
# ==============================================================================
# Ce logger est dÃ©diÃ© Ã  la construction des prompts d'examens.
# Il est configurÃ© pour Ãªtre trÃ¨s verbeux afin de tracer chaque variable injectÃ©e.
logger = logging.getLogger("exam_prompts")
logger.setLevel(logging.DEBUG)

if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter(
        '%(asctime)s - [PROMPT-BUILDER] - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)

class ExamPromptBuilder:
    """
    Classe responsable de la construction des instructions (Prompts) pour la
    gÃ©nÃ©ration de rÃ©sultats d'examens mÃ©dicaux (Biologie, Imagerie, Constantes).
    
    PRINCIPE :
    Cette classe ne gÃ©nÃ¨re pas le rÃ©sultat, elle gÃ©nÃ¨re la "recette" trÃ¨s prÃ©cise
    que le LLM devra suivre pour produire le rÃ©sultat.
    """

    def __init__(self):
        logger.info("ğŸ”§ Initialisation du ExamPromptBuilder")
        
        # Template pour les examens de Biologie (Sang, Urine, LCR...)
        self.BIOLOGY_TEMPLATE = """
TU ES UN AUTOMATE DE LABORATOIRE D'ANALYSES MÃ‰DICALES DE HAUTE PRÃ‰CISION.
Ton rÃ´le est de gÃ©nÃ©rer un rapport d'analyse biologique structurÃ©.

--- CONTEXTE PATIENT (DONNÃ‰ES PROTEGÃ‰ES) ---
Sexe : {sexe}
Ã‚ge : {age}
Pathologie RÃ©elle (Inconnue de l'Ã©tudiant) : {pathologie_nom}
GravitÃ© : {gravite}/5

--- VÃ‰RITÃ‰ TERRAIN (DONNÃ‰ES BRUTES DU CAS) ---
Voici les anomalies biologiques rÃ©ellement prÃ©sentes chez ce patient.
Tu DOIS impÃ©rativement inclure ces valeurs dans ton rapport si l'examen demandÃ© les couvre.
{donnees_cachees_json}

--- DEMANDE DE L'Ã‰TUDIANT ---
Examen demandÃ© : "{nom_examen}"
Justification fournie : "{justification}"

--- ALGORITHME DE GÃ‰NÃ‰RATION (RÃˆGLES ABSOLUES) ---
1. PERTINENCE : L'examen demandÃ© couvre-t-il les anomalies listÃ©es dans la "VÃ‰RITÃ‰ TERRAIN" ?
   - OUI : GÃ©nÃ¨re un rapport montrant ces anomalies prÃ©cises (chiffres anormaux, rouge, gras).
   - NON : GÃ©nÃ¨re un rapport STRICTEMENT NORMAL pour cet examen. Ne pas inventer de pathologie.

2. STYLE : Utilise un format technique professionnel (ParamÃ¨tre | Valeur | UnitÃ© | Normes).
   - Pour une NFS : HÃ©maties, Hb, VGM, TCMH, Plaquettes, Leucocytes...
   - Pour un Ionogramme : Na+, K+, Cl-, RÃ©serves alcalines...
   - Pour CRP : Valeur numÃ©rique.

3. COHÃ‰RENCE : 
   - Si le patient est infectÃ© (selon la pathologie), les marqueurs infectieux (CRP, Leucocytes) doivent Ãªtre cohÃ©rents.
   - Si le patient anÃ©mique, l'hÃ©moglobine doit Ãªtre basse.

4. FORMAT DE SORTIE : JSON STRICT.
{{
  "type_resultat": "biologie",
  "valeurs_cles": {{ "Nom ParamÃ¨tre": "Valeur + UnitÃ©" }},  <-- RÃ©sumÃ© des 3-4 valeurs les plus importantes
  "rapport_complet": "Le texte complet du rapport avec tableau des valeurs...",
  "conclusion": "Conclusion courte du biologiste (ex: 'Syndrome inflammatoire biologique', 'Bilan normal')."
}}
"""

        # Template pour l'Imagerie (Radio, Scanner, IRM, Ã‰cho)
        self.IMAGING_TEMPLATE = """
TU ES UN RADIOLOGUE EXPERT (Senior).
Ton rÃ´le est de rÃ©diger le compte-rendu d'un examen d'imagerie.

--- CONTEXTE PATIENT ---
Sexe : {sexe}
Ã‚ge : {age}
Pathologie RÃ©elle : {pathologie_nom}

--- VÃ‰RITÃ‰ TERRAIN (IMAGERIE) ---
Anomalies visuelles thÃ©oriques associÃ©es Ã  cette pathologie :
{description_lesions}

DonnÃ©es spÃ©cifiques ce cas (si disponibles) :
{donnees_cachees_json}

--- DEMANDE ---
Examen : "{nom_examen}"
Justification : "{justification}"

--- ALGORITHME DE GÃ‰NÃ‰RATION ---
1. PERTINENCE : Cet examen peut-il voir la pathologie ? 
   (Ex: Une Radio Thorax VOIT une pneumonie, mais NE VOIT PAS une mÃ©ningite).
   - SI VISIBLE : DÃ©cris les lÃ©sions typiques de la pathologie (opacitÃ©s, fractures, Ã©panchement...).
   - SI INVISIBLE ou HORS ZONE : RÃ©dige un compte-rendu NORMAL (ex: "Transparence pulmonaire normale").

2. STYLE :
   - Technique, descriptif, anatomique.
   - Utilise des termes comme "OpacitÃ©", "HyperclartÃ©", "Hypersignal", "Echostructure".
   - Structure : Indication -> Technique -> RÃ©sultats -> Conclusion.

3. FORMAT DE SORTIE : JSON STRICT.
{{
  "type_resultat": "imagerie",
  "zone_etudiee": "ex: Thorax",
  "protocole": "ex: Incidence face et profil",
  "rapport_complet": "Description dÃ©taillÃ©e...",
  "conclusion": "Conclusion du radiologue (ex: 'Image en faveur d'une pneumopathie lobaire infÃ©rieure droite')."
}}
"""

        # Template gÃ©nÃ©rique (Constantes, ECG, etc.)
        self.GENERIC_TEMPLATE = """
TU ES UN APPAREIL MÃ‰DICAL OU UN INFIRMIER.
TÃ¢che : Fournir le rÃ©sultat de : "{nom_examen}".

CONTEXTE PATIENT : {pathologie_nom}, GravitÃ© {gravite}/5.
DONNÃ‰ES PHYSIOLOGIQUES RÃ‰ELLES : 
{donnees_cachees_json}

CONSIGNE :
GÃ©nÃ¨re des valeurs rÃ©alistes. 
Si l'examen est "Constantes" ou "Vitaux", fournis : TA, FC, FR, SpO2, Temp.
Si l'examen est "ECG", dÃ©cris le rythme et les ondes.

FORMAT DE SORTIE : JSON STRICT.
{{
  "type_resultat": "autre",
  "rapport_complet": "Liste des valeurs ou description...",
  "conclusion": "SynthÃ¨se rapide."
}}
"""

    def build_prompt(
        self, 
        case_data: Dict[str, Any], 
        exam_request: Dict[str, str],
        patient_persona: Dict[str, Any]
    ) -> str:
        """
        Construit le prompt final en choisissant le bon template et en injectant les donnÃ©es.
        
        :param case_data: Dictionnaire contenant 'pathologie', 'donnees_paracliniques', etc.
        :param exam_request: Dictionnaire {'name': '...', 'type': '...', 'justification': '...'}
        :param patient_persona: Dictionnaire {'age': '...', 'genre': '...'}
        """
        request_id = f"PRMPT-{id(exam_request) % 10000}"
        logger.info(f"ğŸ”¨ [{request_id}] Construction du prompt pour : {exam_request.get('name')}")

        # 1. Analyse du type d'examen pour choisir le template
        exam_name = exam_request.get('name', '').lower()
        exam_type = exam_request.get('type', '').lower() # ex: 'biologie', 'imagerie'
        
        template_to_use = self.GENERIC_TEMPLATE
        template_name = "GENERIC"

        # DÃ©tection heuristique si le type n'est pas explicite
        if 'bio' in exam_type or 'sang' in exam_name or 'nfs' in exam_name or 'crp' in exam_name or 'urine' in exam_name:
            template_to_use = self.BIOLOGY_TEMPLATE
            template_name = "BIOLOGY"
        elif 'image' in exam_type or 'radio' in exam_name or 'scanner' in exam_name or 'irm' in exam_name or 'echo' in exam_name:
            template_to_use = self.IMAGING_TEMPLATE
            template_name = "IMAGING"
        
        logger.debug(f"   [{request_id}] Template sÃ©lectionnÃ© : {template_name}")

        # 2. PrÃ©paration des donnÃ©es d'injection (Data Cleaning)
        # On s'assure que les donnÃ©es ne sont jamais 'None' pour Ã©viter les crashs de formatage
        
        pathologie_nom = case_data.get('pathologie_principale', {}).get('nom_fr', 'Pathologie indÃ©terminÃ©e')
        gravite = case_data.get('niveau_gravite', 3)
        
        # DonnÃ©es cachÃ©es (C'est le trÃ©sor !)
        # On va chercher dans 'donnees_paracliniques' qui est un JSON en BDD
        hidden_data = case_data.get('donnees_paracliniques', {})
        if not hidden_data:
            hidden_data = {"note": "Aucune donnÃ©e spÃ©cifique prÃ©-enregistrÃ©e. Improviser selon la pathologie."}
        
        hidden_data_str = json.dumps(hidden_data, ensure_ascii=False, indent=2)
        
        # Pour l'imagerie, on essaie d'extraire des infos spÃ©cifiques sur les lÃ©sions
        description_lesions = "LÃ©sions classiques associÃ©es Ã  cette pathologie."
        if template_name == "IMAGING":
            # On regarde si on a une description dans le cas
            desc = case_data.get('description', '')
            physio = case_data.get('physiopathologie', '')
            description_lesions = f"Base physiopathologique : {physio}\nContexte : {desc}"

        logger.debug(f"   [{request_id}] Injection des donnÃ©es : Patho='{pathologie_nom}', GravitÃ©={gravite}")
        logger.debug(f"   [{request_id}] DonnÃ©es cachÃ©es injectÃ©es (taille) : {len(hidden_data_str)} chars")

        # 3. Formatage final
        try:
            final_prompt = template_to_use.format(
                sexe=patient_persona.get('genre', 'Non spÃ©cifiÃ©'),
                age=patient_persona.get('age', 'Non spÃ©cifiÃ©'),
                pathologie_nom=pathologie_nom,
                gravite=gravite,
                donnees_cachees_json=hidden_data_str,
                nom_examen=exam_request.get('name', 'Examen inconnu'),
                justification=exam_request.get('justification', 'Aucune justification'),
                # Arguments spÃ©cifiques aux templates (on utilise **kwargs style ou defaults)
                description_lesions=description_lesions 
            )
            
            logger.info(f"   âœ… [{request_id}] Prompt construit avec succÃ¨s ({len(final_prompt)} chars).")
            
            # LOG DU PROMPT COMPLET (Pour le debug expert)
            logger.debug(f"\n{'='*20} [{request_id}] CONTENU DU PROMPT {'='*20}")
            logger.debug(final_prompt)
            logger.debug(f"{'='*60}\n")
            
            return final_prompt

        except KeyError as e:
            logger.error(f"   âŒ [{request_id}] Erreur de formatage du template : ClÃ© manquante {e}")
            # Fallback de secours
            return f"GÃ©nÃ¨re un rÃ©sultat pour l'examen {exam_name} concernant un patient atteint de {pathologie_nom}."
        except Exception as e:
            logger.error(f"   âŒ [{request_id}] Erreur inattendue : {str(e)}")
            raise e

# Instance Singleton pour utilisation directe
exam_prompt_builder = ExamPromptBuilder()

=== Fichier: ./app/core/prompts/tutor_prompts.py ===

#=== Fichier: ./app/core/prompts/tutor_prompts.py ===

import logging
import json
import uuid
from typing import Dict, Any, List, Optional
from datetime import datetime

# ==============================================================================
# CONFIGURATION DU LOGGER "PROMPT-TUTOR"
# ==============================================================================
# Ce logger est dÃ©diÃ© Ã  la construction des prompts du Tuteur.
# Il permet de vÃ©rifier que le contexte pÃ©dagogique est correctement assemblÃ©.
logger = logging.getLogger("tutor_prompts")
logger.setLevel(logging.DEBUG)

if not logger.handlers:
    handler = logging.StreamHandler()
    # Format incluant le fichier et la ligne pour un dÃ©bogage rapide
    formatter = logging.Formatter(
        '%(asctime)s - [PROMPT-TUTOR] - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)

class TutorPromptBuilder:
    """
    Classe responsable de la construction des instructions (Prompts) pour l'IA Tuteur.
    
    RÃ”LE :
    Transformer une interaction brute (Question Ã‰tudiant / RÃ©ponse Patient) en un
    problÃ¨me pÃ©dagogique structurÃ© que le LLM peut rÃ©soudre.
    
    PRINCIPES :
    1. Contextualisation : Le Tuteur doit connaÃ®tre la pathologie rÃ©elle pour juger.
    2. PÃ©dagogie : Le Tuteur ne doit pas donner la rÃ©ponse, mais guider la mÃ©thode.
    3. Robustesse : Le format de sortie JSON est forcÃ© par des exemples stricts.
    """

    def __init__(self):
        logger.info("ğŸ”§ Initialisation du TutorPromptBuilder")
        
        # Template principal pour l'analyse pÃ©dagogique
        # ConÃ§u pour forcer l'IA Ã  rÃ©flÃ©chir en 3 temps (MÃ©thode -> InterprÃ©tation -> Correction)
        self.PEDAGOGICAL_ANALYSIS_TEMPLATE = """
TU ES UN PROFESSEUR DE MÃ‰DECINE CHEVRONNÃ‰ (SUPERVISEUR CLINIQUE).
Ton rÃ´le est d'analyser en temps rÃ©el l'interaction entre un Ã©tudiant en mÃ©decine et un patient simulÃ©.
Tu dois fournir un feedback pÃ©dagogique immÃ©diat, bienveillant mais rigoureux.

--- 1. LE CONTEXTE CLINIQUE (VÃ‰RITÃ‰ TERRAIN - CACHÃ‰E Ã€ L'Ã‰TUDIANT) ---
Pathologie rÃ©elle : {pathologie_nom}
RÃ©sumÃ© du cas : {resume_cas}
Phase thÃ©orique actuelle de la consultation : {phase_courante} (ex: AnamnÃ¨se, Examen Physique...)

--- 2. L'INTERACTION Ã€ ANALYSER ---
DERNIÃˆRE QUESTION DE L'Ã‰TUDIANT :
"{question_etudiant}"

RÃ‰PONSE OBTENUE DU PATIENT :
"{reponse_patient}"

--- 3. TA MISSION (ANALYSE PÃ‰DAGOGIQUE) ---
Analyse cet Ã©change selon 3 axes et remplis le JSON ci-dessous.

AXE A : MÃ‰THODOLOGIE (Chronologie & Pertinence)
- La question est-elle posÃ©e au bon moment ? (ex: Ne pas demander des examens avant d'avoir fini l'interrogatoire).
- La question est-elle pertinente pour suspecter/Ã©liminer la pathologie rÃ©elle ?
- Si l'Ã©tudiant saute des Ã©tapes, signale-le.

AXE B : INTERPRÃ‰TATION (SÃ©miologie)
- Analyse la rÃ©ponse du patient. Quels sont les signes cliniques clÃ©s (SÃ©miologie) prÃ©sents dans sa rÃ©ponse ?
- Explique ce que l'Ã©tudiant doit dÃ©duire de cette rÃ©ponse.

AXE C : CORRECTION (L'Exemple)
- Quelle question aurais-tu posÃ©e Ã  sa place pour Ãªtre plus efficace, plus empathique ou plus prÃ©cis ?
- Formule cette question idÃ©ale entre guillemets.

--- 4. FORMAT DE SORTIE OBLIGATOIRE (JSON) ---
Tu dois rÃ©pondre UNIQUEMENT avec un objet JSON valide. Pas de texte avant ou aprÃ¨s.

{{
  "chronology_check": "Analyse critique de la mÃ©thode (1 phrase). Indique si c'est 'PrÃ©maturÃ©', 'Pertinent' ou 'Hors sujet'.",
  "interpretation_guide": "Guide de lecture de la rÃ©ponse du patient. Mets en gras les symptÃ´mes clÃ©s.",
  "better_question": "La question que le professeur aurait posÃ©e."
}}
"""

    def build_feedback_prompt(
        self, 
        case_data: Dict[str, Any], 
        student_msg: str,
        patient_msg: str,
        chat_history_count: int
    ) -> str:
        """
        Construit le prompt complet pour l'analyse pÃ©dagogique.
        
        :param case_data: DonnÃ©es du cas clinique (Pathologie, Description).
        :param student_msg: Le texte envoyÃ© par l'Ã©tudiant.
        :param patient_msg: Le texte rÃ©pondu par le patient (IA).
        :param chat_history_count: Nombre de messages prÃ©cÃ©dents (pour estimer la phase).
        :return: Le prompt formatÃ© prÃªt Ã  Ãªtre envoyÃ© au LLM.
        """
        # ID de trace pour suivre la construction de ce prompt spÃ©cifique dans les logs
        trace_id = f"PRMPT-{str(uuid.uuid4())[:8]}"
        
        logger.info(f"ğŸ”¨ [{trace_id}] DÃ‰BUT construction prompt TUTEUR")
        logger.debug(f"   [{trace_id}] Input Ã‰tudiant : '{student_msg[:50]}...'")
        logger.debug(f"   [{trace_id}] Input Patient  : '{patient_msg[:50]}...'")

        try:
            # 1. Extraction et nettoyage des donnÃ©es du cas
            # -----------------------------------------------------------------
            pathologie_nom = self._safe_get(case_data, 'pathologie_principale.nom_fr', 'Pathologie non spÃ©cifiÃ©e')
            
            # Construction d'un rÃ©sumÃ© contextuel Ã  partir des donnÃ©es brutes
            histoire = self._safe_get(case_data, 'presentation_clinique.histoire_maladie', '')
            
            # On logue les donnÃ©es sensibles (VÃ©ritÃ© Terrain) pour le debug
            logger.debug(f"   [{trace_id}] Contexte VÃ©ritÃ© : Patho='{pathologie_nom}'")

            # 2. Estimation de la phase de consultation
            # -----------------------------------------------------------------
            # Heuristique simple basÃ©e sur le nombre d'Ã©changes
            # 0-4 messages : Accueil / Motif
            # 5-15 messages : AnamnÃ¨se dÃ©taillÃ©e
            # >15 messages : Examen physique / Conclusion
            phase = "IndÃ©terminÃ©e"
            if chat_history_count < 4:
                phase = "DÃ©but de consultation / Accueil / Motif"
            elif chat_history_count < 16:
                phase = "AnamnÃ¨se (Histoire de la maladie & AntÃ©cÃ©dents)"
            else:
                phase = "Examen Clinique ou SynthÃ¨se"
            
            logger.debug(f"   [{trace_id}] Phase estimÃ©e : {phase} (Msg count: {chat_history_count})")

            # 3. Assemblage du Prompt
            # -----------------------------------------------------------------
            final_prompt = self.PEDAGOGICAL_ANALYSIS_TEMPLATE.format(
                pathologie_nom=pathologie_nom,
                resume_cas=histoire[:500] + "..." if len(histoire) > 500 else histoire,
                phase_courante=phase,
                question_etudiant=student_msg,
                reponse_patient=patient_msg
            )

            # 4. Validation et Logging final
            # -----------------------------------------------------------------
            prompt_length = len(final_prompt)
            logger.info(f"   âœ… [{trace_id}] Prompt TUTEUR construit avec succÃ¨s ({prompt_length} chars).")
            
            # DUMP DU PROMPT COMPLET (Niveau DEBUG)
            # C'est ici qu'on vÃ©rifie si l'IA a toutes les infos pour bien juger.
            logger.debug(f"\n{'='*20} [{trace_id}] CONTENU DU PROMPT TUTEUR {'='*20}")
            logger.debug(final_prompt)
            logger.debug(f"{'='*60}\n")
            
            return final_prompt

        except Exception as e:
            logger.error(f"   âŒ [{trace_id}] Erreur critique construction prompt : {str(e)}")
            import traceback
            logger.debug(traceback.format_exc())
            # En cas d'erreur, on retourne un prompt de secours minimaliste
            return self._get_fallback_prompt(student_msg, patient_msg)

    def _safe_get(self, data: Dict, path: str, default: Any = None) -> Any:
        """
        RÃ©cupÃ¨re une valeur dans un dictionnaire imbriquÃ© via une chaÃ®ne pointÃ©e.
        Ex: 'pathologie_principale.nom_fr'
        """
        keys = path.split('.')
        current = data
        try:
            for key in keys:
                if isinstance(current, dict):
                    current = current.get(key, {})
                else:
                    return default
            
            # Si le rÃ©sultat final est un dict vide (valeur par dÃ©faut de .get()), 
            # et que ce n'Ã©tait pas la valeur attendue, on renvoie default.
            if current == {} and default is not None:
                return default
            # Si current est un string/int/list valide
            return current if current else default
        except Exception:
            return default

    def _get_fallback_prompt(self, q: str, r: str) -> str:
        """Prompt de secours minimaliste en cas d'erreur de parsing des donnÃ©es complexes."""
        logger.warning("   âš ï¸ Utilisation du prompt de secours (Fallback).")
        return f"""
Analyse pÃ©dagogique rapide.
Question: "{q}"
RÃ©ponse: "{r}"
Donne un feedback JSON: {{ "chronology_check": "...", "interpretation_guide": "...", "better_question": "..." }}
"""

# ==============================================================================
# SINGLETON
# ==============================================================================
# Instance unique prÃªte Ã  Ãªtre importÃ©e dans les services
tutor_prompt_builder = TutorPromptBuilder()

=== Fichier: ./app/core/htn_planner.py ===



=== Fichier: ./app/core/integrity_validator.py ===



=== Fichier: ./app/core/__init__.py ===



=== Fichier: ./app/core/q_matrix_solver.py ===



=== Fichier: ./app/core/reasoning_engine.py ===

from typing import List, Dict, Any

def evaluate_condition(condition: Dict[str, Any], facts: Dict[str, Any]) -> bool:
    """
    Ã‰value une seule condition par rapport Ã  un ensemble de faits.
    Version trÃ¨s simple pour commencer.
    """
    fact_type = condition.get("fact")
    fact_value = condition.get("value")
    operator = condition.get("operator")

    if fact_type == "symptom" and operator == "present":
        return fact_value in facts.get("symptoms", [])
    
    if fact_type == "context" and operator == "is":
        return fact_value in facts.get("context", [])
    
    # Ajouter d'autres logiques d'Ã©valuation ici plus tard (ex: age > 65)
    
    return False


def forward_chaining_engine(rules: List[Dict[str, Any]], facts: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Moteur de raisonnement simple en chaÃ®nage avant.

    :param rules: Une liste de rÃ¨gles, oÃ¹ chaque rÃ¨gle est un dictionnaire
                  avec les clÃ©s 'conditions' et 'actions'.
    :param facts: Un dictionnaire reprÃ©sentant les faits connus sur le patient
                  (ex: {"symptoms": ["FiÃ¨vre", "Toux"], "context": ["zone_endemique"]}).
    :return: Une liste de toutes les actions des rÃ¨gles qui ont Ã©tÃ© dÃ©clenchÃ©es.
    """
    triggered_actions = []

    for rule in rules:
        conditions = rule.get("conditions", {})
        
        # Pour l'instant, nous ne gÃ©rons que l'opÃ©rateur "AND"
        if conditions.get("operator") == "AND":
            all_conditions_met = True
            for condition in conditions.get("rules", []):
                if not evaluate_condition(condition, facts):
                    all_conditions_met = False
                    break  # Inutile de vÃ©rifier les autres conditions de cette rÃ¨gle
            
            if all_conditions_met:
                # Toutes les conditions sont remplies, on ajoute les actions
                triggered_actions.extend(rule.get("actions", []))

    return triggered_actions

"""""
# Ajoutez ce bloc Ã  la fin du fichier pour tester
if __name__ == "__main__":
    # DÃ©finir une rÃ¨gle de test (copiÃ©e de notre exemple prÃ©cÃ©dent)
    test_rule = {
        "code_regle": "DIAG_PALU_SIMPLE_01",
        "conditions": {
            "operator": "AND",
            "rules": [
                {"fact": "symptom", "value": "FiÃ¨vre", "operator": "present"},
                {"fact": "context", "value": "zone_endemique", "operator": "is"}
            ]
        },
        "actions": [
            {"action": "add_hypothesis", "pathology": "Paludisme simple", "confidence": 0.7}
        ]
    }
    
    # DÃ©finir des faits qui devraient dÃ©clencher la rÃ¨gle
    patient_facts = {
        "symptoms": ["FiÃ¨vre", "Toux"],
        "context": ["zone_endemique"]
    }
    
    print("Test du moteur de raisonnement...")
    conclusions = forward_chaining_engine(rules=[test_rule], facts=patient_facts)
    
    print(f"Faits: {patient_facts}")
    print(f"RÃ¨gles: {[test_rule['code_regle']]}")
    print(f"Conclusions: {conclusions}")
    
    # VÃ©rification du test
    assert len(conclusions) == 1
    assert conclusions[0]['pathology'] == 'Paludisme simple'
    print("\nâœ… Test rÃ©ussi !")
    
    """

=== Fichier: ./app/core/knowledge_graph.py ===



=== Fichier: ./app/ml/embeddings.py ===



=== Fichier: ./app/ml/__init__.py ===



=== Fichier: ./app/ml/clustering.py ===



=== Fichier: ./app/ml/recommendation.py ===



=== Fichier: ./app/ml/similarity.py ===



=== Fichier: ./app/schemas/symptom.py ===

from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from datetime import datetime

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class SymptomBase(BaseModel):
    """
    SchÃ©ma de base pour un symptÃ´me.
    Contient les champs communs Ã  la crÃ©ation et Ã  la lecture.
    """
    nom: str
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    type_symptome: Optional[str] = None
    description: Optional[str] = None
    questions_anamnese: Optional[Dict[str, Any]] = None
    signes_alarme: bool = False


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation (ce que l'API attend dans un POST)
# ==============================================================================
class SymptomCreate(SymptomBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau symptÃ´me via l'API.
    HÃ©rite de SymptomBase et n'ajoute aucun champ supplÃ©mentaire pour l'instant.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour (ce que l'API attend dans un PATCH)
# ==============================================================================
class SymptomUpdate(BaseModel):
    """
    SchÃ©ma utilisÃ© pour mettre Ã  jour un symptÃ´me existant.
    Tous les champs sont optionnels pour permettre des mises Ã  jour partielles.
    """
    nom: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    type_symptome: Optional[str] = None
    description: Optional[str] = None
    questions_anamnese: Optional[Dict[str, Any]] = None
    signes_alarme: Optional[bool] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class Symptom(SymptomBase):
    """
    SchÃ©ma complet pour reprÃ©senter un symptÃ´me, y compris les champs
    gÃ©nÃ©rÃ©s par la base de donnÃ©es comme 'id' et 'created_at'.
    Ce sera le modÃ¨le de rÃ©ponse de l'API.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        """
        Configuration pour Pydantic.
        'from_attributes = True' (anciennement 'orm_mode') permet au modÃ¨le Pydantic
        de lire les donnÃ©es directement depuis un objet SQLAlchemy.
        C'est le lien magique entre notre modÃ¨le de BDD et notre schÃ©ma d'API.
        """
        from_attributes = True

=== Fichier: ./app/schemas/medication.py ===

from pydantic import BaseModel
from typing import Optional, Dict, Any
from datetime import datetime

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class MedicationBase(BaseModel):
    """
    SchÃ©ma de base pour un mÃ©dicament, contenant les champs modifiables.
    """
    dci: str
    nom_commercial: Optional[str] = None
    classe_therapeutique: Optional[str] = None
    forme_galenique: Optional[str] = None
    dosage: Optional[str] = None
    voie_administration: Optional[str] = None
    mecanisme_action: Optional[str] = None
    indications: Optional[Dict[str, Any]] = None
    contre_indications: Optional[Dict[str, Any]] = None
    effets_secondaires: Optional[Dict[str, Any]] = None
    interactions_medicamenteuses: Optional[Dict[str, Any]] = None
    precautions_emploi: Optional[str] = None
    posologie_standard: Optional[Dict[str, Any]] = None
    disponibilite_cameroun: Optional[str] = None
    cout_moyen_fcfa: Optional[int] = None
    statut_prescription: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation
# ==============================================================================
class MedicationCreate(MedicationBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau mÃ©dicament.
    'dci' est le seul champ strictement requis.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour
# ==============================================================================
class MedicationUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'un mÃ©dicament.
    """
    dci: Optional[str] = None
    nom_commercial: Optional[str] = None
    classe_therapeutique: Optional[str] = None
    # ... (tous les autres champs de MedicationBase en optionnel)
    forme_galenique: Optional[str] = None
    dosage: Optional[str] = None
    voie_administration: Optional[str] = None
    mecanisme_action: Optional[str] = None
    indications: Optional[Dict[str, Any]] = None
    contre_indications: Optional[Dict[str, Any]] = None
    effets_secondaires: Optional[Dict[str, Any]] = None
    interactions_medicamenteuses: Optional[Dict[str, Any]] = None
    precautions_emploi: Optional[str] = None
    posologie_standard: Optional[Dict[str, Any]] = None
    disponibilite_cameroun: Optional[str] = None
    cout_moyen_fcfa: Optional[int] = None
    statut_prescription: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (RÃ©ponse API)
# ==============================================================================
class Medication(MedicationBase):
    """
    SchÃ©ma complet pour reprÃ©senter un mÃ©dicament en rÃ©ponse d'API.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

=== Fichier: ./app/schemas/clinical_case.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date
from decimal import Decimal

# Importer les autres schÃ©mas pour les rÃ©ponses imbriquÃ©es
from .disease import Disease
from .media import ImageMedicale
from .symptom import Symptom






# --- NOUVEAUX SOUS-SCHÃ‰MAS ---
class SymptomInCase(BaseModel):
    symptome_id: int
    details: str # Ex: "FiÃ¨vre Ã©levÃ©e (40Â°C) apparue brutalement il y a 48h"

class PresentationClinique(BaseModel):
    histoire_maladie: str
    symptomes_patient: List[SymptomInCase]
    antecedents: Optional[Dict[str, Any]] = None
# ==============================================================================
# SchÃ©ma de Base et de CrÃ©ation
# ==============================================================================
class ClinicalCaseBase(BaseModel):
    """
    SchÃ©ma de base pour un cas clinique, contenant les champs Ã©ditables.
    """
    code_fultang: str = Field(..., description="Identifiant unique (Fultang ou synthÃ©tique)")
    pathologie_principale_id: Optional[int] = None
    pathologies_secondaires_ids: Optional[List[int]] = []
    presentation_clinique: PresentationClinique
    donnees_paracliniques: Optional[Dict[str, Any]] = None
    evolution_patient: Optional[str] = None
    images_associees_ids: Optional[List[int]] = []
    sons_associes_ids: Optional[List[int]] = []
    medicaments_prescrits: Optional[List[Dict[str, Any]]] = []
    niveau_difficulte: int = Field(default=3, ge=1, le=101)
    duree_estimee_resolution_min: Optional[int] = None
    objectifs_apprentissage: Optional[List[str]] = []
    competences_requises: Optional[Dict[str, Any]] = {}


class ClinicalCaseCreate(ClinicalCaseBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau cas clinique via l'API.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour
# ==============================================================================
class ClinicalCaseUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'un cas clinique.
    """
    code_fultang: Optional[str] = None
    pathologie_principale_id: Optional[int] = None
    presentation_clinique: Optional[Dict[str, Any]] = None
    donnees_paracliniques: Optional[Dict[str, Any]] = None
    evolution_patient: Optional[str] = None
    images_associees_ids: Optional[List[int]] = None
    sons_associes_ids: Optional[List[int]] = None
    medicaments_prescrits: Optional[List[Dict[str, Any]]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=101)
    duree_estimee_resolution_min: Optional[int] = None
    objectifs_apprentissage: Optional[List[str]] = None
    competences_requises: Optional[Dict[str, Any]] = None
    valide_expert: Optional[bool] = None
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# SchÃ©mas pour la Lecture (RÃ©ponse API)
# ==============================================================================
class ClinicalCaseSimple(BaseModel):
    """
    SchÃ©ma simplifiÃ© pour les listes de cas cliniques.
    """
    id: int
    code_fultang: str
    niveau_difficulte: int
    pathologie_principale: Optional[Disease] = None # Affiche l'objet maladie complet
    nb_images: int
    nb_sons: int

    class Config:
        from_attributes = True


# --- NOUVEAU SCHÃ‰MA DE LECTURE ENRICHI ---
class SymptomDetailInCase(BaseModel):
    symptome: Symptom # L'objet symptÃ´me complet
    details: str # Les dÃ©tails spÃ©cifiques au cas

class PresentationCliniqueDetail(BaseModel):
    histoire_maladie: str
    symptomes_patient: List[SymptomDetailInCase]
    antecedents: Optional[Dict[str, Any]] = None


class ClinicalCase(ClinicalCaseBase):
    id: int
    created_at: datetime
    updated_at: datetime
    
    pathologie_principale: Optional[Disease] = None
    pathologies_secondaires: List[Disease] = [] # <- AJOUTER
    images_associees: List[ImageMedicale] = []
    
    # --- ENRICHISSEMENT DE LA PRÃ‰SENTATION CLINIQUE ---
    presentation_clinique_detail: Optional[PresentationCliniqueDetail] = None

    class Config:
        from_attributes = True



=== Fichier: ./app/schemas/relations.py ===

from pydantic import BaseModel, Field
from typing import Any, Dict, Optional
from decimal import Decimal

# Importer les schÃ©mas de base pour l'affichage
from .symptom import Symptom
from .disease import Disease
from .medication import Medication


# ==============================================================================
# SchÃ©ma de Base et de CrÃ©ation pour l'Association
# ==============================================================================
class PathologieSymptomeBase(BaseModel):
    """
    SchÃ©ma de base pour l'association Pathologie-SymptÃ´me.
    Contient les champs nÃ©cessaires pour crÃ©er ou mettre Ã  jour le lien.
    """
    pathologie_id: int
    symptome_id: int
    probabilite: Optional[Decimal] = Field(None, ge=0, le=1)
    sensibilite: Optional[Decimal] = Field(None, ge=0, le=1)
    specificite: Optional[Decimal] = Field(None, ge=0, le=1)
    phase_maladie: Optional[str] = None
    frequence: Optional[str] = None
    est_pathognomonique: bool = False
    importance_diagnostique: Optional[int] = Field(None, ge=1, le=5)

class PathologieSymptomeCreate(PathologieSymptomeBase):
    """
    SchÃ©ma utilisÃ© spÃ©cifiquement pour crÃ©er une nouvelle association.
    """
    pass


# ==============================================================================
# SchÃ©mas pour la Lecture (RÃ©ponse de l'API)
# ==============================================================================
class PathologieSymptome(PathologieSymptomeBase):
    """
    SchÃ©ma complet pour la rÃ©ponse de l'API, incluant l'ID de l'association.
    """
    id: int

    class Config:
        from_attributes = True


class SymptomForDiseaseDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'un symptÃ´me DANS le contexte d'une pathologie.
    """
    symptome: Symptom
    probabilite: Optional[Decimal]
    importance_diagnostique: Optional[int]
    est_pathognomonique: bool

    class Config:
        from_attributes = True


class DiseaseForSymptomDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'une pathologie DANS le contexte d'un symptÃ´me
    (utile pour le diagnostic diffÃ©rentiel).
    """
    pathologie: Disease
    probabilite: Optional[Decimal]
    importance_diagnostique: Optional[int]

    class Config:
        from_attributes = True



# Contenu Ã  AJOUTER Ã  la fin de app/schemas/relations.py

# Importer le schÃ©ma de base pour l'affichage


# ==============================================================================
# SchÃ©mas pour l'Association Traitement-Pathologie
# ==============================================================================
class TraitementPathologieBase(BaseModel):
    pathologie_id: int
    medicament_id: int
    type_traitement: Optional[str] = None
    ligne_traitement: Optional[int] = None
    indication_precise: Optional[str] = None
    efficacite_taux: Optional[Decimal] = Field(None, ge=0, le=100)
    duree_traitement_jours: Optional[int] = None
    posologie_detaillee: Optional[Dict[str, Any]] = None
    niveau_preuve: Optional[str] = None
    guidelines_source: Optional[str] = None
    rang_preference: Optional[int] = 99

class TraitementPathologieCreate(TraitementPathologieBase):
    pass

class TraitementPathologie(TraitementPathologieBase):
    id: int
    class Config:
        from_attributes = True

class MedicationForDiseaseDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'un mÃ©dicament DANS le contexte d'une pathologie.
    """
    medicament: Medication
    type_traitement: Optional[str]
    ligne_traitement: Optional[int]
    rang_preference: Optional[int]
    
    class Config:
        from_attributes = True

# ==============================================================================
# SchÃ©mas pour l'Association Traitement-SymptÃ´me
# ==============================================================================
class TraitementSymptomeBase(BaseModel):
    symptome_id: int
    medicament_id: int
    efficacite: Optional[str] = None
    rapidite_action: Optional[str] = None
    posologie_recommandee: Optional[str] = None
    rang_preference: Optional[int] = 99

class TraitementSymptomeCreate(TraitementSymptomeBase):
    pass

class TraitementSymptome(TraitementSymptomeBase):
    id: int
    class Config:
        from_attributes = True

class MedicationForSymptomDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'un mÃ©dicament DANS le contexte d'un symptÃ´me.
    """
    medicament: Medication
    efficacite: Optional[str]
    rang_preference: Optional[int]

    class Config:
        from_attributes = True

=== Fichier: ./app/schemas/tracking_models.py ===



=== Fichier: ./app/schemas/__init__.py ===

# ==============================================================================
# FICHIER D'INITIALISATION DU PACKAGE 'schemas'
# ------------------------------------------------------------------------------
# Ce fichier a deux rÃ´les principaux :
# 1. Il signale Ã  Python que le dossier 'schemas' est un "package", c'est-Ã -dire
#    un ensemble de modules qui peuvent Ãªtre importÃ©s.
# 2. Il dÃ©finit ce qui est accessible publiquement lorsque l'on importe 'schemas'.
#    C'est le "hall d'entrÃ©e" du package.
# ==============================================================================

# --- IMPORTS EXISTANTS (validÃ©s) ---
# Chaque ligne rend des classes spÃ©cifiques directement accessibles
# depuis le package 'schemas'.
# Exemple : `from app import schemas` puis `schemas.Symptom`

from .symptom import SymptomCreate, SymptomBase, SymptomUpdate, Symptom
from .disease import DiseaseCreate, DiseaseBase, DiseaseUpdate, Disease
from .medication import MedicationCreate, MedicationBase, MedicationUpdate, Medication
from .media import ImageMedicaleBase, ImageMedicaleUpdate, ImageMedicale
from .clinical_case import ClinicalCaseCreate, ClinicalCaseBase, ClinicalCaseUpdate, ClinicalCase
from .expert_strategy import ExpertStrategyCreate, ExpertStrategyBase, ExpertStrategyUpdate, ExpertStrategy

# --- NOUVEAUX IMPORTS (pour corriger les erreurs) ---

# 1. CORRECTION POUR 'chat_message'
# Cette ligne importe les classes `ChatMessage` et `ChatMessageCreate` depuis le
# fichier `chat_message.py`. Sans cela, l'erreur `AttributeError: module 'app.schemas'
# has no attribute 'ChatMessageCreate'` se produit.
from .chat_message import ChatMessage, ChatMessageCreate

# 2. IMPORTATION DES MODULES COMPLETS
# Pour les schÃ©mas complexes comme 'relations' et 'simulation', il est souvent
# plus propre d'importer le module entier.
# Cela signifie qu'on y accÃ©dera avec une syntaxe comme `schemas.simulation.SessionStartRequest`.
# C'est ce que nous avons dÃ©jÃ  fait dans le code des services.

# Rend le module 'relations.py' accessible via `schemas.relations`
from . import relations

# Rend le module 'simulation.py' accessible via `schemas.simulation`.
# C'est cette ligne qui a corrigÃ© la premiÃ¨re erreur `AttributeError` que vous aviez.
from . import simulation

# ==============================================================================
# FIN DU FICHIER
# ------------------------------------------------------------------------------
# Avec ce fichier, l'application sait maintenant oÃ¹ trouver TOUS les schÃ©mas
# Pydantic dont elle a besoin, que ce soit par import direct de classe
# (ex: schemas.Symptom) ou par import de module (ex: schemas.simulation.HintResponse).
# ==============================================================================

=== Fichier: ./app/schemas/simulation.py ===

#=== Fichier: ./app/schemas/simulation.py ===

import logging
import json
from uuid import UUID
from datetime import datetime
from typing import Optional, Dict, Any, List, Union
from typing_extensions import Literal

from pydantic import BaseModel, Field, field_validator, model_validator, ConfigDict

# ==============================================================================
# CONFIGURATION DU LOGGER "SCHEMA-VALIDATOR"
# ==============================================================================
# Ce logger permet de tracer les erreurs de validation des donnÃ©es entrantes/sortantes.
# C'est une couche de sÃ©curitÃ© supplÃ©mentaire souvent nÃ©gligÃ©e.
logger = logging.getLogger("schema_validator")
logger.setLevel(logging.DEBUG)

if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - [SCHEMA] - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

# ==============================================================================
# SCHÃ‰MAS PARTAGÃ‰S / UTILITAIRES
# ==============================================================================

class ActionMetadata(BaseModel):
    """
    MÃ©tadonnÃ©es associÃ©es Ã  une action (coÃ»t, temps, impact).
    UtilisÃ© pour le retour d'information vers le frontend (gamification).
    """
    virtual_cost: int = Field(0, description="CoÃ»t de l'action en devise virtuelle (FCFA)")
    virtual_duration: int = Field(0, description="Temps Ã©coulÃ© dans la simulation (minutes)")
    impact_score: Optional[float] = Field(None, description="Score d'impact pÃ©dagogique (interne)")

    model_config = ConfigDict(populate_by_name=True)


class ExamResultContent(BaseModel):
    """
    Structure normalisÃ©e d'un rÃ©sultat d'examen gÃ©nÃ©rÃ© par l'IA.
    Permet au frontend d'afficher un rapport mÃ©dical propre.
    """
    type_resultat: str = Field(..., description="CatÃ©gorie (biologie, imagerie, autre)")
    rapport_complet: str = Field(..., description="Le corps du texte technique")
    conclusion: str = Field(..., description="La synthÃ¨se clinique")
    valeurs_cles: Optional[Dict[str, str]] = Field(None, description="Couples clÃ©/valeur pour affichage rapide (ex: Hb: 8g/dL)")
    
    # Champs optionnels pour l'imagerie
    zone_etudiee: Optional[str] = None
    protocole: Optional[str] = None

# ==============================================================================
# 1. DÃ‰MARRAGE DE SESSION
# ==============================================================================

class SessionStartRequest(BaseModel):
    """
    Payload pour initier une nouvelle simulation.
    """
    learner_id: int = Field(..., gt=0, description="ID de l'apprenant (doit exister en BDD)")
    category: str = Field(..., min_length=3, max_length=50, description="SpÃ©cialitÃ© visÃ©e (ex: Cardiologie)")
    mode: Optional[Literal["training", "exam"]] = Field("training", description="Mode de session")

    @field_validator('category')
    @classmethod
    def validate_category(cls, v):
        logger.debug(f"ğŸ” Validation catÃ©gorie: {v}")
        allowed = ["Cardiologie", "Pneumologie", "Infectiologie", "Urgences", "PÃ©diatrie", "Neurologie", "Gastro-entÃ©rologie"]
        # On fait une validation souple (case insensitive)
        v_cap = v.capitalize()
        if v_cap not in allowed:
            # On logue mais on laisse passer pour la flexibilitÃ©, ou on rejette.
            # Ici, on rejette pour la rigueur.
            logger.warning(f"âš ï¸ CatÃ©gorie inconnue demandÃ©e: {v}")
            # raise ValueError(f"CatÃ©gorie non supportÃ©e. Choix: {', '.join(allowed)}") 
            # CommentÃ© pour permettre le test 'Infectiologie' si non listÃ© ci-dessus
        return v_cap

class SessionStartResponse(BaseModel):
    """
    RÃ©ponse renvoyÃ©e aprÃ¨s la crÃ©ation de la session.
    """
    session_id: UUID = Field(..., description="Token unique de la session")
    session_type: str = Field(..., description="Type dÃ©terminÃ© par le systÃ¨me (formative/sommative)")
    
    # On importe ClinicalCase ici pour Ã©viter les imports circulaires au niveau module
    # ou on utilise un Any/Dict si le schÃ©ma complet est trop lourd
    clinical_case: Dict[str, Any] = Field(..., description="DonnÃ©es du cas (sans la solution)")
    
    start_time: datetime = Field(default_factory=datetime.now)
    initial_virtual_time: str = Field("08:00", description="Heure de dÃ©but dans la simulation")

    model_config = ConfigDict(from_attributes=True)

# ==============================================================================
# 2. ACTIONS DE L'APPRENANT (CÅ“ur de la boucle)
# ==============================================================================

class LearnerActionRequest(BaseModel):
    """
    L'apprenant effectue une action clinique.
    C'est ce schÃ©ma qui est envoyÃ© au `TutorService`.
    """
    action_type: str = Field(..., description="CatÃ©gorie (examen, traitement, geste, question)")
    action_name: str = Field(..., min_length=2, description="Nom prÃ©cis (ex: 'NFS', 'Amoxicilline')")
    justification: Optional[str] = Field(None, description="Pourquoi cette action ? (Pour l'Ã©valuation)")
    
    # NouveautÃ© : ParamÃ¨tres additionnels pour prÃ©ciser la demande
    parameters: Optional[Dict[str, Any]] = Field(
        default_factory=dict, 
        description="DÃ©tails (ex: {'dose': '1g', 'voie': 'IV'} ou {'contraste': true})"
    )

    @field_validator('action_type')
    @classmethod
    def validate_type(cls, v):
        logger.debug(f"ğŸ” Validation action_type: {v}")
        v = v.lower().strip()
        # Normalisation
        if v in ['examen', 'exam', 'biologie', 'imagerie']: return 'examen_complementaire'
        if v in ['traitement', 'drug', 'medicament']: return 'prescription'
        if v in ['geste', 'intervention']: return 'intervention'
        if v in ['constantes', 'vitaux']: return 'parametres_vitaux'
        if v in ['consultation_image', 'consulter_image']: return 'consulter_image'
        return v

    @field_validator('action_name')
    @classmethod
    def validate_name(cls, v):
        if len(v) < 2:
            logger.error(f"âŒ Nom d'action trop court: {v}")
            raise ValueError("Le nom de l'action est trop court")
        return v

class LearnerActionResponse(BaseModel):
    """
    RÃ©ponse du systÃ¨me Ã  une action.
    Contient le rÃ©sultat (gÃ©nÃ©rÃ© par IA ou statique) et le feedback tuteur.
    """
    action_type: str
    action_name: str
    
    # Le rÃ©sultat peut Ãªtre complexe (Dict) ou simple (str)
    # On utilise Union ou Dict[str, Any] pour la flexibilitÃ©
    result: Union[ExamResultContent, Dict[str, Any], str] = Field(
        ..., 
        description="Le rÃ©sultat clinique (Rapport labo, Observation, etc.)"
    )
    
    feedback: Optional[str] = Field(None, description="Feedback pÃ©dagogique immÃ©diat (Tuteur)")
    
    # MÃ©tadonnÃ©es pour l'interface utilisateur
    meta: Optional[ActionMetadata] = Field(
        None, 
        description="CoÃ»t et temps consommÃ©s par cette action"
    )
    
    timestamp: datetime = Field(default_factory=datetime.now)

# ==============================================================================
# 3. SYSTÃˆME D'INDICES (HINTS)
# ==============================================================================

class HintRequest(BaseModel):
    """(Optionnel) Si on veut paramÃ©trer la demande d'indice plus tard."""
    context_focus: Optional[str] = None

class HintResponse(BaseModel):
    """
    Un indice gÃ©nÃ©rÃ© par le tuteur IA.
    """
    hint_type: str = Field(..., description="Type (socratique, direct, clinique)")
    content: str = Field(..., description="Le texte de l'indice")
    cost_penalty: int = Field(0, description="PÃ©nalitÃ© de score associÃ©e (si applicable)")

# ==============================================================================
# 4. SOUMISSION FINALE ET Ã‰VALUATION
# ==============================================================================

class SubmissionRequest(BaseModel):
    """
    L'apprenant termine le cas et propose son plan EN LANGAGE NATUREL.
    
    Changement majeur : On ne demande plus d'IDs de base de donnÃ©es.
    On demande Ã  l'Ã©tudiant d'Ã©crire son diagnostic et son traitement comme dans un dossier mÃ©dical.
    L'IA se chargera de la validation sÃ©mantique.
    """
    diagnosed_pathology_text: str = Field(
        ..., 
        min_length=3, 
        max_length=500,
        description="Le diagnostic posÃ© par l'Ã©tudiant (ex: 'Paludisme grave', 'Grippe')"
    )
    
    prescribed_treatment_text: str = Field(
        ..., 
        min_length=3,
        max_length=2000,
        description="La description du traitement (ex: 'Artesunate IV, ParacÃ©tamol', 'Repos')"
    )
    
    # On garde ce champ s'il veut ajouter des commentaires sur sa dÃ©marche
    final_justification: Optional[str] = Field(
        None, 
        description="Justification ou raisonnement clinique supplÃ©mentaire (optionnel)"
    )

    @field_validator('diagnosed_pathology_text')
    @classmethod
    def validate_diag_text(cls, v):
        logger.debug(f"ğŸ” Validation diagnostic (SÃ©mantique): '{v}'")
        v_clean = v.strip()
        if len(v_clean) < 3:
            logger.error(f"âŒ Diagnostic trop court: '{v}'")
            raise ValueError("Le diagnostic doit Ãªtre explicite (min 3 caractÃ¨res).")
        return v_clean

    @field_validator('prescribed_treatment_text')
    @classmethod
    def validate_treatment_text(cls, v):
        logger.debug(f"ğŸ” Validation traitement (SÃ©mantique): '{v[:50]}...'")
        v_clean = v.strip()
        if len(v_clean) < 3:
            logger.error(f"âŒ Traitement trop court: '{v}'")
            raise ValueError("Veuillez dÃ©crire le traitement ou Ã©crire 'Aucun'.")
        return v_clean

class EvaluationResult(BaseModel):
    """
    DÃ©tail des notes attribuÃ©es par l'IA Juge.
    """
    score_diagnostic: float = Field(..., ge=0, le=10, description="PrÃ©cision du diagnostic /10")
    score_therapeutique: float = Field(..., ge=0, le=5, description="Pertinence traitement /5")
    score_demarche: float = Field(..., ge=0, le=5, description="QualitÃ© de la dÃ©marche /5")
    score_total: float = Field(..., ge=0, le=20, description="Note finale /20")

class SubmissionResponse(BaseModel):
    """
    Le rapport final renvoyÃ© au frontend.
    """
    evaluation: EvaluationResult
    feedback_global: str = Field(..., description="Texte pÃ©dagogique gÃ©nÃ©rÃ© par l'IA")
    recommendation_next_step: str = Field(..., description="Conseil pour la suite")
    
    # MÃ©ta-donnÃ©es de fin de session
    session_duration_seconds: Optional[int] = None
    virtual_cost_total: Optional[int] = None

# ==============================================================================
# 5. SCHÃ‰MAS DE CHAT (Rappel pour complÃ©tude)
# ==============================================================================
# Ces schÃ©mas sont souvent dÃ©finis dans chat_message.py mais peuvent Ãªtre 
# rÃ©fÃ©rencÃ©s ici si besoin d'agrÃ©gation.

# Note : On s'assure que tout est cohÃ©rent avec models/tracking_models.py

logger.info("âœ… SchÃ©mas de simulation chargÃ©s et configurÃ©s.")

=== Fichier: ./app/schemas/expert_strategy.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date
from decimal import Decimal

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class ExpertStrategyBase(BaseModel):
    """
    SchÃ©ma de base pour une rÃ¨gle/stratÃ©gie experte.
    """
    code_regle: str = Field(..., max_length=50)
    categorie: str
    priorite: int = Field(default=5, ge=1, le=10)
    conditions: Dict[str, Any]
    actions: List[Dict[str, Any]]
    description_naturelle: Optional[str] = None
    justification_medicale: Optional[str] = None
    expert_auteur: Optional[str] = None
    date_validation: Optional[date] = None
    est_active: bool = True


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation
# ==============================================================================
class ExpertStrategyCreate(ExpertStrategyBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er une nouvelle rÃ¨gle.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour
# ==============================================================================
class ExpertStrategyUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'une rÃ¨gle.
    """
    code_regle: Optional[str] = Field(None, max_length=50)
    categorie: Optional[str] = None
    priorite: Optional[int] = Field(None, ge=1, le=10)
    conditions: Optional[Dict[str, Any]] = None
    actions: Optional[List[Dict[str, Any]]] = None
    description_naturelle: Optional[str] = None
    justification_medicale: Optional[str] = None
    expert_auteur: Optional[str] = None
    date_validation: Optional[date] = None
    est_active: Optional[bool] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (RÃ©ponse API)
# ==============================================================================
class ExpertStrategy(ExpertStrategyBase):
    """
    SchÃ©ma complet pour reprÃ©senter une rÃ¨gle en rÃ©ponse d'API.
    """
    id: int
    nb_activations: int
    taux_succes: Optional[Decimal] = None
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

=== Fichier: ./app/schemas/response.py ===



=== Fichier: ./app/schemas/media.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date

# ==============================================================================
# SchÃ©ma de Base pour les MÃ©tadonnÃ©es d'une Image
# ==============================================================================
class ImageMedicaleBase(BaseModel):
    """
    SchÃ©ma de base contenant les mÃ©tadonnÃ©es modifiables d'une image mÃ©dicale.
    """
    type_examen: str
    sous_type: Optional[str] = None
    pathologie_id: Optional[int] = None
    description: Optional[str] = None
    signes_radiologiques: Optional[Dict[str, Any]] = None
    annotations: Optional[List[Dict[str, Any]]] = None
    interpretation_experte: Optional[str] = None
    diagnostic_differentiel: Optional[List[str]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=5)
    qualite_image: Optional[int] = Field(None, ge=1, le=5)
    valide_expert: Optional[bool] = False
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour des MÃ©tadonnÃ©es
# ==============================================================================
class ImageMedicaleUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle des mÃ©tadonnÃ©es d'une image.
    Tous les champs sont optionnels.
    """
    type_examen: Optional[str] = None
    sous_type: Optional[str] = None
    pathologie_id: Optional[int] = None
    description: Optional[str] = None
    signes_radiologiques: Optional[Dict[str, Any]] = None
    annotations: Optional[List[Dict[str, Any]]] = None
    interpretation_experte: Optional[str] = None
    diagnostic_differentiel: Optional[List[str]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=5)
    qualite_image: Optional[int] = Field(None, ge=1, le=5)
    valide_expert: Optional[bool] = None
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (RÃ©ponse API)
# ==============================================================================
class ImageMedicale(ImageMedicaleBase):
    """
    SchÃ©ma complet pour reprÃ©senter les mÃ©tadonnÃ©es d'une image en rÃ©ponse d'API.
    """
    id: int
    fichier_url: str
    fichier_miniature_url: Optional[str] = None
    format_image: Optional[str] = None
    taille_ko: Optional[int] = None
    resolution: Optional[str] = None
    created_at: datetime

    class Config:
        from_attributes = True

# Nous ajouterons les schÃ©mas pour SonMedical ici plus tard.

=== Fichier: ./app/schemas/disease.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime
from decimal import Decimal

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class DiseaseBase(BaseModel):
    """
    SchÃ©ma de base pour une pathologie, contenant les champs modifiables.
    """
    nom_fr: str
    code_icd10: str
    nom_en: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    prevalence_cameroun: Optional[Decimal] = Field(None, ge=0, le=100)
    niveau_gravite: Optional[int] = Field(None, ge=1, le=5)
    description: Optional[str] = None
    physiopathologie: Optional[str] = None
    evolution_naturelle: Optional[str] = None
    complications: Optional[Dict[str, Any]] = None
    facteurs_risque: Optional[Dict[str, Any]] = None
    prevention: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation (ce que l'API attend dans un POST)
# ==============================================================================
class DiseaseCreate(DiseaseBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er une nouvelle pathologie.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour (ce que l'API attend dans un PATCH)
# ==============================================================================
class DiseaseUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'une pathologie.
    Tous les champs sont optionnels.
    """
    nom_fr: Optional[str] = None
    code_icd10: Optional[str] = None
    nom_en: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    prevalence_cameroun: Optional[Decimal] = Field(None, ge=0, le=100)
    niveau_gravite: Optional[int] = Field(None, ge=1, le=5)
    description: Optional[str] = None
    physiopathologie: Optional[str] = None
    evolution_naturelle: Optional[str] = None
    complications: Optional[Dict[str, Any]] = None
    facteurs_risque: Optional[Dict[str, Any]] = None
    prevention: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class Disease(DiseaseBase):
    """
    SchÃ©ma complet pour reprÃ©senter une pathologie en rÃ©ponse d'API.
    Inclut les champs non modifiables comme 'id' et les horodatages.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        """
        Permet la conversion automatique depuis un objet SQLAlchemy.
        """
        from_attributes = True

=== Fichier: ./app/schemas/diagnostic.py ===



=== Fichier: ./app/schemas/chat_message.py ===

from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
from datetime import datetime
from uuid import UUID

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class ChatMessageBase(BaseModel):
    """
    SchÃ©ma de base pour un message de chat.
    Contient les champs communs.
    """
    sender: str = Field(..., description="Qui envoie le message (ex: 'student', 'patient_llm', 'tutor_system')")
    content: str = Field(..., description="Le contenu textuel du message.")


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation (ce que le Frontend envoie)
# ==============================================================================
class ChatMessageCreate(ChatMessageBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau message de chat via l'API.
    La session_id sera fournie dans l'URL, pas dans le corps.
    """
    message_metadata: Optional[Dict[str, Any]] = Field(None, description="MÃ©tadonnÃ©es optionnelles (ex: intention dÃ©tectÃ©e)")


# ==============================================================================
# SchÃ©ma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class ChatMessage(ChatMessageBase):
    """
    SchÃ©ma complet pour reprÃ©senter un message de chat en rÃ©ponse d'API.
    """
    id: int
    session_id: UUID
    timestamp: datetime
    message_metadata: Optional[Dict[str, Any]] = None

    class Config:
        """
        Permet la conversion automatique depuis un objet SQLAlchemy.
        """
        from_attributes = True

=== Fichier: ./app/schemas/base.py ===



=== Fichier: ./app/schemas/request.py ===



=== Fichier: ./app/api/v1/chat.py ===

#=== Fichier: ./app/api/v1/chat.py ===

import logging
import time
import uuid
from typing import List
from uuid import UUID

from fastapi import APIRouter, Depends, HTTPException, status, Request
from sqlalchemy.orm import Session

from ... import schemas, models
from ...services import chat_service
from ...dependencies import get_db

# ==============================================================================
# CONFIGURATION DU LOGGER API
# ==============================================================================
logger = logging.getLogger("api_chat")
logger.setLevel(logging.DEBUG)

if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - [API-CHAT] - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

router = APIRouter(
    prefix="/chat",
    tags=["Chat"]
)

@router.post(
    "/sessions/{session_id}/messages", 
    response_model=schemas.chat_message.ChatMessage, 
    status_code=status.HTTP_201_CREATED
)
def post_chat_message(
    session_id: UUID,
    message_data: schemas.chat_message.ChatMessageCreate,
    db: Session = Depends(get_db)
):
    """
    Poste un nouveau message dans le chat d'une session de simulation.
    
    ATTENTION : Cet endpoint est synchrone et bloquant. 
    Si c'est un message de l'Ã©tudiant, il va dÃ©clencher le Patient Actor (IA).
    La rÃ©ponse peut prendre quelques secondes.
    """
    # ID de requÃªte pour corrÃ©ler avec les logs des services
    req_id = str(uuid.uuid4())[:8]
    start_time = time.time()
    
    logger.info(f"ğŸ“¥ [REQ-{req_id}] POST /messages | Session: {session_id}")
    logger.debug(f"   [REQ-{req_id}] Payload: Sender='{message_data.sender}' | Content='{message_data.content[:50]}...'")

    try:
        # Appel au service (qui va orchestrer l'IA si nÃ©cessaire)
        new_message = chat_service.create_chat_message(
            db=db, 
            session_id=session_id, 
            message=message_data
        )
        
        duration = time.time() - start_time
        logger.info(f"   âœ… [REQ-{req_id}] SuccÃ¨s HTTP 201 | DurÃ©e totale: {duration:.2f}s | Msg ID: {new_message.id}")
        
        return new_message

    except ValueError as e:
        # Erreur fonctionnelle (ex: Session introuvable)
        logger.warning(f"   âš ï¸ [REQ-{req_id}] Erreur 404 (Resource Not Found): {str(e)}")
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
    
    except Exception as e:
        # Erreur technique (Bug code, Crash DB, Crash IA critique)
        logger.error(f"   âŒ [REQ-{req_id}] Erreur 500 (Internal Server Error): {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, 
            detail=f"Erreur interne lors du traitement du message: {str(e)}"
        )

@router.get(
    "/sessions/{session_id}/messages", 
    response_model=List[schemas.chat_message.ChatMessage]
)
def get_chat_history(
    session_id: UUID, 
    db: Session = Depends(get_db)
):
    """
    RÃ©cupÃ¨re l'historique complet des messages pour une session.
    UtilisÃ© par le frontend pour rafraÃ®chir la vue (polling) et voir si le patient a rÃ©pondu.
    """
    req_id = str(uuid.uuid4())[:8]
    start_time = time.time()
    
    logger.debug(f"ğŸ” [REQ-{req_id}] GET /messages | Session: {session_id}")

    try:
        # VÃ©rification prÃ©-service pour un log API plus propre
        # (Bien que le service le fasse aussi, le faire ici permet de logger l'erreur HTTP correspondante)
        session = db.query(models.SimulationSession).filter(models.SimulationSession.id == session_id).first()
        if not session:
            logger.warning(f"   âš ï¸ [REQ-{req_id}] Session introuvable.")
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"La session {session_id} n'existe pas.")
        
        messages = chat_service.get_messages_by_session(db=db, session_id=session_id)
        
        duration = time.time() - start_time
        logger.info(f"   âœ… [REQ-{req_id}] SuccÃ¨s HTTP 200 | {len(messages)} messages rÃ©cupÃ©rÃ©s | {duration:.3f}s")
        
        return messages

    except HTTPException:
        raise # On relance les exceptions HTTP crÃ©Ã©es au-dessus
    
    except Exception as e:
        logger.error(f"   âŒ [REQ-{req_id}] Erreur 500 rÃ©cupÃ©ration historique: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Impossible de rÃ©cupÃ©rer l'historique."
        )

=== Fichier: ./app/api/v1/__init__.py ===



=== Fichier: ./app/api/v1/simulation.py ===

#=== Fichier: ./app/api/v1/simulation.py ===

import logging
import time
import uuid
from typing import Any, Dict
from uuid import UUID

from fastapi import APIRouter, Depends, HTTPException, status, Body
from sqlalchemy.orm import Session

from ... import schemas, models
from ...services import tutor_service
from ...dependencies import get_db

# ==============================================================================
# CONFIGURATION DU LOGGER API SIMULATION
# ==============================================================================
logger = logging.getLogger("api_simulation")
logger.setLevel(logging.DEBUG)

if not logger.handlers:
    handler = logging.StreamHandler()
    # Format enrichi pour le debug API
    formatter = logging.Formatter('%(asctime)s - [API-SIM] - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

router = APIRouter(
    prefix="/simulation",
    tags=["Simulation"]
)

# ==============================================================================
# 1. DÃ‰MARRAGE DE SESSION
# ==============================================================================

@router.post(
    "/sessions/start",
    response_model=schemas.simulation.SessionStartResponse,
    status_code=status.HTTP_201_CREATED
)
def start_simulation_session(
    request_data: schemas.simulation.SessionStartRequest,
    db: Session = Depends(get_db)
):
    """
    DÃ©marre une nouvelle session de simulation pour un apprenant.
    Initialise le contexte, choisit un cas clinique et prÃ©pare le patient virtuel.
    """
    req_id = str(uuid.uuid4())[:8]
    start_time = time.time()
    
    logger.info(f"ğŸ“¥ [REQ-{req_id}] POST /sessions/start | Learner: {request_data.learner_id} | Cat: {request_data.category}")

    try:
        # Appel au service orchestrateur
        session, clinical_case, session_type = tutor_service.start_new_session(
            db=db,
            learner_id=request_data.learner_id,
            category=request_data.category
        )
        
        # --- SÃ‰RIALISATION MANUELLE (Protection Pydantic) ---
        # On convertit l'objet SQLAlchemy Pathologie en dictionnaire simple
        # pour Ã©viter l'erreur "Unable to serialize unknown type"
        patho_dict = None
        if clinical_case.pathologie_principale:
            p = clinical_case.pathologie_principale
            patho_dict = {
                "id": p.id,
                "nom_fr": p.nom_fr,
                "code_icd10": p.code_icd10,
                "categorie": p.categorie,
                "description": p.description
            }

        # Construction du dictionnaire pour le schÃ©ma de rÃ©ponse
        case_dict = {
            "id": clinical_case.id,
            "code_fultang": clinical_case.code_fultang,
            "niveau_difficulte": clinical_case.niveau_difficulte,
            "pathologie_principale": patho_dict, # Dict pur, pas d'objet ORM
            "presentation_clinique": clinical_case.presentation_clinique,
            "donnees_paracliniques": clinical_case.donnees_paracliniques
        }

        response = schemas.simulation.SessionStartResponse(
            session_id=session.id,
            session_type=session_type,
            clinical_case=case_dict,
            start_time=session.start_time
        )
        
        duration = time.time() - start_time
        logger.info(f"   âœ… [REQ-{req_id}] Session dÃ©marrÃ©e : {session.id} ({duration:.2f}s)")
        
        return response

    except ValueError as e:
        logger.warning(f"   âš ï¸ [REQ-{req_id}] Erreur validation (400/404): {str(e)}")
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
        
    except Exception as e:
        logger.critical(f"   âŒ [REQ-{req_id}] Erreur serveur (500): {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur interne lors du dÃ©marrage de la session: {str(e)}"
        )

# ==============================================================================
# 2. ACTIONS (Examens, Traitements, Gestes)
# ==============================================================================

@router.post(
    "/sessions/{session_id}/actions",
    response_model=schemas.simulation.LearnerActionResponse
)
def perform_learner_action(
    session_id: UUID,
    action_data: schemas.simulation.LearnerActionRequest,
    db: Session = Depends(get_db)
):
    """
    Traite une action effectuÃ©e par l'apprenant (Examen, Prescription).
    DÃ©clenche l'IA gÃ©nÃ©ratrice pour les rÃ©sultats d'examens.
    """
    req_id = str(uuid.uuid4())[:8]
    start_time = time.time()
    
    logger.info(f"ğŸ“¥ [REQ-{req_id}] POST /actions | Session: {session_id}")
    logger.debug(f"   [REQ-{req_id}] Action: {action_data.action_type} -> {action_data.action_name}")

    try:
        # Appel au service Tutor
        result_data, feedback = tutor_service.process_learner_action(
            db=db,
            session_id=session_id,
            action_data=action_data
        )
        
        # Reconstruction des mÃ©tadonnÃ©es pour l'affichage frontend
        from ...services.tutor_service import VirtualTimeManager, VirtualBudgetManager
        cost = VirtualBudgetManager.estimate_cost(action_data.action_name)
        duration_min = VirtualTimeManager.calculate_duration(action_data.action_type, action_data.action_name)
        
        meta = schemas.simulation.ActionMetadata(
            virtual_cost=cost,
            virtual_duration=duration_min
        )

        response = schemas.simulation.LearnerActionResponse(
            action_type=action_data.action_type,
            action_name=action_data.action_name,
            result=result_data,
            feedback=feedback,
            meta=meta
        )
        
        duration = time.time() - start_time
        logger.info(f"   âœ… [REQ-{req_id}] Action traitÃ©e avec succÃ¨s ({duration:.2f}s)")
        
        return response

    except ValueError as e:
        logger.warning(f"   âš ï¸ [REQ-{req_id}] Erreur fonctionnelle: {str(e)}")
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
        
    except Exception as e:
        logger.error(f"   âŒ [REQ-{req_id}] Erreur technique action: {str(e)}")
        import traceback
        logger.debug(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur lors du traitement de l'action: {str(e)}"
        )

# ==============================================================================
# 3. INDICES (Hints)
# ==============================================================================

@router.post(
    "/sessions/{session_id}/request-hint",
    response_model=schemas.simulation.HintResponse
)
def request_hint(
    session_id: UUID,
    db: Session = Depends(get_db)
):
    """
    Permet Ã  un apprenant de demander un indice pour la session en cours.
    """
    req_id = str(uuid.uuid4())[:8]
    logger.info(f"ğŸ“¥ [REQ-{req_id}] POST /request-hint | Session: {session_id}")

    try:
        hint_type, hint_content = tutor_service.provide_hint(
            db=db,
            session_id=session_id
        )
        
        response = schemas.simulation.HintResponse(
            hint_type=hint_type,
            content=hint_content,
            cost_penalty=5 
        )
        
        logger.info(f"   âœ… [REQ-{req_id}] Indice fourni ({hint_type})")
        return response

    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
    except Exception as e:
        logger.error(f"   âŒ [REQ-{req_id}] Erreur indice: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Impossible de gÃ©nÃ©rer un indice."
        )

# ==============================================================================
# 4. SOUMISSION FINALE (Mode SÃ©mantique)
# ==============================================================================

@router.post(
    "/sessions/{session_id}/submit",
    response_model=schemas.simulation.SubmissionResponse
)
def submit_final_diagnosis(
    session_id: UUID,
    submission_data: schemas.simulation.SubmissionRequest,
    db: Session = Depends(get_db)
):
    """
    Soumet le diagnostic et le traitement final de l'apprenant pour Ã©valuation.
    Accepte maintenant du texte libre qui sera analysÃ© sÃ©mantiquement par l'IA.
    """
    req_id = str(uuid.uuid4())[:8]
    start_time = time.time()
    
    logger.info(f"ğŸ“¥ [REQ-{req_id}] POST /submit | Session: {session_id}")
    
    # LOGS SÃ‰MANTIQUES : On affiche ce que l'Ã©tudiant a Ã©crit
    diag_text = submission_data.diagnosed_pathology_text
    treat_text = submission_data.prescribed_treatment_text
    # Tronquage pour l'affichage propre
    treat_preview = treat_text[:50] + "..." if len(treat_text) > 50 else treat_text
    
    logger.info(f"   ğŸ“ Diagnostic soumis : '{diag_text}'")
    logger.info(f"   ğŸ’Š Traitement soumis : '{treat_preview}'")

    try:
        # Appel au service d'Ã©valuation (IA Juge)
        eval_result, feedback, recommendation = tutor_service.evaluate_submission(
            db=db,
            session_id=session_id,
            submission_data=submission_data
        )

        response = schemas.simulation.SubmissionResponse(
            evaluation=eval_result,
            feedback_global=feedback,
            recommendation_next_step=recommendation,
            # On pourrait ajouter ici les mÃ©triques finales calculÃ©es
            session_duration_seconds=int(time.time() - start_time) 
        )
        
        duration = time.time() - start_time
        logger.info(f"   ğŸ† [REQ-{req_id}] Ã‰valuation terminÃ©e. Note: {eval_result.score_total}/20 ({duration:.2f}s)")
        
        return response

    except ValueError as e:
        logger.warning(f"   âš ï¸ [REQ-{req_id}] DonnÃ©es invalides (404): {str(e)}")
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))
    except Exception as e:
        logger.critical(f"   âŒ [REQ-{req_id}] Erreur critique Ã©valuation (500): {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur lors de l'Ã©valuation: {str(e)}"
        )

=== Fichier: ./app/api/v1/q_matrix.py ===



=== Fichier: ./app/api/v1/fultang.py ===



=== Fichier: ./app/api/v1/media.py ===

from fastapi import (
    APIRouter,
    Depends,
    HTTPException,
    status,
    UploadFile,
    File,
    Form
)
from sqlalchemy.orm import Session
from typing import List, Optional

from ... import schemas, models
from ...services import media_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/media",
    tags=["Media"]
)


@router.post("/images/upload", response_model=schemas.media.ImageMedicale, status_code=status.HTTP_201_CREATED)
async def upload_image_medicale(
    file: UploadFile = File(..., description="Le fichier image Ã  uploader"),
    type_examen: str = Form(..., description="Type d'examen (ex: Radiographie)"),
    sous_type: Optional[str] = Form(None, description="Sous-type (ex: Thorax)"),
    pathologie_id: Optional[int] = Form(None, description="ID de la pathologie associÃ©e"),
    description: Optional[str] = Form(None, description="Description de l'image"),
    db: Session = Depends(get_db)
):
    """
    Uploade une image mÃ©dicale et crÃ©e l'enregistrement de ses mÃ©tadonnÃ©es.
    """
    # VÃ©rifier le type de fichier si nÃ©cessaire
    if not file.content_type.startswith("image/"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Le fichier uploadÃ© n'est pas une image."
        )

    db_image = await media_service.create_image_medicale(
        db=db,
        file=file,
        type_examen=type_examen,
        sous_type=sous_type,
        pathologie_id=pathologie_id,
        description=description
    )
    return db_image


@router.get("/images", response_model=List[schemas.media.ImageMedicale])
def read_all_images_metadata(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste des mÃ©tadonnÃ©es de toutes les images mÃ©dicales.
    """
    images = media_service.get_all_images_medicales(db, skip=skip, limit=limit)
    return images


@router.get("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def read_image_metadata(image_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re les mÃ©tadonnÃ©es d'une image mÃ©dicale spÃ©cifique par son ID.
    """
    db_image = media_service.get_image_medicale_by_id(db, image_id=image_id)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvÃ©e.")
    return db_image


@router.patch("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def update_image_metadata(
    image_id: int,
    metadata_update: schemas.media.ImageMedicaleUpdate,
    db: Session = Depends(get_db)
):
    """
    Met Ã  jour les mÃ©tadonnÃ©es d'une image mÃ©dicale existante.
    """
    db_image = media_service.update_image_medicale_metadata(db, image_id=image_id, image_update=metadata_update)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvÃ©e.")
    return db_image


@router.delete("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def delete_image(image_id: int, db: Session = Depends(get_db)):
    """
    Supprime une image mÃ©dicale (mÃ©tadonnÃ©es et fichier physique).
    """
    db_image = media_service.delete_image_medicale(db, image_id=image_id)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvÃ©e.")
    return db_image

=== Fichier: ./app/api/v1/expert_strategies.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import expert_strategy_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/expert-strategies",
    tags=["Expert Strategies"]
)


@router.post("/", response_model=schemas.expert_strategy.ExpertStrategy, status_code=status.HTTP_201_CREATED)
def create_expert_strategy(strategy_data: schemas.expert_strategy.ExpertStrategyCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e une nouvelle rÃ¨gle/stratÃ©gie experte.
    """
    db_strategy = expert_strategy_service.get_strategy_by_code(db, code=strategy_data.code_regle)
    if db_strategy:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Une rÃ¨gle avec le code '{strategy_data.code_regle}' existe dÃ©jÃ ."
        )
    return expert_strategy_service.create_strategy(db=db, strategy=strategy_data)


@router.get("/", response_model=List[schemas.expert_strategy.ExpertStrategy])
def read_all_expert_strategies(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de toutes les rÃ¨gles expertes.
    """
    strategies = expert_strategy_service.get_all_strategies(db, skip=skip, limit=limit)
    return strategies


@router.get("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def read_expert_strategy(strategy_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une rÃ¨gle experte par son ID.
    """
    db_strategy = expert_strategy_service.get_strategy_by_id(db, strategy_id=strategy_id)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="RÃ¨gle non trouvÃ©e.")
    return db_strategy


@router.patch("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def update_expert_strategy(strategy_id: int, strategy_data: schemas.expert_strategy.ExpertStrategyUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour une rÃ¨gle experte.
    """
    db_strategy = expert_strategy_service.update_strategy(db, strategy_id=strategy_id, strategy_update=strategy_data)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="RÃ¨gle non trouvÃ©e.")
    return db_strategy


@router.delete("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def delete_expert_strategy(strategy_id: int, db: Session = Depends(get_db)):
    """
    Supprime une rÃ¨gle experte.
    """
    db_strategy = expert_strategy_service.delete_strategy(db, strategy_id=strategy_id)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="RÃ¨gle non trouvÃ©e.")
    return db_strategy

=== Fichier: ./app/api/v1/learning_paths.py ===



=== Fichier: ./app/api/v1/diseases.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import disease_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/diseases",
    tags=["Diseases"]
)


@router.post("/", response_model=schemas.disease.Disease, status_code=status.HTTP_201_CREATED)
def create_disease(disease_data: schemas.disease.DiseaseCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e une nouvelle pathologie.
    VÃ©rifie l'unicitÃ© du code CIM-10.
    """
    db_disease = disease_service.get_disease_by_icd10(db, icd10_code=disease_data.code_icd10)
    if db_disease:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Une pathologie avec le code CIM-10 '{disease_data.code_icd10}' existe dÃ©jÃ ."
        )
    return disease_service.create_disease(db=db, disease=disease_data)


@router.get("/", response_model=List[schemas.disease.Disease])
def read_diseases(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de pathologies.
    """
    diseases = disease_service.get_all_diseases(db, skip=skip, limit=limit)
    return diseases


@router.get("/{disease_id}", response_model=schemas.disease.Disease)
def read_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une pathologie par son ID.
    """
    db_disease = disease_service.get_disease_by_id(db, disease_id=disease_id)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvÃ©e.")
    return db_disease


@router.patch("/{disease_id}", response_model=schemas.disease.Disease)
def update_disease(disease_id: int, disease_data: schemas.disease.DiseaseUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour une pathologie.
    """
    db_disease = disease_service.update_disease(db, disease_id=disease_id, disease_update=disease_data)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvÃ©e.")
    return db_disease


@router.delete("/{disease_id}", response_model=schemas.disease.Disease)
def delete_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    Supprime une pathologie.
    """
    db_disease = disease_service.delete_disease(db, disease_id=disease_id)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvÃ©e.")
    return db_disease

# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/diseases.py

@router.post(
    "/{disease_id}/symptoms",
    response_model=schemas.relations.PathologieSymptome,
    status_code=status.HTTP_201_CREATED,
    tags=["Disease-Symptom Relations"] # Un nouveau tag pour l'organisation
)
def add_symptom_to_disease(
    disease_id: int, 
    association_data: schemas.relations.PathologieSymptomeCreate, 
    db: Session = Depends(get_db)
):
    """
    Associe un symptÃ´me Ã  une pathologie avec des attributs de relation
    (probabilitÃ©, importance, etc.).
    """
    # Assurer la cohÃ©rence des IDs
    if disease_id != association_data.pathologie_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="L'ID de la pathologie dans l'URL ne correspond pas Ã  celui dans le corps de la requÃªte."
        )
    
    try:
        return disease_service.add_symptom_to_disease(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))


@router.get(
    "/{disease_id}/symptoms",
    response_model=List[schemas.relations.SymptomForDiseaseDetail],
    tags=["Disease-Symptom Relations"]
)
def get_symptoms_for_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste de tous les symptÃ´mes associÃ©s Ã  une pathologie,
    avec les dÃ©tails de la relation et les dÃ©tails du symptÃ´me lui-mÃªme.
    """
    associations = disease_service.get_symptoms_for_disease(db, disease_id=disease_id)
    if not associations:
        # Ce n'est pas une erreur, la maladie peut simplement n'avoir aucun symptÃ´me associÃ© pour l'instant
        return []
    
    # Transformer les donnÃ©es pour correspondre au schÃ©ma de rÃ©ponse attendu
    response = []
    for assoc in associations:
        response.append({
            "symptome": assoc.symptome, # L'objet Symptom complet
            "probabilite": assoc.probabilite,
            "importance_diagnostique": assoc.importance_diagnostique,
            "est_pathognomonique": assoc.est_pathognomonique
        })
    return response


# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/diseases.py

@router.post(
    "/{disease_id}/treatments",
    response_model=schemas.relations.TraitementPathologie,
    status_code=status.HTTP_201_CREATED,
    tags=["Therapeutic Relations"]
)
def add_treatment_to_disease(
    disease_id: int, 
    association_data: schemas.relations.TraitementPathologieCreate, 
    db: Session = Depends(get_db)
):
    """
    Associe un mÃ©dicament Ã  une pathologie en tant que traitement.
    """
    if disease_id != association_data.pathologie_id:
        raise HTTPException(status_code=400, detail="IncohÃ©rence des IDs de pathologie.")
    
    try:
        return disease_service.add_treatment_to_disease(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get(
    "/{disease_id}/treatments",
    response_model=List[schemas.relations.MedicationForDiseaseDetail],
    tags=["Therapeutic Relations"]
)
def get_treatments_for_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste des traitements recommandÃ©s pour une pathologie.
    """
    associations = disease_service.get_treatments_for_disease(db, disease_id=disease_id)
    return [
        {
            "medicament": assoc.medicament,
            "type_traitement": assoc.type_traitement,
            "ligne_traitement": assoc.ligne_traitement,
            "rang_preference": assoc.rang_preference,
        }
        for assoc in associations
    ]

=== Fichier: ./app/api/v1/diagnostic.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List, Dict, Any

from ...services import diagnostic_engine
from ...dependencies import get_db

router = APIRouter(
    prefix="/diagnostic-engine",
    tags=["Diagnostic Engine"]
)


@router.post("/run", response_model=List[Dict[str, Any]])
def run_diagnostic_engine(
    patient_facts: diagnostic_engine.DiagnosticInput,
    db: Session = Depends(get_db)
):
    """
    ExÃ©cute le moteur de raisonnement sur un ensemble de faits patient.

    Prend en entrÃ©e une liste de symptÃ´mes et de contextes, et retourne
    une liste d'actions/conclusions basÃ©es sur les rÃ¨gles expertes actives
    dans le systÃ¨me.
    """
    if not patient_facts.symptoms:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="La liste des symptÃ´mes ne peut pas Ãªtre vide."
        )

    conclusions = diagnostic_engine.run_diagnostic(db=db, patient_facts=patient_facts)
    
    return conclusions

=== Fichier: ./app/api/v1/clinical_cases.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import clinical_case_service, media_service, symptom_service, disease_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/clinical-cases",
    tags=["Clinical Cases"]
)


@router.post("/", response_model=schemas.clinical_case.ClinicalCase, status_code=status.HTTP_201_CREATED)
def create_clinical_case(case_data: schemas.clinical_case.ClinicalCaseCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e un nouveau cas clinique.
    """
    db_case_by_code = clinical_case_service.get_case_by_code(db, code=case_data.code_fultang)
    if db_case_by_code:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Un cas avec le code '{case_data.code_fultang}' existe dÃ©jÃ ."
        )
    try:
        # Le service create_case retournera un objet SQLAlchemy
        db_case = clinical_case_service.create_case(db=db, case=case_data)
        # La conversion vers le schÃ©ma Pydantic se fait automatiquement par FastAPI
        return db_case
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))


@router.get("/", response_model=List[schemas.clinical_case.ClinicalCaseSimple])
def read_all_clinical_cases(skip: int = 0, limit: int = 25, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste simplifiÃ©e de cas cliniques.
    """
    cases = clinical_case_service.get_all_cases(db, skip=skip, limit=limit)
    
    # La conversion vers le schÃ©ma Pydantic gÃ¨re automatiquement la construction de la rÃ©ponse
    # en utilisant les relations SQLAlchemy et les configurations 'from_attributes'.
    # Cependant, pour des champs calculÃ©s comme 'nb_images', nous devons construire la rÃ©ponse manuellement.
    response = []
    for case in cases:
        case_simple = schemas.clinical_case.ClinicalCaseSimple(
            id=case.id,
            code_fultang=case.code_fultang,
            niveau_difficulte=case.niveau_difficulte,
            pathologie_principale=case.pathologie_principale,
            nb_images=len(case.images_associees_ids) if case.images_associees_ids else 0,
            nb_sons=len(case.sons_associes_ids) if case.sons_associes_ids else 0,
        )
        response.append(case_simple)
    return response


@router.get("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def read_clinical_case(case_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un cas clinique complet par son ID, avec tous les objets liÃ©s.
    """
    # 1. RÃ©cupÃ©rer le cas brut
    db_case = clinical_case_service.get_case_by_id(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=404, detail="Cas clinique non trouvÃ©.")
    
    # 2. Convertir en dictionnaire pour pouvoir injecter les champs enrichis
    case_dict = db_case.__dict__

    # 3. Enrichir : Pathologies Secondaires
    pathologies_secondaires = []
    if db_case.pathologies_secondaires_ids:
        for p_id in db_case.pathologies_secondaires_ids:
            p_obj = disease_service.get_disease_by_id(db, disease_id=p_id)
            if p_obj:
                pathologies_secondaires.append(p_obj)
    case_dict['pathologies_secondaires'] = pathologies_secondaires

    # 4. Enrichir : Images
    images = []
    if db_case.images_associees_ids:
        for img_id in db_case.images_associees_ids:
            img = media_service.get_image_medicale_by_id(db, image_id=img_id)
            if img:
                images.append(img)
    case_dict['images_associees'] = images

    # 5. Enrichir : PrÃ©sentation Clinique DÃ©taillÃ©e
    # Le champ 'presentation_clinique' en base contient juste des IDs.
    # Nous devons aller chercher les objets SymptÃ´mes complets.
    symptomes_details_in_case = []
    presentation_dict = db_case.presentation_clinique or {}
    
    if 'symptomes_patient' in presentation_dict:
        for item in presentation_dict['symptomes_patient']:
            # item ressemble Ã  {'symptome_id': 1, 'details': 'FiÃ¨vre forte'}
            sympt_id = item.get('symptome_id')
            sympt_obj = symptom_service.get_symptom_by_id(db, symptom_id=sympt_id)
            
            if sympt_obj:
                symptomes_details_in_case.append({
                    "symptome": sympt_obj, # L'objet complet
                    "details": item.get('details', '')
                })
    
    case_dict['presentation_clinique_detail'] = {
        "histoire_maladie": presentation_dict.get('histoire_maladie', ''),
        "symptomes_patient": symptomes_details_in_case,
        "antecedents": presentation_dict.get('antecedents')
    }

    # 6. Validation et Retour
    # On passe le dictionnaire enrichi Ã  Pydantic pour qu'il le valide et le formate
    return schemas.clinical_case.ClinicalCase.model_validate(case_dict)

@router.patch("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def update_clinical_case(case_id: int, case_data: schemas.clinical_case.ClinicalCaseUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour un cas clinique.
    """
    db_case = clinical_case_service.update_case(db, case_id=case_id, case_update=case_data)
    if db_case is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Cas clinique non trouvÃ©.")
    # La conversion vers le schÃ©ma de rÃ©ponse se fait automatiquement
    return db_case


@router.delete("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def delete_clinical_case(case_id: int, db: Session = Depends(get_db)):
    """
    Supprime un cas clinique.
    """
    db_case = clinical_case_service.delete_case(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Cas clinique non trouvÃ©.")
    # La conversion vers le schÃ©ma de rÃ©ponse se fait automatiquement
    return db_case



@router.get("/{case_id}/simple", response_model=schemas.clinical_case.ClinicalCaseSimple)
def read_clinical_case_simple(case_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un cas clinique dans une structure simplifiÃ©e avec la pathologie principale complÃ¨te.
    Retourne exactement la mÃªme structure que ClinicalCaseSimple mais avec l'objet pathologie_principale complet.
    """
    # RÃ©cupÃ©rer le cas
    db_case = clinical_case_service.get_case_by_id(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=404, detail="Cas clinique non trouvÃ©.")
    
    # Construire la rÃ©ponse simple
    case_simple = schemas.clinical_case.ClinicalCaseSimple(
        id=db_case.id,
        code_fultang=db_case.code_fultang,
        niveau_difficulte=db_case.niveau_difficulte,
        pathologie_principale=db_case.pathologie_principale,  # L'objet complet sera sÃ©rialisÃ©
        nb_images=len(db_case.images_associees_ids) if db_case.images_associees_ids else 0,
        nb_sons=len(db_case.sons_associes_ids) if db_case.sons_associes_ids else 0,
    )
    
    return case_simple

=== Fichier: ./app/api/v1/knowledge_graph.py ===



=== Fichier: ./app/api/v1/medications.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import medication_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/medications",
    tags=["Medications"]
)


@router.post("/", response_model=schemas.medication.Medication, status_code=status.HTTP_201_CREATED)
def create_medication(medication_data: schemas.medication.MedicationCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e un nouveau mÃ©dicament.
    VÃ©rifie l'unicitÃ© du DCI (DÃ©nomination Commune Internationale).
    """
    db_medication = medication_service.get_medication_by_dci(db, dci=medication_data.dci)
    if db_medication:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Un mÃ©dicament avec le DCI '{medication_data.dci}' existe dÃ©jÃ ."
        )
    return medication_service.create_medication(db=db, medication=medication_data)


@router.get("/", response_model=List[schemas.medication.Medication])
def read_medications(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de mÃ©dicaments.
    """
    medications = medication_service.get_all_medications(db, skip=skip, limit=limit)
    return medications


@router.get("/{medication_id}", response_model=schemas.medication.Medication)
def read_medication(medication_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un mÃ©dicament par son ID.
    """
    db_medication = medication_service.get_medication_by_id(db, medication_id=medication_id)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="MÃ©dicament non trouvÃ©.")
    return db_medication


@router.patch("/{medication_id}", response_model=schemas.medication.Medication)
def update_medication(medication_id: int, medication_data: schemas.medication.MedicationUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour un mÃ©dicament.
    """
    db_medication = medication_service.update_medication(db, medication_id=medication_id, medication_update=medication_data)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="MÃ©dicament non trouvÃ©.")
    return db_medication


@router.delete("/{medication_id}", response_model=schemas.medication.Medication)
def delete_medication(medication_id: int, db: Session = Depends(get_db)):
    """
    Supprime un mÃ©dicament.
    """
    db_medication = medication_service.delete_medication(db, medication_id=medication_id)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="MÃ©dicament non trouvÃ©.")
    return db_medication

=== Fichier: ./app/api/v1/symptoms.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import symptom_service
from ...dependencies import get_db

# CrÃ©ation d'un nouveau routeur.
# C'est comme une mini-application FastAPI que l'on pourra inclure dans notre app principale.
router = APIRouter(
    prefix="/symptoms",  # Toutes les routes de ce fichier commenceront par /symptoms
    tags=["Symptoms"]      # Groupe les routes dans la documentation interactive
)


@router.post("/", response_model=schemas.Symptom, status_code=status.HTTP_201_CREATED)
def create_symptom(symptom: schemas.SymptomCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e un nouveau symptÃ´me.
    """
    # VÃ©rifie si un symptÃ´me avec le mÃªme nom existe dÃ©jÃ 
    db_symptom = symptom_service.get_symptom_by_name(db, name=symptom.nom)
    if db_symptom:
        raise HTTPException(status_code=400, detail="Un symptÃ´me avec ce nom existe dÃ©jÃ .")
    
    return symptom_service.create_symptom(db=db, symptom=symptom)


@router.get("/", response_model=List[schemas.Symptom])
def read_symptoms(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de symptÃ´mes.
    """
    symptoms = symptom_service.get_all_symptoms(db, skip=skip, limit=limit)
    return symptoms


@router.get("/{symptom_id}", response_model=schemas.Symptom)
def read_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un symptÃ´me par son ID.
    """
    db_symptom = symptom_service.get_symptom_by_id(db, symptom_id=symptom_id)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="SymptÃ´me non trouvÃ©.")
    return db_symptom


@router.patch("/{symptom_id}", response_model=schemas.Symptom)
def update_symptom(symptom_id: int, symptom: schemas.SymptomUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour un symptÃ´me.
    """
    db_symptom = symptom_service.update_symptom(db, symptom_id=symptom_id, symptom_update=symptom)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="SymptÃ´me non trouvÃ©.")
    return db_symptom


@router.delete("/{symptom_id}", response_model=schemas.Symptom)
def delete_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    Supprime un symptÃ´me.
    """
    db_symptom = symptom_service.delete_symptom(db, symptom_id=symptom_id)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="SymptÃ´me non trouvÃ©.")
    return db_symptom

# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/symptoms.py

@router.get(
    "/{symptom_id}/diseases",
    response_model=List[schemas.relations.DiseaseForSymptomDetail],
    tags=["Disease-Symptom Relations"]
)
def get_diseases_for_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste de toutes les pathologies pouvant prÃ©senter ce symptÃ´me
    (utile pour le diagnostic diffÃ©rentiel).
    """
    associations = symptom_service.get_diseases_for_symptom(db, symptom_id=symptom_id)
    if not associations:
        return []
        
    response = []
    for assoc in associations:
        response.append({
            "pathologie": assoc.pathologie,
            "probabilite": assoc.probabilite,
            "importance_diagnostique": assoc.importance_diagnostique
        })
    return response



# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/symptoms.py

@router.post(
    "/{symptom_id}/treatments",
    response_model=schemas.relations.TraitementSymptome,
    status_code=status.HTTP_201_CREATED,
    tags=["Therapeutic Relations"]
)
def add_treatment_to_symptom(
    symptom_id: int,
    association_data: schemas.relations.TraitementSymptomeCreate,
    db: Session = Depends(get_db)
):
    """
    Associe un mÃ©dicament Ã  un symptÃ´me pour un traitement symptomatique.
    """
    if symptom_id != association_data.symptome_id:
        raise HTTPException(status_code=400, detail="IncohÃ©rence des IDs de symptÃ´me.")
    
    try:
        return symptom_service.add_treatment_to_symptom(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get(
    "/{symptom_id}/treatments",
    response_model=List[schemas.relations.MedicationForSymptomDetail],
    tags=["Therapeutic Relations"]
)
def get_treatments_for_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste des traitements pour un symptÃ´me spÃ©cifique.
    """
    associations = symptom_service.get_treatments_for_symptom(db, symptom_id=symptom_id)
    return [
        {
            "medicament": assoc.medicament,
            "efficacite": assoc.efficacite,
            "rang_preference": assoc.rang_preference,
        }
        for assoc in associations
    ]

=== Fichier: ./app/api/__init__.py ===



=== Fichier: ./app/database.py ===

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from .config import settings

# L'objet 'engine' est le point d'entrÃ©e principal pour communiquer avec la BDD.
engine = create_engine(
    settings.DATABASE_URL,
    # pool_pre_ping=True # Option utile en production
)

# La 'SessionLocal' est une "usine" Ã  sessions de base de donnÃ©es.
# Chaque fois que nous aurons besoin de parler Ã  la BDD, nous demanderons une session Ã  cette usine.
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

=== Fichier: ./app/models/tutor_models.py ===

from sqlalchemy import Column, Integer, String, Text, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean
from sqlalchemy.orm import relationship
from sqlalchemy.dialects.postgresql import UUID
from .base import Base

class LearningPath(Base):
    __tablename__ = "learning_paths"

    id = Column(Integer, primary_key=True, index=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    
    algorithme_recommandation = Column(String(100))
    ordered_case_ids = Column(JSON, comment="Liste ordonnÃ©e des IDs des cas") 
    progression = Column(Float, default=0.0)
    status = Column(String(50), default="in_progress")
    created_at = Column(TIMESTAMP, server_default=text("now()"))

    learner = relationship("Learner")


class TutorDecision(Base):
    __tablename__ = "tutor_decisions"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    trigger_event_id = Column(Integer, ForeignKey("interaction_logs.id"), nullable=True)
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    strategy_used = Column(String(100)) # Socratique, Scaffolding...
    action_choisie = Column(String(100)) # Hint, Encouragement
    intervention_content = Column(Text)
    rationale = Column(JSON) # Pourquoi j'ai fait Ã§a ?
    succes_intervention = Column(Boolean, nullable=True)

    session = relationship("SimulationSession", back_populates="tutor_decisions")


class TutorStrategiesHistory(Base):
    __tablename__ = "tutor_strategies_history"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    strategy_name = Column(String(100))
    relevance_score = Column(Float)


class TutorScaffoldingState(Base):
    __tablename__ = "tutor_scaffolding_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    competence_cible_id = Column(Integer, ForeignKey("competences_cliniques.id"))
    current_level = Column(Integer, default=0)
    indices_deja_donnes = Column(JSON)


class TutorSocraticState(Base):
    __tablename__ = "tutor_socratic_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    tactic_used = Column(String(100))
    target_concept = Column(String(255))
    step_in_dialogue = Column(Integer)


class TutorMotivationalState(Base):
    __tablename__ = "tutor_motivational_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    intervention_type = Column(String(100))
    emotional_state_before = Column(JSON)


class TutorFeedbackLog(Base):
    __tablename__ = "tutor_feedback_logs"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    feedback_type = Column(String(50))
    content = Column(Text)

=== Fichier: ./app/models/symptom.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    Boolean,
    JSON,
    TIMESTAMP,
    text
)
from pgvector.sqlalchemy import Vector
from sqlalchemy.orm import relationship

from .base import Base


class Symptom(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des symptÃ´mes.

    Cette table est le catalogue central de tous les symptÃ´mes connus par le systÃ¨me expert.
    Elle inclut des informations dÃ©taillÃ©es pour permettre un raisonnement clinique fin
    et des recherches sÃ©mantiques.
    """
    __tablename__ = "symptomes"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et CatÃ©gorisation ---
    nom = Column(String(255), nullable=False, unique=True, index=True)
    nom_local = Column(String(255), comment="Nom vernaculaire ou local, ex: 'Ntou-tou' pour la toux")
    categorie = Column(String(100), index=True, comment="CatÃ©gorie fonctionnelle (ex: Respiratoire, Neurologique, Digestif)")
    type_symptome = Column(String(50), comment="Type de symptÃ´me (ex: Subjectif, Objectif, Signe clinique)")

    # --- Description et Contexte Clinique ---
    description = Column(Text, comment="Description dÃ©taillÃ©e du symptÃ´me et de sa signification clinique.")
    questions_anamnese = Column(JSON, comment="Liste structurÃ©e de questions pour explorer ce symptÃ´me (ex: PQRST)")
    signes_alarme = Column(Boolean, default=False, nullable=False, comment="Indique si ce symptÃ´me est un signe de gravitÃ© ('red flag')")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    # Relation vers la table d'association 'pathologie_symptomes'
    # 'back_populates' assure la synchronisation de la relation des deux cÃ´tÃ©s.
    # 'cascade' signifie que si un symptÃ´me est supprimÃ©, ses associations le seront aussi.
    pathologies = relationship(
        "PathologieSymptome",
        back_populates="symptome",
        cascade="all, delete-orphan"
    )
    traitements = relationship(
        "TraitementSymptome",
        back_populates="symptome",
        cascade="all, delete-orphan"
    )

    def __repr__(self) -> str:
        return f"<Symptom(id={self.id}, nom='{self.nom}')>"

=== Fichier: ./app/models/medication.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    text
)
from pgvector.sqlalchemy import Vector
from sqlalchemy.orm import relationship
from .base import Base


class Medication(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des mÃ©dicaments.

    Cette table est le catalogue central de tous les mÃ©dicaments connus par le systÃ¨me,
    incluant des informations pharmacologiques et contextuelles (disponibilitÃ©, coÃ»t).
    """
    __tablename__ = "medicaments"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification ---
    nom_commercial = Column(String(255), index=True)
    dci = Column(String(255), nullable=False, index=True, comment="DÃ©nomination Commune Internationale")
    
    # --- Classification et Formulation ---
    classe_therapeutique = Column(String(255), index=True)
    forme_galenique = Column(String(100), comment="Ex: ComprimÃ©, Sirop, Injectable")
    dosage = Column(String(100))
    voie_administration = Column(String(100), comment="Ex: Orale, IV, IM, CutanÃ©e")

    # --- Informations Pharmacologiques ---
    mecanisme_action = Column(Text)
    indications = Column(JSON)
    contre_indications = Column(JSON)
    effets_secondaires = Column(JSON)
    interactions_medicamenteuses = Column(JSON)
    precautions_emploi = Column(Text)
    posologie_standard = Column(JSON, comment="Posologie standard par Ã¢ge, poids, indication")

    # --- Contexte Local (Cameroun) ---
    disponibilite_cameroun = Column(String(50), comment="Ex: Urbain, Rural, CHU_uniquement")
    cout_moyen_fcfa = Column(Integer)
    statut_prescription = Column(String(50), comment="Ex: Prescription_obligatoire, OTC")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    traitements_pathologies = relationship("TraitementPathologie", back_populates="medicament")
    traitements_symptomes = relationship("TraitementSymptome", back_populates="medicament")

    def __repr__(self) -> str:
        return f"<Medication(id={self.id}, dci='{self.dci}')>"

=== Fichier: ./app/models/clinical_case.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    ForeignKey,
    ARRAY,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class ClinicalCase(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des cas cliniques enrichis.
    C'est l'objet central utilisÃ© pour les scÃ©narios d'apprentissage.
    """
    __tablename__ = "cas_cliniques_enrichis"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et IntÃ©gritÃ© ---
    code_fultang = Column(String(100), unique=True, index=True, comment="Identifiant unique provenant de Fultang (ou synthÃ©tique)")
    hash_integrite = Column(String(64), nullable=True, comment="SHA-256 pour la preuve d'intÃ©gritÃ© des donnÃ©es brutes")

    # --- Liaisons aux Connaissances de Base ---
    pathologie_principale_id = Column(Integer, ForeignKey("pathologies.id"), nullable=True, index=True)
    pathologies_secondaires_ids = Column(ARRAY(Integer), comment="Liste d'IDs de pathologies comorbides ou secondaires")

    # --- DonnÃ©es du ScÃ©nario ---
    donnees_brutes = Column(JSON, nullable=True, comment="DonnÃ©es originales (ex: de Fultang) avant traitement")
    presentation_clinique = Column(JSON, nullable=False, comment="Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.")
    donnees_paracliniques = Column(JSON, comment="RÃ©sultats des examens pour ce cas spÃ©cifique")
    evolution_patient = Column(Text, comment="Description de l'Ã©volution du patient pendant le cas")
    
    # --- Liaisons MultimÃ©dia ---
    images_associees_ids = Column(ARRAY(Integer), comment="Liste des IDs des images de la table 'images_medicales'")
    sons_associes_ids = Column(ARRAY(Integer), comment="Liste des IDs des sons de la table 'sons_medicaux'")

    # --- Liaisons ThÃ©rapeutiques ---
    medicaments_prescrits = Column(JSON, comment="Liste des mÃ©dicaments prescrits dans ce cas")

    # --- MÃ©tadonnÃ©es PÃ©dagogiques ---
    niveau_difficulte = Column(Integer, default=3, comment="DifficultÃ© du cas (1-5)")
    duree_estimee_resolution_min = Column(Integer, comment="Temps estimÃ© pour rÃ©soudre le cas")
    objectifs_apprentissage = Column(JSON, comment="Liste des compÃ©tences Ã  acquÃ©rir")
    competences_requises = Column(JSON, comment="Mapping Q-Matrix pour ce cas")

    valide_expert = Column(Boolean, default=False)
    
    # ClÃ© Ã©trangÃ¨re vers la table experts
    expert_validateur_id = Column(Integer, ForeignKey("experts.id"), nullable=True)
    
    # Relation avec ExpertUser
    expert_validateur = relationship("ExpertUser", back_populates="cas_valides")
    date_validation = Column(Date)

    qualite_donnees = Column(Integer, comment="QualitÃ© des donnÃ©es sources (1-5)")

    # --- MÃ©triques d'Utilisation ---
    nb_utilisations = Column(Integer, default=0)
    note_moyenne_apprenants = Column(DECIMAL(3, 2))
    taux_succes_diagnostic = Column(DECIMAL(5, 2))
    
    # --- Intelligence Artificielle ---
    embedding_texte = Column(Vector(384), nullable=True, comment="Embedding de la description textuelle du cas")
    embedding_global = Column(Vector(1536), nullable=True, comment="Embedding multimodal fusionnÃ© (texte+image+son)")
    
    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    pathologie_principale = relationship("Disease")

    def __repr__(self) -> str:
        return f"<ClinicalCase(id={self.id}, code='{self.code_fultang}')>"

=== Fichier: ./app/models/learner_models.py ===

from sqlalchemy import Column, Integer, String, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean
from sqlalchemy.orm import relationship
from .base import Base

class Learner(Base):
    __tablename__ = "learners"

    id = Column(Integer, primary_key=True, index=True)
    matricule = Column(String(50), unique=True, index=True)
    nom = Column(String(255))
    email = Column(String(255), unique=True, index=True)
    niveau_etudes = Column(String(50)) # Med 3, Interne...
    specialite_visee = Column(String(100))
    langue_preferee = Column(String(10), default="fr")
    date_inscription = Column(TIMESTAMP, server_default=text("now()"))

    # Relations
    competency_mastery = relationship("LearnerCompetencyMastery", back_populates="learner")
    misconceptions = relationship("LearnerMisconception", back_populates="learner")
    sessions = relationship("SimulationSession", back_populates="learner")


class LearnerCompetencyMastery(Base):
    __tablename__ = "learner_competency_mastery"

    id = Column(Integer, primary_key=True, index=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    mastery_level = Column(Float, default=0.0) # ProbabilitÃ© BKT (0-1)
    confidence = Column(Float, default=0.0) # Certitude du systÃ¨me
    last_practice_date = Column(TIMESTAMP)
    nb_success = Column(Integer, default=0)
    nb_failures = Column(Integer, default=0)
    streak_correct = Column(Integer, default=0)

    learner = relationship("Learner", back_populates="competency_mastery")
    competence = relationship("Competence") # Lien vers Module Expert


class LearnerCognitiveProfile(Base):
    __tablename__ = "learner_cognitive_profiles"

    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), unique=True)
    
    vitesse_assimilation = Column(Float)
    capacite_memoire_travail = Column(Float)
    tendance_impulsivite = Column(Float) # 0 (RÃ©flÃ©chi) - 1 (Impulsif)
    prefer_visual = Column(Boolean, default=False)
    
    learner = relationship("Learner")


class LearnerMisconception(Base):
    __tablename__ = "learner_misconceptions"

    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    
    type_erreur = Column(String(255)) # ex: "Confond Virus/BactÃ©rie"
    frequence_apparition = Column(Integer, default=1)
    resistance_correction = Column(Float, default=0.0) # 0-1
    detected_at = Column(TIMESTAMP, server_default=text("now()"))
    
    learner = relationship("Learner", back_populates="misconceptions")


class LearnerGoal(Base):
    __tablename__ = "learner_goals"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    type_objectif = Column(String(100))
    domaine_cible = Column(String(100))
    date_limite = Column(TIMESTAMP)
    statut = Column(String(50)) # en_cours, atteint, abandonne


class LearnerPreference(Base):
    __tablename__ = "learner_preferences"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    cle = Column(String(100))
    valeur = Column(String(255))


class LearnerAchievement(Base):
    __tablename__ = "learner_achievements"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    badge_id = Column(String(100))
    date_obtention = Column(TIMESTAMP, server_default=text("now()"))


class LearnerStrategy(Base):
    __tablename__ = "learner_strategies"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    strategy_name = Column(String(100)) # ex: "Gaming", "Help Seeking"
    frequency = Column(Integer)
    effectiveness = Column(Float)

=== Fichier: ./app/models/relations.py ===

from sqlalchemy import (
    JSON,
    Column,
    Integer,
    ForeignKey,
    DECIMAL,
    String,
    Boolean,
    Text
)
from sqlalchemy.orm import relationship

from .base import Base


class PathologieSymptome(Base):
    """
    ModÃ¨le de la table d'association entre Pathologies et SymptÃ´mes.

    Cette table matÃ©rialise la relation "plusieurs-Ã -plusieurs" et permet de stocker
    des informations contextuelles sur le lien, telles que la probabilitÃ©
    d'apparition, la spÃ©cificitÃ©, etc.
    """
    __tablename__ = "pathologie_symptomes"

    id = Column(Integer, primary_key=True)

    # --- ClÃ©s Ã‰trangÃ¨res ---
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=False)
    symptome_id = Column(Integer, ForeignKey("symptomes.id"), nullable=False)

    # --- Attributs de la Relation ---
    probabilite = Column(DECIMAL(5, 4), comment="ProbabilitÃ© d'apparition du symptÃ´me pour cette pathologie P(symptÃ´me|pathologie)")
    sensibilite = Column(DECIMAL(5, 4))
    specificite = Column(DECIMAL(5, 4))
    phase_maladie = Column(String(50), comment="Phase de la maladie oÃ¹ le symptÃ´me apparaÃ®t (ex: PrÃ©coce, Tardive)")
    frequence = Column(String(50), comment="FrÃ©quence d'apparition (ex: Constant, FrÃ©quent, Occasionnel)")
    est_pathognomonique = Column(Boolean, default=False, comment="Si True, ce symptÃ´me seul suffit presque Ã  poser le diagnostic")
    importance_diagnostique = Column(Integer, comment="Ã‰chelle de 1 Ã  5 sur l'importance de ce symptÃ´me pour le diagnostic")

    # --- Relations Inverses (Back-population) ---
    # Permet d'accÃ©der Ã  l'objet parent directement depuis une instance de cette classe.
    # ex: mon_association.pathologie -> renvoie l'objet Disease
    pathologie = relationship("Disease", back_populates="symptomes")
    symptome = relationship("Symptom", back_populates="pathologies")

    def __repr__(self) -> str:
        return f"<PathologieSymptome(pathologie_id={self.pathologie_id}, symptome_id={self.symptome_id})>"
    

# Contenu Ã  AJOUTER Ã  la fin de app/models/relations.py

class TraitementPathologie(Base):
    """
    Table d'association pour les traitements spÃ©cifiques aux pathologies.
    """
    __tablename__ = "traitements_pathologies"

    id = Column(Integer, primary_key=True)
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=False)
    medicament_id = Column(Integer, ForeignKey("medicaments.id"), nullable=False)

    type_traitement = Column(String(50), comment="Ex: Premiere_intention, Alternative, Adjuvant")
    ligne_traitement = Column(Integer, comment="Ex: 1Ã¨re ligne, 2e ligne")
    indication_precise = Column(Text)
    efficacite_taux = Column(DECIMAL(5, 2), comment="Taux de succÃ¨s en %")
    duree_traitement_jours = Column(Integer)
    posologie_detaillee = Column(JSON)
    niveau_preuve = Column(String(50), comment="Grade de recommandation (A, B, C)")
    guidelines_source = Column(String(255), comment="Source (OMS, MINSANTE Cameroun, etc.)")
    rang_preference = Column(Integer, default=99)

    pathologie = relationship("Disease", back_populates="traitements")
    medicament = relationship("Medication", back_populates="traitements_pathologies")


class TraitementSymptome(Base):
    """
    Table d'association pour les traitements symptomatiques.
    """
    __tablename__ = "traitements_symptomes"

    id = Column(Integer, primary_key=True)
    symptome_id = Column(Integer, ForeignKey("symptomes.id"), nullable=False)
    medicament_id = Column(Integer, ForeignKey("medicaments.id"), nullable=False)

    efficacite = Column(String(50), comment="Ex: Tres_efficace, Efficace, Modere")
    rapidite_action = Column(String(100), comment="Ex: Immediate, <30min")
    posologie_recommandee = Column(Text)
    rang_preference = Column(Integer, default=99)
    
    symptome = relationship("Symptom", back_populates="traitements")
    medicament = relationship("Medication", back_populates="traitements_symptomes")




=== Fichier: ./app/models/tracking_models.py ===

from sqlalchemy import Column, Integer, String, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean, Text
from sqlalchemy.orm import relationship
from sqlalchemy.dialects.postgresql import UUID
import uuid
from .base import Base

class SimulationSession(Base):
    __tablename__ = "simulation_sessions"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    cas_clinique_id = Column(Integer, ForeignKey("cas_cliniques_enrichis.id"), nullable=False)
    
    start_time = Column(TIMESTAMP, server_default=text("now()"))
    end_time = Column(TIMESTAMP)
    score_final = Column(Float)
    temps_total = Column(Integer)
    cout_virtuel_genere = Column(Integer)
    statut = Column(String(50), default="en_cours")
    raison_fin = Column(String(100))
    current_stage = Column(String(50))
    context_state = Column(JSON)

    learner = relationship("Learner", back_populates="sessions")
    cas_clinique = relationship("ClinicalCase")
    
    # --- Relations ---
    messages = relationship("ChatMessage", back_populates="session", cascade="all, delete-orphan")
    tutor_decisions = relationship("TutorDecision", back_populates="session")
    
    # --- RELATION VERS INTERACTION LOG CORRIGÃ‰E ET ACTIVÃ‰E ---
    logs = relationship("InteractionLog", back_populates="session", cascade="all, delete-orphan")
    # ----------------------------------------------------

class ChatMessage(Base):
    __tablename__ = "chat_messages"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"), nullable=False)
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    sender = Column(String(50), nullable=False) # student, patient, tutor
    content = Column(Text, nullable=False)
    
    # Suppression des champs qui n'existent plus dans la migration la plus rÃ©cente
    # intention_detectee = Column(String(100))
    # sentiment_analyse = Column(String(50))
    message_metadata = Column(JSON)

    session = relationship("SimulationSession", back_populates="messages")


# === CLASSE 'InteractionLog' AJOUTÃ‰E ===
# Ce modÃ¨le manquait, ce qui causait l'ImportError.
class InteractionLog(Base):
    __tablename__ = "interaction_logs"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    action_category = Column(String(50))
    action_type = Column(String(100))
    action_content = Column(JSON)
    response_latency = Column(Integer)
    charge_cognitive_estimee = Column(Float)
    est_pertinent = Column(Boolean)

    session = relationship("SimulationSession", back_populates="logs")


# === CLASSE 'LearnerAffectiveState' AJOUTÃ‰E ===
# Ce modÃ¨le Ã©tait Ã©galement importÃ© dans __init__.py mais manquant dans ce fichier.
class LearnerAffectiveState(Base):
    __tablename__ = "learner_affective_states"

    id = Column(Integer, primary_key=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    stress_level = Column(Float)
    confidence_level = Column(Float)
    motivation_level = Column(Float)
    frustration_level = Column(Float)

    session = relationship("SimulationSession")

=== Fichier: ./app/models/prerequisite.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    ForeignKey,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship

from .base import Base


class Competence(Base):
    """
    ModÃ¨le SQLAlchemy pour les compÃ©tences cliniques (Knowledge Components).
    """
    __tablename__ = "competences_cliniques"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification ---
    code_competence = Column(String(50), unique=True, nullable=False, index=True, comment="Code unique (ex: 'ANAMNESE_DOULEUR')")
    nom = Column(String(255), nullable=False)
    categorie = Column(String(100), index=True, comment="Ex: Anamnese, Examen_physique, Raisonnement, Technique")
    
    # --- PÃ©dagogie ---
    niveau_bloom = Column(Integer, comment="Niveau dans la taxonomie de Bloom (1-6)")
    description = Column(Text)
    objectifs_apprentissage = Column(JSON, comment="Liste dÃ©taillÃ©e des objectifs")
    criteres_maitrise = Column(JSON, comment="CritÃ¨res pour valider la compÃ©tence")
    
    # --- HiÃ©rarchie (Parent/Enfant) ---
    parent_competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=True)
    ordre_apprentissage = Column(Integer, default=0)

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # --- Relations ---
    children = relationship("Competence", 
                          back_populates="parent",
                          cascade="all, delete-orphan")
    
    parent = relationship("Competence", 
                        back_populates="children",
                        remote_side=[id])

    # Relation vers les prÃ©requis
    prerequis = relationship(
        "Competence",
        secondary="prerequis_competences",
        primaryjoin="Competence.id==prerequis_competences.c.competence_id",
        secondaryjoin="Competence.id==prerequis_competences.c.prerequis_id",
        backref="est_prerequis_pour"
    )

    def __repr__(self) -> str:
        return f"<Competence(code='{self.code_competence}', nom='{self.nom}')>"


class PrerequisCompetence(Base):
    """
    Table d'association pour le graphe de prÃ©requis entre compÃ©tences.
    Permet de dire : "Pour apprendre A, il faut d'abord maÃ®triser B".
    """
    __tablename__ = "prerequis_competences"

    id = Column(Integer, primary_key=True)
    
    # La compÃ©tence cible (Celle qu'on veut apprendre)
    competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    # La compÃ©tence prÃ©requise (Celle qu'on doit dÃ©jÃ  avoir)
    prerequis_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    # --- MÃ©tadonnÃ©es de la relation ---
    type_relation = Column(String(50), default="STRICT", comment="STRICT, RECOMMANDE, SUPPORTIF")
    force_relation = Column(DECIMAL(3, 2), default=1.0, comment="Force du lien (0-1)")

    def __repr__(self) -> str:
        return f"<Prerequis(target={self.competence_id}, needed={self.prerequis_id})>"

=== Fichier: ./app/models/__init__.py ===

# ==============================================================================
# FICHIER D'INITIALISATION DU PACKAGE 'models'
# ------------------------------------------------------------------------------
# Ce fichier centralise l'importation de toutes les classes de modÃ¨les SQLAlchemy,
# les rendant facilement accessibles depuis le reste de l'application via
# l'import `from app import models`.
# ==============================================================================

# --- ModÃ¨le de Base ---
from .base import Base

# --- ModÃ¨les du Domaine Expert ---
from .symptom import Symptom
from .disease import Disease
from .medication import Medication
from .media import ImageMedicale
from .clinical_case import ClinicalCase
from .expert_strategy import ExpertStrategy
from .relations import PathologieSymptome, TraitementPathologie, TraitementSymptome
from .prerequisite import Competence, PrerequisCompetence
from .expert_user import ExpertUser

# --- ModÃ¨les de l'Apprenant ---
from .learner_models import (
    Learner,
    LearnerCompetencyMastery,
    LearnerCognitiveProfile,
    LearnerMisconception,
    LearnerGoal,
    LearnerPreference,
    LearnerAchievement,
    LearnerStrategy
)

# --- ModÃ¨les de Suivi (Tracking) ---
from .tracking_models import (
    SimulationSession,
    ChatMessage,
    # La ligne ci-dessous est la correction clÃ© pour l'erreur actuelle
    InteractionLog,
    LearnerAffectiveState
)

# --- ModÃ¨les du Tuteur ---
from .tutor_models import (
    LearningPath,
    TutorDecision,
    TutorStrategiesHistory,
    TutorScaffoldingState,
    TutorSocraticState,
    TutorMotivationalState,
    TutorFeedbackLog
)

# ==============================================================================
# FIN DU FICHIER
# ==============================================================================

=== Fichier: ./app/models/expert_user.py ===

from sqlalchemy import Column, Integer, String, Text, Boolean, TIMESTAMP, text
from sqlalchemy.orm import relationship
from .base import Base

class ExpertUser(Base):
    __tablename__ = "experts"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String(255), unique=True, index=True, nullable=False)
    hashed_password = Column(String(255), nullable=False)
    nom_complet = Column(String(255))
    specialite = Column(String(100))
    hopital_affiliation = Column(String(255))
    role = Column(String(50), default="validateur") # superadmin, validateur, contributeur
    
    last_login = Column(TIMESTAMP)
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # Relation avec les cas cliniques validÃ©s
    cas_valides = relationship("ClinicalCase", back_populates="expert_validateur")

=== Fichier: ./app/models/expert_strategy.py ===

from sqlalchemy import (
    DECIMAL,
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    text
)
from sqlalchemy.orm import relationship

from .base import Base


class ExpertStrategy(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des rÃ¨gles de production (stratÃ©gies expertes).
    
    Cette table stocke la logique IF-THEN du systÃ¨me expert.
    """
    __tablename__ = "regles_production"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et MÃ©tadonnÃ©es ---
    code_regle = Column(String(50), unique=True, nullable=False, index=True)
    categorie = Column(String(100), index=True, comment="Ex: DIAGNOSTIC, THERAPEUTIQUE, PEDAGOGIQUE, ALERTE")
    priorite = Column(Integer, default=5, comment="PrioritÃ© d'exÃ©cution (1-10), 10 Ã©tant le plus prioritaire")
    
    # --- Structure de la RÃ¨gle (IF-THEN) ---
    conditions = Column(JSON, nullable=False, comment="Partie 'IF' de la rÃ¨gle, structurÃ©e en JSON")
    # Exemple de 'conditions':
    # {
    #   "operator": "AND",
    #   "rules": [
    #     {"fact": "symptom", "value": "FiÃ¨vre", "operator": "present"},
    #     {"fact": "symptom", "value": "Toux", "operator": "present"},
    #     {"fact": "age", "value": 65, "operator": "greater_than"}
    #   ]
    # }

    actions = Column(JSON, nullable=False, comment="Partie 'THEN' de la rÃ¨gle, structurÃ©e en JSON")
    # Exemple d' 'actions':
    # [
    #   {"action": "add_hypothesis", "pathology": "Pneumonie", "confidence": 0.8},
    #   {"action": "recommend_exam", "exam": "Radio Thorax", "urgency": "high"}
    # ]

    # --- Documentation et Validation ---
    description_naturelle = Column(Text, comment="Description de la rÃ¨gle en langage naturel")
    justification_medicale = Column(Text, comment="Source ou justification clinique de la rÃ¨gle")
    expert_auteur = Column(String(255))
    date_validation = Column(Date)
    est_active = Column(Boolean, default=True, nullable=False)

    # --- MÃ©triques ---
    nb_activations = Column(Integer, default=0)
    taux_succes = Column(DECIMAL(5, 4))

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    def __repr__(self) -> str:
        return f"<ExpertStrategy(id={self.id}, code='{self.code_regle}')>"

=== Fichier: ./app/models/media.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    ForeignKey,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class ImageMedicale(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des images mÃ©dicales.
    Catalogue toutes les images (radios, scanners, etc.) avec leurs mÃ©tadonnÃ©es.
    """
    __tablename__ = "images_medicales"

    id = Column(Integer, primary_key=True, index=True)

    # --- Classification et Liaison ---
    type_examen = Column(String(100), nullable=False, index=True, comment="Ex: Radiographie, Ã‰chographie, Scanner")
    sous_type = Column(String(100), comment="Ex: Thorax, Abdomen, CrÃ¢ne")
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=True, index=True)

    # --- Gestion du Fichier ---
    fichier_url = Column(String(500), nullable=False, comment="URL vers le fichier (S3, stockage local, etc.)")
    fichier_miniature_url = Column(String(500), comment="URL vers une version miniature de l'image")
    format_image = Column(String(20), comment="Ex: DICOM, PNG, JPEG")
    taille_ko = Column(Integer)
    resolution = Column(String(50))

    # --- MÃ©tadonnÃ©es Cliniques ---
    description = Column(Text, comment="Description gÃ©nÃ©rale de l'image ou du cas")
    signes_radiologiques = Column(JSON, comment="Signes spÃ©cifiques visibles (ex: opacitÃ©, Ã©panchement)")
    annotations = Column(JSON, comment="CoordonnÃ©es et descriptions de zones d'intÃ©rÃªt")
    interpretation_experte = Column(Text, comment="Compte-rendu d'un radiologue expert")
    diagnostic_differentiel = Column(JSON, comment="Autres diagnostics possibles basÃ©s sur l'image")

    # --- MÃ©tadonnÃ©es PÃ©dagogiques ---
    niveau_difficulte = Column(Integer, comment="DifficultÃ© d'interprÃ©tation de l'image (1-5)")
    qualite_image = Column(Integer, comment="QualitÃ© technique de l'image (1-5)")

    # --- Intelligence Artificielle ---
    embedding_vision = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle")

    # --- Validation et Horodatage ---
    valide_expert = Column(Boolean, default=False)
    expert_validateur = Column(String(255))
    date_validation = Column(Date)
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # --- Relations ---
    # Permet d'accÃ©der Ã  l'objet Pathologie depuis une ImageMedicale
    pathologie = relationship("Disease") # Nous n'avons pas besoin de back_populates ici pour l'instant

    def __repr__(self) -> str:
        return f"<ImageMedicale(id={self.id}, type='{self.type_examen}')>"


=== Fichier: ./app/models/knowledge_version.py ===



=== Fichier: ./app/models/disease.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class Disease(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des pathologies (maladies).

    Cette table contient toutes les informations dÃ©taillÃ©es sur chaque maladie
    connue par le systÃ¨me, y compris le contexte local, les caractÃ©ristiques
    cliniques et les vecteurs pour l'IA.
    """
    __tablename__ = "pathologies"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et Classification ---
    code_icd10 = Column(String(20), unique=True, index=True, comment="Code international de la maladie (CIM-10)")
    nom_fr = Column(String(255), nullable=False, index=True)
    nom_en = Column(String(255))
    nom_local = Column(String(255), comment="Noms locaux ou courants au Cameroun")
    categorie = Column(String(100), index=True, comment="Ex: Infectieuse, Chronique, Parasitaire")

    # --- DonnÃ©es Cliniques et Ã‰pidÃ©miologiques ---
    prevalence_cameroun = Column(DECIMAL(5, 2), comment="PrÃ©valence en % dans le contexte camerounais")
    niveau_gravite = Column(Integer, comment="Ã‰chelle de 1 (bÃ©nin) Ã  5 (critique)")
    description = Column(Text)
    physiopathologie = Column(Text, comment="MÃ©canisme de la maladie")
    evolution_naturelle = Column(Text, comment="Comment la maladie Ã©volue sans traitement")
    complications = Column(JSON, comment="Complications possibles")
    facteurs_risque = Column(JSON, comment="Facteurs de risque associÃ©s")
    prevention = Column(Text, comment="Mesures de prÃ©vention")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    # Nous prÃ©parons le terrain pour la future relation avec les symptÃ´mes.
    # Pour l'instant, elle reste en commentaire pour Ã©viter les erreurs d'import circulaire.
    symptomes = relationship(
         "PathologieSymptome",
         back_populates="pathologie",
         cascade="all, delete-orphan"
    
     )
    
    traitements = relationship(
        "TraitementPathologie",
        back_populates="pathologie",
        cascade="all, delete-orphan"
    )

    def __repr__(self) -> str:
        return f"<Disease(id={self.id}, nom_fr='{self.nom_fr}')>"

=== Fichier: ./app/models/diagnostic.py ===



=== Fichier: ./app/models/base.py ===

from sqlalchemy.orm import declarative_base

# Cette instance de 'declarative_base' est le catalogue central oÃ¹ SQLAlchemy
# enregistrera toutes les classes de modÃ¨les que nous dÃ©finirons.
# C'est ce que Alembic utilisera pour comparer l'Ã©tat de notre code
# avec l'Ã©tat de la base de donnÃ©es.
Base = declarative_base()

=== Fichier: ./app/__init__.py ===



=== Fichier: ./app/services/fultang_integration/extractor.py ===



=== Fichier: ./app/services/fultang_integration/validator.py ===



=== Fichier: ./app/services/fultang_integration/__init__.py ===



=== Fichier: ./app/services/fultang_integration/anonymizer.py ===



=== Fichier: ./app/services/fultang_integration/case_generator.py ===



=== Fichier: ./app/services/simulation_service.py ===

import logging
from sqlalchemy.orm import Session
from uuid import UUID
from typing import Optional, List, Dict, Any
import json

from .. import models

logger = logging.getLogger(__name__)

def create_session(
    db: Session, 
    learner_id: int, 
    case_id: int, 
    session_type: str,
    formative_count: int = 0,
    formative_cases_pool: List[int] = None
) -> models.SimulationSession:
    """
    CrÃ©e un nouvel enregistrement de session de simulation dans la base de donnÃ©es.
    """
    logger.info(f"ğŸ”¨ [SESSION-FACTORY] CrÃ©ation session...")
    logger.info(f"   - Learner: {learner_id}")
    logger.info(f"   - Case: {case_id}")
    logger.info(f"   - Type: {session_type}")
    logger.info(f"   - Count: {formative_count}")
    
    # SÃ©curisation de la liste pour le JSON
    # On s'assure que c'est une liste d'entiers valide, mÃªme vide
    pool = formative_cases_pool if formative_cases_pool is not None else []
    logger.info(f"   - Pool (raw): {pool}")
    
    # Construction du contexte de session
    # On force la sÃ©rialisation JSON explicite pour Ã©viter les ambiguÃ¯tÃ©s SQLAlchemy
    context = {
        "session_type": session_type,
        "formative_count_since_eval": int(formative_count), # Force int
        "dialogue": [],
        "formative_cases_pool": pool
    }
    
    try:
        # CrÃ©ation de l'instance du modÃ¨le SQLAlchemy
        db_session = models.SimulationSession(
            learner_id=learner_id,
            cas_clinique_id=case_id,
            statut="in_progress",
            # SQLAlchemy gÃ¨re normalement la conversion dict -> JSONB/JSON
            # Mais si Ã§a plante, c'est souvent ici.
            context_state=context 
        )

        db.add(db_session)
        db.commit()
        db.refresh(db_session)

        logger.info(f"   âœ… [CREATED] Session ID: {db_session.id}")
        return db_session
        
    except Exception as e:
        logger.error(f"   âŒ [ERROR] Erreur lors de la crÃ©ation en BDD: {str(e)}")
        import traceback
        logger.error(traceback.format_exc()) # Traceback complet pour le debug
        db.rollback()
        raise e


def get_session_by_id(db: Session, session_id: UUID) -> Optional[models.SimulationSession]:
    """
    RÃ©cupÃ¨re une session de simulation par son ID.
    """
    return db.query(models.SimulationSession).filter(
        models.SimulationSession.id == session_id
    ).first()


def update_session_status(
    db: Session, 
    session_id: UUID, 
    new_status: str, 
    score: float = None
) -> models.SimulationSession:
    """
    Met Ã  jour le statut d'une session et optionnellement son score.
    """
    session = get_session_by_id(db, session_id)
    if not session:
        raise ValueError(f"Session {session_id} introuvable.")
    
    session.statut = new_status
    if score is not None:
        session.score_final = score
    
    db.commit()
    db.refresh(session)
    
    return session

=== Fichier: ./app/services/ai_generation_service.py ===

#=== Fichier: ./app/services/ai_generation_service.py ===

import logging
import requests
import json
import time
import uuid
import re
import traceback
from typing import Dict, Any, List, Tuple, Optional, Union
from enum import Enum

from sqlalchemy.orm import Session, joinedload
from .. import models, schemas
from ..config import settings
from ..core.prompts.exam_prompts import exam_prompt_builder

# ==============================================================================
# CONFIGURATION DU LOGGER "AI-KERNEL" (Niveau Expert / Debugging)
# ==============================================================================
# Ce logger est configurÃ© pour capturer absolument tout ce qui entre et sort.
# Il est distinct du logger principal pour permettre un filtrage fin.
logger = logging.getLogger("ai_kernel")
logger.setLevel(logging.DEBUG)

if not logger.handlers:
    handler = logging.StreamHandler()
    # Format enrichi : Date - Logger - Niveau - Fichier:Ligne - Message
    formatter = logging.Formatter(
        '%(asctime)s - [AI-KERNEL] - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)

# ==============================================================================
# CONSTANTES ET CONFIGURATION
# ==============================================================================

OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"

# ModÃ¨le choisi : Mistral 7B Instruct (Bon rapport qualitÃ©/prix/performance pour le roleplay)
# Alternatives testÃ©es : 'openai/gpt-4o-mini', 'anthropic/claude-3-haiku'
MODEL_NAME = "mistralai/devstral-2512:free" 

# Configuration de rÃ©silience
MAX_RETRIES_NETWORK = 3    # Tentatives en cas d'Ã©chec de connexion
MAX_RETRIES_LOGIC = 2      # Tentatives en cas de JSON malformÃ©
TIMEOUT_SECONDS = 60       # Timeout strict pour ne pas bloquer le worker

class AiTaskType(Enum):
    """Ã‰numÃ©ration des types de tÃ¢ches pour le tagging des logs."""
    CHAT_PATIENT = "CHAT_PATIENT"
    EXAM_GENERATION = "EXAM_GENERATION"
    EVALUATION = "EVALUATION"
    HINT_GENERATION = "HINT_GENERATION"

# ==============================================================================
# UTILITAIRES DE NETTOYAGE ET VALIDATION
# ==============================================================================

def _clean_json_string(json_str: str, trace_id: str = "N/A") -> str:
    """
    Nettoie une chaÃ®ne JSON brute renvoyÃ©e par un LLM.
    Les LLM aiment bien entourer le JSON de balises Markdown ```json ... ``` 
    ou ajouter du texte avant/aprÃ¨s ("Voici le rapport : ...").
    
    :param json_str: La chaÃ®ne brute reÃ§ue de l'API.
    :param trace_id: ID de traÃ§abilitÃ© pour les logs.
    :return: Une chaÃ®ne contenant uniquement le JSON potentiel.
    """
    original_len = len(json_str)
    
    # 1. Supprimer les balises Markdown (classique)
    if "```" in json_str:
        logger.debug(f"   ğŸ§¹ [{trace_id}] DÃ©tection de blocs Markdown, nettoyage en cours...")
        # Regex pour capturer le contenu entre ```json et ``` ou juste ``` et ```
        pattern = r"```(?:json)?\s*(.*?)\s*```"
        match = re.search(pattern, json_str, re.DOTALL)
        if match:
            json_str = match.group(1)
            logger.debug(f"   ğŸ§¹ [{trace_id}] Bloc Markdown extrait.")
    
    # 2. Trouver la premiÃ¨re accolade ouvrante et la derniÃ¨re fermante
    # Cela Ã©limine tout le texte introductif ("Sure, here is the JSON:")
    start = json_str.find("{")
    end = json_str.rfind("}")
    
    if start != -1 and end != -1:
        if start > 0 or end < len(json_str) - 1:
            logger.debug(f"   ğŸ§¹ [{trace_id}] Rognage du texte autour du JSON (Indices: {start} Ã  {end})")
            json_str = json_str[start : end + 1]
    
    final_len = len(json_str)
    if final_len != original_len:
        logger.debug(f"   âœ¨ [{trace_id}] Nettoyage terminÃ© : {original_len} -> {final_len} chars")
        
    return json_str.strip()

def _validate_exam_json_structure(data: Dict[str, Any], trace_id: str) -> bool:
    """
    VÃ©rifie que le JSON d'un examen contient les clÃ©s minimales requises.
    
    :param data: Le dictionnaire parsÃ©.
    :return: True si valide, False sinon.
    """
    required_keys = ["rapport_complet", "conclusion"]
    missing = [k for k in required_keys if k not in data]
    
    if missing:
        logger.error(f"   âŒ [{trace_id}] Validation JSON Ã©chouÃ©e. ClÃ©s manquantes : {missing}")
        return False
    
    # VÃ©rification du contenu non vide
    if not data.get("rapport_complet") or len(str(data["rapport_complet"])) < 10:
        logger.warning(f"   âš ï¸ [{trace_id}] Validation suspecte : 'rapport_complet' semble trop court.")
        # On laisse passer mais on logue le warning
        
    return True

# ==============================================================================
# NOYAU D'APPEL API (CORE)
# ==============================================================================

def _call_openrouter_api(
    input_data: Union[str, List[Dict[str, str]]], 
    json_mode: bool = False,
    temperature: float = 0.7,
    task_type: AiTaskType = AiTaskType.CHAT_PATIENT,
    max_tokens: int = 1500
) -> Any:
    """
    Fonction noyau (Core) pour appeler l'API LLM.
    Elle est conÃ§ue pour Ãªtre une boÃ®te noire totalement transparente via les logs.
    
    :param input_data: Le prompt (str) ou la liste de messages (list).
    :param json_mode: Force le modÃ¨le Ã  produire du JSON et active le validateur.
    :param temperature: CrÃ©ativitÃ© (0.0 = Rigide, 1.0 = Folie).
    :param task_type: Type de tÃ¢che pour le logging.
    """
    trace_id = f"AI-{str(uuid.uuid4())[:6].upper()}"
    
    logger.info(f"âš¡ [{trace_id}] DÃ‰BUT TRANSACTION API | TÃ¢che: {task_type.value} | Mode JSON: {json_mode}")
    logger.debug(f"   [{trace_id}] Config: Temp={temperature}, MaxTokens={max_tokens}, Model={MODEL_NAME}")

    # 1. Normalisation du Payload
    messages = []
    if isinstance(input_data, str):
        messages = [{"role": "user", "content": input_data}]
    else:
        messages = input_data

    # ==========================================================================
    # ğŸ” PROMPT DUMP - LOGGING EXTENSIF
    # ==========================================================================
    logger.debug(f"\n{'='*40} [{trace_id}] PROMPT ENVOYÃ‰ {'='*40}")
    for i, msg in enumerate(messages):
        role = msg.get('role', 'unknown').upper()
        content = msg.get('content', '')
        # Affichage sÃ©curisÃ© (tronquÃ© si trop long pour la console, mais on garde assez pour debug)
        display_content = content if len(content) < 2000 else f"{content[:2000]}... [TRONQUÃ‰ {len(content)-2000} chars]"
        logger.debug(f"[{i}] {role}:\n{display_content}\n{'-'*20}")
    logger.debug(f"{'='*100}\n")
    # ==========================================================================

    headers = {
        "Authorization": f"Bearer {settings.OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://expert-cmck.onrender.com",
        "X-Title": "STI Medical Expert System"
    }
    
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
    }

    if json_mode:
        # Hint pour les modÃ¨les compatibles OpenAI
        payload["response_format"] = {"type": "json_object"}

    # 2. Boucle de Tentatives (Retry Loop)
    attempt = 0
    
    while attempt < MAX_RETRIES_NETWORK:
        attempt += 1
        start_time = time.time()
        
        try:
            if attempt > 1:
                logger.warning(f"   ğŸ”„ [{trace_id}] Tentative rÃ©seau {attempt}/{MAX_RETRIES_NETWORK}...")
                # Backoff exponentiel (2s, 4s, 8s...)
                sleep_time = 2 ** attempt
                time.sleep(sleep_time)

            logger.debug(f"   ğŸš€ [{trace_id}] Envoi requÃªte POST vers {OPENROUTER_API_URL}...")
            
            response = requests.post(
                OPENROUTER_API_URL, 
                headers=headers, 
                data=json.dumps(payload), 
                timeout=TIMEOUT_SECONDS
            )
            
            latency = time.time() - start_time
            
            # --- Analyse de la RÃ©ponse HTTP ---
            if response.status_code == 200:
                response_data = response.json()
                
                # Metrics d'utilisation
                usage = response_data.get('usage', {})
                p_tok = usage.get('prompt_tokens', 0)
                c_tok = usage.get('completion_tokens', 0)
                logger.info(f"   âœ… [{trace_id}] SuccÃ¨s HTTP 200 | Latence: {latency:.2f}s | Tokens: {p_tok} in / {c_tok} out")

                # Extraction du contenu
                try:
                    if not response_data.get('choices'):
                        raise ValueError("Liste 'choices' vide dans la rÃ©ponse API")

                    choice = response_data['choices'][0]
                    raw_content = choice['message']['content']
                    finish_reason = choice.get('finish_reason', 'unknown')
                    
                    if finish_reason == 'length':
                        logger.warning(f"   âš ï¸ [{trace_id}] Attention: La rÃ©ponse a Ã©tÃ© tronquÃ©e (max_tokens atteint). Le JSON risque d'Ãªtre cassÃ©.")

                    # ==========================================================
                    # ğŸ” RESPONSE DUMP
                    # ==========================================================
                    logger.debug(f"\n{'='*40} [{trace_id}] RÃ‰PONSE BRUTE IA {'='*40}")
                    logger.debug(f"{raw_content}")
                    logger.debug(f"{'='*100}\n")
                    # ==========================================================

                    # Traitement JSON si requis
                    if json_mode:
                        cleaned_content = _clean_json_string(raw_content, trace_id)
                        try:
                            parsed_json = json.loads(cleaned_content)
                            logger.info(f"   âœ… [{trace_id}] JSON parsÃ© et validÃ© techniquement.")
                            return parsed_json
                        except json.JSONDecodeError as je:
                            logger.error(f"   âŒ [{trace_id}] Ã‰chec du parsing JSON.")
                            logger.error(f"      Source nettoyÃ©e : {cleaned_content}")
                            logger.error(f"      Erreur Python : {str(je)}")
                            
                            # Logique de Retry "Logique" (si on n'a pas Ã©puisÃ© les essais)
                            # On pourrait relancer l'appel en disant Ã  l'IA qu'elle s'est trompÃ©e,
                            # mais pour ce prototype, on lÃ¨ve l'erreur pour le catch global.
                            raise ValueError(f"L'IA n'a pas produit un JSON valide : {str(je)}")
                    
                    # Mode texte simple
                    return raw_content

                except (KeyError, IndexError, ValueError) as e:
                    logger.error(f"   âŒ [{trace_id}] Erreur structurelle rÃ©ponse API : {str(e)}")
                    # On ne retry pas une erreur de structure interne, c'est probablement fatal
                    raise e

            elif response.status_code == 429:
                logger.warning(f"   âš ï¸ [{trace_id}] Rate Limit atteint (429). Pause forcÃ©e.")
                time.sleep(5) # Pause fixe
                continue 
            
            elif response.status_code >= 500:
                logger.error(f"   ğŸ”¥ [{trace_id}] Erreur Serveur IA ({response.status_code}).")
                logger.debug(f"      Body: {response.text}")
                continue
            
            else:
                # Erreur client (400, 401, 403) -> Pas de retry
                logger.critical(f"   â›” [{trace_id}] Erreur Client {response.status_code}.")
                logger.critical(f"      RÃ©ponse: {response.text}")
                response.raise_for_status()

        except requests.exceptions.RequestException as e:
            logger.error(f"   ğŸŒ [{trace_id}] Exception RÃ©seau : {str(e)}")
            continue

    # Si on sort de la boucle, c'est l'Ã©chec total
    logger.critical(f"   ğŸ’€ [{trace_id}] Ã‰CHEC TOTAL aprÃ¨s {MAX_RETRIES_NETWORK} tentatives rÃ©seaux.")
    
    if json_mode:
        return {} 
    return "(Erreur technique : Le service d'IA est injoignable pour le moment.)"


# ==============================================================================
# SERVICES MÃ‰TIERS (Business Logic)
# ==============================================================================

def generate_patient_reply_chat(messages: List[Dict[str, str]]) -> str:
    """
    GÃ©nÃ¨re la rÃ©plique du patient (Mode Chat).
    
    Cette fonction est appelÃ©e par le PatientActorService.
    Elle privilÃ©gie une tempÃ©rature Ã©levÃ©e pour la variÃ©tÃ© et le naturel.
    """
    try:
        response = _call_openrouter_api(
            input_data=messages,
            json_mode=False,
            temperature=0.85, # CrÃ©atif
            task_type=AiTaskType.CHAT_PATIENT,
            max_tokens=300 # RÃ©ponses courtes (patient)
        )
        
        if isinstance(response, str):
            return response
        return "..."
    except Exception as e:
        logger.error(f"Erreur dans generate_patient_reply_chat: {e}")
        return "(Silence...)"


def generate_exam_result(
    case: models.ClinicalCase, 
    session_history: List[str], 
    exam_name: str,
    exam_justification: str = "Non spÃ©cifiÃ©e"
) -> Dict[str, Any]:
    """
    GÃ©nÃ¨re un rÃ©sultat d'examen mÃ©dical structurÃ©.
    
    C'est le CÅ’UR de la fonctionnalitÃ© d'examen.
    Elle utilise le `ExamPromptBuilder` pour crÃ©er un prompt contextuel hyper-prÃ©cis.
    """
    logger.info(f"ğŸ”¬ [AI-LAB] Demande gÃ©nÃ©ration examen : '{exam_name}'")
    
    # 1. PrÃ©paration des donnÃ©es pour le Builder
    # Conversion du modÃ¨le SQLAlchemy en dict simpliste pour le builder
    case_data = {
        "pathologie_principale": {
            "nom_fr": case.pathologie_principale.nom_fr if case.pathologie_principale else "Inconnue"
        },
        "niveau_gravite": case.niveau_difficulte,
        "donnees_paracliniques": case.donnees_paracliniques,
        "description": case.pathologie_principale.description if case.pathologie_principale else "",
        "physiopathologie": case.pathologie_principale.physiopathologie if case.pathologie_principale else ""
    }
    
    # Extraction sommaire du persona depuis l'historique ou donnÃ©es par dÃ©faut
    # (IdÃ©alement, on devrait passer le persona complet, mais ici on fait simple pour l'Ã¢ge/sexe)
    patient_persona = {
        "age": "Adulte (selon dossier)", # Sera affinÃ© si le texte du cas contient l'Ã¢ge
        "genre": "Non spÃ©cifiÃ©"
    }
    
    exam_req = {
        "name": exam_name,
        "type": "tous", # Le builder dÃ©duira le type (bio/imag)
        "justification": exam_justification
    }

    # 2. Construction du Prompt via le Builder dÃ©diÃ©
    prompt = exam_prompt_builder.build_prompt(
        case_data=case_data,
        exam_request=exam_req,
        patient_persona=patient_persona
    )

    # 3. Appel IA avec logique de retry sur le format JSON
    logic_attempts = 0
    final_result = None
    
    while logic_attempts < MAX_RETRIES_LOGIC:
        logic_attempts += 1
        
        try:
            result = _call_openrouter_api(
                input_data=prompt,
                json_mode=True,
                temperature=0.2, # TrÃ¨s strict pour des donnÃ©es mÃ©dicales
                task_type=AiTaskType.EXAM_GENERATION,
                max_tokens=1000
            )
            
            # 4. Validation MÃ©tier
            if isinstance(result, dict) and _validate_exam_json_structure(result, f"EXAM-{logic_attempts}"):
                final_result = result
                break # SuccÃ¨s !
            else:
                logger.warning(f"   âš ï¸ [AI-LAB] Tentative {logic_attempts}: JSON reÃ§u mais invalide structurellement.")
                # On retente (l'alÃ©atoire de la tempÃ©rature peut aider Ã  corriger)
        
        except Exception as e:
            logger.error(f"   âŒ [AI-LAB] Tentative {logic_attempts} Ã©chouÃ©e : {str(e)}")
            # On retente
            
    # 5. Gestion du Fallback (Si Ã©chec aprÃ¨s retries)
    if not final_result:
        logger.critical(f"   ğŸ’€ [AI-LAB] Ã‰chec dÃ©finitif de gÃ©nÃ©ration de l'examen '{exam_name}'. Utilisation du fallback.")
        return {
            "type_resultat": "erreur",
            "rapport_complet": f"Erreur technique : Impossible de gÃ©nÃ©rer le rapport pour {exam_name}. Veuillez contacter le support.",
            "conclusion": "Examen non rÃ©alisÃ©."
        }
    
    # 6. Post-traitement (optionnel)
    # On pourrait ajouter ici des vÃ©rifications de sÃ©curitÃ© (mots interdits, etc.)
    
    logger.info(f"   ğŸ‰ [AI-LAB] RÃ©sultat gÃ©nÃ©rÃ© avec succÃ¨s. Conclusion : {final_result.get('conclusion', '')[:50]}...")
    return final_result


def evaluate_final_submission(
    db: Session,
    case: models.ClinicalCase,
    submission: schemas.simulation.SubmissionRequest,
    session_history: list
) -> Tuple[schemas.simulation.EvaluationResult, str, str]:
    """
    Le Juge SÃ©mantique. Ã‰value la performance de l'Ã©tudiant en comparant
    ses rÃ©ponses textuelles avec la vÃ©ritÃ© structurÃ©e de la base de donnÃ©es.
    """
    eval_id = f"JUDGE-{str(uuid.uuid4())[:6]}"
    logger.info(f"âš–ï¸ [{eval_id}] DÃ©marrage Ã©valuation SÃ‰MANTIQUE")

    # 1. RÃ©cupÃ©ration de la VÃ‰RITÃ‰ TERRAIN (Ce qu'il fallait trouver)
    # -------------------------------------------------------------------------
    logger.debug(f"   [{eval_id}] Chargement de la vÃ©ritÃ© terrain depuis la BDD...")
    
    # Pathologie correcte
    correct_pathology_name = case.pathologie_principale.nom_fr
    
    # Traitements corrects (liste des mÃ©dicaments liÃ©s Ã  la pathologie)
    correct_treatments_objs = db.query(models.TraitementPathologie).options(
        joinedload(models.TraitementPathologie.medicament)
    ).filter(
        models.TraitementPathologie.pathologie_id == case.pathologie_principale_id
    ).all()
    
    # On construit une liste lisible pour l'IA : "Nom (Type - Ligne)"
    correct_treatments_list = []
    for t in correct_treatments_objs:
        med_name = t.medicament.nom_commercial or t.medicament.dci
        details = []
        if t.type_traitement: details.append(t.type_traitement)
        if t.ligne_traitement: details.append(f"{t.ligne_traitement}Ã¨re ligne")
        
        info_str = f"- {med_name}"
        if details:
            info_str += f" ({', '.join(details)})"
        correct_treatments_list.append(info_str)
    
    correct_treatments_str = "\n".join(correct_treatments_list) if correct_treatments_list else "Pas de traitement spÃ©cifique dÃ©fini en base (se rÃ©fÃ©rer aux guidelines)."

    logger.debug(f"   [{eval_id}] VÃ©ritÃ© Patho: {correct_pathology_name}")
    logger.debug(f"   [{eval_id}] VÃ©ritÃ© Traitements: {len(correct_treatments_list)} items")

    # 2. RÃ©cupÃ©ration de la SOUMISSION Ã‰TUDIANT (Texte libre)
    # -------------------------------------------------------------------------
    student_diagnosis_text = submission.diagnosed_pathology_text
    student_treatment_text = submission.prescribed_treatment_text
    
    logger.debug(f"   [{eval_id}] Input Ã‰tudiant Patho: '{student_diagnosis_text}'")
    logger.debug(f"   [{eval_id}] Input Ã‰tudiant Traitement: '{student_treatment_text[:50]}...'")

    # 3. Formatage de l'historique (Preuves de la dÃ©marche)
    # -------------------------------------------------------------------------
    # On tronque pour ne pas dÃ©passer la fenÃªtre de contexte du LLM
    history_str = json.dumps(session_history, indent=2, ensure_ascii=False)
    if len(history_str) > 5000:
        history_str = history_str[:5000] + "\n... [HISTORIQUE TRONQUÃ‰] ..."

    # 4. Construction du PROMPT DU JURY (Comparaison SÃ©mantique)
    # -------------------------------------------------------------------------
    prompt = f"""
TU ES UN PROFESSEUR DE MÃ‰DECINE EXPERT (JURY D'EXAMEN).
Ta mission est d'Ã©valuer la pertinence clinique de la rÃ©ponse d'un Ã©tudiant.
Tu dois faire une COMPARAISON SÃ‰MANTIQUE entre la vÃ©ritÃ© terrain et la rÃ©ponse de l'Ã©tudiant.

--- 1. LE DIAGNOSTIC ---
VÃ‰RITÃ‰ (Attendu) : "{correct_pathology_name}"
RÃ‰PONSE Ã‰TUDIANT : "{student_diagnosis_text}"

Instruction de notation Diagnostic :
- 10/10 : Diagnostic exact ou synonyme mÃ©dical parfait (ex: "Infarctus" = "IDM").
- 7-9/10 : Diagnostic trÃ¨s proche ou incomplet (ex: "Paludisme" au lieu de "Paludisme grave").
- 4-6/10 : Bonne famille de maladie mais imprÃ©cis (ex: "Infection virale" pour "Grippe").
- 0-3/10 : Diagnostic faux ou dangereux.

--- 2. LE TRAITEMENT ---
VÃ‰RITÃ‰ (RecommandÃ©) :
{correct_treatments_str}

RÃ‰PONSE Ã‰TUDIANT :
"{student_treatment_text}"

Instruction de notation ThÃ©rapeutique :
- Analyse si l'Ã©tudiant a citÃ© les molÃ©cules clÃ©s (DCI ou nom commercial).
- 5/5 : Traitement complet et adaptÃ©.
- 3-4/5 : MolÃ©cule principale prÃ©sente mais incomplet.
- 0-2/5 : Traitement inefficace ou dangereux.

--- 3. LA DÃ‰MARCHE CLINIQUE (HISTORIQUE) ---
Parcours de l'Ã©tudiant :
{history_str}

Instruction de notation DÃ©marche :
- 5/5 : Questions pertinentes, examens justifiÃ©s, logique claire.
- 0-2/5 : Questions au hasard, examens inutiles ("pÃªche aux infos").

--- FORMAT DE SORTIE ATTENDU (JSON) ---
{{
  "score_diagnostic": float,  // Note sur 10
  "score_therapeutique": float, // Note sur 5
  "score_demarche": float,      // Note sur 5
  "feedback_global": "Analyse pÃ©dagogique dÃ©taillÃ©e. Explique pourquoi le diagnostic est bon/mauvais par rapport Ã  la vÃ©ritÃ©. Commente le choix des mÃ©dicaments.",
  "recommendation_next_step": "Conseil court (ex: 'Revoir la pharmacologie des antipaludÃ©ens')."
}}
"""

    # 5. Appel IA
    # -------------------------------------------------------------------------
    logger.info(f"   ğŸš€ [{eval_id}] Envoi du dossier au jury (LLM)...")
    
    # On utilise _call_openrouter_api (assurez-vous qu'elle est bien dÃ©finie dans le fichier complet)
    eval_json = _call_openrouter_api(
        input_data=prompt,
        json_mode=True,
        temperature=0.2, # Faible tempÃ©rature pour une notation objective
        task_type=AiTaskType.EVALUATION
    )

    # 6. Parsing et Validation du RÃ©sultat
    # -------------------------------------------------------------------------
    try:
        # SÃ©curisation des types
        s_diag = float(eval_json.get("score_diagnostic", 0))
        s_ther = float(eval_json.get("score_therapeutique", 0))
        s_dem = float(eval_json.get("score_demarche", 0))
        
        # Clamp des notes (au cas oÃ¹ l'IA note sur 20 au lieu de 10)
        s_diag = min(10, max(0, s_diag))
        s_ther = min(5, max(0, s_ther))
        s_dem = min(5, max(0, s_dem))
        
        total = s_diag + s_ther + s_dem
        
        logger.info(f"   ğŸ† [{eval_id}] Verdict rendu : {total}/20")
        logger.debug(f"      DÃ©tails : Diag={s_diag}/10, Ther={s_ther}/5, Dem={s_dem}/5")
        logger.debug(f"      Feedback : {eval_json.get('feedback_global', '')[:100]}...")

        result_obj = schemas.simulation.EvaluationResult(
            score_diagnostic=s_diag,
            score_therapeutique=s_ther,
            score_demarche=s_dem,
            score_total=total
        )
        
        return result_obj, eval_json.get("feedback_global", "Ã‰valuation complÃ©tÃ©e."), eval_json.get("recommendation_next_step", "Continuer.")

    except Exception as e:
        logger.error(f"   âŒ [{eval_id}] Erreur lecture verdict : {e}")
        logger.debug(f"      JSON reÃ§u : {eval_json}")
        
        # Fallback pour ne pas bloquer l'UI
        return schemas.simulation.EvaluationResult(
            score_diagnostic=0, score_therapeutique=0, score_demarche=0, score_total=0
        ), "Erreur technique lors de l'Ã©valuation automatique. Vos rÃ©ponses ont Ã©tÃ© enregistrÃ©es.", "Veuillez contacter l'administrateur."

def generate_hint(case: models.ClinicalCase, session_history: List[str], hint_level: int) -> Tuple[str, str]:
    """
    GÃ©nÃ¨re un indice.
    """
    logger.info(f"ğŸ’¡ [AI-TUTOR] Indice niveau {hint_level}")
    
    prompt = f"""
ROLE: Tuteur mÃ©dical.
CONTEXTE: Cas de {case.pathologie_principale.nom_fr}.
NIVEAU AIDE: {hint_level}/3.
HISTORIQUE: {str(session_history)[-1000:]}

Donne un indice pÃ©dagogique JSON : {{ "hint_type": "...", "content": "..." }}
"""
    res = _call_openrouter_api(prompt, json_mode=True, task_type=AiTaskType.HINT_GENERATION)
    if isinstance(res, dict):
        return res.get("hint_type", "info"), res.get("content", "Analysez les symptÃ´mes.")
    return "info", "Continuez."

=== Fichier: ./app/services/interaction_log_service.py ===

import logging
from sqlalchemy.orm import Session
from uuid import UUID
from .. import models, schemas

logger = logging.getLogger(__name__)

def create_interaction_log(db: Session, session_id: UUID, action_data: schemas.simulation.LearnerActionRequest) -> models.InteractionLog:
    session = db.query(models.SimulationSession).filter(models.SimulationSession.id == session_id).first()
    if not session:
        logger.error(f"[create_interaction_log] Tentative de log pour une session inexistante: {session_id}")
        raise ValueError(f"Session {session_id} non trouvÃ©e.")

    db_log = models.InteractionLog(
        session_id=session_id,
        action_category="EXAMINATION",
        action_type=action_data.action_type,
        action_content={
            "name": action_data.action_name,
            "justification": action_data.justification or None # Correction pour accepter None
        }
    )

    db.add(db_log)
    db.commit()
    db.refresh(db_log)
    return db_log

=== Fichier: ./app/services/__init__.py ===



=== Fichier: ./app/services/learning_path_service.py ===



=== Fichier: ./app/services/tutor_service.py ===

#=== Fichier: ./app/services/tutor_service.py ===

import logging
import json
import time
import uuid
import random
from datetime import datetime, timedelta
from typing import List, Tuple, Dict, Any, Optional, Union
from enum import Enum

from sqlalchemy.orm import Session, joinedload
from sqlalchemy import desc, func

from .. import models, schemas
from . import (
    simulation_service, 
    interaction_log_service, 
    ai_generation_service, 
    clinical_case_service,
    disease_service
)

# ==============================================================================
# CONFIGURATION DU LOGGER "TUTOR-ORCHESTRATOR"
# ==============================================================================
logger = logging.getLogger("tutor_orchestrator")
logger.setLevel(logging.DEBUG)

if not logger.handlers:
    handler = logging.StreamHandler()
    # Format ultra-prÃ©cis pour le debugging temporel et contextuel
    formatter = logging.Formatter(
        '%(asctime)s - [TUTOR-CORE] - %(levelname)s - [Trace: %(trace_id)s] - %(message)s'
    )
    # Filtre pour injecter trace_id par dÃ©faut si absent
    class ContextFilter(logging.Filter):
        def filter(self, record):
            if not hasattr(record, 'trace_id'):
                record.trace_id = 'SYSTEM'
            return True
    
    handler.addFilter(ContextFilter())
    handler.setFormatter(formatter)
    logger.addHandler(handler)

# ==============================================================================
# CLASSES UTILITAIRES INTERNES (Logique MÃ©tier)
# ==============================================================================

class VirtualTimeManager:
    """GÃ¨re l'avancement du temps dans la simulation en fonction des actions."""
    
    COSTS_MINUTES = {
        "anamnese": 5,
        "examen_clinique": 10,
        "constantes": 2,
        "biologie_standard": 60, # NFS, Iono
        "biologie_complexe": 120, # HÃ©moculture
        "radio": 30,
        "scanner": 45,
        "irm": 60,
        "traitement_iv": 15,
        "traitement_po": 5,
        "avis_specialiste": 240, # 4h
        "default": 15
    }

    @staticmethod
    def calculate_duration(action_type: str, action_name: str) -> int:
        name_lower = action_name.lower()
        type_lower = action_type.lower()
        
        if "scanner" in name_lower or "tdm" in name_lower: return VirtualTimeManager.COSTS_MINUTES["scanner"]
        if "irm" in name_lower: return VirtualTimeManager.COSTS_MINUTES["irm"]
        if "radio" in name_lower or "rx" in name_lower: return VirtualTimeManager.COSTS_MINUTES["radio"]
        if "nfs" in name_lower or "crp" in name_lower: return VirtualTimeManager.COSTS_MINUTES["biologie_standard"]
        if "constante" in name_lower or "vitaux" in name_lower: return VirtualTimeManager.COSTS_MINUTES["constantes"]
        
        return VirtualTimeManager.COSTS_MINUTES.get(type_lower, VirtualTimeManager.COSTS_MINUTES["default"])

class VirtualBudgetManager:
    """GÃ¨re le coÃ»t financier fictif des examens pour l'Ã©valuation Ã©conomique."""
    
    COSTS_CURRENCY = {
        "consultation": 0,
        "biologie_simple": 5000,
        "biologie_complexe": 15000,
        "radio": 10000,
        "scanner": 45000,
        "irm": 100000,
        "echo": 15000,
        "medicament_standard": 2000,
        "default": 1000
    }

    @staticmethod
    def estimate_cost(action_name: str) -> int:
        name_lower = action_name.lower()
        if "scanner" in name_lower: return VirtualBudgetManager.COSTS_CURRENCY["scanner"]
        if "irm" in name_lower: return VirtualBudgetManager.COSTS_CURRENCY["irm"]
        if "radio" in name_lower: return VirtualBudgetManager.COSTS_CURRENCY["radio"]
        if "echo" in name_lower: return VirtualBudgetManager.COSTS_CURRENCY["echo"]
        if "nfs" in name_lower or "crp" in name_lower: return VirtualBudgetManager.COSTS_CURRENCY["biologie_simple"]
        return VirtualBudgetManager.COSTS_CURRENCY["default"]

# ==============================================================================
# LOGIQUE PRINCIPALE DU SERVICE
# ==============================================================================

def start_new_session(
    db: Session, 
    learner_id: int, 
    category: str
) -> Tuple[models.SimulationSession, models.ClinicalCase, str]:
    """
    DÃ©marre une nouvelle session ou reprend une session existante non terminÃ©e.
    IntÃ¨gre une logique de sÃ©lection de cas adaptative.
    """
    trace_id = f"START-{str(uuid.uuid4())[:6]}"
    logger.info(f"ğŸš€ Nouvelle demande de session | Learner: {learner_id} | Cat: {category}", extra={'trace_id': trace_id})

    # 1. VÃ©rification de l'existant (Reprise de session)
    # -------------------------------------------------------------------------
    try:
        existing_session = db.query(models.SimulationSession).join(
            models.ClinicalCase
        ).join(models.Disease).filter(
            models.SimulationSession.learner_id == learner_id,
            models.SimulationSession.statut == "in_progress",
            models.Disease.categorie == category
        ).order_by(models.SimulationSession.start_time.desc()).first()

        if existing_session:
            logger.info(f"   ğŸ”„ Session existante trouvÃ©e ({existing_session.id}). Reprise.", extra={'trace_id': trace_id})
            return existing_session, existing_session.cas_clinique, existing_session.context_state.get("session_type", "formative")
    except Exception as e:
        logger.error(f"   âŒ Erreur lors de la recherche de session existante: {e}", extra={'trace_id': trace_id})

    # 2. Analyse de l'historique pour dÃ©terminer le niveau (Logique de Parcours)
    # -------------------------------------------------------------------------
    logger.debug("   ğŸ“Š Analyse de l'historique pÃ©dagogique...", extra={'trace_id': trace_id})
    
    # RÃ©cupÃ©ration de l'historique des sessions terminÃ©es dans cette catÃ©gorie
    history = db.query(models.SimulationSession).join(
        models.ClinicalCase
    ).join(
        models.Disease
    ).filter(
        models.SimulationSession.learner_id == learner_id,
        models.SimulationSession.statut == "completed",
        models.Disease.categorie == category
    ).order_by(models.SimulationSession.end_time.asc()).all()

    current_level = 1
    session_type = "formative"
    consecutive_success = 0

    # Algorithme simple de progression
    if history:
        last_session = history[-1]
        last_level = last_session.cas_clinique.niveau_difficulte or 1
        last_score = last_session.score_final or 0
        
        logger.debug(f"      DerniÃ¨re session: Niveau {last_level}, Score {last_score}/20", extra={'trace_id': trace_id})
        
        if last_score >= 12: # RÃ©ussite
            current_level = min(30, last_level + 3) # Progression
            logger.info(f"      ğŸ“ˆ Progression : Niveau {last_level} -> {current_level}", extra={'trace_id': trace_id})
        else:
            current_level = max(1, last_level) # Maintien (ou -1 si on veut Ãªtre punitif)
            logger.info(f"      ğŸ“‰ Maintien : Niveau {current_level} (Score insuffisant)", extra={'trace_id': trace_id})
    else:
        logger.info("      ğŸ†• Premier lancement dans cette catÃ©gorie. Niveau 1.", extra={'trace_id': trace_id})

    # 3. SÃ©lection du Cas Clinique
    # -------------------------------------------------------------------------
    logger.debug(f"   ğŸ² SÃ©lection d'un cas clinique (Niveau cible {current_level})...", extra={'trace_id': trace_id})
    
    # IDs Ã  exclure (dÃ©jÃ  faits)
    excluded_ids = [s.cas_clinique_id for s in history]
    
    selected_case = clinical_case_service.get_case_for_progression(
        db, category, current_level, excluded_ids
    )

    if not selected_case:
        logger.warning("   âš ï¸ Aucun cas neuf trouvÃ© au niveau exact. Recherche Ã©largie...", extra={'trace_id': trace_id})
        # Fallback : on prend n'importe quel cas de la catÃ©gorie non fait, peu importe le niveau
        all_cat_cases = clinical_case_service.get_cases_by_category(db, category)
        candidates = [c for c in all_cat_cases if c.id not in excluded_ids]
        
        if candidates:
            selected_case = random.choice(candidates)
            logger.info(f"   â™»ï¸ Cas trouvÃ© (hors niveau) : {selected_case.code_fultang} (Niv {selected_case.niveau_difficulte})", extra={'trace_id': trace_id})
        elif all_cat_cases:
            # Vraiment plus rien de neuf -> Recyclage
            selected_case = random.choice(all_cat_cases)
            logger.warning(f"   â™»ï¸ Recyclage d'un cas dÃ©jÃ  fait : {selected_case.code_fultang}", extra={'trace_id': trace_id})
        else:
            msg = f"Aucun cas clinique disponible dans la catÃ©gorie '{category}'."
            logger.critical(f"   â›” {msg}", extra={'trace_id': trace_id})
            raise ValueError(msg)

    # 4. CrÃ©ation de la Session
    # -------------------------------------------------------------------------
    try:
        new_session = simulation_service.create_session(
            db=db,
            learner_id=learner_id,
            case_id=selected_case.id,
            session_type=session_type,
            formative_count=0,
            formative_cases_pool=[]
        )
        logger.info(f"   ğŸ’¾ Session persistÃ©e avec succÃ¨s : {new_session.id}", extra={'trace_id': trace_id})
        
        return new_session, selected_case, session_type

    except Exception as e:
        logger.error(f"   âŒ Erreur critique crÃ©ation session : {str(e)}", extra={'trace_id': trace_id})
        raise e


def process_learner_action(
    db: Session, 
    session_id: uuid.UUID, 
    action_data: schemas.simulation.LearnerActionRequest
) -> Tuple[Dict[str, Any], str]:
    """
    CÅ“ur rÃ©actif du systÃ¨me de simulation.
    """
    trace_id = f"ACT-{str(uuid.uuid4())[:6]}"
    start_process = time.time()
    
    logger.info(f"ğŸ¬ DÃ©but traitement action : {action_data.action_type} - {action_data.action_name}", extra={'trace_id': trace_id})

    # 1. Chargement et Validation
    session = db.query(models.SimulationSession).filter(models.SimulationSession.id == session_id).first()
    if not session: raise ValueError("Session introuvable")
    clinical_case = session.cas_clinique

    # 2. VÃ©rification Doublons
    previous_logs = db.query(models.InteractionLog).filter(
        models.InteractionLog.session_id == session_id,
        models.InteractionLog.action_type == action_data.action_type
    ).all()
    for log in previous_logs:
        prev_content = log.action_content or {}
        if prev_content.get("name") == action_data.action_name:
            logger.info("   ğŸ”„ Action dÃ©jÃ  rÃ©alisÃ©e prÃ©cÃ©demment.", extra={'trace_id': trace_id})

    # 3. CoÃ»t et Temps
    virtual_duration = VirtualTimeManager.calculate_duration(action_data.action_type, action_data.action_name)
    virtual_cost = VirtualBudgetManager.estimate_cost(action_data.action_name)
    
    # 4. ExÃ©cution Action
    result_data = {}
    feedback_tutor = ""
    action_category = action_data.action_type.lower()

    try:
        # EXAMENS (BIO/RADIO)
        if action_category in ["examen_complementaire", "biologie", "imagerie", "consulter_image"]:
            logger.info("   ğŸ”¬ DÃ©lÃ©gation Ã  l'IA Laboratoire...", extra={'trace_id': trace_id})
            ai_result = ai_generation_service.generate_exam_result(
                case=clinical_case,
                session_history=[],
                exam_name=action_data.action_name,
                exam_justification=action_data.justification
            )
            result_data = ai_result
            if "normal" in str(ai_result.get("conclusion", "")).lower():
                feedback_tutor = "RÃ©sultat revenu normal."
            else:
                feedback_tutor = "RÃ©sultat pathologique reÃ§u."

        # CONSTANTES
        elif action_category in ["parametres_vitaux"]:
            logger.info("   ğŸ’“ DÃ©lÃ©gation Ã  l'IA Monitor...", extra={'trace_id': trace_id})
            ai_result = ai_generation_service.generate_exam_result(
                case=clinical_case,
                session_history=[],
                exam_name="ParamÃ¨tres vitaux complets",
                exam_justification="Surveillance"
            )
            result_data = ai_result
            feedback_tutor = "Constantes prises."

        # PRESCRIPTIONS
        elif action_category in ["prescription", "traitement"]:
            logger.info("   ğŸ’Š Traitement administrÃ©.", extra={'trace_id': trace_id})
            result_data = {"statut": "AdministrÃ©", "observation": "Le patient a reÃ§u le traitement."}
            feedback_tutor = "Traitement notÃ©."

        # AUTRES
        else:
            result_data = {"info": "Action enregistrÃ©e."}
            feedback_tutor = "Action notÃ©e."

    except Exception as e:
        logger.error(f"   âŒ Erreur IA Action : {str(e)}", extra={'trace_id': trace_id})
        result_data = {"erreur": "ProblÃ¨me technique."}
        feedback_tutor = "Erreur systÃ¨me."

    # 5. Mise Ã  jour Session
    session.temps_total = (session.temps_total or 0) + virtual_duration
    session.cout_virtuel_genere = (session.cout_virtuel_genere or 0) + virtual_cost

    # 6. Persistence Log
    try:
        log_content = {
            "name": action_data.action_name,
            "justification": action_data.justification,
            "result_summary": result_data.get("conclusion", "N/A"),
            "full_result": result_data,
            "virtual_cost": virtual_cost
        }
        db_log = models.InteractionLog(
            session_id=session_id,
            timestamp=datetime.now(),
            action_category="EXAMINATION" if action_category in ["examen_complementaire", "biologie", "imagerie"] else "INTERVENTION",
            action_type=action_data.action_type,
            action_content=log_content,
            response_latency=int((time.time() - start_process) * 1000),
            est_pertinent=True
        )
        db.add(db_log)
        db.commit()
        db.refresh(db_log)
    except Exception as e:
        db.rollback()
        logger.critical(f"   ğŸ”¥ Ã‰chec sauvegarde log : {e}", extra={'trace_id': trace_id})

    return result_data, feedback_tutor


def provide_hint(db: Session, session_id: uuid.UUID) -> Tuple[str, str]:
    """Fournit un indice."""
    trace_id = f"HINT-{str(uuid.uuid4())[:6]}"
    logger.info(f"ğŸ’¡ Demande indice Session {session_id}", extra={'trace_id': trace_id})
    session = db.query(models.SimulationSession).filter(models.SimulationSession.id == session_id).first()
    
    try:
        # Historique rÃ©cent pour contexte
        history = [m.content for m in session.messages[-5:]]
        hint_type, hint_content = ai_generation_service.generate_hint(
            case=session.cas_clinique,
            session_history=history,
            hint_level=1
        )
        # PÃ©nalitÃ©
        session.temps_total = (session.temps_total or 0) + 5
        db.commit()
        return hint_type, hint_content
    except Exception as e:
        logger.error(f"   âŒ Erreur indice: {e}", extra={'trace_id': trace_id})
        return "error", "Indisponible."


def evaluate_submission(
    db: Session, 
    session_id: uuid.UUID, 
    submission_data: schemas.simulation.SubmissionRequest
) -> Tuple[schemas.simulation.EvaluationResult, str, str]:
    """
    Termine la session, Ã©value la performance (SÃ©mantique) et met Ã  jour la progression.
    """
    trace_id = f"EVAL-{str(uuid.uuid4())[:6]}"
    start_eval = time.time()
    
    logger.info(f"ğŸ [EVALUATION] Soumission reÃ§ue pour Session {session_id}", extra={'trace_id': trace_id})
    logger.debug(f"   ğŸ“ Diagnostic soumis : {submission_data.diagnosed_pathology_text}", extra={'trace_id': trace_id})
    logger.debug(f"   ğŸ“ Traitement soumis : {submission_data.prescribed_treatment_text[:50]}...", extra={'trace_id': trace_id})

    # 1. Chargement Session
    session = db.query(models.SimulationSession).filter(models.SimulationSession.id == session_id).first()
    if not session: raise ValueError("Session introuvable")

    # 2. Reconstitution Timeline (Fusion Chat + Actions) pour l'IA Juge
    # -------------------------------------------------------------------------
    logger.debug("   ğŸ“œ Reconstitution de la timeline complÃ¨te...", extra={'trace_id': trace_id})
    
    chat_msgs = db.query(models.ChatMessage).filter(models.ChatMessage.session_id == session_id).order_by(models.ChatMessage.timestamp).all()
    actions_logs = db.query(models.InteractionLog).filter(models.InteractionLog.session_id == session_id).order_by(models.InteractionLog.timestamp).all()
    
    timeline = []
    for m in chat_msgs:
        timeline.append({"time": m.timestamp, "type": "DIALOGUE", "actor": m.sender, "detail": m.content})
    for a in actions_logs:
        content_str = a.action_content.get("name") if isinstance(a.action_content, dict) else str(a.action_content)
        timeline.append({"time": a.timestamp, "type": f"ACTION {a.action_type}", "actor": "Ã‰tudiant", "detail": content_str})
    
    timeline.sort(key=lambda x: x['time'])
    history_for_ai = [f"[{t['time'].strftime('%H:%M')}] {t['type']} ({t['actor']}): {t['detail']}" for t in timeline]

    # 3. Appel IA Juge (Comparaison SÃ©mantique)
    # -------------------------------------------------------------------------
    try:
        logger.info("   ğŸ§  Appel au Juge IA...", extra={'trace_id': trace_id})
        
        eval_result, feedback, recommendation = ai_generation_service.evaluate_final_submission(
            db=db,
            case=session.cas_clinique,
            submission=submission_data,
            session_history=history_for_ai
        )
        
        logger.info(f"   ğŸ† Note attribuÃ©e : {eval_result.score_total}/20", extra={'trace_id': trace_id})

        # 4. Mise Ã  jour des DonnÃ©es Apprenant (Progression)
        # ---------------------------------------------------------------------
        logger.info("   ğŸ“ˆ Mise Ã  jour de la progression de l'apprenant...", extra={'trace_id': trace_id})
        
        # A. ClÃ´ture Session
        session.score_final = eval_result.score_total
        session.statut = "completed"
        session.end_time = datetime.now()
        session.raison_fin = "submission"
        
        # Stockage dÃ©tails dans le JSON contextuel pour audit futur
        context = session.context_state or {}
        context["evaluation_details"] = eval_result.model_dump()
        session.context_state = context
        
        # B. Mise Ã  jour LearningPath (Table sÃ©parÃ©e)
        # On vÃ©rifie si une entrÃ©e existe pour cet apprenant
        learning_path = db.query(models.LearningPath).filter(
            models.LearningPath.learner_id == session.learner_id
        ).first()
        
        if not learning_path:
            logger.info("      CrÃ©ation d'un nouveau LearningPath...", extra={'trace_id': trace_id})
            learning_path = models.LearningPath(
                learner_id=session.learner_id,
                progression=0.0,
                status="active"
            )
            db.add(learning_path)
        
        # Logique de mise Ã  jour de la progression (SimplifiÃ©e)
        # On incrÃ©mente la progression globale si la note est bonne
        if eval_result.score_total >= 12:
            # Gain de progression (ex: +5% par cas rÃ©ussi)
            learning_path.progression = min(100.0, (learning_path.progression or 0.0) + 5.0)
            logger.info(f"      âœ… SuccÃ¨s ! Progression totale : {learning_path.progression}%", extra={'trace_id': trace_id})
            
            # Ici, on pourrait aussi mettre Ã  jour les compÃ©tences spÃ©cifiques
            # (LearnerCompetencyMastery) mais cela demande un mapping complexe.
            # Pour l'instant, on se contente du LearningPath global.
        else:
            logger.info("      âŒ Ã‰chec. Pas de progression.", extra={'trace_id': trace_id})

        db.commit()
        
        logger.info(f"ğŸ [EVALUATION] TerminÃ©e en {time.time() - start_eval:.2f}s", extra={'trace_id': trace_id})
        return eval_result, feedback, recommendation

    except Exception as e:
        db.rollback()
        logger.critical(f"   ğŸ”¥ Erreur critique Ã©valuation : {e}", extra={'trace_id': trace_id})
        import traceback
        logger.error(traceback.format_exc())
        raise e

=== Fichier: ./app/services/medication_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_medication_by_id(db: Session, medication_id: int) -> Optional[models.Medication]:
    """
    RÃ©cupÃ¨re un mÃ©dicament par son ID.
    """
    return db.query(models.Medication).filter(models.Medication.id == medication_id).first()

def get_medication_by_dci(db: Session, dci: str) -> Optional[models.Medication]:
    """
    RÃ©cupÃ¨re un mÃ©dicament par son DCI (DÃ©nomination Commune Internationale).
    """
    return db.query(models.Medication).filter(models.Medication.dci == dci).first()

def get_all_medications(db: Session, skip: int = 0, limit: int = 100) -> List[models.Medication]:
    """
    RÃ©cupÃ¨re une liste de tous les mÃ©dicaments avec pagination.
    """
    return db.query(models.Medication).offset(skip).limit(limit).all()

def create_medication(db: Session, medication: schemas.MedicationCreate) -> models.Medication:
    """
    CrÃ©e un nouveau mÃ©dicament dans la base de donnÃ©es.
    """
    medication_data = medication.model_dump()
    db_medication = models.Medication(**medication_data)
    
    db.add(db_medication)
    db.commit()
    db.refresh(db_medication)
    
    return db_medication

def update_medication(db: Session, medication_id: int, medication_update: schemas.MedicationUpdate) -> Optional[models.Medication]:
    """
    Met Ã  jour un mÃ©dicament existant.
    """
    db_medication = get_medication_by_id(db, medication_id)
    if not db_medication:
        return None

    update_data = medication_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_medication, key, value)
        
    db.commit()
    db.refresh(db_medication)
    
    return db_medication

def delete_medication(db: Session, medication_id: int) -> Optional[models.Medication]:
    """
    Supprime un mÃ©dicament de la base de donnÃ©es.
    """
    db_medication = get_medication_by_id(db, medication_id)
    if not db_medication:
        return None

    db.delete(db_medication)
    db.commit()
    
    return db_medication




# Contenu Ã  AJOUTER Ã  la fin de app/services/medication_service.py

def get_diseases_treated_by_medication(db: Session, medication_id: int) -> List[models.TraitementPathologie]:
    """
    RÃ©cupÃ¨re toutes les pathologies traitÃ©es par un mÃ©dicament.
    """
    return db.query(models.TraitementPathologie).filter(models.TraitementPathologie.medicament_id == medication_id).all()


def get_symptoms_treated_by_medication(db: Session, medication_id: int) -> List[models.TraitementSymptome]:
    """
    RÃ©cupÃ¨re tous les symptÃ´mes traitÃ©s par un mÃ©dicament.
    """
    return db.query(models.TraitementSymptome).filter(models.TraitementSymptome.medicament_id == medication_id).all()

=== Fichier: ./app/services/media_service.py ===

import os
from sqlalchemy.orm import Session
from typing import List, Optional
from fastapi import UploadFile
import cloudinary
import cloudinary.uploader

from .. import models, schemas
from ..config import settings

# --- CONFIGURATION CLOUDINARY ---
# Cette configuration est faite une seule fois au chargement du module.
# Elle utilise les variables chargÃ©es depuis votre fichier .env.
cloudinary.config(
    cloud_name = settings.CLOUDINARY_CLOUD_NAME,
    api_key = settings.CLOUDINARY_API_KEY,
    api_secret = settings.CLOUDINARY_API_SECRET,
    secure = True
)


async def save_upload_file_to_cloud(upload_file: UploadFile) -> str:
    """
    Fonction utilitaire pour uploader un fichier directement vers Cloudinary
    et retourner son URL sÃ©curisÃ©e.
    """
    try:
        # Lire le contenu du fichier en mÃ©moire
        content = await upload_file.read()
        
        # Envoyer le contenu Ã  Cloudinary
        upload_result = cloudinary.uploader.upload(
            content,
            folder="sti_medical_expert/uploads"  # Dossier de destination sur Cloudinary
        )
        
        # RÃ©cupÃ©rer l'URL sÃ©curisÃ©e (https://...)
        secure_url = upload_result.get("secure_url")
        if not secure_url:
            raise Exception("Ã‰chec de l'upload vers Cloudinary, URL non retournÃ©e.")
            
        return secure_url
    finally:
        # Toujours fermer le fichier aprÃ¨s lecture
        await upload_file.close()


async def create_image_medicale(
    db: Session,
    file: UploadFile,
    type_examen: str,
    sous_type: Optional[str] = None,
    pathologie_id: Optional[int] = None,
    description: Optional[str] = None
) -> models.ImageMedicale:
    """
    CrÃ©e une nouvelle entrÃ©e pour une image mÃ©dicale.
    1. Sauvegarde le fichier sur Cloudinary.
    2. CrÃ©e l'enregistrement correspondant en base de donnÃ©es avec l'URL cloud.
    """
    # 1. Sauvegarder le fichier physique sur le cloud
    cloud_url = await save_upload_file_to_cloud(file)

    # 2. CrÃ©er l'objet SQLAlchemy avec les mÃ©tadonnÃ©es et l'URL cloud
    db_image = models.ImageMedicale(
        type_examen=type_examen,
        sous_type=sous_type,
        pathologie_id=pathologie_id,
        description=description,
        fichier_url=cloud_url, # <-- C'est maintenant l'URL Cloudinary !
        format_image=file.content_type.split('/')[-1] if file.content_type else None,
        taille_ko=file.size // 1024 if file.size else None,
    )
    
    db.add(db_image)
    db.commit()
    db.refresh(db_image)
    
    return db_image


def get_image_medicale_by_id(db: Session, image_id: int) -> Optional[models.ImageMedicale]:
    """
    RÃ©cupÃ¨re une image mÃ©dicale par son ID.
    """
    return db.query(models.ImageMedicale).filter(models.ImageMedicale.id == image_id).first()


def get_all_images_medicales(db: Session, skip: int = 0, limit: int = 100) -> List[models.ImageMedicale]:
    """
    RÃ©cupÃ¨re une liste de toutes les images mÃ©dicales avec pagination.
    """
    return db.query(models.ImageMedicale).offset(skip).limit(limit).all()


def update_image_medicale_metadata(
    db: Session,
    image_id: int,
    image_update: schemas.ImageMedicaleUpdate
) -> Optional[models.ImageMedicale]:
    """
    Met Ã  jour les mÃ©tadonnÃ©es d'une image mÃ©dicale existante.
    """
    db_image = get_image_medicale_by_id(db, image_id)
    if not db_image:
        return None

    update_data = image_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_image, key, value)
        
    db.commit()
    db.refresh(db_image)
    
    return db_image


def delete_image_medicale(db: Session, image_id: int) -> Optional[models.ImageMedicale]:
    """
    Supprime une image mÃ©dicale.
    1. Supprime l'enregistrement de la base de donnÃ©es.
    2. (Optionnel) Supprime le fichier sur Cloudinary.
    """
    db_image = get_image_medicale_by_id(db, image_id)
    if not db_image:
        return None

    # Optionnel : Ajouter ici la logique pour supprimer l'image de Cloudinary
    # via cloudinary.uploader.destroy(...) si vous voulez un nettoyage complet.
    # Pour l'instant, nous nous contentons de supprimer la rÃ©fÃ©rence.

    db.delete(db_image)
    db.commit()
    
    return db_image

=== Fichier: ./app/services/patient_actor_service.py ===

#=== Fichier: ./app/services/patient_actor_service.py ===

import logging
import json
import time
import re
import random
from typing import List, Dict, Any, Optional, Tuple
from uuid import UUID
from datetime import datetime
import uuid

from sqlalchemy.orm import Session
from sqlalchemy import desc

# Import des modÃ¨les et services existants
from .. import models
from . import ai_generation_service, interaction_log_service

# ==============================================================================
# CONFIGURATION DU LOGGER AVANCÃ‰
# ==============================================================================
# On configure un logger spÃ©cifique qui permettra de filtrer les logs du "Cerveau Patient"
logger = logging.getLogger("patient_actor")
logger.setLevel(logging.DEBUG)

# Si aucun handler n'est configurÃ© (pour Ã©viter la duplication), on en ajoute un basique
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - [PATIENT-BRAIN] - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

class PatientActorService:
    """
    Service responsable de l'incarnation du patient virtuel (Patient Actor).
    
    ARCHITECTURE :
    Ce service agit comme un 'orchestrateur de contexte'. Il ne se contente pas
    d'envoyer du texte Ã  un LLM. Il reconstruit l'Ã©tat mental et physiologique
    du patient Ã  chaque interaction.
    
    FLUX DE TRAITEMENT :
    1. RÃ©cupÃ©ration du Cas Clinique (La vÃ©ritÃ© terrain).
    2. GÃ©nÃ©ration/RÃ©cupÃ©ration du Persona (Qui suis-je ?).
    3. Analyse de l'historique (Qu'est-ce qu'on s'est dit ?).
    4. Analyse des Ã©vÃ©nements (M'a-t-on soignÃ© ?).
    5. Construction du Prompt SystÃ¨me (IngÃ©nierie de prompt).
    6. Appel LLM.
    7. Post-traitement et nettoyage.
    """

    _instance = None

    def __new__(cls):
        """Pattern Singleton pour Ã©viter de rÃ©instancier le service Ã  chaque requÃªte."""
        if cls._instance is None:
            cls._instance = super(PatientActorService, cls).__new__(cls)
            logger.info("âœ¨ Initialisation du PatientActorService (Singleton)")
        return cls._instance

    def __init__(self):
        # Template de prompt trÃ¨s strict pour Ã©viter les dÃ©rives de l'IA
        self.BASE_SYSTEM_PROMPT = """
CONTEXTE : SIMULATION MÃ‰DICALE PÃ‰DAGOGIQUE.
TU JOUES LE RÃ”LE D'UN PATIENT. TU N'ES PAS UNE IA, NI UN MÃ‰DECIN.

--- TON IDENTITÃ‰ (PERSONA) ---
Nom : {nom}
Ã‚ge : {age}
MÃ©tier : {metier}
Niveau d'Ã©ducation : {education}
Niveau de stress actuel : {stress_level}/10
Trait de caractÃ¨re dominant : {trait_caractere}

--- TA SITUATION MÃ‰DICALE (VÃ‰RITÃ‰ ABSOLUE) ---
Voici ce que tu ressens. Tu ne dois JAMAIS inventer de symptÃ´mes qui ne sont pas listÃ©s ici.
Si le mÃ©decin te demande quelque chose qui n'est pas dans cette liste, rÃ©ponds que tu ne sais pas ou que tout va bien de ce cÃ´tÃ©-lÃ .

SYMPTÃ”MES PRINCIPAUX :
{symptomes_liste}

HISTOIRE DE LA MALADIE (Ce qui t'est arrivÃ©) :
{histoire_maladie}

ANTÃ‰CÃ‰DENTS (Ton passÃ© mÃ©dical) :
{antecedents}

CONTEXTE DYNAMIQUE (Ce qui vient de se passer dans la consultation) :
{dynamic_context}

--- RÃˆGLES DE JEU DE RÃ”LE (STRICTES) ---
1. LANGAGE : Parle comme un patient camerounais {education}. N'utilise JAMAIS de jargon mÃ©dical (ex: dis "j'ai mal au ventre" et pas "douleur abdominale").
2. RÃ‰VÃ‰LATION PROGRESSIVE : Ne dÃ©balle pas toutes les informations d'un coup. RÃ©ponds uniquement Ã  la question posÃ©e. Laisse l'Ã©tudiant chercher.
3. COHÃ‰RENCE : RÃ©fÃ¨re-toi Ã  l'historique de la conversation ci-dessous. Ne te rÃ©pÃ¨te pas inutilement.
4. Ã‰TAT D'ESPRIT : Ton niveau de stress ({stress_level}/10) doit transparaÃ®tre dans ta faÃ§on de parler (ex: phrases courtes si stressÃ©, plaintes si douleur).
5. INTERDIT : Ne donne JAMAIS le diagnostic final. Tu es lÃ  pour consulter, tu ne sais pas ce que tu as.

--- INSTRUCTION FINALE ---
L'Ã©tudiant en mÃ©decine te parle. RÃ©ponds-lui directement, en restant dans ton personnage.
"""

    def generate_response(self, db: Session, session_id: UUID, student_message: str) -> str:
        """
        Point d'entrÃ©e principal pour gÃ©nÃ©rer une rÃ©ponse du patient.
        
        :param db: Session SQLAlchemy active.
        :param session_id: ID unique de la session de simulation.
        :param student_message: Le texte envoyÃ© par l'apprenant.
        :return: La rÃ©ponse textuelle du patient simulÃ©.
        """
        correlation_id = str(uuid.uuid4())[:8] # Pour tracer cette exÃ©cution spÃ©cifique dans les logs
        start_time = time.time()
        
        logger.info(f"ğŸ¬ [REQ-{correlation_id}] DÃ‰BUT GÃ‰NÃ‰RATION RÃ‰PONSE PATIENT")
        logger.info(f"   ğŸ“ Session ID : {session_id}")
        logger.info(f"   ğŸ—£ï¸ Message Ã‰tudiant : '{student_message}'")

        try:
            # --- Ã‰TAPE 1 : Chargement du contexte (Session & Cas) ---
            logger.debug(f"   [REQ-{correlation_id}] Ã‰tape 1: Chargement du contexte BDD...")
            session_obj = db.query(models.SimulationSession).filter(
                models.SimulationSession.id == session_id
            ).first()

            if not session_obj:
                msg = f"Session {session_id} introuvable en base de donnÃ©es."
                logger.critical(f"   âŒ [REQ-{correlation_id}] {msg}")
                return "..."

            clinical_case = session_obj.cas_clinique
            if not clinical_case:
                msg = f"Aucun cas clinique associÃ© Ã  la session {session_id}."
                logger.critical(f"   âŒ [REQ-{correlation_id}] {msg}")
                return "(Le patient semble absent... Erreur de configuration du cas)"

            logger.info(f"   âœ… [REQ-{correlation_id}] Contexte chargÃ©: Cas '{clinical_case.code_fultang}' (ID: {clinical_case.id})")

            # --- Ã‰TAPE 2 : Construction du Persona ---
            logger.debug(f"   [REQ-{correlation_id}] Ã‰tape 2: GÃ©nÃ©ration du Persona...")
            persona = self._get_or_create_persona(clinical_case)
            logger.info(f"   ğŸ‘¤ [REQ-{correlation_id}] Persona actif: {persona['nom']} ({persona['age']}, {persona['metier']})")

            # --- Ã‰TAPE 3 : Extraction de la VÃ©ritÃ© Clinique ---
            logger.debug(f"   [REQ-{correlation_id}] Ã‰tape 3: Extraction des donnÃ©es cliniques...")
            clinical_data = self._extract_clinical_data(db, clinical_case)
            
            # --- Ã‰TAPE 4 : Analyse Contextuelle (Actions prÃ©cÃ©dentes) ---
            logger.debug(f"   [REQ-{correlation_id}] Ã‰tape 4: Analyse des Ã©vÃ©nements rÃ©cents...")
            dynamic_context = self._analyze_recent_events(db, session_id)
            if dynamic_context:
                logger.info(f"   âš¡ [REQ-{correlation_id}] Contexte dynamique dÃ©tectÃ©: {dynamic_context}")

            # --- Ã‰TAPE 5 : Construction de l'Historique de Conversation ---
            logger.debug(f"   [REQ-{correlation_id}] Ã‰tape 5: RÃ©cupÃ©ration historique chat...")
            chat_history_str = self._format_chat_history(db, session_id, limit=10)
            
            # --- Ã‰TAPE 6 : Assemblage du Prompt ---
            logger.debug(f"   [REQ-{correlation_id}] Ã‰tape 6: Assemblage du Prompt SystÃ¨me...")
            final_prompt = self.BASE_SYSTEM_PROMPT.format(
                nom=persona['nom'],
                age=persona['age'],
                metier=persona['metier'],
                education=persona['education'],
                stress_level=persona['stress_level'],
                trait_caractere=persona['trait'],
                symptomes_liste=clinical_data['symptomes'],
                histoire_maladie=clinical_data['histoire'],
                antecedents=clinical_data['antecedents'],
                dynamic_context=dynamic_context if dynamic_context else "Rien de particulier ne s'est passÃ© rÃ©cemment."
            )

            # Ajout de l'historique conversationnel Ã  la fin pour le LLM
            messages_payload = [
                {"role": "system", "content": final_prompt}
            ]
            
            # On parse l'historique formatÃ© pour le remettre en structure message (si nÃ©cessaire par l'API)
            # Ou on l'envoie comme contexte. Ici, on va utiliser une mÃ©thode propre.
            raw_history = self._get_raw_chat_history(db, session_id, limit=10)
            for msg in raw_history:
                role = "assistant" if msg.sender == "Patient" else "user"
                # Nettoyage basique du contenu
                content = msg.content.strip() if msg.content else "..."
                messages_payload.append({"role": role, "content": content})
            
            # Ajout du message actuel
            messages_payload.append({"role": "user", "content": student_message})

            logger.debug(f"   ğŸ“¦ [REQ-{correlation_id}] Payload LLM prÃªt ({len(messages_payload)} messages).")
            # Log dÃ©taillÃ© du system prompt pour debug (tronquÃ©)
            logger.debug(f"   ğŸ“„ [REQ-{correlation_id}] System Prompt (Preview): {final_prompt[:300]}...")

            # --- Ã‰TAPE 7 : Appel au Service IA ---
            logger.info(f"   ğŸš€ [REQ-{correlation_id}] Appel API IA en cours...")
            
            # Note: On convertit tout en texte car l'API actuelle _call_openrouter_api prend un string unique
            # Dans une version V2, ai_generation_service devrait accepter une liste de messages.
            full_text_prompt = self._convert_payload_to_text(messages_payload)
            
            ai_response_raw = ai_generation_service._call_openrouter_api(full_text_prompt)
            
            # --- Ã‰TAPE 8 : Traitement de la RÃ©ponse ---
            logger.debug(f"   [REQ-{correlation_id}] Ã‰tape 8: Parsing rÃ©ponse IA...")
            
            patient_response_text = "..."
            
            # L'IA retourne souvent un JSON (car le service est configurÃ© pour le mode JSON)
            # Il faut extraire le texte "parlÃ©"
            if isinstance(ai_response_raw, dict):
                # On cherche les clÃ©s probables
                keys_to_check = ['response', 'content', 'patient_response', 'text', 'message']
                found = False
                for key in keys_to_check:
                    if key in ai_response_raw and ai_response_raw[key]:
                        patient_response_text = ai_response_raw[key]
                        found = True
                        break
                
                if not found:
                    # Si aucune clÃ© standard, on prend la premiÃ¨re valeur string trouvÃ©e
                    logger.warning(f"   âš ï¸ [REQ-{correlation_id}] Structure JSON IA inconnue: {ai_response_raw.keys()}")
                    for v in ai_response_raw.values():
                        if isinstance(v, str):
                            patient_response_text = v
                            break
            elif isinstance(ai_response_raw, str):
                patient_response_text = ai_response_raw
            
            # Nettoyage final (suppression de guillemets parasites, etc.)
            patient_response_text = self._clean_text_response(patient_response_text)

            execution_time = time.time() - start_time
            logger.info(f"   ğŸ [REQ-{correlation_id}] FIN GÃ‰NÃ‰RATION ({execution_time:.2f}s)")
            logger.info(f"   ğŸ—£ï¸ [PATIENT] : {patient_response_text[:100]}...")

            return patient_response_text

        except Exception as e:
            logger.error(f"   âŒ [REQ-{correlation_id}] ERREUR CRITIQUE DANS PATIENT_ACTOR: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            # Fallback en cas de crash complet pour ne pas casser l'UI
            return "Je... excusez-moi, j'ai un moment d'absence. Pouvez-vous rÃ©pÃ©ter ?"

    # ==============================================================================
    # MÃ‰THODES PRIVÃ‰ES (HELPER METHODS)
    # ==============================================================================

    def _get_or_create_persona(self, case: models.ClinicalCase) -> Dict[str, Any]:
        """
        GÃ©nÃ¨re un persona cohÃ©rent et dÃ©terministe basÃ© sur l'ID du cas.
        Cela garantit que si on relance la session, le patient a le mÃªme nom/Ã¢ge.
        """
        # Utiliser l'ID du cas comme graine (seed) pour le gÃ©nÃ©rateur alÃ©atoire
        seed_value = case.id if case.id else 12345
        rng = random.Random(seed_value)

        # Banques de donnÃ©es pour la gÃ©nÃ©ration
        noms_famille = ["Kamga", "Abessolo", "Nguema", "Tchatat", "Mbarga", "Eto'o", "Fossi", "Minka", "Onana", "Siewe"]
        prenoms_h = ["Jean", "Pierre", "Paul", "Joseph", "Emmanuel", "Samuel", "Roger", "Alain"]
        prenoms_f = ["Marie", "Suzanne", "Jeanne", "Bernadette", "Chantal", "Solange", "Carine", "Odile"]
        
        metiers_ville = ["CommerÃ§ant", "Enseignant", "Fonctionnaire", "Chauffeur de taxi", "Ã‰tudiant", "Comptable"]
        metiers_campagne = ["Agriculteur", "Ã‰leveur", "CommerÃ§ant", "RetraitÃ©"]
        
        # DÃ©termination du genre (50/50 ou basÃ© sur le cas si spÃ©cifiÃ© plus tard)
        genre = rng.choice(["H", "F"])
        
        # GÃ©nÃ©ration
        nom = rng.choice(noms_famille)
        prenom = rng.choice(prenoms_h) if genre == "H" else rng.choice(prenoms_f)
        full_name = f"{prenom} {nom}"
        
        # Ã‚ge : on essaie de le parser de l'histoire, sinon alÃ©atoire cohÃ©rent
        age = rng.randint(25, 75)
        raw_history = str(case.presentation_clinique.get('histoire_maladie', ''))
        # Tentative naÃ¯ve d'extraction d'Ã¢ge par regex (ex: "Patient de 45 ans")
        age_match = re.search(r'(\d{2})\s*ans', raw_history)
        if age_match:
            age = int(age_match.group(1))
            logger.debug(f"      -> Ã‚ge extrait du texte : {age} ans")
        
        # Contexte social
        milieu = rng.choice(["Ville", "Campagne"])
        metier = rng.choice(metiers_ville) if milieu == "Ville" else rng.choice(metiers_campagne)
        
        # Niveau d'Ã©ducation (impacte le vocabulaire)
        education_level = rng.choice(["primaire (parle simplement)", "secondaire (vocabulaire standard)", "universitaire (articulÃ©)"])
        
        # Niveau de stress (1-10)
        # On augmente le stress si le cas est grave (niveau_difficulte)
        base_stress = rng.randint(1, 5)
        case_severity = case.niveau_difficulte if case.niveau_difficulte else 1
        stress_level = min(10, base_stress + int(case_severity / 2))

        return {
            "nom": full_name,
            "genre": genre,
            "age": f"{age} ans",
            "metier": metier,
            "education": education_level,
            "stress_level": stress_level,
            "trait": rng.choice(["Bavard", "Timide", "Anxieux", "StoÃ¯que", "Impatient", "Confus"])
        }

    def _extract_clinical_data(self, db: Session, case: models.ClinicalCase) -> Dict[str, str]:
        """
        Transforme les donnÃ©es relationnelles/JSON de la BDD en texte narratif pour le prompt.
        """
        # 1. Histoire
        presentation = case.presentation_clinique or {}
        histoire = presentation.get("histoire_maladie", "Pas d'histoire disponible.")
        
        # 2. SymptÃ´mes
        # Les symptÃ´mes sont souvent stockÃ©s sous forme d'IDs dans le JSON presentation_clinique
        # Structure attendue : [{'symptome_id': 123, 'details': '...'}, ...]
        symptomes_txt = []
        raw_symptoms = presentation.get("symptomes_patient", [])
        
        if isinstance(raw_symptoms, list):
            for item in raw_symptoms:
                if isinstance(item, dict):
                    s_id = item.get("symptome_id")
                    details = item.get("details", "")
                    
                    # RÃ©cupÃ©ration du nom du symptÃ´me
                    symptom_name = "SymptÃ´me inconnu"
                    if s_id:
                        symptom_obj = db.query(models.Symptom).filter(models.Symptom.id == s_id).first()
                        if symptom_obj:
                            symptom_name = symptom_obj.nom
                            # Ajout du nom local si disponible pour plus de rÃ©alisme
                            if symptom_obj.nom_local:
                                symptom_name += f" (ou '{symptom_obj.nom_local}')"
                    
                    line = f"- {symptom_name}"
                    if details:
                        line += f" : {details}"
                    symptomes_txt.append(line)
        
        if not symptomes_txt:
            symptomes_txt = ["Aucun symptÃ´me spÃ©cifique listÃ© (improviser selon l'histoire)."]

        # 3. AntÃ©cÃ©dents
        antecedents_raw = presentation.get("antecedents", {})
        antecedents_txt = "Aucun antÃ©cÃ©dent notable."
        if isinstance(antecedents_raw, dict):
            # Transformation simple du dict en texte
            parts = []
            for k, v in antecedents_raw.items():
                if isinstance(v, list):
                    v_str = ", ".join(v)
                    parts.append(f"{k}: {v_str}")
                else:
                    parts.append(f"{k}: {v}")
            if parts:
                antecedents_txt = "\n".join(parts)
        elif isinstance(antecedents_raw, str):
            antecedents_txt = antecedents_raw

        return {
            "histoire": histoire,
            "symptomes": "\n".join(symptomes_txt),
            "antecedents": antecedents_txt
        }

    def _analyze_recent_events(self, db: Session, session_id: UUID) -> Optional[str]:
        """
        VÃ©rifie les logs d'interaction pour voir si des actions pertinentes ont eu lieu
        rÃ©cemment (ex: prise de mÃ©dicament) et adapte le contexte.
        """
        # RÃ©cupÃ©rer les 5 derniÃ¨res actions
        recent_logs = db.query(models.InteractionLog).filter(
            models.InteractionLog.session_id == session_id
        ).order_by(models.InteractionLog.timestamp.desc()).limit(5).all()
        
        context_updates = []
        
        for log in recent_logs:
            # Exemple : Si l'Ã©tudiant a prescrit un antidouleur
            # Note: Il faudrait une logique plus poussÃ©e pour mapper les types de mÃ©dicaments
            # Ici on fait une dÃ©tection basique sur le nom de l'action
            content = log.action_content or {}
            action_name = str(content.get("name", "")).lower()
            
            if "paracÃ©tamol" in action_name or "morphine" in action_name or "antalgique" in action_name:
                context_updates.append("Le mÃ©decin t'a donnÃ© un mÃ©dicament contre la douleur. Tu commences Ã  te sentir un peu soulagÃ©.")
            
            if "examen" in action_name:
                context_updates.append(f"Le mÃ©decin t'a fait passer un examen : {action_name}. Tu attends les rÃ©sultats.")

        if context_updates:
            return "\n".join(context_updates)
        return None

    def _get_raw_chat_history(self, db: Session, session_id: UUID, limit: int = 10) -> List[models.ChatMessage]:
        """RÃ©cupÃ¨re les objets messages bruts."""
        return db.query(models.ChatMessage).filter(
            models.ChatMessage.session_id == session_id
        ).order_by(models.ChatMessage.timestamp.desc()).limit(limit).all()[::-1] # Ordre chronologique

    def _format_chat_history(self, db: Session, session_id: UUID, limit: int = 10) -> str:
        """Formate l'historique en bloc de texte pour le log ou le debug."""
        msgs = self._get_raw_chat_history(db, session_id, limit)
        txt = ""
        for m in msgs:
            txt += f"[{m.sender}]: {m.content}\n"
        return txt

    def _convert_payload_to_text(self, messages: List[Dict[str, str]]) -> str:
        """
        Convertit la liste de messages structurÃ©s en un prompt textuel unique
        pour l'API d'IA actuelle.
        """
        prompt = ""
        for msg in messages:
            role = msg['role'].upper()
            content = msg['content']
            prompt += f"\n--- {role} ---\n{content}\n"
        
        prompt += "\n--- ASSISTANT (PATIENT) ---\n"
        return prompt

    def _clean_text_response(self, text: str) -> str:
        """
        Nettoie la rÃ©ponse gÃ©nÃ©rÃ©e par l'IA pour enlever les artefacts.
        """
        if not text:
            return "..."
            
        # Supprimer les balises JSON si l'IA a hallucinÃ© du JSON
        if text.strip().startswith("{") and text.strip().endswith("}"):
            try:
                data = json.loads(text)
                # Chercher une valeur textuelle
                return str(list(data.values())[0])
            except:
                pass
        
        # Supprimer les prÃ©fixes de rÃ´le que l'IA ajoute parfois
        text = re.sub(r'^(Patient|Assistant|Moi) :', '', text, flags=re.IGNORECASE)
        
        # Supprimer les guillemets englobants
        text = text.strip().strip('"').strip("'")
        
        return text

# Instance globale prÃªte Ã  l'emploi
patient_actor_service = PatientActorService()

=== Fichier: ./app/services/symptom_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas
from ..utils.exceptions import NotFoundException # Nous crÃ©erons ce fichier plus tard


def get_symptom_by_id(db: Session, symptom_id: int) -> Optional[models.Symptom]:
    """
    RÃ©cupÃ¨re un symptÃ´me par son ID.
    """
    return db.query(models.Symptom).filter(models.Symptom.id == symptom_id).first()


def get_symptom_by_name(db: Session, name: str) -> Optional[models.Symptom]:
    """
    RÃ©cupÃ¨re un symptÃ´me par son nom.
    """
    return db.query(models.Symptom).filter(models.Symptom.nom == name).first()


def get_all_symptoms(db: Session, skip: int = 0, limit: int = 100) -> List[models.Symptom]:
    """
    RÃ©cupÃ¨re une liste de tous les symptÃ´mes avec pagination.
    """
    return db.query(models.Symptom).offset(skip).limit(limit).all()


def create_symptom(db: Session, symptom: schemas.SymptomCreate) -> models.Symptom:
    """
    CrÃ©e un nouveau symptÃ´me dans la base de donnÃ©es.
    
    Prend un schÃ©ma Pydantic 'SymptomCreate' en entrÃ©e, le convertit en
    modÃ¨le SQLAlchemy 'Symptom' et l'ajoute Ã  la base de donnÃ©es.
    """
    # Convertit le schÃ©ma Pydantic en dictionnaire
    symptom_data = symptom.model_dump()
    
    # CrÃ©e une instance du modÃ¨le SQLAlchemy
    db_symptom = models.Symptom(**symptom_data)
    
    # Ajoute l'instance Ã  la session de la base de donnÃ©es
    db.add(db_symptom)
    # Valide la transaction pour l'Ã©crire en base
    db.commit()
    # RafraÃ®chit l'instance pour obtenir les valeurs gÃ©nÃ©rÃ©es par la BDD (comme l'ID)
    db.refresh(db_symptom)
    
    return db_symptom


def update_symptom(db: Session, symptom_id: int, symptom_update: schemas.SymptomUpdate) -> Optional[models.Symptom]:
    """
    Met Ã  jour un symptÃ´me existant.
    """
    db_symptom = get_symptom_by_id(db, symptom_id)
    if not db_symptom:
        # Plus tard, nous lÃ¨verons une exception personnalisÃ©e
        # raise NotFoundException(detail=f"Symptom with id {symptom_id} not found")
        return None

    # Convertit le schÃ©ma Pydantic en dictionnaire, en excluant les valeurs non dÃ©finies
    update_data = symptom_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_symptom, key, value)
        
    db.commit()
    db.refresh(db_symptom)
    
    return db_symptom


def delete_symptom(db: Session, symptom_id: int) -> Optional[models.Symptom]:
    """
    Supprime un symptÃ´me de la base de donnÃ©es.
    """
    db_symptom = get_symptom_by_id(db, symptom_id)
    if not db_symptom:
        # raise NotFoundException(detail=f"Symptom with id {symptom_id} not found")
        return None

    db.delete(db_symptom)
    db.commit()
    
    return db_symptom

def get_diseases_for_symptom(db: Session, symptom_id: int) -> List[models.PathologieSymptome]:
    """
    RÃ©cupÃ¨re toutes les pathologies associÃ©es Ã  un symptÃ´me (diagnostic diffÃ©rentiel).
    """
    return db.query(models.PathologieSymptome).filter(models.PathologieSymptome.symptome_id == symptom_id).all()





def add_treatment_to_symptom(db: Session, association_data: schemas.relations.TraitementSymptomeCreate) -> models.TraitementSymptome:
    """
    Associe un mÃ©dicament Ã  un symptÃ´me en tant que traitement symptomatique.
    """
    db_symptom = get_symptom_by_id(db, symptom_id=association_data.symptome_id)
    from . import medication_service
    db_medication = medication_service.get_medication_by_id(db, medication_id=association_data.medicament_id)

    if not db_symptom or not db_medication:
        raise ValueError("SymptÃ´me ou MÃ©dicament non trouvÃ©.")

    association = models.TraitementSymptome(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_treatments_for_symptom(db: Session, symptom_id: int) -> List[models.TraitementSymptome]:
    """
    RÃ©cupÃ¨re tous les traitements associÃ©s Ã  un symptÃ´me.
    """
    return db.query(models.TraitementSymptome).filter(models.TraitementSymptome.symptome_id == symptom_id).all()

=== Fichier: ./app/services/clinical_case_service.py ===

import logging
from sqlalchemy.orm import Session
from typing import List, Optional
import random

from .. import models, schemas
from . import disease_service, media_service

# Logger spÃ©cifique
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

def get_case_by_id(db: Session, case_id: int) -> Optional[models.ClinicalCase]:
    return db.query(models.ClinicalCase).filter(models.ClinicalCase.id == case_id).first()

def get_case_by_code(db: Session, code: str) -> Optional[models.ClinicalCase]:
    return db.query(models.ClinicalCase).filter(models.ClinicalCase.code_fultang == code).first()

def get_all_cases(db: Session, skip: int = 0, limit: int = 100) -> List[models.ClinicalCase]:
    return db.query(models.ClinicalCase).offset(skip).limit(limit).all()

def get_case_for_progression(
    db: Session, 
    category: str, 
    target_difficulty: int, 
    exclude_case_ids: List[int]
) -> Optional[models.ClinicalCase]:
    """
    Recherche intelligente de cas.
    """
    logger.info(f"ğŸ“š [CASE-SEARCH] Recherche: Cat='{category}', Cible={target_difficulty}")
    logger.debug(f"   -> Exclusions ({len(exclude_case_ids)}): {exclude_case_ids}")

    base_query = db.query(models.ClinicalCase).join(
        models.Disease, models.ClinicalCase.pathologie_principale_id == models.Disease.id
    ).filter(
        models.Disease.categorie == category,
        models.ClinicalCase.id.notin_(exclude_case_ids)
    )

    # Fonction helper pour sÃ©curiser le niveau
    def get_difficulty(c):
        return c.niveau_difficulte if c.niveau_difficulte is not None else 1

    # 1. Recherche stricte (Cible +/- 2)
    strict_candidates = base_query.filter(
        models.ClinicalCase.niveau_difficulte.between(target_difficulty - 2, target_difficulty + 2)
    ).all()
    
    logger.debug(f"   -> Candidats stricts (+/-2): {len(strict_candidates)}")

    if strict_candidates:
        chosen = random.choice(strict_candidates)
        logger.info(f"   âœ… [FOUND] Cas strict trouvÃ©: {chosen.id} (Niveau {get_difficulty(chosen)})")
        return chosen

    # 2. Recherche Ã©largie (Cible +/- 5)
    wide_candidates = base_query.filter(
        models.ClinicalCase.niveau_difficulte.between(target_difficulty - 5, target_difficulty + 5)
    ).all()

    logger.debug(f"   -> Candidats larges (+/-5): {len(wide_candidates)}")

    if wide_candidates:
        chosen = min(wide_candidates, key=lambda c: abs(get_difficulty(c) - target_difficulty))
        logger.info(f"   âœ… [FOUND] Cas large trouvÃ©: {chosen.id} (Niveau {get_difficulty(chosen)})")
        return chosen

    # 3. Fallback
    fallback_candidates = base_query.all()
    logger.debug(f"   -> Candidats fallback (tout reste): {len(fallback_candidates)}")
    
    if fallback_candidates:
        # On filtre ceux qui n'ont pas de niveau pour Ã©viter les erreurs, ou on leur donne une valeur par dÃ©faut
        valid_candidates = [c for c in fallback_candidates]
        
        if not valid_candidates:
             logger.error("   âŒ [ERROR] Cas trouvÃ©s mais aucun valide (problÃ¨me de donnÃ©es ?)")
             return None

        chosen = min(valid_candidates, key=lambda c: abs(get_difficulty(c) - target_difficulty))
        logger.info(f"   âš ï¸ [FOUND] Cas fallback trouvÃ©: {chosen.id} (Niveau {get_difficulty(chosen)})")
        return chosen

    logger.error("   âŒ [NOT-FOUND] Aucun cas disponible.")
    return None



# --- NOUVELLE FONCTION ---
def get_cases_by_category(db: Session, category: str) -> List[models.ClinicalCase]:
    """RÃ©cupÃ¨re tous les cas d'une catÃ©gorie spÃ©cifique."""
    return db.query(models.ClinicalCase).join(
        models.Disease, models.ClinicalCase.pathologie_principale_id == models.Disease.id
    ).filter(
        models.Disease.categorie == category
    ).all()



# Fonctions CRUD standard
def create_case(db: Session, case: schemas.ClinicalCaseCreate) -> models.ClinicalCase:
    if case.pathologie_principale_id:
        if not disease_service.get_disease_by_id(db, case.pathologie_principale_id):
            raise ValueError(f"Pathologie {case.pathologie_principale_id} introuvable")
    
    case_data = case.model_dump()
    db_case = models.ClinicalCase(**case_data)
    db.add(db_case)
    db.commit()
    db.refresh(db_case)
    return db_case

def update_case(db: Session, case_id: int, case_update: schemas.ClinicalCaseUpdate) -> Optional[models.ClinicalCase]:
    db_case = get_case_by_id(db, case_id)
    if not db_case: return None
    for key, value in case_update.model_dump(exclude_unset=True).items():
        setattr(db_case, key, value)
    db.commit()
    db.refresh(db_case)
    return db_case

def delete_case(db: Session, case_id: int) -> Optional[models.ClinicalCase]:
    db_case = get_case_by_id(db, case_id)
    if not db_case: return None
    db.delete(db_case)
    db.commit()
    return db_case

=== Fichier: ./app/services/expert_strategy_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_strategy_by_id(db: Session, strategy_id: int) -> Optional[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re une rÃ¨gle par son ID.
    """
    return db.query(models.ExpertStrategy).filter(models.ExpertStrategy.id == strategy_id).first()

def get_strategy_by_code(db: Session, code: str) -> Optional[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re une rÃ¨gle par son code unique.
    """
    return db.query(models.ExpertStrategy).filter(models.ExpertStrategy.code_regle == code).first()

def get_all_strategies(db: Session, skip: int = 0, limit: int = 100) -> List[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re une liste de toutes les rÃ¨gles avec pagination.
    """
    return db.query(models.ExpertStrategy).offset(skip).limit(limit).all()

def get_active_strategies_by_category(db: Session, category: str) -> List[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re toutes les rÃ¨gles actives pour une catÃ©gorie donnÃ©e, triÃ©es par prioritÃ©.
    Cette fonction sera trÃ¨s utile pour le moteur de raisonnement.
    """
    return db.query(models.ExpertStrategy).filter(
        models.ExpertStrategy.categorie == category,
        models.ExpertStrategy.est_active == True
    ).order_by(models.ExpertStrategy.priorite.desc()).all()


def create_strategy(db: Session, strategy: schemas.ExpertStrategyCreate) -> models.ExpertStrategy:
    """
    CrÃ©e une nouvelle rÃ¨gle dans la base de donnÃ©es.
    """
    strategy_data = strategy.model_dump()
    db_strategy = models.ExpertStrategy(**strategy_data)
    
    db.add(db_strategy)
    db.commit()
    db.refresh(db_strategy)
    
    return db_strategy

def update_strategy(db: Session, strategy_id: int, strategy_update: schemas.ExpertStrategyUpdate) -> Optional[models.ExpertStrategy]:
    """
    Met Ã  jour une rÃ¨gle existante.
    """
    db_strategy = get_strategy_by_id(db, strategy_id)
    if not db_strategy:
        return None

    update_data = strategy_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_strategy, key, value)
        
    db.commit()
    db.refresh(db_strategy)
    
    return db_strategy

def delete_strategy(db: Session, strategy_id: int) -> Optional[models.ExpertStrategy]:
    """
    Supprime une rÃ¨gle de la base de donnÃ©es.
    """
    db_strategy = get_strategy_by_id(db, strategy_id)
    if not db_strategy:
        return None

    db.delete(db_strategy)
    db.commit()
    
    return db_strategy

=== Fichier: ./app/services/embedding_service.py ===

from sentence_transformers import SentenceTransformer
import logging

# Configuration du logging
logger = logging.getLogger(__name__)

class EmbeddingService:
    """
    Service pour gÃ©nÃ©rer des embeddings (vecteurs) Ã  partir de texte.
    Utilise le modÃ¨le 'all-MiniLM-L6-v2' qui est un excellent compromis
    rapiditÃ©/qualitÃ© pour l'anglais et le franÃ§ais technique.
    """
    
    _instance = None
    _model = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(EmbeddingService, cls).__new__(cls)
            logger.info("Initialisation du modÃ¨le d'embedding...")
            # Chargement du modÃ¨le. On essaie sans le prÃ©fixe 'sentence-transformers/'
            # Si cela Ã©choue encore, nous essaierons une autre approche.
            try:
                cls._model = SentenceTransformer('all-MiniLM-L6-v2')
            except Exception as e:
                logger.error(f"Erreur chargement modÃ¨le 'all-MiniLM-L6-v2': {e}")
                # Tentative de repli explicite
                cls._model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
            
            logger.info("ModÃ¨le d'embedding chargÃ© avec succÃ¨s.")
        return cls._instance

    def get_text_embedding(self, text: str) -> list:
        """
        GÃ©nÃ¨re un vecteur d'embedding pour une chaÃ®ne de caractÃ¨res donnÃ©e.
        
        :param text: Le texte Ã  vectoriser.
        :return: Une liste de flottants (le vecteur).
        """
        if not text or not isinstance(text, str):
            return None
            
        try:
            # Le modÃ¨le retourne un numpy array, on le convertit en liste simple
            # pour qu'il soit compatible avec pgvector et JSON.
            embedding = self._model.encode(text)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"Erreur lors de la vectorisation du texte : {e}")
            return None

# Instance globale prÃªte Ã  l'emploi
embedding_service = EmbeddingService()

=== Fichier: ./app/services/chat_service.py ===

#=== Fichier: ./app/services/chat_service.py ===

import logging
import time
import uuid
import json
from typing import List, Optional
from uuid import UUID
from datetime import datetime

from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError

from .. import models, schemas
from .patient_actor_service import patient_actor_service

# ==============================================================================
# CONFIGURATION DU LOGGER "CHAT"
# ==============================================================================
logger = logging.getLogger("chat_service")
logger.setLevel(logging.DEBUG)

if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - [CHAT-SVC] - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)

def create_chat_message(db: Session, session_id: UUID, message: schemas.ChatMessageCreate) -> models.ChatMessage:
    """
    CrÃ©e un message dans le chat et, si l'expÃ©diteur est l'Ã©tudiant, 
    dÃ©clenche la rÃ©ponse automatique du Patient Actor.
    
    Cette fonction est le "Chef d'Orchestre" du dialogue.
    """
    request_id = str(uuid.uuid4())[:8]
    start_total = time.time()
    
    logger.info(f"ğŸ“¨ [REQ-{request_id}] Nouvelle demande de message pour Session {session_id}")
    logger.debug(f"   [REQ-{request_id}] DonnÃ©es brutes reÃ§ues : {message.model_dump()}")

    # 1. Validation PrÃ©alable de la Session
    # -------------------------------------------------------------------------
    try:
        logger.debug(f"   [REQ-{request_id}] VÃ©rification existence session...")
        db_session = db.query(models.SimulationSession).filter(
            models.SimulationSession.id == session_id
        ).first()

        if not db_session:
            logger.error(f"   âŒ [REQ-{request_id}] Session introuvable UUID={session_id}")
            raise ValueError(f"La session avec l'ID {session_id} n'a pas Ã©tÃ© trouvÃ©e.")
        
        # VÃ©rification si la session est terminÃ©e (optionnel, selon rÃ¨gles mÃ©tier)
        if db_session.statut in ["completed", "abandoned"]:
            logger.warning(f"   âš ï¸ [REQ-{request_id}] Tentative d'Ã©criture dans une session terminÃ©e ({db_session.statut})")
            # On laisse passer pour l'instant, mais on logue le warning.

    except SQLAlchemyError as e:
        logger.critical(f"   âŒ [REQ-{request_id}] Erreur DB lors de la vÃ©rification session : {str(e)}")
        raise e

    # 2. Persistance du Message de l'Apprenant (USER)
    # -------------------------------------------------------------------------
    learner_msg_obj = None
    try:
        logger.info(f"   ğŸ’¾ [REQ-{request_id}] Enregistrement message APPRENANT...")
        
        learner_msg_obj = models.ChatMessage(
            session_id=session_id,
            sender=message.sender,
            content=message.content,
            message_metadata=message.message_metadata or {},
            timestamp=datetime.now()
        )
        
        db.add(learner_msg_obj)
        db.commit()
        db.refresh(learner_msg_obj)
        
        logger.info(f"   âœ… [REQ-{request_id}] Message Apprenant sauvegardÃ© (ID: {learner_msg_obj.id})")

    except Exception as e:
        db.rollback()
        logger.error(f"   âŒ [REQ-{request_id}] Ã‰chec sauvegarde message apprenant : {str(e)}")
        raise e

    # 3. DÃ©clenchement du Patient Actor (IA)
    # -------------------------------------------------------------------------
    # On ne dÃ©clenche que si c'est un Ã©tudiant/apprenant qui parle.
    # Si c'est "System" ou "Tutor" ou dÃ©jÃ  "Patient", on ne rÃ©pond pas.
    
    AUTHORIZED_SENDERS_TRIGGER = ["student", "apprenant", "learner", "user"]
    sender_normalized = message.sender.lower().strip()
    
    if sender_normalized in AUTHORIZED_SENDERS_TRIGGER:
        logger.info(f"   ğŸ­ [REQ-{request_id}] DÃ©clenchement du PATIENT ACTOR requis (Sender='{message.sender}')")
        
        try:
            # Appel synchrone au service Patient Actor
            # Note : Cela peut prendre 2 Ã  10 secondes selon le LLM.
            actor_start = time.time()
            
            logger.debug(f"   [REQ-{request_id}] >> Passage de relais au PatientActorService...")
            
            patient_response_text = patient_actor_service.generate_response(
                db=db,
                session_id=session_id,
                student_message=message.content
            )
            
            actor_duration = time.time() - actor_start
            logger.debug(f"   [REQ-{request_id}] << Retour du PatientActorService ({actor_duration:.2f}s)")
            
            if not patient_response_text:
                logger.warning(f"   âš ï¸ [REQ-{request_id}] Le Patient Actor a renvoyÃ© une rÃ©ponse vide.")
                patient_response_text = "..."

            # 4. Persistance de la RÃ©ponse du Patient (AI)
            # ---------------------------------------------------------------------
            logger.info(f"   ğŸ’¾ [REQ-{request_id}] Enregistrement rÃ©ponse PATIENT...")
            
            patient_msg_obj = models.ChatMessage(
                session_id=session_id,
                sender="Patient", # ExpÃ©diteur normalisÃ©
                content=patient_response_text,
                message_metadata={
                    "generated_by": "PatientActorService",
                    "model": "LLM", 
                    "reply_to": learner_msg_obj.id,
                    "processing_time": f"{actor_duration:.2f}s"
                },
                timestamp=datetime.now()
            )
            
            db.add(patient_msg_obj)
            db.commit()
            db.refresh(patient_msg_obj)
            
            logger.info(f"   âœ… [REQ-{request_id}] RÃ©ponse Patient sauvegardÃ©e (ID: {patient_msg_obj.id})")

        except Exception as e:
            # Si l'IA plante, on ne veut pas faire Ã©chouer la requÃªte HTTP de l'Ã©tudiant.
            # Son message a dÃ©jÃ  Ã©tÃ© enregistrÃ© Ã  l'Ã©tape 2.
            # On logue l'erreur critique mais on continue.
            logger.critical(f"   âŒ [REQ-{request_id}] CRASH PATIENT ACTOR : {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            
            # Optionnel : InsÃ©rer un message systÃ¨me d'erreur dans le chat ?
            # Pour l'instant, on laisse silencieux pour ne pas briser l'immersion,
            # ou on pourrait mettre un message "Le patient ne semble pas vous entendre..."
    else:
        logger.info(f"   zzz [REQ-{request_id}] Pas de dÃ©clenchement IA (Sender '{message.sender}' ignorÃ©)")

    total_duration = time.time() - start_total
    logger.info(f"ğŸ [REQ-{request_id}] Traitement message terminÃ© en {total_duration:.2f}s")
    
    # On retourne l'objet message INITIAL (celui de l'utilisateur), 
    # car c'est la rÃ©ponse REST standard Ã  un POST.
    # Le frontend devra rafraÃ®chir (GET) pour voir la rÃ©ponse du patient.
    return learner_msg_obj


def get_messages_by_session(db: Session, session_id: UUID) -> List[models.ChatMessage]:
    """
    RÃ©cupÃ¨re l'historique complet des messages pour une session.
    TriÃ© par ordre chronologique croissant (du plus vieux au plus rÃ©cent).
    """
    start = time.time()
    request_id = str(uuid.uuid4())[:4]
    
    logger.debug(f"ğŸ“œ [HIST-{request_id}] RÃ©cupÃ©ration historique Session {session_id}")
    
    try:
        messages = db.query(models.ChatMessage).filter(
            models.ChatMessage.session_id == session_id
        ).order_by(models.ChatMessage.timestamp.asc()).all()
        
        duration = time.time() - start
        
        # Logs statistiques
        count_student = sum(1 for m in messages if m.sender in ["Apprenant", "Student", "student"])
        count_patient = sum(1 for m in messages if m.sender == "Patient")
        count_system = len(messages) - count_student - count_patient
        
        logger.info(f"   âœ… [HIST-{request_id}] {len(messages)} messages trouvÃ©s ({duration:.3f}s)")
        logger.debug(f"      - Apprenant : {count_student}")
        logger.debug(f"      - Patient   : {count_patient}")
        logger.debug(f"      - SystÃ¨me   : {count_system}")
        
        return messages
        
    except SQLAlchemyError as e:
        logger.error(f"   âŒ [HIST-{request_id}] Erreur DB lecture historique : {str(e)}")
        raise e

=== Fichier: ./app/services/diagnostic_engine.py ===

from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional

from .. import models
from ..core import reasoning_engine
from . import expert_strategy_service

# Pour le typage, nous pouvons dÃ©finir un schÃ©ma simple ici
from pydantic import BaseModel

class DiagnosticInput(BaseModel):
    """
    SchÃ©ma simple pour les donnÃ©es d'entrÃ©e du moteur de diagnostic.
    """
    symptoms: List[str]
    context: List[str] = []
    age: Optional[int] = None
    # ... d'autres faits pertinents pourraient Ãªtre ajoutÃ©s ici


def run_diagnostic(db: Session, patient_facts: DiagnosticInput) -> List[Dict[str, Any]]:
    """
    Orchestre le processus de diagnostic.

    1. RÃ©cupÃ¨re les rÃ¨gles de diagnostic actives depuis la base de donnÃ©es.
    2. Formate les faits du patient.
    3. Appelle le moteur de raisonnement.
    4. Retourne les actions/conclusions.
    """
    # 1. RÃ©cupÃ©rer les rÃ¨gles
    # On utilise la fonction 'intelligente' que nous avions crÃ©Ã©e dans le service des stratÃ©gies
    diagnostic_rules_db = expert_strategy_service.get_active_strategies_by_category(
        db, category="DIAGNOSTIC"
    )

    if not diagnostic_rules_db:
        return []

    # Convertir les objets SQLAlchemy en dictionnaires simples pour le moteur de logique pure
    rules_list = [
        {
            "code_regle": rule.code_regle,
            "conditions": rule.conditions,
            "actions": rule.actions,
        }
        for rule in diagnostic_rules_db
    ]

    # 2. Formater les faits (dÃ©jÃ  au bon format grÃ¢ce Ã  Pydantic)
    facts_dict = patient_facts.model_dump()

    # 3. Appeler le moteur de raisonnement
    conclusions = reasoning_engine.forward_chaining_engine(
        rules=rules_list,
        facts=facts_dict
    )

    # 4. Retourner les conclusions
    return conclusions

=== Fichier: ./app/services/q_matrix_service.py ===



=== Fichier: ./app/services/disease_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_disease_by_id(db: Session, disease_id: int) -> Optional[models.Disease]:
    """
    RÃ©cupÃ¨re une pathologie par son ID.
    """
    return db.query(models.Disease).filter(models.Disease.id == disease_id).first()

def get_disease_by_icd10(db: Session, icd10_code: str) -> Optional[models.Disease]:
    """
    RÃ©cupÃ¨re une pathologie par son code CIM-10.
    """
    return db.query(models.Disease).filter(models.Disease.code_icd10 == icd10_code).first()

def get_all_diseases(db: Session, skip: int = 0, limit: int = 100) -> List[models.Disease]:
    """
    RÃ©cupÃ¨re une liste de toutes les pathologies avec pagination.
    """
    return db.query(models.Disease).offset(skip).limit(limit).all()

def create_disease(db: Session, disease: schemas.DiseaseCreate) -> models.Disease:
    """
    CrÃ©e une nouvelle pathologie dans la base de donnÃ©es.
    """
    disease_data = disease.model_dump()
    db_disease = models.Disease(**disease_data)
    
    db.add(db_disease)
    db.commit()
    db.refresh(db_disease)
    
    return db_disease

def update_disease(db: Session, disease_id: int, disease_update: schemas.DiseaseUpdate) -> Optional[models.Disease]:
    """
    Met Ã  jour une pathologie existante.
    """
    db_disease = get_disease_by_id(db, disease_id)
    if not db_disease:
        return None

    update_data = disease_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_disease, key, value)
        
    db.commit()
    db.refresh(db_disease)
    
    return db_disease

def delete_disease(db: Session, disease_id: int) -> Optional[models.Disease]:
    """
    Supprime une pathologie de la base de donnÃ©es.
    """
    db_disease = get_disease_by_id(db, disease_id)
    if not db_disease:
        return None

    db.delete(db_disease)
    db.commit()
    
    return db_disease

def add_symptom_to_disease(db: Session, association_data: schemas.relations.PathologieSymptomeCreate) -> models.PathologieSymptome:
    """
    Associe un symptÃ´me Ã  une pathologie avec des attributs de relation.
    """
    # VÃ©rifier que la pathologie et le symptÃ´me existent
    db_disease = get_disease_by_id(db, disease_id=association_data.pathologie_id)
    # Nous aurons besoin d'importer le symptom_service pour cette vÃ©rification
    from . import symptom_service
    db_symptom = symptom_service.get_symptom_by_id(db, symptom_id=association_data.symptome_id)

    if not db_disease or not db_symptom:
        # IdÃ©alement, lever une exception plus spÃ©cifique
        raise ValueError("Pathologie ou SymptÃ´me non trouvÃ©.")

    # CrÃ©er l'objet d'association
    association = models.PathologieSymptome(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_symptoms_for_disease(db: Session, disease_id: int) -> List[models.PathologieSymptome]:
    """
    RÃ©cupÃ¨re tous les symptÃ´mes associÃ©s Ã  une pathologie, avec les dÃ©tails de la relation.
    """
    return db.query(models.PathologieSymptome).filter(models.PathologieSymptome.pathologie_id == disease_id).all()


def add_treatment_to_disease(db: Session, association_data: schemas.relations.TraitementPathologieCreate) -> models.TraitementPathologie:
    """
    Associe un mÃ©dicament Ã  une pathologie en tant que traitement.
    """
    db_disease = get_disease_by_id(db, disease_id=association_data.pathologie_id)
    from . import medication_service
    db_medication = medication_service.get_medication_by_id(db, medication_id=association_data.medicament_id)

    if not db_disease or not db_medication:
        raise ValueError("Pathologie ou MÃ©dicament non trouvÃ©.")

    association = models.TraitementPathologie(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_treatments_for_disease(db: Session, disease_id: int) -> List[models.TraitementPathologie]:
    """
    RÃ©cupÃ¨re tous les traitements associÃ©s Ã  une pathologie.
    """
    return db.query(models.TraitementPathologie).filter(models.TraitementPathologie.pathologie_id == disease_id).all()

=== Fichier: ./app/dependencies.py ===

# app/dependencies.py
from .database import SessionLocal

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

=== Fichier: ./app/middleware/logging_middleware.py ===



=== Fichier: ./app/middleware/__init__.py ===



=== Fichier: ./app/middleware/error_handler.py ===



=== Fichier: ./app/middleware/cors_middleware.py ===



=== Fichier: ./app/config.py ===

from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # ... (existant)
    DATABASE_URL: str
    
    # --- AJOUT ---
    CLOUDINARY_CLOUD_NAME: str
    CLOUDINARY_API_KEY: str
    CLOUDINARY_API_SECRET: str

    OPENROUTER_API_KEY: str
    # -------------

    class Config:
        env_file = ".env"
        extra = "ignore"

settings = Settings()

=== Fichier: ./app/utils/anonymization.py ===



=== Fichier: ./app/utils/__init__.py ===



=== Fichier: ./app/utils/formatters.py ===



=== Fichier: ./app/utils/crypto.py ===



=== Fichier: ./app/utils/validators.py ===



=== Fichier: ./app/utils/exceptions.py ===

# app/utils/exceptions.py

class NotFoundException(Exception):
    """
    Exception personnalisÃ©e Ã  lever lorsque'une ressource n'est pas trouvÃ©e
    dans la base de donnÃ©es.
    """
    def __init__(self, detail: str):
        self.detail = detail

=== Fichier: ./app/utils/logging.py ===

import logging
import os
import sys

def setup_logging():
    """
    Configure le logging pour Ã©crire dans un fichier et sur la console.
    """
    # CrÃ©er le dossier de logs s'il n'existe pas
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    log_file = os.path.join(log_dir, "simulation.log")

    # CrÃ©er un logger
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)

    # EmpÃªcher les double logs si la fonction est appelÃ©e plusieurs fois
    if logger.hasHandlers():
        logger.handlers.clear()

    # Formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - [%(levelname)s] - %(message)s'
    )

    # Handler pour Ã©crire dans le fichier
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    # Handler pour afficher aussi dans la console (utile pour Render)
    stream_handler = logging.StreamHandler(sys.stdout)
    stream_handler.setFormatter(formatter)
    logger.addHandler(stream_handler)

    logging.info("=" * 50)
    logging.info("Logging configurÃ©. Les logs seront Ã©crits ici et dans le fichier.")
    logging.info("=" * 50)

=== Fichier: ./setup.py ===



=== Fichier: ./testcategorie.py ===

import requests
import json
from datetime import datetime
import time

# Configuration
BASE_URL = "https://expert-cmck.onrender.com/api/v1"
OUTPUT_FILE = f"update_categories_priority_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

# Mapping des catÃ©gories basÃ© sur les mots-clÃ©s
CATEGORY_MAPPINGS = {
    'Cardiologie': [
        'heart', 'cardiac', 'cardio', 'myocard', 'pericardium', 'endocardium',
        'atrial', 'ventricular', 'coronary', 'angina', 'infarction', 'ischemic',
        'arrhythmia', 'tachycardia', 'bradycardia', 'fibrillation', 'hypertension',
        'valve', 'valvular', 'mitral', 'aortic', 'tricuspid', 'pulmonary',
        'congestive', 'failure', 'cardiomyopathy', 'stenosis', 'systolic', 'diastolic'
    ],
    'PÃ©diatrie': [
        'neonatal', 'newborn', 'infant', 'congenital', 'birth', 'fetal',
        'pediatric', 'childhood', 'developmental', 'baby'
    ],
    'ORL': [
        'ear', 'nose', 'throat', 'pharynx', 'larynx', 'tonsil', 'adenoid',
        'sinus', 'nasal', 'otitis', 'pharyngitis', 'laryngitis', 'rhinitis',
        'mastoid', 'auditory', 'hearing', 'olfactory', 'voice', 'vocal'
    ],
    'Neurologie': [
        'brain', 'cerebral', 'cerebr', 'neurological', 'neurol', 'nervous',
        'epilep', 'seizure', 'stroke', 'hemorrhage', 'hematoma', 'meningitis',
        'encephalitis', 'skull', 'cranial', 'paralysis', 'parkinson', 'dementia',
        'alzheimer', 'multiple sclerosis', 'neuropathy', 'spinal', 'vertebra',
        'intracranial', 'subarachnoid', 'subdural', 'extradural', 'concussion',
        'coma', 'consciousness'
    ],
    'Ophtalmologie': [
        'eye', 'ocular', 'ophthalm', 'vision', 'visual', 'retina', 'cornea',
        'lens', 'pupil', 'iris', 'glaucoma', 'cataract', 'conjunctiv', 'eyelid',
        'blindness', 'optic', 'lacrimal'
    ],
    'OrthopÃ©die': [
        'bone', 'fracture', 'orthopedic', 'skeletal', 'joint', 'arthritis',
        'osteo', 'femur', 'tibia', 'fibula', 'humerus', 'radius', 'ulna',
        'vertebra', 'spine', 'spinal', 'hip', 'knee', 'ankle', 'shoulder',
        'elbow', 'wrist', 'ligament', 'tendon', 'cartilage', 'meniscus',
        'dislocation', 'sprain', 'musculoskeletal', 'limb', 'amputation',
        'intertrochanteric', 'cervical', 'lumbar'
    ],
    'Pneumologie': [
        'lung', 'pulmonary', 'respiratory', 'bronch', 'pneumonia', 'asthma',
        'pleura', 'thorax', 'chest', 'breathing', 'dyspnea', 'emphysema',
        'tuberculosis', 'copd', 'alveolar', 'trachea', 'mediastin', 'ventilat'
    ],
    'Urgences': [
        'emergency', 'trauma', 'injury', 'wound', 'shock', 'poisoning',
        'burn', 'acute', 'severe', 'critical', 'sepsis',
        'septic', 'anaphylaxis', 'overdose', 'accident', 'multiple injuries'
    ],
    'Infectiologie': [
        'infection', 'infectious', 'bacterial', 'viral', 'fungal', 'parasite',
        'abscess', 'cellulitis', 'tuberculosis', 'hiv', 'aids',
        'hepatitis', 'bacilli', 'bacteriological'
    ],
    'GastroentÃ©rologie': [
        'gastro', 'intestin', 'stomach', 'bowel', 'colon', 'rectum', 'anus',
        'esophag', 'duoden', 'ileum', 'jejunum', 'liver', 'hepatic', 'cirrhosis',
        'pancrea', 'gallbladder', 'cholecyst', 'bile', 'biliary', 'ulcer',
        'crohn', 'colitis', 'diverticu', 'hernia', 'peritonitis', 'ascites',
        'fistula', 'tracheoesophageal', 'cholangitis'
    ],
    'NÃ©phrologie': [
        'kidney', 'renal', 'urinary', 'bladder', 'ureter', 'urethra',
        'nephritis', 'nephrotic', 'dialysis', 'uremia', 'proteinuria',
        'hematuria', 'cystitis', 'pyelonephritis'
    ],
    'Dermatologie': [
        'skin', 'derma', 'cutaneous', 'subcutaneous', 'rash', 'lesion',
        'wound', 'cellulitis', 'erythema', 'psoriasis',
        'eczema', 'melanoma', 'carcinoma', 'tissue', 'nodosum'
    ],
    'Endocrinologie': [
        'diabetes', 'diabetic', 'thyroid', 'goiter', 'hormone', 'endocrine',
        'pituitary', 'adrenal', 'pancreatic', 'metabolic', 'gland', 'multinodular'
    ],
    'HÃ©matologie': [
        'blood', 'anemia', 'leukemia', 'lymphoma', 'coagulation', 'bleeding',
        'hemorrhag', 'thrombosis', 'embolism', 'platelet', 'hemophilia'
    ],
    'Rhumatologie': [
        'arthritis', 'rheumat', 'gout', 'lupus', 'spondylitis', 'inflammatory'
    ],
    'Vasculaire': [
        'vascular', 'artery', 'vein', 'carotid', 'occlusion', 'stenosis',
        'atherosclerosis', 'aneurysm'
    ]
}

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    END = '\033[0m'

def print_color(message, color=None, end='\n'):
    if color:
        print(f"{color}{message}{Colors.END}", end=end)
    else:
        print(message, end=end)

def normalize_text(text):
    if not text:
        return ""
    return text.lower().strip()

def determine_category(disease_name):
    """DÃ©termine la catÃ©gorie basÃ©e sur le nom de la pathologie"""
    if not disease_name:
        return None
    
    normalized_name = normalize_text(disease_name)
    category_scores = {}
    
    for category, keywords in CATEGORY_MAPPINGS.items():
        score = 0
        for keyword in keywords:
            if keyword in normalized_name:
                # Score pondÃ©rÃ© selon la longueur du keyword
                score += len(keyword)
        
        if score > 0:
            category_scores[category] = score
    
    if category_scores:
        return max(category_scores, key=category_scores.get)
    
    return None

def fetch_all_clinical_cases():
    """RÃ©cupÃ¨re tous les cas cliniques"""
    print_color("\nğŸ“¥ Ã‰tape 1: RÃ©cupÃ©ration des cas cliniques...", Colors.CYAN)
    
    all_cases = []
    skip = 0
    limit = 100
    page = 1
    
    while True:
        try:
            params = {"skip": skip, "limit": limit}
            response = requests.get(f"{BASE_URL}/clinical-cases/", params=params, timeout=60)
            
            if response.status_code == 200:
                cases = response.json()
                if not cases:
                    break
                
                all_cases.extend(cases)
                print_color(f"   Page {page}: +{len(cases)} cas (Total: {len(all_cases)})", Colors.BLUE)
                
                if len(cases) < limit:
                    break
                
                skip += limit
                page += 1
            else:
                break
        except Exception as e:
            print_color(f"   âŒ Erreur: {str(e)}", Colors.RED)
            break
    
    print_color(f"âœ… Total: {len(all_cases)} cas cliniques\n", Colors.GREEN)
    return all_cases

def fetch_all_diseases():
    """RÃ©cupÃ¨re toutes les pathologies"""
    print_color("\nğŸ“¥ Ã‰tape 2: RÃ©cupÃ©ration des pathologies...", Colors.CYAN)
    
    all_diseases = []
    skip = 0
    limit = 100
    page = 1
    
    while True:
        try:
            params = {"skip": skip, "limit": limit}
            response = requests.get(f"{BASE_URL}/diseases/", params=params, timeout=60)
            
            if response.status_code == 200:
                diseases = response.json()
                if not diseases:
                    break
                
                all_diseases.extend(diseases)
                print_color(f"   Page {page}: +{len(diseases)} pathologies (Total: {len(all_diseases)})", Colors.BLUE)
                
                if len(diseases) < limit:
                    break
                
                skip += limit
                page += 1
            else:
                break
        except Exception as e:
            print_color(f"   âŒ Erreur: {str(e)}", Colors.RED)
            break
    
    print_color(f"âœ… Total: {len(all_diseases)} pathologies\n", Colors.GREEN)
    return all_diseases

def update_disease_category(disease_id, new_category):
    """Met Ã  jour la catÃ©gorie d'une pathologie"""
    try:
        data = {"categorie": new_category}
        response = requests.patch(
            f"{BASE_URL}/diseases/{disease_id}",
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            return True, "OK"
        else:
            return False, f"HTTP {response.status_code}"
    except Exception as e:
        return False, str(e)

def main():
    print_color("\n" + "="*100, Colors.CYAN)
    print_color("MISE Ã€ JOUR DES CATÃ‰GORIES AVEC PRIORITÃ‰ CAS CLINIQUES", Colors.CYAN)
    print_color("="*100, Colors.CYAN)
    print_color(f"\nğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", Colors.BLUE)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as log_file:
        
        def log(message):
            log_file.write(message + '\n')
            log_file.flush()
        
        log("="*100)
        log(f"MISE Ã€ JOUR AVEC PRIORITÃ‰ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        log("="*100)
        
        # Ã‰tape 1: RÃ©cupÃ©rer les cas cliniques
        clinical_cases = fetch_all_clinical_cases()
        
        # Ã‰tape 2: RÃ©cupÃ©rer toutes les pathologies
        all_diseases = fetch_all_diseases()
        
        if not all_diseases:
            print_color("âŒ Aucune pathologie rÃ©cupÃ©rÃ©e", Colors.RED)
            return
        
        # CrÃ©er un dict pour accÃ¨s rapide
        diseases_dict = {d['id']: d for d in all_diseases}
        
        # Ã‰tape 3: Identifier les pathologies principales des cas
        print_color("ğŸ” Ã‰tape 3: Identification des pathologies principales...\n", Colors.YELLOW)
        
        priority_disease_ids = set()
        for case in clinical_cases:
            patho_principale = case.get('pathologie_principale')
            if isinstance(patho_principale, dict):
                priority_disease_ids.add(patho_principale['id'])
        
        print_color(f"âœ… {len(priority_disease_ids)} pathologies prioritaires identifiÃ©es\n", Colors.GREEN)
        log(f"\nPathologies prioritaires (cas cliniques): {len(priority_disease_ids)}")
        
        # Ã‰tape 4: SÃ©parer en prioritaires et secondaires
        print_color("ğŸ“‹ Ã‰tape 4: Analyse et classification...\n", Colors.YELLOW)
        
        priority_updates = []
        secondary_updates = []
        category_stats = {}
        
        for disease in all_diseases:
            disease_id = disease['id']
            disease_name = disease.get('nom_fr', '')
            current_category = disease.get('categorie', '')
            
            new_category = determine_category(disease_name)
            
            if new_category:
                if new_category not in category_stats:
                    category_stats[new_category] = 0
                category_stats[new_category] += 1
                
                if current_category != new_category:
                    update_info = {
                        'id': disease_id,
                        'name': disease_name,
                        'old_category': current_category,
                        'new_category': new_category
                    }
                    
                    if disease_id in priority_disease_ids:
                        priority_updates.append(update_info)
                    else:
                        secondary_updates.append(update_info)
        
        # Afficher statistiques
        print_color("ğŸ“Š Statistiques:", Colors.CYAN)
        print_color(f"   â€¢ Pathologies prioritaires Ã  mettre Ã  jour: {len(priority_updates)}", Colors.MAGENTA)
        print_color(f"   â€¢ Pathologies secondaires Ã  mettre Ã  jour: {len(secondary_updates)}", Colors.BLUE)
        print_color(f"   â€¢ Total Ã  mettre Ã  jour: {len(priority_updates) + len(secondary_updates)}\n", Colors.YELLOW)
        
        log(f"\nPathologies prioritaires Ã  MAJ: {len(priority_updates)}")
        log(f"Pathologies secondaires Ã  MAJ: {len(secondary_updates)}")
        
        # Afficher rÃ©partition par catÃ©gorie
        print_color("ğŸ“ˆ RÃ©partition par catÃ©gorie:", Colors.CYAN)
        for category in sorted(category_stats.keys()):
            count = category_stats[category]
            print_color(f"   â€¢ {category}: {count} pathologies", Colors.BLUE)
        
        # Demander confirmation
        print_color(f"\nâš ï¸  Continuer avec la mise Ã  jour? (o/n): ", Colors.YELLOW, end='')
        confirm = input().strip().lower()
        
        if confirm != 'o':
            print_color("âŒ Mise Ã  jour annulÃ©e", Colors.RED)
            return
        
        # Mise Ã  jour avec prioritÃ©
        stats = {
            'priority_success': 0,
            'priority_failed': 0,
            'secondary_success': 0,
            'secondary_failed': 0
        }
        
        # PHASE 1: Pathologies prioritaires (cas cliniques)
        if priority_updates:
            print_color(f"\nğŸ¯ PHASE 1: Mise Ã  jour des pathologies PRIORITAIRES ({len(priority_updates)})", Colors.MAGENTA)
            print_color("="*100, Colors.MAGENTA)
            log("\n" + "="*100)
            log("PHASE 1: PATHOLOGIES PRIORITAIRES (CAS CLINIQUES)")
            log("="*100 + "\n")
            
            for idx, update in enumerate(priority_updates, 1):
                if idx % 10 == 0:
                    print_color(f"   [{idx}/{len(priority_updates)}] Progression: {(idx/len(priority_updates)*100):.1f}%", Colors.BLUE)
                
                log(f"\n[P-{idx}/{len(priority_updates)}] ID: {update['id']}")
                log(f"Nom: {update['name'][:80]}")
                log(f"{update['old_category']} â†’ {update['new_category']}")
                
                success, message = update_disease_category(update['id'], update['new_category'])
                
                if success:
                    stats['priority_success'] += 1
                    log("âœ… SuccÃ¨s")
                else:
                    stats['priority_failed'] += 1
                    log(f"âŒ Ã‰chec: {message}")
                
                time.sleep(0.1)
            
            print_color(f"\nâœ… Phase 1 terminÃ©e: {stats['priority_success']}/{len(priority_updates)} succÃ¨s\n", Colors.GREEN)
        
        # PHASE 2: Pathologies secondaires
        if secondary_updates:
            print_color(f"\nğŸ“š PHASE 2: Mise Ã  jour des pathologies SECONDAIRES ({len(secondary_updates)})", Colors.BLUE)
            print_color("="*100, Colors.BLUE)
            log("\n" + "="*100)
            log("PHASE 2: PATHOLOGIES SECONDAIRES")
            log("="*100 + "\n")
            
            for idx, update in enumerate(secondary_updates, 1):
                if idx % 50 == 0:
                    print_color(f"   [{idx}/{len(secondary_updates)}] Progression: {(idx/len(secondary_updates)*100):.1f}%", Colors.BLUE)
                
                log(f"\n[S-{idx}/{len(secondary_updates)}] ID: {update['id']}")
                log(f"{update['old_category']} â†’ {update['new_category']}")
                
                success, message = update_disease_category(update['id'], update['new_category'])
                
                if success:
                    stats['secondary_success'] += 1
                else:
                    stats['secondary_failed'] += 1
                
                time.sleep(0.05)  # Pause plus courte pour les secondaires
            
            print_color(f"\nâœ… Phase 2 terminÃ©e: {stats['secondary_success']}/{len(secondary_updates)} succÃ¨s\n", Colors.GREEN)
        
        # RÃ©sumÃ© final
        print_color(f"\n{'='*100}", Colors.CYAN)
        print_color("RÃ‰SUMÃ‰ FINAL", Colors.CYAN)
        print_color(f"{'='*100}", Colors.CYAN)
        
        total_success = stats['priority_success'] + stats['secondary_success']
        total_failed = stats['priority_failed'] + stats['secondary_failed']
        total = total_success + total_failed
        
        summary = f"""
ğŸ¯ PATHOLOGIES PRIORITAIRES (Cas cliniques):
   â€¢ TraitÃ©es: {len(priority_updates)}
   â€¢ SuccÃ¨s: {stats['priority_success']}
   â€¢ Ã‰checs: {stats['priority_failed']}
   â€¢ Taux: {(stats['priority_success']/max(len(priority_updates),1)*100):.1f}%

ğŸ“š PATHOLOGIES SECONDAIRES:
   â€¢ TraitÃ©es: {len(secondary_updates)}
   â€¢ SuccÃ¨s: {stats['secondary_success']}
   â€¢ Ã‰checs: {stats['secondary_failed']}
   â€¢ Taux: {(stats['secondary_success']/max(len(secondary_updates),1)*100):.1f}%

ğŸ“Š TOTAL GLOBAL:
   â€¢ Total traitÃ©: {total}
   â€¢ SuccÃ¨s: {total_success}
   â€¢ Ã‰checs: {total_failed}
   â€¢ Taux global: {(total_success/max(total,1)*100):.1f}%
"""
        print_color(summary, Colors.GREEN)
        log("\n" + "="*100)
        log("RÃ‰SUMÃ‰ FINAL")
        log("="*100)
        log(summary)
        
        log(f"\nğŸ“„ Fichier de log: {OUTPUT_FILE}")
        log(f"ğŸ“… Date fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        log("="*100)
    
    print_color(f"\nğŸ“„ Rapport complet: {OUTPUT_FILE}", Colors.CYAN)
    print_color(f"{'='*100}\n", Colors.CYAN)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print_color("\n\nâš ï¸  Script interrompu", Colors.YELLOW)
    except Exception as e:
        print_color(f"\n\nâŒ ERREUR: {str(e)}", Colors.RED)
        import traceback
        traceback.print_exc()

=== Fichier: ./llm_integration/prompt_templates/patient_simulation.py ===



=== Fichier: ./llm_integration/prompt_templates/__init__.py ===



=== Fichier: ./llm_integration/prompt_templates/diagnostic_guidance.py ===



=== Fichier: ./llm_integration/prompt_templates/feedback_generation.py ===



=== Fichier: ./llm_integration/rag/__init__.py ===



=== Fichier: ./llm_integration/rag/response_generator.py ===



=== Fichier: ./llm_integration/rag/retriever.py ===



=== Fichier: ./llm_integration/__init__.py ===



=== Fichier: ./llm_integration/training/conversation_extractor.py ===



=== Fichier: ./llm_integration/training/__init__.py ===



=== Fichier: ./llm_integration/training/dataset_preparation.py ===



=== Fichier: ./llm_integration/training/finetuning_pipeline.py ===



=== Fichier: ./llm_integration/conversation/__init__.py ===



=== Fichier: ./llm_integration/conversation/patient_agent.py ===



=== Fichier: ./llm_integration/conversation/dialogue_manager.py ===



=== Fichier: ./llm_integration/conversation/tutor_agent.py ===



=== Fichier: ./testworkf.py ===

import requests
import json
from datetime import datetime
import time
import sys

# ==============================================================================
# CONFIGURATION HYBRIDE
# ==============================================================================
# URL pour la gestion des apprenants (Stable / DÃ©ployÃ©)
LEARNER_BASE_URL = "https://appren-docker.onrender.com/api/v1"

# URL pour la simulation et le tuteur (En cours de dev / Local)
SIMULATION_BASE_URL = "http://127.0.0.1:8000/api/v1"

# Fichier de log
OUTPUT_FILE = f"test_hybrid_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

# CatÃ©gorie cible
TARGET_CATEGORY = "Infectiologie"

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    END = '\033[0m'

class WorkflowTester:
    def __init__(self, filename):
        self.file = open(filename, 'w', encoding='utf-8')
        self.learner_id = None
        self.step_count = 0
        
    def log(self, message, color=None, level="INFO"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_msg = f"[{timestamp}] [{level}] {message}"
        self.file.write(formatted_msg + '\n')
        self.file.flush()
        
        if color:
            print(f"{color}{formatted_msg}{Colors.END}")
        else:
            print(formatted_msg)

    def fail(self, message):
        self.log(f"âŒ {message}", Colors.RED, "FAIL")
        return False

    def success(self, message):
        self.log(f"âœ… {message}", Colors.GREEN, "SUCCESS")
        return True

tester = WorkflowTester(OUTPUT_FILE)

def step_1_create_learner_remote():
    """CrÃ©e l'apprenant sur le serveur Render."""
    tester.step_count += 1
    tester.log(f"\n--- Ã‰TAPE {tester.step_count}: CRÃ‰ATION APPRENANT (DISTANT) ---", Colors.CYAN)
    tester.log(f"Cible: {LEARNER_BASE_URL}")
    
    unique_id = int(time.time())
    data = {
        "matricule": f"HYBRID_TEST_{unique_id}",
        "nom": f"Hybrid Tester {unique_id}",
        "email": f"hybrid_{unique_id}@test.com",
        "niveau_etudes": "Interne",
        "specialite_visee": "MÃ©decine GÃ©nÃ©rale",
        "langue_preferee": "fr"
    }
    
    try:
        response = requests.post(f"{LEARNER_BASE_URL}/learners/", json=data, timeout=30)
        
        if response.status_code == 201:
            res = response.json()
            tester.learner_id = res['id']
            return tester.success(f"Apprenant crÃ©Ã© sur Render avec ID: {tester.learner_id}")
        else:
            return tester.fail(f"Erreur crÃ©ation Render ({response.status_code}): {response.text}")
            
    except Exception as e:
        return tester.fail(f"Exception connexion Render: {str(e)}")

def step_run_session_local(expected_type=None, session_label=""):
    """ExÃ©cute une session complÃ¨te sur le serveur Local."""
    tester.step_count += 1
    tester.log(f"\n--- Ã‰TAPE {tester.step_count}: SESSION {session_label} (LOCAL) ---", Colors.BLUE)
    
    # 1. START
    start_data = {"learner_id": tester.learner_id, "category": TARGET_CATEGORY}
    try:
        res_start = requests.post(f"{SIMULATION_BASE_URL}/simulation/sessions/start", json=start_data)
        
        if res_start.status_code not in [200, 201]:
            return tester.fail(f"Erreur Start Local ({res_start.status_code}): {res_start.text}")
        
        session = res_start.json()
        session_id = session['session_id']
        actual_type = session['session_type']
        case = session.get('clinical_case', {})
        difficulty = case.get('niveau_difficulte')
        patho_id = case.get('pathologie_principale', {}).get('id')
        
        tester.log(f"   Session ID: {session_id}")
        tester.log(f"   Type: {actual_type}")
        tester.log(f"   Niveau: {difficulty}/30")
        
        if expected_type and actual_type != expected_type:
            tester.log(f"âš ï¸ TYPE INATTENDU: Attendu '{expected_type}', ReÃ§u '{actual_type}'", Colors.YELLOW)
        
        # 2. CHAT (SimulÃ© pour activer le systÃ¨me)
        requests.post(f"{SIMULATION_BASE_URL}/chat/sessions/{session_id}/messages", json={
            "sender": "Apprenant", "content": "Je commence l'examen."
        })
        
        # 3. ACTION (SimulÃ© pour loguer une activitÃ©)
        requests.post(f"{SIMULATION_BASE_URL}/simulation/sessions/{session_id}/actions", json={
            "action_type": "examen", "action_name": "NFS", "justification": "Test"
        })

        # 4. SUBMIT (Forcer la rÃ©ussite)
        # On soumet le bon ID de pathologie pour garantir une bonne note
        submit_data = {
            "diagnosed_pathology_id": patho_id,
            "prescribed_medication_ids": [] # Liste vide ok pour le test
        }
        
        time.sleep(1) # Petite pause
        
        res_submit = requests.post(f"{SIMULATION_BASE_URL}/simulation/sessions/{session_id}/submit", json=submit_data)
        
        if res_submit.status_code == 200:
            eval_data = res_submit.json()
            score = eval_data['evaluation']['score_total']
            
            # Afficher rÃ©sultat
            color = Colors.GREEN if score >= 12 else Colors.RED
            tester.log(f"   Note finale: {score}/20", color)
            
            return {
                "success": True,
                "score": score,
                "difficulty": difficulty,
                "type": actual_type
            }
        else:
            return tester.fail(f"Erreur Submit Local ({res_submit.status_code}): {res_submit.text}")

    except Exception as e:
        return tester.fail(f"Exception locale: {str(e)}")

def main():
    tester.log("ğŸš€ DÃ‰MARRAGE DU TEST HYBRIDE (RENDER + LOCAL)", Colors.MAGENTA)
    tester.log("====================================================")
    
    # 1. CrÃ©ation Apprenant (Render)
    if not step_1_create_learner_remote():
        tester.log("âŒ ArrÃªt du test : Impossible de crÃ©er l'apprenant.", Colors.RED)
        return

    # 2. Session Test Positionnement (Local)
    res_test = step_run_session_local(expected_type="test", session_label="Test Positionnement")
    if not res_test or not res_test['success']: return
    
    initial_level = res_test['difficulty']
    tester.log(f"ğŸ NIVEAU INITIAL: {initial_level}", Colors.YELLOW)
    
    # 3. Cycle Formatif (3 Sessions) (Local)
    for i in range(1, 4):
        res = step_run_session_local(expected_type="formative", session_label=f"Formative #{i}")
        if not res or not res['success']: return
        time.sleep(1)

    # 4. Session Sommative (Local)
    res_exam = step_run_session_local(expected_type="sommative", session_label="EXAMEN SOMMATIF")
    if not res_exam or not res_exam['success']: return
    
    exam_score = res_exam['score']
    
    # 5. VÃ©rification Progression (Local)
    tester.log("\n--- VÃ‰RIFICATION DE LA PROGRESSION ---", Colors.CYAN)
    
    res_check = step_run_session_local(expected_type="formative", session_label="Post-Examen")
    if not res_check or not res_check['success']: return
    
    new_level = res_check['difficulty']
    
    tester.log(f"\nğŸ“Š BILAN:", Colors.MAGENTA)
    tester.log(f"   Niveau Avant: {initial_level}")
    tester.log(f"   Note Examen:  {exam_score}/20")
    tester.log(f"   Niveau AprÃ¨s: {new_level}")
    
    if exam_score >= 12:
        if new_level > initial_level:
            tester.success("ğŸ‰ PROGRESSION VALIDÃ‰E : Le niveau a augmentÃ© aprÃ¨s rÃ©ussite !")
        else:
            tester.fail("â›” BUG : Note suffisante mais le niveau n'a pas augmentÃ©.")
    else:
        if new_level <= initial_level:
            tester.success("ğŸ›¡ï¸ SÃ‰CURITÃ‰ VALIDÃ‰E : Note insuffisante, pas de progression (ou maintien).")
        else:
            tester.fail("â›” BUG : Le niveau a augmentÃ© malgrÃ© une note insuffisante.")

if __name__ == "__main__":
    main()

=== Fichier: ./alembic/versions/7108003f9629_add_cas_symptomes_association_and_.py ===

"""Add cas_symptomes association and update models

Revision ID: 7108003f9629
Revises: 4f66bc9b6081
Create Date: 2025-11-07 10:04:10.734115+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '7108003f9629'
down_revision = '4f66bc9b6081'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('cas_symptomes')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_symptomes',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('cas_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('symptome_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('details_contextuels', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True, comment="Description narrative du symptÃ´me dans ce cas (ex: 'FiÃ¨vre Ã  40Â°C depuis 3 jours')"),
    sa.ForeignKeyConstraint(['cas_id'], ['cas_cliniques_enrichis.id'], name=op.f('cas_symptomes_cas_id_fkey')),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], name=op.f('cas_symptomes_symptome_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('cas_symptomes_pkey'))
    )
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/b6afb34f22d7_add_publication_status_to_clinical_cases.py ===

"""Add publication status to clinical cases

Revision ID: b6afb34f22d7
Revises: a0ee48d62174
Create Date: 2026-01-11 22:28:01.220042+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'b6afb34f22d7'
down_revision = 'a0ee48d62174'
branch_labels = None
depends_on = None


def upgrade() -> None:
    print("\n--- [LOG] DÃ‰BUT de la migration 'b6afb34f22d7' (upgrade) ---")
    
    try:
        print("    -> Tentative de suppression de la contrainte 'learner_knowledge_concept_id_fkey'")
        op.drop_constraint(
            'learner_knowledge_concept_id_fkey',
            'learner_knowledge',
            type_='foreignkey'
        )
        print("    -> âœ… Contrainte supprimÃ©e.")
    except Exception as e:
        print(f"    -> âš ï¸ Ã‰chec de la suppression de la contrainte (peut-Ãªtre dÃ©jÃ  supprimÃ©e) : {e}")

    try:
        print("    -> Tentative de suppression de la table 'concepts'")
        op.drop_table('concepts')
        print("    -> âœ… Table supprimÃ©e.")
    except Exception as e:
        print(f"    -> âš ï¸ Ã‰chec de la suppression de la table (peut-Ãªtre dÃ©jÃ  supprimÃ©e) : {e}")
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_learning_histories_id'), table_name='learning_histories')
    op.drop_table('learning_histories')
    op.drop_index(op.f('ix_learner_performances_id'), table_name='learner_performances')
    op.drop_table('learner_performances')
    op.drop_index(op.f('ix_learner_behaviors_id'), table_name='learner_behaviors')
    op.drop_table('learner_behaviors')
    op.drop_index(op.f('ix_concepts_id'), table_name='concepts')
    op.drop_table('concepts')
    op.drop_index(op.f('ix_learner_knowledge_id'), table_name='learner_knowledge')
    op.drop_table('learner_knowledge')
    op.add_column('cas_cliniques_enrichis', sa.Column('statut_publication', sa.String(length=50), nullable=False, comment='Statut du cas: brouillon, en_revision, valide, archive'))
    op.create_index(op.f('ix_cas_cliniques_enrichis_statut_publication'), 'cas_cliniques_enrichis', ['statut_publication'], unique=False)
    op.drop_index(op.f('ix_tutor_decisions_case_id'), table_name='tutor_decisions')
    op.drop_index(op.f('ix_tutor_decisions_learner_id'), table_name='tutor_decisions')
    op.drop_column('tutor_decisions', 'learner_id')
    op.drop_column('tutor_decisions', 'case_id')
    op.drop_column('tutor_decisions', 'metadata_snapshot')
    op.drop_column('tutor_socratic_state', 'updated_at')
    op.drop_column('tutor_socratic_state', 'current_step_focus')
    op.drop_column('tutor_socratic_state', 'last_question_asked')
    op.drop_column('tutor_socratic_state', 'dialogue_history')

    op.drop_constraint(
        'learner_knowledge_concept_id_fkey', # Le nom de la contrainte
        'learner_knowledge',                 # La table oÃ¹ elle se trouve
        type_='foreignkey'
    )
    # --------------------

    # 2. Maintenant, on peut supprimer la table
    op.drop_table('concepts')

    # ... reste du fichier (probablement l'ajout de la colonne 'statut_publication')
    op.add_column('cas_cliniques_enrichis', sa.Column('statut_publication', sa.String(length=50), nullable=False, server_default='brouillon'))
    
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('tutor_socratic_state', sa.Column('dialogue_history', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'[]'::jsonb"), autoincrement=False, nullable=True))
    op.add_column('tutor_socratic_state', sa.Column('last_question_asked', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('tutor_socratic_state', sa.Column('current_step_focus', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('tutor_socratic_state', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True))
    op.add_column('tutor_decisions', sa.Column('metadata_snapshot', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=True))
    op.add_column('tutor_decisions', sa.Column('case_id', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('tutor_decisions', sa.Column('learner_id', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.create_index(op.f('ix_tutor_decisions_learner_id'), 'tutor_decisions', ['learner_id'], unique=False)
    op.create_index(op.f('ix_tutor_decisions_case_id'), 'tutor_decisions', ['case_id'], unique=False)
    op.drop_index(op.f('ix_cas_cliniques_enrichis_statut_publication'), table_name='cas_cliniques_enrichis')
    op.drop_column('cas_cliniques_enrichis', 'statut_publication')
    op.create_table('learner_knowledge',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('concept_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('mastery_level', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['concept_id'], ['concepts.id'], name=op.f('learner_knowledge_concept_id_fkey')),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learner_knowledge_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learner_knowledge_pkey'))
    )
    op.create_index(op.f('ix_learner_knowledge_id'), 'learner_knowledge', ['id'], unique=False)
    op.create_table('concepts',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('concepts_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('p_init', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('p_transit', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('p_guess', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('p_slip', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='concepts_pkey'),
    sa.UniqueConstraint('name', name='concepts_name_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('ix_concepts_id'), 'concepts', ['id'], unique=False)
    op.create_table('learner_behaviors',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('sessions_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('activities_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('total_time_spent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('engagement_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learner_behaviors_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learner_behaviors_pkey'))
    )
    op.create_index(op.f('ix_learner_behaviors_id'), 'learner_behaviors', ['id'], unique=False)
    op.create_table('learner_performances',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('concept_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('activity_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('time_spent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('attempts', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['concept_id'], ['concepts.id'], name=op.f('learner_performances_concept_id_fkey')),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learner_performances_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learner_performances_pkey'))
    )
    op.create_index(op.f('ix_learner_performances_id'), 'learner_performances', ['id'], unique=False)
    op.create_table('learning_histories',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('activity_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('activity_ref', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('success', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('score', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('time_spent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learning_histories_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learning_histories_pkey'))
    )
    op.create_index(op.f('ix_learning_histories_id'), 'learning_histories', ['id'], unique=False)
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/994203ee2537_add_cas_symptomes_association_table.py ===

"""Add cas_symptomes association table

Revision ID: 994203ee2537
Revises: a6bc48307908
Create Date: 2025-11-07 09:49:25.031773+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '994203ee2537'
down_revision = 'a6bc48307908'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('cas_id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('details_contextuels', sa.JSON(), nullable=True, comment="Description narrative du symptÃ´me dans ce cas (ex: 'FiÃ¨vre Ã  40Â°C depuis 3 jours')"),
    sa.ForeignKeyConstraint(['cas_id'], ['cas_cliniques_enrichis.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_nullable=False)
    op.drop_table('cas_symptomes')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/bc127903e3d2_add_expert_validateur_id_to_clinicalcase.py ===

"""Add expert_validateur_id to ClinicalCase

Revision ID: bc127903e3d2
Revises: 16068309bdb8
Create Date: 2025-12-25 00:23:58.911118+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector


# revision identifiers, used by Alembic.
revision = 'bc127903e3d2'
down_revision = '16068309bdb8'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('expert_validateur_id', sa.Integer(), nullable=True))
    op.create_foreign_key(None, 'cas_cliniques_enrichis', 'experts', ['expert_validateur_id'], ['id'])
    op.drop_column('cas_cliniques_enrichis', 'expert_validateur')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('expert_validateur', sa.VARCHAR(length=255), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'cas_cliniques_enrichis', type_='foreignkey')
    op.drop_column('cas_cliniques_enrichis', 'expert_validateur_id')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/bc4cda91a030_add_learner_tracking_and_tutor_tables.py ===

"""Add Learner, Tracking and Tutor tables

Revision ID: bc4cda91a030
Revises: afeac86179db
Create Date: 2025-12-19 10:03:40.038591+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'bc4cda91a030'
down_revision = 'afeac86179db'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/a6bc48307908_create_clinical_cases_table.py ===

"""Create clinical_cases table

Revision ID: a6bc48307908
Revises: b2699b90c4a9
Create Date: 2025-11-07 09:29:53.852125+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'a6bc48307908'
down_revision = 'b2699b90c4a9'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_cliniques_enrichis',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_fultang', sa.String(length=100), nullable=True, comment='Identifiant unique provenant de Fultang (ou synthÃ©tique)'),
    sa.Column('hash_integrite', sa.String(length=64), nullable=True, comment="SHA-256 pour la preuve d'intÃ©gritÃ© des donnÃ©es brutes"),
    sa.Column('pathologie_principale_id', sa.Integer(), nullable=True),
    sa.Column('donnees_brutes', sa.JSON(), nullable=True, comment='DonnÃ©es originales (ex: de Fultang) avant traitement'),
    sa.Column('presentation_clinique', sa.JSON(), nullable=False, comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.'),
    sa.Column('donnees_paracliniques', sa.JSON(), nullable=True, comment='RÃ©sultats des examens pour ce cas spÃ©cifique'),
    sa.Column('evolution_patient', sa.Text(), nullable=True, comment="Description de l'Ã©volution du patient pendant le cas"),
    sa.Column('images_associees_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste des IDs des images de la table 'images_medicales'"),
    sa.Column('sons_associes_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste des IDs des sons de la table 'sons_medicaux'"),
    sa.Column('medicaments_prescrits', sa.JSON(), nullable=True, comment='Liste des mÃ©dicaments prescrits dans ce cas'),
    sa.Column('niveau_difficulte', sa.Integer(), nullable=True, comment='DifficultÃ© du cas (1-5)'),
    sa.Column('duree_estimee_resolution_min', sa.Integer(), nullable=True, comment='Temps estimÃ© pour rÃ©soudre le cas'),
    sa.Column('objectifs_apprentissage', sa.JSON(), nullable=True, comment='Liste des compÃ©tences Ã  acquÃ©rir'),
    sa.Column('competences_requises', sa.JSON(), nullable=True, comment='Mapping Q-Matrix pour ce cas'),
    sa.Column('valide_expert', sa.Boolean(), nullable=True),
    sa.Column('expert_validateur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('qualite_donnees', sa.Integer(), nullable=True, comment='QualitÃ© des donnÃ©es sources (1-5)'),
    sa.Column('nb_utilisations', sa.Integer(), nullable=True),
    sa.Column('note_moyenne_apprenants', sa.DECIMAL(precision=3, scale=2), nullable=True),
    sa.Column('taux_succes_diagnostic', sa.DECIMAL(precision=5, scale=2), nullable=True),
    sa.Column('embedding_texte', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment='Embedding de la description textuelle du cas'),
    sa.Column('embedding_global', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True, comment='Embedding multimodal fusionnÃ© (texte+image+son)'),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['pathologie_principale_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_cas_cliniques_enrichis_code_fultang'), 'cas_cliniques_enrichis', ['code_fultang'], unique=True)
    op.create_index(op.f('ix_cas_cliniques_enrichis_id'), 'cas_cliniques_enrichis', ['id'], unique=False)
    op.create_index(op.f('ix_cas_cliniques_enrichis_pathologie_principale_id'), 'cas_cliniques_enrichis', ['pathologie_principale_id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_cas_cliniques_enrichis_pathologie_principale_id'), table_name='cas_cliniques_enrichis')
    op.drop_index(op.f('ix_cas_cliniques_enrichis_id'), table_name='cas_cliniques_enrichis')
    op.drop_index(op.f('ix_cas_cliniques_enrichis_code_fultang'), table_name='cas_cliniques_enrichis')
    op.drop_table('cas_cliniques_enrichis')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/4f66bc9b6081_add_cas_symptomes_association_and_.py ===

"""Add cas_symptomes association and update models

Revision ID: 4f66bc9b6081
Revises: 994203ee2537
Create Date: 2025-11-07 10:03:23.727581+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '4f66bc9b6081'
down_revision = '994203ee2537'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_nullable=False)
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/eb403e41e275_fix_expert_validateur_relationship.py ===

"""fix expert_validateur relationship

Revision ID: eb403e41e275
Revises: bc127903e3d2
Create Date: 2025-12-25 00:30:17.468368+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector


# revision identifiers, used by Alembic.
revision = 'eb403e41e275'
down_revision = 'bc127903e3d2'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/5c3894aa1b50_change_embedding_dimensions_to_384.py ===

"""change embedding dimensions to 384

Revision ID: 5c3894aa1b50
Revises: eb403e41e275
Create Date: 2025-12-26 00:14:27.010127+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '5c3894aa1b50'
down_revision = 'eb403e41e275'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'embedding_texte',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment='Embedding de la description textuelle du cas',
               existing_nullable=True)
    op.alter_column('images_medicales', 'embedding_vision',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle",
               existing_nullable=True)
    op.alter_column('medicaments', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires",
               existing_nullable=True)
    op.alter_column('pathologies', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique",
               existing_nullable=True)
    op.alter_column('symptomes', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)",
               existing_nullable=True)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('symptomes', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)",
               existing_nullable=True)
    op.alter_column('pathologies', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique",
               existing_nullable=True)
    op.alter_column('medicaments', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires",
               existing_nullable=True)
    op.alter_column('images_medicales', 'embedding_vision',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle",
               existing_nullable=True)
    op.alter_column('cas_cliniques_enrichis', 'embedding_texte',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment='Embedding de la description textuelle du cas',
               existing_nullable=True)
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/de1d3372f456_add_secondary_pathologies_to_clinical_.py ===

"""Add secondary pathologies to clinical cases

Revision ID: de1d3372f456
Revises: 7108003f9629
Create Date: 2025-11-07 13:38:16.973024+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'de1d3372f456'
down_revision = '7108003f9629'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('pathologies_secondaires_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste d'IDs de pathologies comorbides ou secondaires"))
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('cas_cliniques_enrichis', 'pathologies_secondaires_ids')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/f29ac6884d1c_create_medications_table.py ===

"""Create medications table

Revision ID: f29ac6884d1c
Revises: 8e5b38bb2891
Create Date: 2025-11-06 20:17:47.401019+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'f29ac6884d1c'
down_revision = '8e5b38bb2891'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('medicaments',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('nom_commercial', sa.String(length=255), nullable=True),
    sa.Column('dci', sa.String(length=255), nullable=False, comment='DÃ©nomination Commune Internationale'),
    sa.Column('classe_therapeutique', sa.String(length=255), nullable=True),
    sa.Column('forme_galenique', sa.String(length=100), nullable=True, comment='Ex: ComprimÃ©, Sirop, Injectable'),
    sa.Column('dosage', sa.String(length=100), nullable=True),
    sa.Column('voie_administration', sa.String(length=100), nullable=True, comment='Ex: Orale, IV, IM, CutanÃ©e'),
    sa.Column('mecanisme_action', sa.Text(), nullable=True),
    sa.Column('indications', sa.JSON(), nullable=True),
    sa.Column('contre_indications', sa.JSON(), nullable=True),
    sa.Column('effets_secondaires', sa.JSON(), nullable=True),
    sa.Column('interactions_medicamenteuses', sa.JSON(), nullable=True),
    sa.Column('precautions_emploi', sa.Text(), nullable=True),
    sa.Column('posologie_standard', sa.JSON(), nullable=True, comment='Posologie standard par Ã¢ge, poids, indication'),
    sa.Column('disponibilite_cameroun', sa.String(length=50), nullable=True, comment='Ex: Urbain, Rural, CHU_uniquement'),
    sa.Column('cout_moyen_fcfa', sa.Integer(), nullable=True),
    sa.Column('statut_prescription', sa.String(length=50), nullable=True, comment='Ex: Prescription_obligatoire, OTC'),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_medicaments_classe_therapeutique'), 'medicaments', ['classe_therapeutique'], unique=False)
    op.create_index(op.f('ix_medicaments_dci'), 'medicaments', ['dci'], unique=False)
    op.create_index(op.f('ix_medicaments_id'), 'medicaments', ['id'], unique=False)
    op.create_index(op.f('ix_medicaments_nom_commercial'), 'medicaments', ['nom_commercial'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_medicaments_nom_commercial'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_id'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_dci'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_classe_therapeutique'), table_name='medicaments')
    op.drop_table('medicaments')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/8e5b38bb2891_create_symptoms_table.py ===

"""Create symptoms table

Revision ID: 8e5b38bb2891
Revises: 6eb5a7dba20c
Create Date: 2025-11-06 19:31:00.822591+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '8e5b38bb2891'
down_revision = '6eb5a7dba20c'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('pathologie_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('pathologie_id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('probabilite', sa.DECIMAL(precision=5, scale=4), nullable=True, comment="ProbabilitÃ© d'apparition du symptÃ´me pour cette pathologie P(symptÃ´me|pathologie)"),
    sa.Column('sensibilite', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('specificite', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('phase_maladie', sa.String(length=50), nullable=True, comment='Phase de la maladie oÃ¹ le symptÃ´me apparaÃ®t (ex: PrÃ©coce, Tardive)'),
    sa.Column('frequence', sa.String(length=50), nullable=True, comment="FrÃ©quence d'apparition (ex: Constant, FrÃ©quent, Occasionnel)"),
    sa.Column('est_pathognomonique', sa.Boolean(), nullable=True, comment='Si True, ce symptÃ´me seul suffit presque Ã  poser le diagnostic'),
    sa.Column('importance_diagnostique', sa.Integer(), nullable=True, comment="Ã‰chelle de 1 Ã  5 sur l'importance de ce symptÃ´me pour le diagnostic"),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('pathologie_symptomes')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/4b1e2599b918_initial_empty_migration.py ===

"""Initial empty migration

Revision ID: 4b1e2599b918
Revises: 
Create Date: 2025-11-06 11:09:36.525928+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '4b1e2599b918'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    pass


def downgrade():
    pass


=== Fichier: ./alembic/versions/b2699b90c4a9_create_media_table.py ===

"""Create media table

Revision ID: b2699b90c4a9
Revises: 9aed193ba8b7
Create Date: 2025-11-07 07:45:54.209466+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'b2699b90c4a9'
down_revision = '9aed193ba8b7'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('images_medicales',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('type_examen', sa.String(length=100), nullable=False, comment='Ex: Radiographie, Ã‰chographie, Scanner'),
    sa.Column('sous_type', sa.String(length=100), nullable=True, comment='Ex: Thorax, Abdomen, CrÃ¢ne'),
    sa.Column('pathologie_id', sa.Integer(), nullable=True),
    sa.Column('fichier_url', sa.String(length=500), nullable=False, comment='URL vers le fichier (S3, stockage local, etc.)'),
    sa.Column('fichier_miniature_url', sa.String(length=500), nullable=True, comment="URL vers une version miniature de l'image"),
    sa.Column('format_image', sa.String(length=20), nullable=True, comment='Ex: DICOM, PNG, JPEG'),
    sa.Column('taille_ko', sa.Integer(), nullable=True),
    sa.Column('resolution', sa.String(length=50), nullable=True),
    sa.Column('description', sa.Text(), nullable=True, comment="Description gÃ©nÃ©rale de l'image ou du cas"),
    sa.Column('signes_radiologiques', sa.JSON(), nullable=True, comment='Signes spÃ©cifiques visibles (ex: opacitÃ©, Ã©panchement)'),
    sa.Column('annotations', sa.JSON(), nullable=True, comment="CoordonnÃ©es et descriptions de zones d'intÃ©rÃªt"),
    sa.Column('interpretation_experte', sa.Text(), nullable=True, comment="Compte-rendu d'un radiologue expert"),
    sa.Column('diagnostic_differentiel', sa.JSON(), nullable=True, comment="Autres diagnostics possibles basÃ©s sur l'image"),
    sa.Column('niveau_difficulte', sa.Integer(), nullable=True, comment="DifficultÃ© d'interprÃ©tation de l'image (1-5)"),
    sa.Column('qualite_image', sa.Integer(), nullable=True, comment="QualitÃ© technique de l'image (1-5)"),
    sa.Column('embedding_vision', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle"),
    sa.Column('valide_expert', sa.Boolean(), nullable=True),
    sa.Column('expert_validateur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_images_medicales_id'), 'images_medicales', ['id'], unique=False)
    op.create_index(op.f('ix_images_medicales_pathologie_id'), 'images_medicales', ['pathologie_id'], unique=False)
    op.create_index(op.f('ix_images_medicales_type_examen'), 'images_medicales', ['type_examen'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_images_medicales_type_examen'), table_name='images_medicales')
    op.drop_index(op.f('ix_images_medicales_pathologie_id'), table_name='images_medicales')
    op.drop_index(op.f('ix_images_medicales_id'), table_name='images_medicales')
    op.drop_table('images_medicales')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/afeac86179db_create_competencies_and_prerequisites_.py ===

"""Create competencies and prerequisites tables

Revision ID: afeac86179db
Revises: 03d192a5f522
Create Date: 2025-11-29 20:23:29.605930+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'afeac86179db'
down_revision = '03d192a5f522'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('competences_cliniques',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_competence', sa.String(length=50), nullable=False, comment="Code unique (ex: 'ANAMNESE_DOULEUR')"),
    sa.Column('nom', sa.String(length=255), nullable=False),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: Anamnese, Examen_physique, Raisonnement, Technique'),
    sa.Column('niveau_bloom', sa.Integer(), nullable=True, comment='Niveau dans la taxonomie de Bloom (1-6)'),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('objectifs_apprentissage', sa.JSON(), nullable=True, comment='Liste dÃ©taillÃ©e des objectifs'),
    sa.Column('criteres_maitrise', sa.JSON(), nullable=True, comment='CritÃ¨res pour valider la compÃ©tence'),
    sa.Column('parent_competence_id', sa.Integer(), nullable=True),
    sa.Column('ordre_apprentissage', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['parent_competence_id'], ['competences_cliniques.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_competences_cliniques_categorie'), 'competences_cliniques', ['categorie'], unique=False)
    op.create_index(op.f('ix_competences_cliniques_code_competence'), 'competences_cliniques', ['code_competence'], unique=True)
    op.create_index(op.f('ix_competences_cliniques_id'), 'competences_cliniques', ['id'], unique=False)
    op.create_table('prerequis_competences',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('competence_id', sa.Integer(), nullable=False),
    sa.Column('prerequis_id', sa.Integer(), nullable=False),
    sa.Column('type_relation', sa.String(length=50), nullable=True, comment='STRICT, RECOMMANDE, SUPPORTIF'),
    sa.Column('force_relation', sa.DECIMAL(precision=3, scale=2), nullable=True, comment='Force du lien (0-1)'),
    sa.ForeignKeyConstraint(['competence_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['prerequis_id'], ['competences_cliniques.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('prerequis_competences')
    op.drop_index(op.f('ix_competences_cliniques_id'), table_name='competences_cliniques')
    op.drop_index(op.f('ix_competences_cliniques_code_competence'), table_name='competences_cliniques')
    op.drop_index(op.f('ix_competences_cliniques_categorie'), table_name='competences_cliniques')
    op.drop_table('competences_cliniques')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/7995e67f8833_create_symptoms_table.py ===

"""Create symptoms table

Revision ID: 7995e67f8833
Revises: 4b1e2599b918
Create Date: 2025-11-06 12:48:47.725270+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '7995e67f8833'
down_revision = '4b1e2599b918'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('nom', sa.String(length=255), nullable=False),
    sa.Column('nom_local', sa.String(length=255), nullable=True, comment="Nom vernaculaire ou local, ex: 'Ntou-tou' pour la toux"),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='CatÃ©gorie fonctionnelle (ex: Respiratoire, Neurologique, Digestif)'),
    sa.Column('type_symptome', sa.String(length=50), nullable=True, comment='Type de symptÃ´me (ex: Subjectif, Objectif, Signe clinique)'),
    sa.Column('description', sa.Text(), nullable=True, comment='Description dÃ©taillÃ©e du symptÃ´me et de sa signification clinique.'),
    sa.Column('questions_anamnese', sa.JSON(), nullable=True, comment='Liste structurÃ©e de questions pour explorer ce symptÃ´me (ex: PQRST)'),
    sa.Column('signes_alarme', sa.Boolean(), nullable=False, comment="Indique si ce symptÃ´me est un signe de gravitÃ© ('red flag')"),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_symptomes_categorie'), 'symptomes', ['categorie'], unique=False)
    op.create_index(op.f('ix_symptomes_id'), 'symptomes', ['id'], unique=False)
    op.create_index(op.f('ix_symptomes_nom'), 'symptomes', ['nom'], unique=True)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_symptomes_nom'), table_name='symptomes')
    op.drop_index(op.f('ix_symptomes_id'), table_name='symptomes')
    op.drop_index(op.f('ix_symptomes_categorie'), table_name='symptomes')
    op.drop_table('symptomes')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/16068309bdb8_add_learner_tracking_tutor_and_.py ===

"""Add Learner, Tracking, Tutor and ExpertUser tables

Revision ID: 16068309bdb8
Revises: bc4cda91a030
Create Date: 2025-12-23 02:00:58.044928+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '16068309bdb8'
down_revision = 'bc4cda91a030'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('experts',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('email', sa.String(length=255), nullable=False),
    sa.Column('hashed_password', sa.String(length=255), nullable=False),
    sa.Column('nom_complet', sa.String(length=255), nullable=True),
    sa.Column('specialite', sa.String(length=100), nullable=True),
    sa.Column('hopital_affiliation', sa.String(length=255), nullable=True),
    sa.Column('role', sa.String(length=50), nullable=True),
    sa.Column('last_login', sa.TIMESTAMP(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_experts_email'), 'experts', ['email'], unique=True)
    op.create_index(op.f('ix_experts_id'), 'experts', ['id'], unique=False)
    op.create_table('learners',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('matricule', sa.String(length=50), nullable=True),
    sa.Column('nom', sa.String(length=255), nullable=True),
    sa.Column('email', sa.String(length=255), nullable=True),
    sa.Column('niveau_etudes', sa.String(length=50), nullable=True),
    sa.Column('specialite_visee', sa.String(length=100), nullable=True),
    sa.Column('langue_preferee', sa.String(length=10), nullable=True),
    sa.Column('date_inscription', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learners_email'), 'learners', ['email'], unique=True)
    op.create_index(op.f('ix_learners_id'), 'learners', ['id'], unique=False)
    op.create_index(op.f('ix_learners_matricule'), 'learners', ['matricule'], unique=True)
    op.create_table('learner_achievements',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('badge_id', sa.String(length=100), nullable=True),
    sa.Column('date_obtention', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_cognitive_profiles',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('vitesse_assimilation', sa.Float(), nullable=True),
    sa.Column('capacite_memoire_travail', sa.Float(), nullable=True),
    sa.Column('tendance_impulsivite', sa.Float(), nullable=True),
    sa.Column('prefer_visual', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('learner_id')
    )
    op.create_table('learner_competency_mastery',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('competence_id', sa.Integer(), nullable=False),
    sa.Column('mastery_level', sa.Float(), nullable=True),
    sa.Column('confidence', sa.Float(), nullable=True),
    sa.Column('last_practice_date', sa.TIMESTAMP(), nullable=True),
    sa.Column('nb_success', sa.Integer(), nullable=True),
    sa.Column('nb_failures', sa.Integer(), nullable=True),
    sa.Column('streak_correct', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['competence_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learner_competency_mastery_id'), 'learner_competency_mastery', ['id'], unique=False)
    op.create_table('learner_goals',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('type_objectif', sa.String(length=100), nullable=True),
    sa.Column('domaine_cible', sa.String(length=100), nullable=True),
    sa.Column('date_limite', sa.TIMESTAMP(), nullable=True),
    sa.Column('statut', sa.String(length=50), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_misconceptions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('type_erreur', sa.String(length=255), nullable=True),
    sa.Column('frequence_apparition', sa.Integer(), nullable=True),
    sa.Column('resistance_correction', sa.Float(), nullable=True),
    sa.Column('detected_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_preferences',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('cle', sa.String(length=100), nullable=True),
    sa.Column('valeur', sa.String(length=255), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_strategies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('strategy_name', sa.String(length=100), nullable=True),
    sa.Column('frequency', sa.Integer(), nullable=True),
    sa.Column('effectiveness', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learning_paths',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('algorithme_recommandation', sa.String(length=100), nullable=True),
    sa.Column('ordered_case_ids', sa.JSON(), nullable=True, comment='Liste ordonnÃ©e des IDs des cas'),
    sa.Column('progression', sa.Float(), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learning_paths_id'), 'learning_paths', ['id'], unique=False)
    op.create_table('simulation_sessions',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('cas_clinique_id', sa.Integer(), nullable=False),
    sa.Column('start_time', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('end_time', sa.TIMESTAMP(), nullable=True),
    sa.Column('score_final', sa.Float(), nullable=True),
    sa.Column('temps_total', sa.Integer(), nullable=True),
    sa.Column('cout_virtuel_genere', sa.Integer(), nullable=True),
    sa.Column('statut', sa.String(length=50), nullable=True),
    sa.Column('raison_fin', sa.String(length=100), nullable=True),
    sa.Column('current_stage', sa.String(length=50), nullable=True),
    sa.Column('context_state', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['cas_clinique_id'], ['cas_cliniques_enrichis.id'], ),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('chat_messages',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('sender', sa.String(length=50), nullable=True),
    sa.Column('content', sa.Text(), nullable=True),
    sa.Column('intention_detectee', sa.String(length=100), nullable=True),
    sa.Column('sentiment_analyse', sa.String(length=50), nullable=True),
    sa.Column('message_metadata', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_chat_messages_id'), 'chat_messages', ['id'], unique=False)
    op.create_table('interaction_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('action_category', sa.String(length=50), nullable=True),
    sa.Column('action_type', sa.String(length=100), nullable=True),
    sa.Column('action_content', sa.JSON(), nullable=True),
    sa.Column('response_latency', sa.Integer(), nullable=True),
    sa.Column('charge_cognitive_estimee', sa.Float(), nullable=True),
    sa.Column('est_pertinent', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_interaction_logs_id'), 'interaction_logs', ['id'], unique=False)
    op.create_table('learner_affective_states',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('stress_level', sa.Float(), nullable=True),
    sa.Column('confidence_level', sa.Float(), nullable=True),
    sa.Column('motivation_level', sa.Float(), nullable=True),
    sa.Column('frustration_level', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('tutor_feedback_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('feedback_type', sa.String(length=50), nullable=True),
    sa.Column('content', sa.Text(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_feedback_logs_id'), 'tutor_feedback_logs', ['id'], unique=False)
    op.create_table('tutor_motivational_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('intervention_type', sa.String(length=100), nullable=True),
    sa.Column('emotional_state_before', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_motivational_state_id'), 'tutor_motivational_state', ['id'], unique=False)
    op.create_table('tutor_scaffolding_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('competence_cible_id', sa.Integer(), nullable=True),
    sa.Column('current_level', sa.Integer(), nullable=True),
    sa.Column('indices_deja_donnes', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['competence_cible_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_scaffolding_state_id'), 'tutor_scaffolding_state', ['id'], unique=False)
    op.create_table('tutor_socratic_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('tactic_used', sa.String(length=100), nullable=True),
    sa.Column('target_concept', sa.String(length=255), nullable=True),
    sa.Column('step_in_dialogue', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_socratic_state_id'), 'tutor_socratic_state', ['id'], unique=False)
    op.create_table('tutor_strategies_history',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('strategy_name', sa.String(length=100), nullable=True),
    sa.Column('relevance_score', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_strategies_history_id'), 'tutor_strategies_history', ['id'], unique=False)
    op.create_table('tutor_decisions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('trigger_event_id', sa.Integer(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('strategy_used', sa.String(length=100), nullable=True),
    sa.Column('action_choisie', sa.String(length=100), nullable=True),
    sa.Column('intervention_content', sa.Text(), nullable=True),
    sa.Column('rationale', sa.JSON(), nullable=True),
    sa.Column('succes_intervention', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.ForeignKeyConstraint(['trigger_event_id'], ['interaction_logs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_decisions_id'), 'tutor_decisions', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_tutor_decisions_id'), table_name='tutor_decisions')
    op.drop_table('tutor_decisions')
    op.drop_index(op.f('ix_tutor_strategies_history_id'), table_name='tutor_strategies_history')
    op.drop_table('tutor_strategies_history')
    op.drop_index(op.f('ix_tutor_socratic_state_id'), table_name='tutor_socratic_state')
    op.drop_table('tutor_socratic_state')
    op.drop_index(op.f('ix_tutor_scaffolding_state_id'), table_name='tutor_scaffolding_state')
    op.drop_table('tutor_scaffolding_state')
    op.drop_index(op.f('ix_tutor_motivational_state_id'), table_name='tutor_motivational_state')
    op.drop_table('tutor_motivational_state')
    op.drop_index(op.f('ix_tutor_feedback_logs_id'), table_name='tutor_feedback_logs')
    op.drop_table('tutor_feedback_logs')
    op.drop_table('learner_affective_states')
    op.drop_index(op.f('ix_interaction_logs_id'), table_name='interaction_logs')
    op.drop_table('interaction_logs')
    op.drop_index(op.f('ix_chat_messages_id'), table_name='chat_messages')
    op.drop_table('chat_messages')
    op.drop_table('simulation_sessions')
    op.drop_index(op.f('ix_learning_paths_id'), table_name='learning_paths')
    op.drop_table('learning_paths')
    op.drop_table('learner_strategies')
    op.drop_table('learner_preferences')
    op.drop_table('learner_misconceptions')
    op.drop_table('learner_goals')
    op.drop_index(op.f('ix_learner_competency_mastery_id'), table_name='learner_competency_mastery')
    op.drop_table('learner_competency_mastery')
    op.drop_table('learner_cognitive_profiles')
    op.drop_table('learner_achievements')
    op.drop_index(op.f('ix_learners_matricule'), table_name='learners')
    op.drop_index(op.f('ix_learners_id'), table_name='learners')
    op.drop_index(op.f('ix_learners_email'), table_name='learners')
    op.drop_table('learners')
    op.drop_index(op.f('ix_experts_id'), table_name='experts')
    op.drop_index(op.f('ix_experts_email'), table_name='experts')
    op.drop_table('experts')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/6eb5a7dba20c_create_symptoms_table.py ===

"""Create symptoms table

Revision ID: 6eb5a7dba20c
Revises: 7995e67f8833
Create Date: 2025-11-06 19:20:35.224401+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '6eb5a7dba20c'
down_revision = '7995e67f8833'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('pathologies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_icd10', sa.String(length=20), nullable=True, comment='Code international de la maladie (CIM-10)'),
    sa.Column('nom_fr', sa.String(length=255), nullable=False),
    sa.Column('nom_en', sa.String(length=255), nullable=True),
    sa.Column('nom_local', sa.String(length=255), nullable=True, comment='Noms locaux ou courants au Cameroun'),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: Infectieuse, Chronique, Parasitaire'),
    sa.Column('prevalence_cameroun', sa.DECIMAL(precision=5, scale=2), nullable=True, comment='PrÃ©valence en % dans le contexte camerounais'),
    sa.Column('niveau_gravite', sa.Integer(), nullable=True, comment='Ã‰chelle de 1 (bÃ©nin) Ã  5 (critique)'),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('physiopathologie', sa.Text(), nullable=True, comment='MÃ©canisme de la maladie'),
    sa.Column('evolution_naturelle', sa.Text(), nullable=True, comment='Comment la maladie Ã©volue sans traitement'),
    sa.Column('complications', sa.JSON(), nullable=True, comment='Complications possibles'),
    sa.Column('facteurs_risque', sa.JSON(), nullable=True, comment='Facteurs de risque associÃ©s'),
    sa.Column('prevention', sa.Text(), nullable=True, comment='Mesures de prÃ©vention'),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_pathologies_categorie'), 'pathologies', ['categorie'], unique=False)
    op.create_index(op.f('ix_pathologies_code_icd10'), 'pathologies', ['code_icd10'], unique=True)
    op.create_index(op.f('ix_pathologies_id'), 'pathologies', ['id'], unique=False)
    op.create_index(op.f('ix_pathologies_nom_fr'), 'pathologies', ['nom_fr'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_pathologies_nom_fr'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_id'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_code_icd10'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_categorie'), table_name='pathologies')
    op.drop_table('pathologies')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/a0ee48d62174_change_embedding_dimensions_to_384.py ===

"""change embedding dimensions to 384

Revision ID: a0ee48d62174
Revises: 5c3894aa1b50
Create Date: 2025-12-26 00:19:52.135785+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'a0ee48d62174'
down_revision = '5c3894aa1b50'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/9aed193ba8b7_create_therapeutic_relations_tables.py ===

"""Create therapeutic relations tables

Revision ID: 9aed193ba8b7
Revises: f29ac6884d1c
Create Date: 2025-11-06 20:44:30.949745+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '9aed193ba8b7'
down_revision = 'f29ac6884d1c'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('traitements_pathologies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('pathologie_id', sa.Integer(), nullable=False),
    sa.Column('medicament_id', sa.Integer(), nullable=False),
    sa.Column('type_traitement', sa.String(length=50), nullable=True, comment='Ex: Premiere_intention, Alternative, Adjuvant'),
    sa.Column('ligne_traitement', sa.Integer(), nullable=True, comment='Ex: 1Ã¨re ligne, 2e ligne'),
    sa.Column('indication_precise', sa.Text(), nullable=True),
    sa.Column('efficacite_taux', sa.DECIMAL(precision=5, scale=2), nullable=True, comment='Taux de succÃ¨s en %'),
    sa.Column('duree_traitement_jours', sa.Integer(), nullable=True),
    sa.Column('posologie_detaillee', sa.JSON(), nullable=True),
    sa.Column('niveau_preuve', sa.String(length=50), nullable=True, comment='Grade de recommandation (A, B, C)'),
    sa.Column('guidelines_source', sa.String(length=255), nullable=True, comment='Source (OMS, MINSANTE Cameroun, etc.)'),
    sa.Column('rang_preference', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['medicament_id'], ['medicaments.id'], ),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('traitements_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('medicament_id', sa.Integer(), nullable=False),
    sa.Column('efficacite', sa.String(length=50), nullable=True, comment='Ex: Tres_efficace, Efficace, Modere'),
    sa.Column('rapidite_action', sa.String(length=100), nullable=True, comment='Ex: Immediate, <30min'),
    sa.Column('posologie_recommandee', sa.Text(), nullable=True),
    sa.Column('rang_preference', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['medicament_id'], ['medicaments.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('traitements_symptomes')
    op.drop_table('traitements_pathologies')
    # ### end Alembic commands ###


=== Fichier: ./alembic/versions/03d192a5f522_add_expert_intelligence.py ===

"""Add expert intelligence

Revision ID: 03d192a5f522
Revises: de1d3372f456
Create Date: 2025-11-07 14:06:32.502322+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '03d192a5f522'
down_revision = 'de1d3372f456'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('regles_production',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_regle', sa.String(length=50), nullable=False),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: DIAGNOSTIC, THERAPEUTIQUE, PEDAGOGIQUE, ALERTE'),
    sa.Column('priorite', sa.Integer(), nullable=True, comment="PrioritÃ© d'exÃ©cution (1-10), 10 Ã©tant le plus prioritaire"),
    sa.Column('conditions', sa.JSON(), nullable=False, comment="Partie 'IF' de la rÃ¨gle, structurÃ©e en JSON"),
    sa.Column('actions', sa.JSON(), nullable=False, comment="Partie 'THEN' de la rÃ¨gle, structurÃ©e en JSON"),
    sa.Column('description_naturelle', sa.Text(), nullable=True, comment='Description de la rÃ¨gle en langage naturel'),
    sa.Column('justification_medicale', sa.Text(), nullable=True, comment='Source ou justification clinique de la rÃ¨gle'),
    sa.Column('expert_auteur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('est_active', sa.Boolean(), nullable=False),
    sa.Column('nb_activations', sa.Integer(), nullable=True),
    sa.Column('taux_succes', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_regles_production_categorie'), 'regles_production', ['categorie'], unique=False)
    op.create_index(op.f('ix_regles_production_code_regle'), 'regles_production', ['code_regle'], unique=True)
    op.create_index(op.f('ix_regles_production_id'), 'regles_production', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_regles_production_id'), table_name='regles_production')
    op.drop_index(op.f('ix_regles_production_code_regle'), table_name='regles_production')
    op.drop_index(op.f('ix_regles_production_categorie'), table_name='regles_production')
    op.drop_table('regles_production')
    # ### end Alembic commands ###


=== Fichier: ./scripts/run_dataset_import.py ===

import sys
import os

# Le sys.path.insert n'est plus nÃ©cessaire si on lance avec 'python -m'
# Mais on le garde au cas oÃ¹, en le sÃ©curisant
if __name__ == "__main__" and __package__ is None:
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from datasets.integrators.mimic3_dics_integrator import MIMIC3DictionariesIntegrator
from datasets.integrators.mimic3_integrator import MIMIC3RelationsIntegrator
from datasets.assembler.case_assembler import CaseAssembler
from datasets.integrators.manual_images_integrator import ManualImagesIntegrator

# --- CONFIGURATION DES CHEMINS D'ACCÃˆS ---
MIMIC_BASE_PATH = "/home/clement/TÃ©lÃ©chargements/archive (1)/mimic-iii-clinical-database-demo-1.4"
SOURCE_IMAGES_DIR = "/home/clement/TÃ©lÃ©chargements/imgradio" 
MAPPING_CSV_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'datasets/mapping/images_mapping.csv'))

MIMIC_FILES_PATHS = {
    "d_icd_diagnoses": os.path.join(MIMIC_BASE_PATH, "D_ICD_DIAGNOSES.csv"),
    "d_labitems": os.path.join(MIMIC_BASE_PATH, "D_LABITEMS.csv"),
    "d_items": os.path.join(MIMIC_BASE_PATH, "D_ITEMS.csv"),
    "prescriptions": os.path.join(MIMIC_BASE_PATH, "PRESCRIPTIONS.csv"),
    "diagnoses_icd": os.path.join(MIMIC_BASE_PATH, "DIAGNOSES_ICD.csv"),
    "labevents": os.path.join(MIMIC_BASE_PATH, "LABEVENTS.csv"),
    "admissions": os.path.join(MIMIC_BASE_PATH, "ADMISSIONS.csv"),
}

def check_paths(paths: dict):
    all_found = True
    for key, path in paths.items():
        if not os.path.exists(path):
            print(f"âŒ ERREUR: Fichier non trouvÃ© pour '{key}': {path}")
            all_found = False
    return all_found

def main():
    print("--- DÃ©marrage du script d'importation complet ---")
    
    if not check_paths(MIMIC_FILES_PATHS):
        print("\nAttention: Fichiers MIMIC manquants.")
        # On continue quand mÃªme pour tester les autres intÃ©grateurs si besoin
    
    db_session = SessionLocal()
    
    try:
        print("\n" + "="*50)
        print("Ã‰TAPE 1: PEUPLEMENT DES DICTIONNAIRES")
        dics_integrator = MIMIC3DictionariesIntegrator(db_session=db_session, paths=MIMIC_FILES_PATHS)
        dics_integrator.run_all()

        print("\n" + "="*50)
        print("Ã‰TAPE 2: CRÃ‰ATION DES RELATIONS")
        relations_integrator = MIMIC3RelationsIntegrator(db_session=db_session, paths=MIMIC_FILES_PATHS)
        relations_integrator.run()

        print("\n" + "="*50)
        print("Ã‰TAPE 3: ASSEMBLAGE DES CAS CLINIQUES")
        case_assembler = CaseAssembler(db_session=db_session, paths=MIMIC_FILES_PATHS)
        case_assembler.run()

        print("\n" + "="*50)
        print("Ã‰TAPE 4: IMPORTATION DES IMAGES MANUELLES")
        if not os.path.exists(MAPPING_CSV_PATH):
            print(f"âŒ ERREUR: Fichier de mapping non trouvÃ© : {MAPPING_CSV_PATH}")
        else:
            images_integrator = ManualImagesIntegrator(
                db_session=db_session,
                mapping_csv_path=MAPPING_CSV_PATH,
                source_images_dir="" 
            )
            images_integrator.run()

    except Exception as e:
        print(f"\nâŒ UNE ERREUR CRITIQUE EST SURVENUE : {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        print("\nFermeture de la session de base de donnÃ©es.")
        db_session.close()

if __name__ == "__main__":
    main()

=== Fichier: ./scripts/run_assembler.py ===



=== Fichier: ./scripts/apply_mapping.py ===

import sys
import os
import io
import csv
from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError

# Assurer que le script peut trouver les modules de l'application
# Ce bloc est important car le script est exÃ©cutÃ© depuis le rÃ©pertoire racine du projet
if os.getcwd() not in sys.path:
    sys.path.insert(0, os.getcwd())

from app.database import SessionLocal
from app import models

# ==============================================================================
# CONFIGURATION
# ==============================================================================
# Seuil de score minimum pour qu'une association soit appliquÃ©e.
# Ajustez cette valeur si nÃ©cessaire. Un score de 30 semble un bon dÃ©but.
SCORE_THRESHOLD = 10

# Les donnÃ©es CSV extraites de votre rapport.
# Coller directement les donnÃ©es ici rend le script autonome.
CSV_DATA = """case_id,pathologie_id,pathologie_name,image_id,image_type,score,type_association
1041,25579,"Closed fracture of surgical neck of humerus",198,"Radio Ã‰paule",40,PROPOSITION
1041,25579,"Closed fracture of surgical neck of humerus",203,"Radio Coude",20,PROPOSITION
1041,25579,"Closed fracture of surgical neck of humerus",204,"Radio Coude",20,PROPOSITION
1043,19789,"Intracerebral hemorrhage",199,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1043,19789,"Intracerebral hemorrhage",233,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1044,19759,"Congestive heart failure, unspecified",200,"Radio Thorax",40,PROPOSITION
1044,19759,"Congestive heart failure, unspecified",201,"Radio Thorax",20,PROPOSITION
1044,19759,"Congestive heart failure, unspecified",202,"Radio Thorax",20,PROPOSITION
1046,25597,"Other closed fracture of lower end of humerus",198,"Radio Ã‰paule",20,PROPOSITION
1046,25597,"Other closed fracture of lower end of humerus",203,"Radio Coude",20,PROPOSITION
1046,25597,"Other closed fracture of lower end of humerus",204,"Radio Coude",20,PROPOSITION
1047,17069,"Toxic multinodular goiter without mention of thyrotoxic crisis or storm",205,"Ã‰cho ThyroÃ¯de",30,PROPOSITION
1047,17069,"Toxic multinodular goiter without mention of thyrotoxic crisis or storm",206,"Ã‰cho ThyroÃ¯de",30,PROPOSITION
1048,19795,"Occlusion and stenosis of carotid artery without mention of cerebral infarction",207,"Echo-Doppler",30,PROPOSITION
1048,19795,"Occlusion and stenosis of carotid artery without mention of cerebral infarction",208,"Echo-Doppler",30,PROPOSITION
1048,19795,"Occlusion and stenosis of carotid artery without mention of cerebral infarction",209,"Echo-Doppler",30,PROPOSITION
1050,26912,"Infection and inflammatory reaction due to other internal orthopedic device, implant, and graft",210,"Radio",20,PROPOSITION
1050,26912,"Infection and inflammatory reaction due to other internal orthopedic device, implant, and graft",211,"Radio",20,PROPOSITION
1051,19596,"Unspecified hypertensive heart disease with heart failure",200,"Radio Thorax",30,PROPOSITION
1051,19596,"Unspecified hypertensive heart disease with heart failure",201,"Radio Thorax",30,PROPOSITION
1051,19596,"Unspecified hypertensive heart disease with heart failure",202,"Radio Thorax",30,PROPOSITION
1058,21090,"Cirrhosis of liver without mention of alcohol",219,"Ã‰cho Abdo",20,PROPOSITION
1058,21090,"Cirrhosis of liver without mention of alcohol",270,"Ã‰cho Abdo",20,PROPOSITION
1059,21090,"Cirrhosis of liver without mention of alcohol",219,"Ã‰cho Abdo",20,PROPOSITION
1059,21090,"Cirrhosis of liver without mention of alcohol",270,"Ã‰cho Abdo",20,PROPOSITION
1060,19759,"Congestive heart failure, unspecified",200,"Radio Thorax",40,PROPOSITION
1060,19759,"Congestive heart failure, unspecified",201,"Radio Thorax",20,PROPOSITION
1060,19759,"Congestive heart failure, unspecified",202,"Radio Thorax",20,PROPOSITION
1061,23049,"Closed fracture of base of skull with subarachnoid, subdural, and extradural hemorrhage, with prolonged [more than 24 hours] loss of consciousness, without return to pre-existing conscious level",221,"Scanner CÃ©rÃ©bral",30,PROPOSITION
1061,23049,"Closed fracture of base of skull with subarachnoid, subdural, and extradural hemorrhage, with prolonged [more than 24 hours] loss of consciousness, without return to pre-existing conscious level",235,"Scanner CÃ©rÃ©bral",20,PROPOSITION
1071,19789,"Intracerebral hemorrhage",199,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1071,19789,"Intracerebral hemorrhage",233,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1076,24386,"Other open skull fracture with subarachnoid, subdural, and extradural hemorrhage, with prolonged [more than 24 hours] loss of consciousness, without return to pre-existing conscious level",235,"Scanner CÃ©rÃ©bral",30,PROPOSITION
1076,24386,"Other open skull fracture with subarachnoid, subdural, and extradural hemorrhage, with prolonged [more than 24 hours] loss of consciousness, without return to pre-existing conscious level",221,"Scanner CÃ©rÃ©bral",20,PROPOSITION
1081,19759,"Congestive heart failure, unspecified",200,"Radio Thorax",40,PROPOSITION
1081,19759,"Congestive heart failure, unspecified",201,"Radio Thorax",20,PROPOSITION
1081,19759,"Congestive heart failure, unspecified",202,"Radio Thorax",20,PROPOSITION
1083,19759,"Congestive heart failure, unspecified",200,"Radio Thorax",40,PROPOSITION
1083,19759,"Congestive heart failure, unspecified",201,"Radio Thorax",20,PROPOSITION
1083,19759,"Congestive heart failure, unspecified",202,"Radio Thorax",20,PROPOSITION
1086,21128,"Acute cholecystitis",242,"Ã‰cho Abdo",40,PROPOSITION
1087,21334,"Chronic or unspecified duodenal ulcer with hemorrhage, without mention of obstruction",243,"Gastroscopie",20,PROPOSITION
1087,21334,"Chronic or unspecified duodenal ulcer with hemorrhage, without mention of obstruction",244,"Gastroscopie",20,PROPOSITION
1087,21334,"Chronic or unspecified duodenal ulcer with hemorrhage, without mention of obstruction",245,"Gastroscopie",20,PROPOSITION
1089,22193,"Closed fracture of intertrochanteric section of neck of femur",198,"Radio Ã‰paule",20,PROPOSITION
1089,22193,"Closed fracture of intertrochanteric section of neck of femur",246,"Radio Bassin",20,PROPOSITION
1097,21140,"Cholangitis",255,"Scanner/Ã‰cho",30,PROPOSITION
1097,21140,"Cholangitis",256,"Scanner/Ã‰cho",30,PROPOSITION
1099,24405,"Subarachnoid hemorrhage following injury without mention of open intracranial wound, with loss of consciousness of unspecified duration",257,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1104,19764,"Acute on chronic systolic heart failure",200,"Radio Thorax",20,PROPOSITION
1104,19764,"Acute on chronic systolic heart failure",201,"Radio Thorax",20,PROPOSITION
1104,19764,"Acute on chronic systolic heart failure",202,"Radio Thorax",20,PROPOSITION
1106,21302,"Tracheoesophageal fistula",260,"Transit",40,PROPOSITION
1108,21128,"Acute cholecystitis",242,"Ã‰cho Abdo",40,PROPOSITION
1113,27653,"Ventilator associated pneumonia",261,"Radio Thorax",50,PROPOSITION
1129,27723,"Closed fracture of first cervical vertebra",247,"Scanner Rachis",20,PROPOSITION
1130,19762,"Acute systolic heart failure",200,"Radio Thorax",20,PROPOSITION
1130,19762,"Acute systolic heart failure",201,"Radio Thorax",20,PROPOSITION
1130,19762,"Acute systolic heart failure",202,"Radio Thorax",20,PROPOSITION
"""

def apply_associations():
    """
    Script principal pour lire le CSV et appliquer les associations
    Ã  la base de donnÃ©es.
    """
    db: Session = SessionLocal()
    
    csv_file = io.StringIO(CSV_DATA)
    reader = csv.DictReader(csv_file)
    
    associations_applied = 0
    associations_skipped = 0
    errors = 0
    
    print("ğŸš€ DÃ©marrage du script d'application des associations...")
    print(f"Seuil de score minimum pour l'association : {SCORE_THRESHOLD}")
    print("-" * 50)
    
    try:
        for row in reader:
            case_id = int(row['case_id'])
            pathologie_id = int(row['pathologie_id'])
            image_id = int(row['image_id'])
            score = int(row['score'])

            if score < SCORE_THRESHOLD:
                print(f"â© Cas {case_id} -> Image {image_id}: Score ({score}) trop bas. IgnorÃ©.")
                associations_skipped += 1
                continue

            print(f" APPLYING: Cas #{case_id} â†’ Pathologie #{pathologie_id} â†’ Image #{image_id} (Score: {score})")

            db_case = db.query(models.ClinicalCase).filter(models.ClinicalCase.id == case_id).first()
            db_image = db.query(models.ImageMedicale).filter(models.ImageMedicale.id == image_id).first()
            
            if not db_case or not db_image:
                print(f"   âŒ ERREUR: Cas #{case_id} ou Image #{image_id} non trouvÃ©(e) dans la base de donnÃ©es.")
                errors += 1
                continue

            db_image.pathologie_id = pathologie_id
            print(f"   âœ… Image #{image_id}: pathologie_id mis Ã  jour avec {pathologie_id}.")

            if db_case.images_associees_ids is None:
                db_case.images_associees_ids = []
            
            current_ids = list(db_case.images_associees_ids)
            if image_id not in current_ids:
                current_ids.append(image_id)
                db_case.images_associees_ids = current_ids
                print(f"   âœ… Cas #{case_id}: Image #{image_id} ajoutÃ©e Ã  images_associees_ids.")
            else:
                print(f"   â„¹ï¸ Cas #{case_id}: L'image #{image_id} Ã©tait dÃ©jÃ  associÃ©e.")

            associations_applied += 1

        print("-" * 50)
        print("Toutes les lignes ont Ã©tÃ© traitÃ©es. Validation des changements...")
        db.commit()
        print("âœ… Changements validÃ©s dans la base de donnÃ©es.")

    except SQLAlchemyError as e:
        print(f"\nâŒ ERREUR DE BASE DE DONNÃ‰ES: {e}")
        print("Annulation de toutes les modifications (rollback).")
        db.rollback()
        errors += 1
    except Exception as e:
        print(f"\nâŒ ERREUR INATTENDUE: {e}")
        print("Annulation des modifications (rollback).")
        db.rollback()
        errors += 1
    finally:
        print("\n" + "=" * 50)
        print("RÃ‰SUMÃ‰ DE L'OPÃ‰RATION")
        print(f"   Associations appliquÃ©es : {associations_applied}")
        print(f"   Associations ignorÃ©es (score bas) : {associations_skipped}")
        print(f"   Erreurs rencontrÃ©es : {errors}")
        print("=" * 50)
        db.close()
        print("Connexion Ã  la base de donnÃ©es fermÃ©e.")

if __name__ == "__main__":
    apply_associations()

=== Fichier: ./scripts/generate_q_matrix.py ===

import sys
import os

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app import models

def generate_matrix():
    db = SessionLocal()
    print("--- GÃ©nÃ©ration de la Q-Matrix (Lien Cas <-> CompÃ©tences) ---")

    # 1. Charger toutes les compÃ©tences pour avoir leurs IDs et codes
    competencies = db.query(models.Competence).all()
    comp_map = {c.code_competence: c.id for c in competencies}
    
    if not comp_map:
        print("âŒ Aucune compÃ©tence trouvÃ©e. Veuillez lancer populate_competencies.py d'abord.")
        return

    # 2. RÃ©cupÃ©rer tous les cas cliniques
    cases = db.query(models.ClinicalCase).all()
    print(f"Traitement de {len(cases)} cas cliniques...")

    count_updated = 0
    for case in cases:
        required_skills = {} # Dictionnaire pour stocker les compÃ©tences requises {code: id}

        # --- RÃˆGLES D'ATTRIBUTION DES COMPÃ‰TENCES ---

        # RÃ¨gle 1 : Socle commun (Tout cas nÃ©cessite ces bases)
        # Bloom 1-2
        common_skills = ["IDENTIFIER_MOTIF", "EMPATHIE", "ANAMNESE_HISTOIRE"]
        for code in common_skills:
            if code in comp_map:
                required_skills[code] = comp_map[code]

        # RÃ¨gle 2 : Si le cas a des symptÃ´mes biologiques (Labo)
        # Bloom 4
        if case.donnees_paracliniques and "lab_results" in case.donnees_paracliniques:
            if len(case.donnees_paracliniques["lab_results"]) > 0:
                if "INTERPRETATION_BIOLOGIE" in comp_map:
                    required_skills["INTERPRETATION_BIOLOGIE"] = comp_map["INTERPRETATION_BIOLOGIE"]

        # RÃ¨gle 3 : Si le cas a des images
        # Bloom 4
        if case.images_associees_ids and len(case.images_associees_ids) > 0:
            if "INTERPRETATION_IMAGERIE" in comp_map:
                required_skills["INTERPRETATION_IMAGERIE"] = comp_map["INTERPRETATION_IMAGERIE"]

        # RÃ¨gle 4 : Si le cas a des mÃ©dicaments prescrits
        # Bloom 6
        if case.medicaments_prescrits and len(case.medicaments_prescrits) > 0:
            if "PRESCRIPTION_THERAPEUTIQUE" in comp_map:
                required_skills["PRESCRIPTION_THERAPEUTIQUE"] = comp_map["PRESCRIPTION_THERAPEUTIQUE"]
        
        # RÃ¨gle 5 : CompÃ©tences de Raisonnement (Toujours nÃ©cessaires pour un cas complet)
        # Bloom 4-5
        reasoning_skills = ["GENERATION_HYPOTHESES", "DIAGNOSTIC_DIFFERENTIEL", "SYNTHESE_CLINIQUE"]
        for code in reasoning_skills:
            if code in comp_map:
                required_skills[code] = comp_map[code]

        # --- MISE Ã€ JOUR DU CAS ---
        
        # On sauvegarde le rÃ©sultat sous forme de JSON { "CODE_COMPETENCE": ID_COMPETENCE }
        case.competences_requises = required_skills
        
        # On calcule un niveau de difficultÃ© suggÃ©rÃ© basÃ© sur la richesse du cas
        # Base: 1. +1 si labo, +1 si images, +1 si mÃ©dicaments, +1 si comorbiditÃ©s
        difficulty = 1
        if "INTERPRETATION_BIOLOGIE" in required_skills: difficulty += 1
        if "INTERPRETATION_IMAGERIE" in required_skills: difficulty += 1
        if "PRESCRIPTION_THERAPEUTIQUE" in required_skills: difficulty += 1
        if case.pathologies_secondaires_ids: difficulty += 1
        
        case.niveau_difficulte = min(difficulty, 5) # Max 5

        count_updated += 1

    db.commit()
    db.close()
    print(f"âœ¨ TerminÃ©. {count_updated} cas cliniques mis Ã  jour avec leur Q-Matrix.")

if __name__ == "__main__":
    generate_matrix()

=== Fichier: ./scripts/backup_restore.py ===



=== Fichier: ./scripts/populate_from_datasets.py ===



=== Fichier: ./scripts/link_images_to_cases.py ===

import sys
import os
from sqlalchemy.orm import Session
from collections import defaultdict
import random

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app import models

def link_images_to_cases():
    """
    Script pour lier les images existantes aux cas cliniques basÃ©s sur la pathologie.
    """
    print("ğŸš€ DÃ©marrage du script de liaison Images â†” Cas Cliniques...")
    
    db = SessionLocal()
    
    try:
        # --- Ã‰tape 1: PrÃ©-charger toutes les images par pathologie ---
        print("  -> PrÃ©-chargement de la bibliothÃ¨que d'images...")
        
        images_by_pathology = defaultdict(list)
        all_images = db.query(models.ImageMedicale).filter(
            models.ImageMedicale.pathologie_id.isnot(None)
        ).all()
        
        for img in all_images:
            images_by_pathology[img.pathologie_id].append(img.id)
            
        print(f"     -> {len(all_images)} images trouvÃ©es et groupÃ©es par {len(images_by_pathology)} pathologies.")

        # --- Ã‰tape 2: Parcourir tous les cas cliniques ---
        print("\n  -> Analyse des cas cliniques Ã  enrichir...")
        
        # On ne prend que les cas qui n'ont pas encore d'images
        cases_to_update = db.query(models.ClinicalCase).filter(
            (models.ClinicalCase.images_associees_ids == None) |
            (models.ClinicalCase.images_associees_ids == [])
        ).all()
        
        print(f"     -> {len(cases_to_update)} cas cliniques sans images trouvÃ©s.")
        
        update_count = 0
        
        for case in cases_to_update:
            pathologie_id = case.pathologie_principale_id
            
            # --- Ã‰tape 3: Trouver des images compatibles ---
            if pathologie_id in images_by_pathology:
                
                # RÃ©cupÃ©rer la liste des images disponibles pour cette pathologie
                available_image_ids = images_by_pathology[pathologie_id]
                
                # --- Ã‰tape 4: CrÃ©er le lien ---
                # On associe une image alÃ©atoire parmi celles disponibles
                selected_image_id = random.choice(available_image_ids)
                
                case.images_associees_ids = [selected_image_id]
                
                print(f"     -> âœ… Cas {case.id} (Pathologie {pathologie_id}) liÃ© Ã  l'Image {selected_image_id}.")
                update_count += 1
        
        if update_count > 0:
            print(f"\n  -> Validation de {update_count} mises Ã  jour dans la base de donnÃ©es...")
            db.commit()
            print("     -> âœ… TerminÃ©.")
        else:
            print("\n  -> Aucun nouveau lien Ã  crÃ©er.")

        print(f"\nâœ¨ Script de liaison terminÃ©. {update_count} cas cliniques ont Ã©tÃ© enrichis avec une image.")
        
    except Exception as e:
        print(f"âŒ Erreur critique : {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    link_images_to_cases()

=== Fichier: ./scripts/migrate_fultang_data.py ===



=== Fichier: ./scripts/export_training_data.py ===



=== Fichier: ./scripts/migration_img.py ===

import sys
import os
import cloudinary
import cloudinary.uploader
from sqlalchemy.orm import Session
from datetime import datetime

# Configuration du chemin pour les imports de l'application
# Permet au script de "voir" le dossier app/ mÃªme s'il est dans scripts/
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app.models.media import ImageMedicale
from app.config import settings

# 1. Configuration Cloudinary
# Les clÃ©s sont chargÃ©es depuis votre fichier .env via settings
cloudinary.config( 
    cloud_name = settings.CLOUDINARY_CLOUD_NAME, 
    api_key = settings.CLOUDINARY_API_KEY, 
    api_secret = settings.CLOUDINARY_API_SECRET,
    secure = True
)

OUTPUT_LOG_FILE = "migration_mapping_log.txt"

def migrate_images():
    print("ğŸš€ DÃ©marrage de la migration des images vers Cloudinary...")
    print(f"ğŸ“„ Un rapport sera gÃ©nÃ©rÃ© dans : {OUTPUT_LOG_FILE}")
    
    db = SessionLocal()
    mapping_log = [] # Liste pour stocker les correspondances
    
    try:
        # 2. RÃ©cupÃ©rer les images locales
        # On filtre celles qui ne commencent PAS par 'http'
        images_to_migrate = db.query(ImageMedicale).filter(
            ~ImageMedicale.fichier_url.like('http%')
        ).all()
        
        total_images = len(images_to_migrate)
        print(f"ğŸ“Š {total_images} images trouvÃ©es Ã  migrer.")
        
        # En-tÃªte du fichier de log
        mapping_log.append(f"--- RAPPORT DE MIGRATION DU {datetime.now()} ---")
        mapping_log.append(f"Total Ã  traiter : {total_images}\n")
        mapping_log.append(f"{'ID':<5} | {'ANCIEN CHEMIN LOCAL':<60} | {'NOUVELLE URL CLOUDINARY'}")
        mapping_log.append("-" * 150)
        
        success_count = 0
        error_count = 0
        
        for img in images_to_migrate:
            # Reconstruire le chemin absolu du fichier sur votre machine
            # On suppose que le chemin en BDD est relatif Ã  la racine du projet
            # ex: "storage/media/images/radio.jpg"
            local_rel_path = img.fichier_url
            local_abs_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', local_rel_path))
            
            print(f"  -> Traitement ID {img.id}...")
            
            if os.path.exists(local_abs_path):
                try:
                    # 3. Upload vers Cloudinary
                    # folder="sti_medical/radiology" permet de ranger les fichiers dans le cloud
                    upload_result = cloudinary.uploader.upload(
                        local_abs_path, 
                        folder="sti_medical_expert/radiology",
                        public_id=f"img_{img.id}_{os.path.basename(local_abs_path).split('.')[0]}" 
                    )
                    
                    new_url = upload_result.get("secure_url")
                    
                    # 4. Mise Ã  jour de la Base de DonnÃ©es
                    img.fichier_url = new_url
                    
                    # Ajout au rapport
                    log_line = f"{img.id:<5} | {local_rel_path:<60} | {new_url}"
                    mapping_log.append(log_line)
                    
                    success_count += 1
                    print(f"     âœ… SuccÃ¨s.")
                    
                except Exception as e:
                    error_msg = f"ERREUR UPLOAD: {str(e)}"
                    print(f"     âŒ {error_msg}")
                    mapping_log.append(f"{img.id:<5} | {local_rel_path:<60} | {error_msg}")
                    error_count += 1
            else:
                error_msg = "FICHIER LOCAL INTROUVABLE"
                print(f"     âš ï¸ {error_msg} : {local_abs_path}")
                mapping_log.append(f"{img.id:<5} | {local_rel_path:<60} | {error_msg}")
                error_count += 1
        
        # Validation finale des changements en BDD
        db.commit()
        
        # Ã‰criture du fichier de log
        mapping_log.append("\n" + "-" * 150)
        mapping_log.append(f"RÃ‰SUMÃ‰ : SuccÃ¨s {success_count} / Erreurs {error_count}")
        
        with open(OUTPUT_LOG_FILE, "w", encoding="utf-8") as f:
            f.write("\n".join(mapping_log))
            
        print(f"\nâœ¨ Migration terminÃ©e.")
        print(f"âœ… SuccÃ¨s : {success_count}")
        print(f"âŒ Erreurs : {error_count}")
        print(f"ğŸ“„ Rapport sauvegardÃ© : {os.path.abspath(OUTPUT_LOG_FILE)}")
        
    except Exception as e:
        print(f"âŒ Erreur critique du script : {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    migrate_images()

=== Fichier: ./scripts/check_relations.py ===

import sys
import os
from sqlalchemy import inspect

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import engine
# Importez tous les modÃ¨les pour Ãªtre sÃ»r qu'ils sont enregistrÃ©s
from app import models 

def check_db_relations():
    inspector = inspect(engine)
    table_names = inspector.get_table_names()
    
    print(f"\n--- AUDIT DE LA BASE DE DONNÃ‰ES ({len(table_names)} tables trouvÃ©es) ---\n")
    
    # 1. VÃ©rification des Tables
    print("ğŸ“‹ LISTE DES TABLES :")
    for table in sorted(table_names):
        print(f"  - {table}")
        
    print("\nğŸ”— VÃ‰RIFICATION DES RELATIONS (ClÃ©s Ã‰trangÃ¨res) :")
    
    # 2. VÃ©rification des ClÃ©s Ã‰trangÃ¨res
    relations_found = 0
    for table_name in sorted(table_names):
        fks = inspector.get_foreign_keys(table_name)
        if fks:
            print(f"\n  TABLE '{table_name}' est liÃ©e Ã  :")
            for fk in fks:
                referred_table = fk.get('referred_table')
                constrained_columns = fk['constrained_columns'] # La colonne source (ex: learner_id)
                referred_columns = fk['referred_columns'] # La colonne cible (ex: id)
                
                print(f"    -> {referred_table} (via {constrained_columns[0]} -> {referred_columns[0]})")
                relations_found += 1
    
    print(f"\nâœ¨ Total de {relations_found} relations de clÃ© Ã©trangÃ¨re trouvÃ©es.")
    
    if relations_found > 10: # On en attend beaucoup
        print("âœ… La structure relationnelle semble riche et interconnectÃ©e.")
    else:
        print("âš ï¸ Attention : Peu de relations trouvÃ©es. VÃ©rifiez vos modÃ¨les.")

if __name__ == "__main__":
    check_db_relations()

=== Fichier: ./scripts/validate_cases.py ===



=== Fichier: ./scripts/init_db.py ===



=== Fichier: ./scripts/populate_competencies.py ===

import sys
import os

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app import models

def populate():
    db = SessionLocal()
    print("--- Peuplement des CompÃ©tences Cliniques (Structure Consultation & Bloom) ---")

    # ---------------------------------------------------------
    # 1. CompÃ©tences Racines (Les Grandes Ã‰tapes de la Consultation)
    # ---------------------------------------------------------
    root_skills = [
        {"code": "RELATION", "nom": "1. Accueil et Relation Patient", "cat": "Communication", "bloom": 2},
        {"code": "ANAMNESE", "nom": "2. AnamnÃ¨se (Interrogatoire)", "cat": "EnquÃªte", "bloom": 3},
        {"code": "EXAMEN_PHYSIQUE", "nom": "3. Examen Clinique", "cat": "Observation", "bloom": 3},
        {"code": "RAISONNEMENT", "nom": "4. Raisonnement Diagnostique", "cat": "Raisonnement", "bloom": 4},
        {"code": "PARACLINIQUE", "nom": "5. Examens ComplÃ©mentaires", "cat": "Investigation", "bloom": 4},
        {"code": "SYNTHESE", "nom": "6. Diagnostic et Explication", "cat": "SynthÃ¨se", "bloom": 5},
        {"code": "PRISE_EN_CHARGE", "nom": "7. Traitement et Suivi", "cat": "Action", "bloom": 6},
    ]

    roots = {}
    for skill in root_skills:
        existing = db.query(models.Competence).filter(models.Competence.code_competence == skill["code"]).first()
        if not existing:
            new_skill = models.Competence(
                code_competence=skill["code"],
                nom=skill["nom"],
                categorie=skill["cat"],
                niveau_bloom=skill["bloom"],
                description=f"CompÃ©tence racine pour l'Ã©tape : {skill['nom']}"
            )
            db.add(new_skill)
            db.commit()
            db.refresh(new_skill)
            roots[skill["code"]] = new_skill
            print(f"âœ… Racine crÃ©Ã©e : {skill['nom']} (Bloom {skill['bloom']})")
        else:
            roots[skill["code"]] = existing
            print(f"â„¹ï¸ Racine existante : {skill['nom']}")

    # ---------------------------------------------------------
    # 2. Sous-CompÃ©tences SpÃ©cifiques (DÃ©tails opÃ©ratoires)
    # ---------------------------------------------------------
    specific_skills = [
        # 1. Accueil
        {"code": "IDENTIFIER_MOTIF", "nom": "Identifier le motif de consultation", "parent": "RELATION", "bloom": 1},
        {"code": "EMPATHIE", "nom": "Communication empathique", "parent": "RELATION", "bloom": 2},

        # 2. AnamnÃ¨se
        {"code": "ANAMNESE_HISTOIRE", "nom": "CaractÃ©riser l'histoire de la maladie (PQRST)", "parent": "ANAMNESE", "bloom": 3},
        {"code": "ANAMNESE_ANTECEDENTS", "nom": "Recueillir les antÃ©cÃ©dents (perso/famille)", "parent": "ANAMNESE", "bloom": 2},
        {"code": "ANAMNESE_TRAITEMENTS", "nom": "Recenser traitements et allergies", "parent": "ANAMNESE", "bloom": 2},
        {"code": "ANAMNESE_MODE_VIE", "nom": "Identifier les facteurs de mode de vie", "parent": "ANAMNESE", "bloom": 2},

        # 3. Examen Physique
        {"code": "SIGNES_VITAUX", "nom": "Mesurer et interprÃ©ter les constantes", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},
        {"code": "EXAMEN_CIBLE", "nom": "RÃ©aliser l'examen physique ciblÃ©", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},
        {"code": "RECONNAISSANCE_SIGNES", "nom": "ReconnaÃ®tre les signes physiques d'alerte", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},

        # 4. Raisonnement
        {"code": "GENERATION_HYPOTHESES", "nom": "Formuler des hypothÃ¨ses diagnostiques", "parent": "RAISONNEMENT", "bloom": 4},
        {"code": "DIAGNOSTIC_DIFFERENTIEL", "nom": "Mener un diagnostic diffÃ©rentiel", "parent": "RAISONNEMENT", "bloom": 5},

        # 5. Paraclinique
        {"code": "PRESCRIPTION_PERTINENTE", "nom": "Prescrire les examens pertinents", "parent": "PARACLINIQUE", "bloom": 5},
        {"code": "INTERPRETATION_BIOLOGIE", "nom": "InterprÃ©ter les rÃ©sultats biologiques", "parent": "PARACLINIQUE", "bloom": 4},
        {"code": "INTERPRETATION_IMAGERIE", "nom": "InterprÃ©ter l'imagerie mÃ©dicale", "parent": "PARACLINIQUE", "bloom": 4},

        # 6. SynthÃ¨se
        {"code": "SYNTHESE_CLINIQUE", "nom": "IntÃ©grer les donnÃ©es pour conclure", "parent": "SYNTHESE", "bloom": 5},
        {"code": "ANNONCE_DIAGNOSTIC", "nom": "Expliquer le diagnostic au patient", "parent": "SYNTHESE", "bloom": 3},

        # 7. Prise en charge
        {"code": "PRESCRIPTION_THERAPEUTIQUE", "nom": "Ã‰tablir le plan thÃ©rapeutique", "parent": "PRISE_EN_CHARGE", "bloom": 6},
        {"code": "EDUCATION_PATIENT", "nom": "Ã‰duquer le patient sur sa maladie", "parent": "PRISE_EN_CHARGE", "bloom": 3},
        {"code": "SUIVI_EVOLUTION", "nom": "Planifier le suivi et la surveillance", "parent": "PRISE_EN_CHARGE", "bloom": 5},
    ]

    created_skills = {}
    for skill in specific_skills:
        existing = db.query(models.Competence).filter(models.Competence.code_competence == skill["code"]).first()
        if not existing:
            parent = roots.get(skill["parent"])
            new_skill = models.Competence(
                code_competence=skill["code"],
                nom=skill["nom"],
                categorie=parent.categorie if parent else "Autre",
                parent_competence_id=parent.id if parent else None,
                niveau_bloom=skill["bloom"],
                description=f"Sous-compÃ©tence de : {parent.nom if parent else 'Racine'}"
            )
            db.add(new_skill)
            db.commit()
            db.refresh(new_skill)
            created_skills[skill["code"]] = new_skill
            print(f"  -> Sous-compÃ©tence crÃ©Ã©e : {skill['nom']} (Bloom {skill['bloom']})")
        else:
            created_skills[skill["code"]] = existing

    # ---------------------------------------------------------
    # 3. CrÃ©ation des PrÃ©requis (Le Graphe de DÃ©pendance)
    # ---------------------------------------------------------
    # Logique : "Pour faire B, il faut savoir faire A"
    prerequisites = [
        # Logique interne Ã  l'AnamnÃ¨se
        ("ANAMNESE_HISTOIRE", "IDENTIFIER_MOTIF"), # On ne peut pas creuser l'histoire si on n'a pas le motif
        
        # Logique AnamnÃ¨se -> Examen
        ("EXAMEN_CIBLE", "ANAMNESE_HISTOIRE"), # L'examen est guidÃ© par l'histoire
        
        # Logique vers Raisonnement
        ("GENERATION_HYPOTHESES", "ANAMNESE_HISTOIRE"),
        ("GENERATION_HYPOTHESES", "SIGNES_VITAUX"),
        
        # Logique vers Paraclinique
        ("PRESCRIPTION_PERTINENTE", "GENERATION_HYPOTHESES"), # On prescrit pour tester une hypothÃ¨se
        
        # Logique vers SynthÃ¨se
        ("SYNTHESE_CLINIQUE", "INTERPRETATION_BIOLOGIE"),
        ("SYNTHESE_CLINIQUE", "DIAGNOSTIC_DIFFERENTIEL"),
        
        # Logique vers Traitement (Le sommet)
        ("PRESCRIPTION_THERAPEUTIQUE", "SYNTHESE_CLINIQUE"), # Pas de traitement sans diagnostic
        ("EDUCATION_PATIENT", "SYNTHESE_CLINIQUE"),
    ]

    for target_code, req_code in prerequisites:
        target = created_skills.get(target_code)
        req = created_skills.get(req_code)

        if target and req:
            # VÃ©rifier si le lien existe dÃ©jÃ 
            link_exists = db.query(models.PrerequisCompetence).filter(
                models.PrerequisCompetence.competence_id == target.id,
                models.PrerequisCompetence.prerequis_id == req.id
            ).first()

            if not link_exists:
                new_link = models.PrerequisCompetence(
                    competence_id=target.id,
                    prerequis_id=req.id,
                    type_relation="STRICT"
                )
                db.add(new_link)
                print(f"    ğŸ”— PrÃ©requis crÃ©Ã© : {req.nom} -> {target.nom}")

    db.commit()
    db.close()
    print("âœ¨ Peuplement des compÃ©tences pÃ©dagogiques terminÃ©.")

if __name__ == "__main__":
    populate()

=== Fichier: ./testembedding.py ===

from app.services.embedding_service import embedding_service

text = "Pneumonie avec fiÃ¨vre Ã©levÃ©e"
vector = embedding_service.get_text_embedding(text)

print(f"Texte : {text}")
print(f"Taille du vecteur : {len(vector)}")
print(f"AperÃ§u : {vector[:5]}...")

=== Fichier: ./tests/conftest.py ===



=== Fichier: ./tests/fixtures/__init__.py ===



=== Fichier: ./tests/__init__.py ===



=== Fichier: ./tests/integration/__init__.py ===



=== Fichier: ./tests/unit/__init__.py ===



=== Fichier: ./test_api_lerner.py ===

import requests
import json
from datetime import datetime
import time
import uuid

# Configuration
BASE_URL = "https://appren-docker.onrender.com"
OUTPUT_FILE = f"test_api_learner_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    END = '\033[0m'

class APITester:
    def __init__(self, filename):
        self.filename = filename
        self.file = open(filename, 'w', encoding='utf-8')
        self.test_count = 0
        self.success_count = 0
        self.fail_count = 0
        self.created_ids = {}
        
    def write(self, message, color=None):
        """Ã‰crit dans le fichier et affiche Ã  l'Ã©cran"""
        self.file.write(message + '\n')
        self.file.flush()
        
        if color:
            print(f"{color}{message}{Colors.END}")
        else:
            print(message)
    
    def section(self, title):
        separator = '='*100
        self.write(f"\n{separator}")
        self.write(f"  {title}")
        self.write(separator)
    
    def test_header(self, method, endpoint, description):
        self.test_count += 1
        header = f"\n{'â”€'*100}\nTEST #{self.test_count}: {method} {endpoint}\nDescription: {description}\n{'â”€'*100}"
        self.write(header, Colors.CYAN)
    
    def log_request(self, method, url, data=None, params=None):
        self.write(f"\nğŸ“¤ REQUÃŠTE:", Colors.BLUE)
        self.write(f"   MÃ©thode: {method}")
        self.write(f"   URL: {url}")
        if params:
            self.write(f"   ParamÃ¨tres: {json.dumps(params, indent=6, ensure_ascii=False)}")
        if data:
            self.write(f"   DonnÃ©es envoyÃ©es:")
            self.write(json.dumps(data, indent=6, ensure_ascii=False))
    
    def log_response(self, response, show_full=True):
        self.write(f"\nğŸ“¥ RÃ‰PONSE:", Colors.BLUE)
        self.write(f"   Status Code: {response.status_code}")
        self.write(f"   Temps de rÃ©ponse: {response.elapsed.total_seconds():.2f}s")
        
        try:
            data = response.json()
            if show_full:
                self.write(f"   DonnÃ©es reÃ§ues:")
                self.write(json.dumps(data, indent=6, ensure_ascii=False))
            else:
                if isinstance(data, list):
                    self.write(f"   Type: Liste de {len(data)} Ã©lÃ©ments")
                    if len(data) > 0:
                        self.write(f"   Premier Ã©lÃ©ment:")
                        self.write(json.dumps(data[0], indent=6, ensure_ascii=False))
                else:
                    self.write(f"   DonnÃ©es reÃ§ues:")
                    self.write(json.dumps(data, indent=6, ensure_ascii=False))
        except:
            self.write(f"   RÃ©ponse texte: {response.text[:500]}")
    
    def mark_success(self, message=""):
        self.success_count += 1
        self.write(f"\nâœ… SUCCÃˆS: {message}", Colors.GREEN)
    
    def mark_failure(self, message=""):
        self.fail_count += 1
        self.write(f"\nâŒ Ã‰CHEC: {message}", Colors.RED)
    
    def summary(self):
        self.section("RÃ‰SUMÃ‰ DES TESTS")
        self.write(f"Total de tests: {self.test_count}")
        self.write(f"SuccÃ¨s: {self.success_count}", Colors.GREEN)
        self.write(f"Ã‰checs: {self.fail_count}", Colors.RED)
        self.write(f"Taux de rÃ©ussite: {(self.success_count/self.test_count*100):.1f}%" if self.test_count > 0 else "N/A")
        
        if self.created_ids:
            self.write("\nğŸ“ IDs crÃ©Ã©s pendant les tests:")
            for key, value in self.created_ids.items():
                self.write(f"   {key}: {value}")
    
    def close(self):
        self.file.close()
    
    def wait_for_user(self):
        """Attend que l'utilisateur appuie sur EntrÃ©e"""
        input(f"\n{Colors.YELLOW}â¸  Appuyez sur EntrÃ©e pour continuer...{Colors.END}")

# Instance globale
tester = None

# =============================================================================
# TESTS LEARNERS
# =============================================================================

def test_learners_create():
    tester.test_header("POST", "/learners/", "CrÃ©er un nouvel apprenant")
    
    data = {
        "matricule": f"TEST_{int(time.time())}",
        "nom": "Ã‰tudiant Test API",
        "email": f"test_{int(time.time())}@example.com",
        "niveau_etudes": "M2",
        "specialite_visee": "MÃ©decine GÃ©nÃ©rale",
        "langue_preferee": "FranÃ§ais",
        "date_inscription": datetime.now().isoformat()
    }
    
    tester.log_request("POST", f"{BASE_URL}/learners/", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/learners/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.created_ids['learner'] = result['id']
            tester.mark_success(f"Apprenant crÃ©Ã© avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_learners_list():
    tester.test_header("GET", "/learners/", "RÃ©cupÃ©rer la liste des apprenants")
    
    tester.log_request("GET", f"{BASE_URL}/learners/")
    
    try:
        response = requests.get(f"{BASE_URL}/learners/", timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} apprenants")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_learners_read():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/learners/{learner_id}", "RÃ©cupÃ©rer un apprenant par ID")
    
    tester.log_request("GET", f"{BASE_URL}/learners/{learner_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/learners/{learner_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Apprenant rÃ©cupÃ©rÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS COGNITIVE PROFILE
# =============================================================================

def test_cognitive_create():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", "/cognitive/", "CrÃ©er un profil cognitif")
    
    data = {
        "learner_id": tester.created_ids['learner'],
        "vitesse_assimilation": 7,
        "capacite_memoire_travail": 8,
        "tendance_impulsivite": 3,
        "prefer_visual": True
    }
    
    tester.log_request("POST", f"{BASE_URL}/cognitive/", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/cognitive/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Profil cognitif crÃ©Ã©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_cognitive_read():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/cognitive/{learner_id}", "RÃ©cupÃ©rer le profil cognitif")
    
    tester.log_request("GET", f"{BASE_URL}/cognitive/{learner_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/cognitive/{learner_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Profil cognitif rÃ©cupÃ©rÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_cognitive_update():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("PUT", f"/cognitive/{learner_id}", "Mettre Ã  jour le profil cognitif")
    
    data = {
        "learner_id": learner_id,
        "vitesse_assimilation": 9,
        "capacite_memoire_travail": 8,
        "tendance_impulsivite": 2,
        "prefer_visual": True
    }
    
    tester.log_request("PUT", f"{BASE_URL}/cognitive/{learner_id}", data=data)
    
    try:
        response = requests.put(f"{BASE_URL}/cognitive/{learner_id}", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Profil cognitif mis Ã  jour")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS AFFECTIVE STATE
# =============================================================================

def test_affective_create():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", "/affective/", "CrÃ©er un Ã©tat affectif")
    
    session_id = str(uuid.uuid4())
    tester.created_ids['session'] = session_id
    
    data = {
        "learner_id": tester.created_ids['learner'],
        "session_id": session_id,
        "timestamp": datetime.now().isoformat(),
        "stress_level": 3,
        "confidence_level": 7,
        "motivation_level": 8,
        "frustration_level": 2
    }
    
    tester.log_request("POST", f"{BASE_URL}/affective/", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/affective/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Ã‰tat affectif crÃ©Ã©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_affective_read_session():
    if 'session' not in tester.created_ids:
        tester.write("âš ï¸  Aucune session crÃ©Ã©e, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.created_ids['session']
    tester.test_header("GET", f"/affective/session/{session_id}", "RÃ©cupÃ©rer l'Ã©tat affectif d'une session")
    
    tester.log_request("GET", f"{BASE_URL}/affective/session/{session_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/affective/session/{session_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Ã‰tat affectif de session rÃ©cupÃ©rÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_affective_latest():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/affective/learner/{learner_id}/latest", "RÃ©cupÃ©rer le dernier Ã©tat affectif")
    
    tester.log_request("GET", f"{BASE_URL}/affective/learner/{learner_id}/latest")
    
    try:
        response = requests.get(f"{BASE_URL}/affective/learner/{learner_id}/latest", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Dernier Ã©tat affectif rÃ©cupÃ©rÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_affective_history():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/affective/learner/{learner_id}/history", "RÃ©cupÃ©rer l'historique affectif")
    
    tester.log_request("GET", f"{BASE_URL}/affective/learner/{learner_id}/history")
    
    try:
        response = requests.get(f"{BASE_URL}/affective/learner/{learner_id}/history", timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Historique rÃ©cupÃ©rÃ©: {len(data)} entrÃ©es")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS COMPETENCY MASTERY
# =============================================================================

def test_mastery_create():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", "/competency-mastery/", "CrÃ©er une maÃ®trise de compÃ©tence")
    
    data = {
        "learner_id": tester.created_ids['learner'],
        "competence_id": 1,
        "mastery_level": 7,
        "confidence": 8,
        "last_practice_date": datetime.now().isoformat(),
        "nb_success": 5,
        "nb_failures": 2,
        "streak_correct": 3
    }
    
    tester.log_request("POST", f"{BASE_URL}/competency-mastery/", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/competency-mastery/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.created_ids['competence'] = 1
            tester.mark_success("MaÃ®trise de compÃ©tence crÃ©Ã©e")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_mastery_list():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/competency-mastery/learner/{learner_id}", "Lister les compÃ©tences maÃ®trisÃ©es")
    
    tester.log_request("GET", f"{BASE_URL}/competency-mastery/learner/{learner_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/competency-mastery/learner/{learner_id}", timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} compÃ©tences")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_mastery_read():
    if 'learner' not in tester.created_ids or 'competence' not in tester.created_ids:
        tester.write("âš ï¸  DonnÃ©es manquantes, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    competence_id = tester.created_ids['competence']
    tester.test_header("GET", f"/competency-mastery/{learner_id}/{competence_id}", 
                      "RÃ©cupÃ©rer une compÃ©tence spÃ©cifique")
    
    tester.log_request("GET", f"{BASE_URL}/competency-mastery/{learner_id}/{competence_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/competency-mastery/{learner_id}/{competence_id}", timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("CompÃ©tence rÃ©cupÃ©rÃ©e")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS GOALS
# =============================================================================

def test_goals_create():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", "/goals/", "CrÃ©er un objectif d'apprentissage")
    
    data = {
        "learner_id": tester.created_ids['learner'],
        "type_objectif": "MaÃ®triser le diagnostic diffÃ©rentiel",
        "domaine_cible": "Cardiologie",
        "date_limite": "2026-06-30T00:00:00",
        "statut": "En cours"
    }
    
    tester.log_request("POST", f"{BASE_URL}/goals/", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/goals/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.created_ids['goal'] = result['id']
            tester.mark_success(f"Objectif crÃ©Ã© avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_goals_list():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/goals/learner/{learner_id}", "Lister les objectifs d'un apprenant")
    
    tester.log_request("GET", f"{BASE_URL}/goals/learner/{learner_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/goals/learner/{learner_id}", timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} objectifs")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS MISCONCEPTIONS
# =============================================================================

def test_misconceptions_create():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", "/misconceptions/", "CrÃ©er une erreur conceptuelle")
    
    data = {
        "learner_id": tester.created_ids['learner'],
        "type_erreur": "Confusion entre insuffisance cardiaque et infarctus",
        "frequence_apparition": 3,
        "resistance_correction": 2,
        "detected_at": datetime.now().isoformat()
    }
    
    tester.log_request("POST", f"{BASE_URL}/misconceptions/", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/misconceptions/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.created_ids['misconception'] = result['id']
            tester.mark_success(f"Erreur conceptuelle crÃ©Ã©e avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_misconceptions_list():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/misconceptions/learner/{learner_id}", 
                      "Lister les erreurs conceptuelles")
    
    tester.log_request("GET", f"{BASE_URL}/misconceptions/learner/{learner_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/misconceptions/learner/{learner_id}", timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} erreurs")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS PREFERENCES
# =============================================================================

def test_preferences_create():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", "/preferences/", "CrÃ©er une prÃ©fÃ©rence")
    
    data = {
        "learner_id": tester.created_ids['learner'],
        "cle": "theme",
        "valeur": "dark"
    }
    
    tester.log_request("POST", f"{BASE_URL}/preferences/", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/preferences/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.created_ids['preference'] = result['id']
            tester.mark_success(f"PrÃ©fÃ©rence crÃ©Ã©e avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_preferences_list():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/preferences/learner/{learner_id}", "Lister les prÃ©fÃ©rences")
    
    tester.log_request("GET", f"{BASE_URL}/preferences/learner/{learner_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/preferences/learner/{learner_id}", timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} prÃ©fÃ©rences")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS STRATEGIES
# =============================================================================

def test_strategies_create():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", "/strategies/", "CrÃ©er une stratÃ©gie d'apprentissage")
    
    data = {
        "learner_id": tester.created_ids['learner'],
        "strategy_name": "RÃ©pÃ©tition espacÃ©e",
        "frequency": 8,
        "effectiveness": 9
    }
    
    tester.log_request("POST", f"{BASE_URL}/strategies/", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/strategies/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.created_ids['strategy'] = result['id']
            tester.mark_success(f"StratÃ©gie crÃ©Ã©e avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_strategies_list():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/strategies/learner/{learner_id}", "Lister les stratÃ©gies")
    
    tester.log_request("GET", f"{BASE_URL}/strategies/learner/{learner_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/strategies/learner/{learner_id}", timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} stratÃ©gies")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS ACHIEVEMENTS
# =============================================================================

def test_achievements_create():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", "/achievements/", "CrÃ©er un achievement/badge")
    
    data = {
        "learner_id": tester.created_ids['learner'],
        "badge_id": "first_diagnosis",
        "date_obtention": datetime.now().isoformat()
    }
    
    tester.log_request("POST", f"{BASE_URL}/achievements/", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/achievements/", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.created_ids['achievement'] = result['id']
            tester.mark_success(f"Achievement crÃ©Ã© avec ID: {result['id']}")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_achievements_list():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("GET", f"/achievements/learner/{learner_id}", "Lister les achievements")
    
    tester.log_request("GET", f"{BASE_URL}/achievements/learner/{learner_id}")
    
    try:
        response = requests.get(f"{BASE_URL}/achievements/learner/{learner_id}", timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.mark_success(f"Liste rÃ©cupÃ©rÃ©e: {len(data)} achievements")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS AUTH
# =============================================================================

def test_auth_login():
    tester.test_header("POST", "/learner/auth/login", "Connexion d'un apprenant")
    
    # Utiliser un apprenant existant de la liste
    data = {
        "email": "marie.tchuente@univ-test.cm",
        "matricule": "MED-2025-0042"
    }
    
    tester.log_request("POST", f"{BASE_URL}/learner/auth/login", data=data)
    
    try:
        response = requests.post(f"{BASE_URL}/learner/auth/login", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            if 'access_token' in result:
                tester.created_ids['access_token'] = result['access_token']
                tester.mark_success("Connexion rÃ©ussie, token obtenu")
                return True
            else:
                tester.mark_failure("Pas de token dans la rÃ©ponse")
                return False
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_auth_me():
    if 'access_token' not in tester.created_ids:
        tester.write("âš ï¸  Pas de token, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("GET", "/learner/auth/me", "RÃ©cupÃ©rer profil utilisateur authentifiÃ©")
    
    headers = {"Authorization": f"Bearer {tester.created_ids['access_token']}"}
    tester.log_request("GET", f"{BASE_URL}/learner/auth/me")
    
    try:
        response = requests.get(f"{BASE_URL}/learner/auth/me", headers=headers, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Profil utilisateur rÃ©cupÃ©rÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TESTS LEARNER TRACE
# =============================================================================

def test_traces_get():
    tester.test_header("GET", "/learner/traces", "RÃ©cupÃ©rer les traces d'apprentissage")
    
    params = {"skip": 0, "limit": 10}
    tester.log_request("GET", f"{BASE_URL}/learner/traces", params=params)
    
    try:
        response = requests.get(f"{BASE_URL}/learner/traces", params=params, timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            if 'learners' in data:
                tester.mark_success(f"Traces rÃ©cupÃ©rÃ©es: {len(data['learners'])} apprenants")
                return True
            else:
                tester.mark_success("Traces rÃ©cupÃ©rÃ©es")
                return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

def test_traces_update():
    if 'learner' not in tester.created_ids:
        tester.write("âš ï¸  Aucun apprenant crÃ©Ã©, test ignorÃ©", Colors.YELLOW)
        return False
    
    learner_id = tester.created_ids['learner']
    tester.test_header("PATCH", f"/learner/traces/{learner_id}", "Mettre Ã  jour les traces")
    
    data = {
        "identification": {
            "matricule": f"TEST_{int(time.time())}",
            "nom": "Ã‰tudiant Test API Updated",
            "email": f"test_{int(time.time())}@example.com",
            "niveau_etudes": "M2",
            "specialite_visee": "MÃ©decine GÃ©nÃ©rale",
            "langue_preferee": "FranÃ§ais"
        },
        "cognitive_profile": {
            "vitesse_assimilation": 8,
            "capacite_memoire_travail": 7,
            "tendance_impulsivite": 2,
            "prefer_visual": True
        }
    }
    
    tester.log_request("PATCH", f"{BASE_URL}/learner/traces/{learner_id}", data=data)
    
    try:
        response = requests.patch(f"{BASE_URL}/learner/traces/{learner_id}", json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            tester.mark_success("Traces mises Ã  jour")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# NETTOYAGE
# =============================================================================

def cleanup_test_data():
    """Supprime les donnÃ©es de test crÃ©Ã©es"""
    tester.section("NETTOYAGE DES DONNÃ‰ES DE TEST")
    
    cleanup_order = [
        ('achievement', 'achievements', 'Achievement'),
        ('strategy', 'strategies', 'StratÃ©gie'),
        ('preference', 'preferences', 'PrÃ©fÃ©rence'),
        ('misconception', 'misconceptions', 'Erreur conceptuelle'),
        ('goal', 'goals', 'Objectif'),
        # Note: cognitive profile se supprime automatiquement avec learner
        # Note: affective states restent pour historique
    ]
    
    for key, endpoint, name in cleanup_order:
        if key in tester.created_ids:
            item_id = tester.created_ids[key]
            tester.write(f"\nğŸ—‘ï¸  Suppression {name} ID {item_id}...", Colors.YELLOW)
            
            try:
                response = requests.delete(f"{BASE_URL}/{endpoint}/{item_id}", timeout=30)
                if response.status_code == 200:
                    tester.write(f"âœ… {name} supprimÃ©", Colors.GREEN)
                else:
                    tester.write(f"âš ï¸  Erreur {response.status_code}", Colors.YELLOW)
            except Exception as e:
                tester.write(f"âŒ Exception: {str(e)}", Colors.RED)

# =============================================================================
# FONCTION PRINCIPALE
# =============================================================================

def main():
    global tester
    tester = APITester(OUTPUT_FILE)
    
    tester.section("TEST SYSTÃ‰MATIQUE COMPLET DE L'API APPRENANT STI")
    tester.write(f"URL: {BASE_URL}")
    tester.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    tester.write(f"Fichier de sortie: {OUTPUT_FILE}")
    
    print(f"\n{Colors.CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"â•‘  TEST AUTOMATIQUE API MODULE APPRENANT                        â•‘")
    print(f"â•‘  Chaque test s'exÃ©cutera et attendra votre validation        â•‘")
    print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.END}\n")
    
    try:
        # =====================================================================
        # MODULE 1: LEARNERS (3 tests)
        # =====================================================================
        tester.section("MODULE 1: LEARNERS - Gestion des apprenants")
        
        test_learners_create()
        tester.wait_for_user()
        
        test_learners_list()
        tester.wait_for_user()
        
        test_learners_read()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 2: COGNITIVE PROFILE (3 tests)
        # =====================================================================
        tester.section("MODULE 2: COGNITIVE PROFILE - Profil cognitif")
        
        test_cognitive_create()
        tester.wait_for_user()
        
        test_cognitive_read()
        tester.wait_for_user()
        
        test_cognitive_update()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 3: AFFECTIVE STATE (4 tests)
        # =====================================================================
        tester.section("MODULE 3: AFFECTIVE STATE - Ã‰tat affectif")
        
        test_affective_create()
        tester.wait_for_user()
        
        test_affective_read_session()
        tester.wait_for_user()
        
        test_affective_latest()
        tester.wait_for_user()
        
        test_affective_history()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 4: COMPETENCY MASTERY (3 tests)
        # =====================================================================
        tester.section("MODULE 4: COMPETENCY MASTERY - MaÃ®trise des compÃ©tences")
        
        test_mastery_create()
        tester.wait_for_user()
        
        test_mastery_list()
        tester.wait_for_user()
        
        test_mastery_read()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 5: GOALS (2 tests)
        # =====================================================================
        tester.section("MODULE 5: GOALS - Objectifs d'apprentissage")
        
        test_goals_create()
        tester.wait_for_user()
        
        test_goals_list()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 6: MISCONCEPTIONS (2 tests)
        # =====================================================================
        tester.section("MODULE 6: MISCONCEPTIONS - Erreurs conceptuelles")
        
        test_misconceptions_create()
        tester.wait_for_user()
        
        test_misconceptions_list()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 7: PREFERENCES (2 tests)
        # =====================================================================
        tester.section("MODULE 7: PREFERENCES - PrÃ©fÃ©rences utilisateur")
        
        test_preferences_create()
        tester.wait_for_user()
        
        test_preferences_list()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 8: STRATEGIES (2 tests)
        # =====================================================================
        tester.section("MODULE 8: STRATEGIES - StratÃ©gies d'apprentissage")
        
        test_strategies_create()
        tester.wait_for_user()
        
        test_strategies_list()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 9: ACHIEVEMENTS (2 tests)
        # =====================================================================
        tester.section("MODULE 9: ACHIEVEMENTS - Badges et rÃ©compenses")
        
        test_achievements_create()
        tester.wait_for_user()
        
        test_achievements_list()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 10: AUTH (2 tests)
        # =====================================================================
        tester.section("MODULE 10: AUTH - Authentification")
        
        test_auth_login()
        tester.wait_for_user()
        
        test_auth_me()
        tester.wait_for_user()
        
        # =====================================================================
        # MODULE 11: LEARNER TRACE (2 tests)
        # =====================================================================
        tester.section("MODULE 11: LEARNER TRACE - Traces d'apprentissage")
        
        test_traces_get()
        tester.wait_for_user()
        
        test_traces_update()
        tester.wait_for_user()
        
        # =====================================================================
        # RÃ‰SUMÃ‰ FINAL
        # =====================================================================
        tester.summary()
        
        # =====================================================================
        # NETTOYAGE OPTIONNEL
        # =====================================================================
        print(f"\n{Colors.YELLOW}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"â•‘  NETTOYAGE DES DONNÃ‰ES DE TEST                                â•‘")
        print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.END}\n")
        print(f"{Colors.YELLOW}Voulez-vous supprimer les donnÃ©es de test crÃ©Ã©es? (o/n): {Colors.END}", end='')
        
        if input().lower() == 'o':
            cleanup_test_data()
        else:
            tester.write("\nâš ï¸  DonnÃ©es de test conservÃ©es", Colors.YELLOW)
            tester.write("IDs conservÃ©s pour rÃ©fÃ©rence future:")
            for key, value in tester.created_ids.items():
                tester.write(f"   - {key}: {value}")
        
    except KeyboardInterrupt:
        tester.write("\n\nâš ï¸  Tests interrompus par l'utilisateur", Colors.YELLOW)
        tester.summary()
    except Exception as e:
        tester.write(f"\n\nâŒ ERREUR CRITIQUE: {str(e)}", Colors.RED)
        import traceback
        tester.write(traceback.format_exc())
        tester.summary()
    finally:
        tester.close()
        print(f"\n{Colors.GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"â•‘  TESTS TERMINÃ‰S                                               â•‘")
        print(f"â•‘  RÃ©sultats sauvegardÃ©s dans: {OUTPUT_FILE:31s} â•‘")
        print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.END}\n")


# =====================================================================
# POINT D'ENTRÃ‰E
# =====================================================================

if __name__ == "__main__":
    main()

=== Fichier: ./python_files_backup/app/main.py ===

from fastapi import FastAPI
from .api.v1 import symptoms,diseases,medications,media,clinical_cases,expert_strategies,diagnostic,chat

app = FastAPI(
    title="STI Medical Expert Module",
    description="Base de connaissances et moteur de raisonnement pour le STI mÃ©dical.",
    version="0.1.0"
)


app.include_router(symptoms.router, prefix="/api/v1")
app.include_router(diseases.router, prefix="/api/v1")
app.include_router(medications.router, prefix="/api/v1")
app.include_router(media.router, prefix="/api/v1")
app.include_router(clinical_cases.router, prefix="/api/v1")
app.include_router(expert_strategies.router, prefix="/api/v1")
app.include_router(diagnostic.router, prefix="/api/v1")

app.include_router(chat.router, prefix="/api/v1")


@app.get("/")
def read_root():
    """
    Endpoint racine pour vÃ©rifier que le service est en ligne.
    """
    return {"status": "Service is running"}

=== Fichier: ./python_files_backup/app/core/cognitive_diagnosis.py ===



=== Fichier: ./python_files_backup/app/core/prerequisite_graph.py ===



=== Fichier: ./python_files_backup/app/core/htn_planner.py ===



=== Fichier: ./python_files_backup/app/core/integrity_validator.py ===



=== Fichier: ./python_files_backup/app/core/__init__.py ===



=== Fichier: ./python_files_backup/app/core/q_matrix_solver.py ===



=== Fichier: ./python_files_backup/app/core/reasoning_engine.py ===

from typing import List, Dict, Any

def evaluate_condition(condition: Dict[str, Any], facts: Dict[str, Any]) -> bool:
    """
    Ã‰value une seule condition par rapport Ã  un ensemble de faits.
    Version trÃ¨s simple pour commencer.
    """
    fact_type = condition.get("fact")
    fact_value = condition.get("value")
    operator = condition.get("operator")

    if fact_type == "symptom" and operator == "present":
        return fact_value in facts.get("symptoms", [])
    
    if fact_type == "context" and operator == "is":
        return fact_value in facts.get("context", [])
    
    # Ajouter d'autres logiques d'Ã©valuation ici plus tard (ex: age > 65)
    
    return False


def forward_chaining_engine(rules: List[Dict[str, Any]], facts: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Moteur de raisonnement simple en chaÃ®nage avant.

    :param rules: Une liste de rÃ¨gles, oÃ¹ chaque rÃ¨gle est un dictionnaire
                  avec les clÃ©s 'conditions' et 'actions'.
    :param facts: Un dictionnaire reprÃ©sentant les faits connus sur le patient
                  (ex: {"symptoms": ["FiÃ¨vre", "Toux"], "context": ["zone_endemique"]}).
    :return: Une liste de toutes les actions des rÃ¨gles qui ont Ã©tÃ© dÃ©clenchÃ©es.
    """
    triggered_actions = []

    for rule in rules:
        conditions = rule.get("conditions", {})
        
        # Pour l'instant, nous ne gÃ©rons que l'opÃ©rateur "AND"
        if conditions.get("operator") == "AND":
            all_conditions_met = True
            for condition in conditions.get("rules", []):
                if not evaluate_condition(condition, facts):
                    all_conditions_met = False
                    break  # Inutile de vÃ©rifier les autres conditions de cette rÃ¨gle
            
            if all_conditions_met:
                # Toutes les conditions sont remplies, on ajoute les actions
                triggered_actions.extend(rule.get("actions", []))

    return triggered_actions

"""""
# Ajoutez ce bloc Ã  la fin du fichier pour tester
if __name__ == "__main__":
    # DÃ©finir une rÃ¨gle de test (copiÃ©e de notre exemple prÃ©cÃ©dent)
    test_rule = {
        "code_regle": "DIAG_PALU_SIMPLE_01",
        "conditions": {
            "operator": "AND",
            "rules": [
                {"fact": "symptom", "value": "FiÃ¨vre", "operator": "present"},
                {"fact": "context", "value": "zone_endemique", "operator": "is"}
            ]
        },
        "actions": [
            {"action": "add_hypothesis", "pathology": "Paludisme simple", "confidence": 0.7}
        ]
    }
    
    # DÃ©finir des faits qui devraient dÃ©clencher la rÃ¨gle
    patient_facts = {
        "symptoms": ["FiÃ¨vre", "Toux"],
        "context": ["zone_endemique"]
    }
    
    print("Test du moteur de raisonnement...")
    conclusions = forward_chaining_engine(rules=[test_rule], facts=patient_facts)
    
    print(f"Faits: {patient_facts}")
    print(f"RÃ¨gles: {[test_rule['code_regle']]}")
    print(f"Conclusions: {conclusions}")
    
    # VÃ©rification du test
    assert len(conclusions) == 1
    assert conclusions[0]['pathology'] == 'Paludisme simple'
    print("\nâœ… Test rÃ©ussi !")
    
    """

=== Fichier: ./python_files_backup/app/core/knowledge_graph.py ===



=== Fichier: ./python_files_backup/app/ml/embeddings.py ===



=== Fichier: ./python_files_backup/app/ml/__init__.py ===



=== Fichier: ./python_files_backup/app/ml/clustering.py ===



=== Fichier: ./python_files_backup/app/ml/recommendation.py ===



=== Fichier: ./python_files_backup/app/ml/similarity.py ===



=== Fichier: ./python_files_backup/app/schemas/symptom.py ===

from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from datetime import datetime

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class SymptomBase(BaseModel):
    """
    SchÃ©ma de base pour un symptÃ´me.
    Contient les champs communs Ã  la crÃ©ation et Ã  la lecture.
    """
    nom: str
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    type_symptome: Optional[str] = None
    description: Optional[str] = None
    questions_anamnese: Optional[Dict[str, Any]] = None
    signes_alarme: bool = False


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation (ce que l'API attend dans un POST)
# ==============================================================================
class SymptomCreate(SymptomBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau symptÃ´me via l'API.
    HÃ©rite de SymptomBase et n'ajoute aucun champ supplÃ©mentaire pour l'instant.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour (ce que l'API attend dans un PATCH)
# ==============================================================================
class SymptomUpdate(BaseModel):
    """
    SchÃ©ma utilisÃ© pour mettre Ã  jour un symptÃ´me existant.
    Tous les champs sont optionnels pour permettre des mises Ã  jour partielles.
    """
    nom: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    type_symptome: Optional[str] = None
    description: Optional[str] = None
    questions_anamnese: Optional[Dict[str, Any]] = None
    signes_alarme: Optional[bool] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class Symptom(SymptomBase):
    """
    SchÃ©ma complet pour reprÃ©senter un symptÃ´me, y compris les champs
    gÃ©nÃ©rÃ©s par la base de donnÃ©es comme 'id' et 'created_at'.
    Ce sera le modÃ¨le de rÃ©ponse de l'API.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        """
        Configuration pour Pydantic.
        'from_attributes = True' (anciennement 'orm_mode') permet au modÃ¨le Pydantic
        de lire les donnÃ©es directement depuis un objet SQLAlchemy.
        C'est le lien magique entre notre modÃ¨le de BDD et notre schÃ©ma d'API.
        """
        from_attributes = True

=== Fichier: ./python_files_backup/app/schemas/medication.py ===

from pydantic import BaseModel
from typing import Optional, Dict, Any
from datetime import datetime

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class MedicationBase(BaseModel):
    """
    SchÃ©ma de base pour un mÃ©dicament, contenant les champs modifiables.
    """
    dci: str
    nom_commercial: Optional[str] = None
    classe_therapeutique: Optional[str] = None
    forme_galenique: Optional[str] = None
    dosage: Optional[str] = None
    voie_administration: Optional[str] = None
    mecanisme_action: Optional[str] = None
    indications: Optional[Dict[str, Any]] = None
    contre_indications: Optional[Dict[str, Any]] = None
    effets_secondaires: Optional[Dict[str, Any]] = None
    interactions_medicamenteuses: Optional[Dict[str, Any]] = None
    precautions_emploi: Optional[str] = None
    posologie_standard: Optional[Dict[str, Any]] = None
    disponibilite_cameroun: Optional[str] = None
    cout_moyen_fcfa: Optional[int] = None
    statut_prescription: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation
# ==============================================================================
class MedicationCreate(MedicationBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau mÃ©dicament.
    'dci' est le seul champ strictement requis.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour
# ==============================================================================
class MedicationUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'un mÃ©dicament.
    """
    dci: Optional[str] = None
    nom_commercial: Optional[str] = None
    classe_therapeutique: Optional[str] = None
    # ... (tous les autres champs de MedicationBase en optionnel)
    forme_galenique: Optional[str] = None
    dosage: Optional[str] = None
    voie_administration: Optional[str] = None
    mecanisme_action: Optional[str] = None
    indications: Optional[Dict[str, Any]] = None
    contre_indications: Optional[Dict[str, Any]] = None
    effets_secondaires: Optional[Dict[str, Any]] = None
    interactions_medicamenteuses: Optional[Dict[str, Any]] = None
    precautions_emploi: Optional[str] = None
    posologie_standard: Optional[Dict[str, Any]] = None
    disponibilite_cameroun: Optional[str] = None
    cout_moyen_fcfa: Optional[int] = None
    statut_prescription: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (RÃ©ponse API)
# ==============================================================================
class Medication(MedicationBase):
    """
    SchÃ©ma complet pour reprÃ©senter un mÃ©dicament en rÃ©ponse d'API.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

=== Fichier: ./python_files_backup/app/schemas/clinical_case.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date
from decimal import Decimal

# Importer les autres schÃ©mas pour les rÃ©ponses imbriquÃ©es
from .disease import Disease
from .media import ImageMedicale
from .symptom import Symptom






# --- NOUVEAUX SOUS-SCHÃ‰MAS ---
class SymptomInCase(BaseModel):
    symptome_id: int
    details: str # Ex: "FiÃ¨vre Ã©levÃ©e (40Â°C) apparue brutalement il y a 48h"

class PresentationClinique(BaseModel):
    histoire_maladie: str
    symptomes_patient: List[SymptomInCase]
    antecedents: Optional[Dict[str, Any]] = None
# ==============================================================================
# SchÃ©ma de Base et de CrÃ©ation
# ==============================================================================
class ClinicalCaseBase(BaseModel):
    """
    SchÃ©ma de base pour un cas clinique, contenant les champs Ã©ditables.
    """
    code_fultang: str = Field(..., description="Identifiant unique (Fultang ou synthÃ©tique)")
    pathologie_principale_id: Optional[int] = None
    pathologies_secondaires_ids: Optional[List[int]] = []
    presentation_clinique: PresentationClinique
    donnees_paracliniques: Optional[Dict[str, Any]] = None
    evolution_patient: Optional[str] = None
    images_associees_ids: Optional[List[int]] = []
    sons_associes_ids: Optional[List[int]] = []
    medicaments_prescrits: Optional[List[Dict[str, Any]]] = []
    niveau_difficulte: int = Field(default=3, ge=1, le=101)
    duree_estimee_resolution_min: Optional[int] = None
    objectifs_apprentissage: Optional[List[str]] = []
    competences_requises: Optional[Dict[str, Any]] = {}


class ClinicalCaseCreate(ClinicalCaseBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau cas clinique via l'API.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour
# ==============================================================================
class ClinicalCaseUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'un cas clinique.
    """
    code_fultang: Optional[str] = None
    pathologie_principale_id: Optional[int] = None
    presentation_clinique: Optional[Dict[str, Any]] = None
    donnees_paracliniques: Optional[Dict[str, Any]] = None
    evolution_patient: Optional[str] = None
    images_associees_ids: Optional[List[int]] = None
    sons_associes_ids: Optional[List[int]] = None
    medicaments_prescrits: Optional[List[Dict[str, Any]]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=101)
    duree_estimee_resolution_min: Optional[int] = None
    objectifs_apprentissage: Optional[List[str]] = None
    competences_requises: Optional[Dict[str, Any]] = None
    valide_expert: Optional[bool] = None
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# SchÃ©mas pour la Lecture (RÃ©ponse API)
# ==============================================================================
class ClinicalCaseSimple(BaseModel):
    """
    SchÃ©ma simplifiÃ© pour les listes de cas cliniques.
    """
    id: int
    code_fultang: str
    niveau_difficulte: int
    pathologie_principale: Optional[Disease] = None # Affiche l'objet maladie complet
    nb_images: int
    nb_sons: int

    class Config:
        from_attributes = True


# --- NOUVEAU SCHÃ‰MA DE LECTURE ENRICHI ---
class SymptomDetailInCase(BaseModel):
    symptome: Symptom # L'objet symptÃ´me complet
    details: str # Les dÃ©tails spÃ©cifiques au cas

class PresentationCliniqueDetail(BaseModel):
    histoire_maladie: str
    symptomes_patient: List[SymptomDetailInCase]
    antecedents: Optional[Dict[str, Any]] = None


class ClinicalCase(ClinicalCaseBase):
    id: int
    created_at: datetime
    updated_at: datetime
    
    pathologie_principale: Optional[Disease] = None
    pathologies_secondaires: List[Disease] = [] # <- AJOUTER
    images_associees: List[ImageMedicale] = []
    
    # --- ENRICHISSEMENT DE LA PRÃ‰SENTATION CLINIQUE ---
    presentation_clinique_detail: Optional[PresentationCliniqueDetail] = None

    class Config:
        from_attributes = True



=== Fichier: ./python_files_backup/app/schemas/relations.py ===

from pydantic import BaseModel, Field
from typing import Any, Dict, Optional
from decimal import Decimal

# Importer les schÃ©mas de base pour l'affichage
from .symptom import Symptom
from .disease import Disease
from .medication import Medication


# ==============================================================================
# SchÃ©ma de Base et de CrÃ©ation pour l'Association
# ==============================================================================
class PathologieSymptomeBase(BaseModel):
    """
    SchÃ©ma de base pour l'association Pathologie-SymptÃ´me.
    Contient les champs nÃ©cessaires pour crÃ©er ou mettre Ã  jour le lien.
    """
    pathologie_id: int
    symptome_id: int
    probabilite: Optional[Decimal] = Field(None, ge=0, le=1)
    sensibilite: Optional[Decimal] = Field(None, ge=0, le=1)
    specificite: Optional[Decimal] = Field(None, ge=0, le=1)
    phase_maladie: Optional[str] = None
    frequence: Optional[str] = None
    est_pathognomonique: bool = False
    importance_diagnostique: Optional[int] = Field(None, ge=1, le=5)

class PathologieSymptomeCreate(PathologieSymptomeBase):
    """
    SchÃ©ma utilisÃ© spÃ©cifiquement pour crÃ©er une nouvelle association.
    """
    pass


# ==============================================================================
# SchÃ©mas pour la Lecture (RÃ©ponse de l'API)
# ==============================================================================
class PathologieSymptome(PathologieSymptomeBase):
    """
    SchÃ©ma complet pour la rÃ©ponse de l'API, incluant l'ID de l'association.
    """
    id: int

    class Config:
        from_attributes = True


class SymptomForDiseaseDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'un symptÃ´me DANS le contexte d'une pathologie.
    """
    symptome: Symptom
    probabilite: Optional[Decimal]
    importance_diagnostique: Optional[int]
    est_pathognomonique: bool

    class Config:
        from_attributes = True


class DiseaseForSymptomDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'une pathologie DANS le contexte d'un symptÃ´me
    (utile pour le diagnostic diffÃ©rentiel).
    """
    pathologie: Disease
    probabilite: Optional[Decimal]
    importance_diagnostique: Optional[int]

    class Config:
        from_attributes = True



# Contenu Ã  AJOUTER Ã  la fin de app/schemas/relations.py

# Importer le schÃ©ma de base pour l'affichage


# ==============================================================================
# SchÃ©mas pour l'Association Traitement-Pathologie
# ==============================================================================
class TraitementPathologieBase(BaseModel):
    pathologie_id: int
    medicament_id: int
    type_traitement: Optional[str] = None
    ligne_traitement: Optional[int] = None
    indication_precise: Optional[str] = None
    efficacite_taux: Optional[Decimal] = Field(None, ge=0, le=100)
    duree_traitement_jours: Optional[int] = None
    posologie_detaillee: Optional[Dict[str, Any]] = None
    niveau_preuve: Optional[str] = None
    guidelines_source: Optional[str] = None
    rang_preference: Optional[int] = 99

class TraitementPathologieCreate(TraitementPathologieBase):
    pass

class TraitementPathologie(TraitementPathologieBase):
    id: int
    class Config:
        from_attributes = True

class MedicationForDiseaseDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'un mÃ©dicament DANS le contexte d'une pathologie.
    """
    medicament: Medication
    type_traitement: Optional[str]
    ligne_traitement: Optional[int]
    rang_preference: Optional[int]
    
    class Config:
        from_attributes = True

# ==============================================================================
# SchÃ©mas pour l'Association Traitement-SymptÃ´me
# ==============================================================================
class TraitementSymptomeBase(BaseModel):
    symptome_id: int
    medicament_id: int
    efficacite: Optional[str] = None
    rapidite_action: Optional[str] = None
    posologie_recommandee: Optional[str] = None
    rang_preference: Optional[int] = 99

class TraitementSymptomeCreate(TraitementSymptomeBase):
    pass

class TraitementSymptome(TraitementSymptomeBase):
    id: int
    class Config:
        from_attributes = True

class MedicationForSymptomDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'un mÃ©dicament DANS le contexte d'un symptÃ´me.
    """
    medicament: Medication
    efficacite: Optional[str]
    rang_preference: Optional[int]

    class Config:
        from_attributes = True

=== Fichier: ./python_files_backup/app/schemas/tracking_models.py ===



=== Fichier: ./python_files_backup/app/schemas/__init__.py ===

from .symptom import SymptomCreate,SymptomBase,SymptomUpdate, Symptom
from .disease import DiseaseCreate,DiseaseBase,DiseaseUpdate, Disease
from . import relations
from .medication import MedicationCreate,MedicationBase,MedicationUpdate, Medication
from .media import ImageMedicaleBase,ImageMedicaleUpdate, ImageMedicale
from .clinical_case import ClinicalCaseCreate,ClinicalCaseBase,ClinicalCaseUpdate, ClinicalCase
from .expert_strategy import ExpertStrategyCreate,ExpertStrategyBase,ExpertStrategyUpdate, ExpertStrategy

=== Fichier: ./python_files_backup/app/schemas/expert_strategy.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date
from decimal import Decimal

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class ExpertStrategyBase(BaseModel):
    """
    SchÃ©ma de base pour une rÃ¨gle/stratÃ©gie experte.
    """
    code_regle: str = Field(..., max_length=50)
    categorie: str
    priorite: int = Field(default=5, ge=1, le=10)
    conditions: Dict[str, Any]
    actions: List[Dict[str, Any]]
    description_naturelle: Optional[str] = None
    justification_medicale: Optional[str] = None
    expert_auteur: Optional[str] = None
    date_validation: Optional[date] = None
    est_active: bool = True


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation
# ==============================================================================
class ExpertStrategyCreate(ExpertStrategyBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er une nouvelle rÃ¨gle.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour
# ==============================================================================
class ExpertStrategyUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'une rÃ¨gle.
    """
    code_regle: Optional[str] = Field(None, max_length=50)
    categorie: Optional[str] = None
    priorite: Optional[int] = Field(None, ge=1, le=10)
    conditions: Optional[Dict[str, Any]] = None
    actions: Optional[List[Dict[str, Any]]] = None
    description_naturelle: Optional[str] = None
    justification_medicale: Optional[str] = None
    expert_auteur: Optional[str] = None
    date_validation: Optional[date] = None
    est_active: Optional[bool] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (RÃ©ponse API)
# ==============================================================================
class ExpertStrategy(ExpertStrategyBase):
    """
    SchÃ©ma complet pour reprÃ©senter une rÃ¨gle en rÃ©ponse d'API.
    """
    id: int
    nb_activations: int
    taux_succes: Optional[Decimal] = None
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

=== Fichier: ./python_files_backup/app/schemas/response.py ===



=== Fichier: ./python_files_backup/app/schemas/media.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date

# ==============================================================================
# SchÃ©ma de Base pour les MÃ©tadonnÃ©es d'une Image
# ==============================================================================
class ImageMedicaleBase(BaseModel):
    """
    SchÃ©ma de base contenant les mÃ©tadonnÃ©es modifiables d'une image mÃ©dicale.
    """
    type_examen: str
    sous_type: Optional[str] = None
    pathologie_id: Optional[int] = None
    description: Optional[str] = None
    signes_radiologiques: Optional[Dict[str, Any]] = None
    annotations: Optional[List[Dict[str, Any]]] = None
    interpretation_experte: Optional[str] = None
    diagnostic_differentiel: Optional[List[str]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=5)
    qualite_image: Optional[int] = Field(None, ge=1, le=5)
    valide_expert: Optional[bool] = False
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour des MÃ©tadonnÃ©es
# ==============================================================================
class ImageMedicaleUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle des mÃ©tadonnÃ©es d'une image.
    Tous les champs sont optionnels.
    """
    type_examen: Optional[str] = None
    sous_type: Optional[str] = None
    pathologie_id: Optional[int] = None
    description: Optional[str] = None
    signes_radiologiques: Optional[Dict[str, Any]] = None
    annotations: Optional[List[Dict[str, Any]]] = None
    interpretation_experte: Optional[str] = None
    diagnostic_differentiel: Optional[List[str]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=5)
    qualite_image: Optional[int] = Field(None, ge=1, le=5)
    valide_expert: Optional[bool] = None
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (RÃ©ponse API)
# ==============================================================================
class ImageMedicale(ImageMedicaleBase):
    """
    SchÃ©ma complet pour reprÃ©senter les mÃ©tadonnÃ©es d'une image en rÃ©ponse d'API.
    """
    id: int
    fichier_url: str
    fichier_miniature_url: Optional[str] = None
    format_image: Optional[str] = None
    taille_ko: Optional[int] = None
    resolution: Optional[str] = None
    created_at: datetime

    class Config:
        from_attributes = True

# Nous ajouterons les schÃ©mas pour SonMedical ici plus tard.

=== Fichier: ./python_files_backup/app/schemas/disease.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime
from decimal import Decimal

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class DiseaseBase(BaseModel):
    """
    SchÃ©ma de base pour une pathologie, contenant les champs modifiables.
    """
    nom_fr: str
    code_icd10: str
    nom_en: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    prevalence_cameroun: Optional[Decimal] = Field(None, ge=0, le=100)
    niveau_gravite: Optional[int] = Field(None, ge=1, le=5)
    description: Optional[str] = None
    physiopathologie: Optional[str] = None
    evolution_naturelle: Optional[str] = None
    complications: Optional[Dict[str, Any]] = None
    facteurs_risque: Optional[Dict[str, Any]] = None
    prevention: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation (ce que l'API attend dans un POST)
# ==============================================================================
class DiseaseCreate(DiseaseBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er une nouvelle pathologie.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour (ce que l'API attend dans un PATCH)
# ==============================================================================
class DiseaseUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'une pathologie.
    Tous les champs sont optionnels.
    """
    nom_fr: Optional[str] = None
    code_icd10: Optional[str] = None
    nom_en: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    prevalence_cameroun: Optional[Decimal] = Field(None, ge=0, le=100)
    niveau_gravite: Optional[int] = Field(None, ge=1, le=5)
    description: Optional[str] = None
    physiopathologie: Optional[str] = None
    evolution_naturelle: Optional[str] = None
    complications: Optional[Dict[str, Any]] = None
    facteurs_risque: Optional[Dict[str, Any]] = None
    prevention: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class Disease(DiseaseBase):
    """
    SchÃ©ma complet pour reprÃ©senter une pathologie en rÃ©ponse d'API.
    Inclut les champs non modifiables comme 'id' et les horodatages.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        """
        Permet la conversion automatique depuis un objet SQLAlchemy.
        """
        from_attributes = True

=== Fichier: ./python_files_backup/app/schemas/diagnostic.py ===



=== Fichier: ./python_files_backup/app/schemas/chat_message.py ===

from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
from datetime import datetime
from uuid import UUID

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class ChatMessageBase(BaseModel):
    """
    SchÃ©ma de base pour un message de chat.
    Contient les champs communs.
    """
    sender: str = Field(..., description="Qui envoie le message (ex: 'student', 'patient_llm', 'tutor_system')")
    content: str = Field(..., description="Le contenu textuel du message.")


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation (ce que le Frontend envoie)
# ==============================================================================
class ChatMessageCreate(ChatMessageBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau message de chat via l'API.
    La session_id sera fournie dans l'URL, pas dans le corps.
    """
    message_metadata: Optional[Dict[str, Any]] = Field(None, description="MÃ©tadonnÃ©es optionnelles (ex: intention dÃ©tectÃ©e)")


# ==============================================================================
# SchÃ©ma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class ChatMessage(ChatMessageBase):
    """
    SchÃ©ma complet pour reprÃ©senter un message de chat en rÃ©ponse d'API.
    """
    id: int
    session_id: UUID
    timestamp: datetime
    message_metadata: Optional[Dict[str, Any]] = None

    class Config:
        """
        Permet la conversion automatique depuis un objet SQLAlchemy.
        """
        from_attributes = True

=== Fichier: ./python_files_backup/app/schemas/base.py ===



=== Fichier: ./python_files_backup/app/schemas/request.py ===



=== Fichier: ./python_files_backup/app/api/v1/chat.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List
from uuid import UUID

from ... import schemas, models  # Import global des packages
from ...services import chat_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/chat",
    tags=["Chat"]
)

@router.post("/sessions/{session_id}/messages", response_model=schemas.chat_message.ChatMessage, status_code=status.HTTP_201_CREATED)
def post_chat_message(
    session_id: UUID,
    message_data: schemas.chat_message.ChatMessageCreate,
    db: Session = Depends(get_db)
):
    """Poste un nouveau message dans le chat d'une session de simulation."""
    try:
        return chat_service.create_chat_message(db=db, session_id=session_id, message=message_data)
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))

@router.get("/sessions/{session_id}/messages", response_model=List[schemas.chat_message.ChatMessage])
def get_chat_history(session_id: UUID, db: Session = Depends(get_db)):
    """RÃ©cupÃ¨re l'historique complet des messages pour une session."""
    session = db.query(models.SimulationSession).filter(models.SimulationSession.id == session_id).first()
    if not session:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"La session avec l'ID {session_id} n'a pas Ã©tÃ© trouvÃ©e.")
        
    messages = chat_service.get_messages_by_session(db=db, session_id=session_id)
    return messages

=== Fichier: ./python_files_backup/app/api/v1/__init__.py ===



=== Fichier: ./python_files_backup/app/api/v1/q_matrix.py ===



=== Fichier: ./python_files_backup/app/api/v1/fultang.py ===



=== Fichier: ./python_files_backup/app/api/v1/media.py ===

from fastapi import (
    APIRouter,
    Depends,
    HTTPException,
    status,
    UploadFile,
    File,
    Form
)
from sqlalchemy.orm import Session
from typing import List, Optional

from ... import schemas, models
from ...services import media_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/media",
    tags=["Media"]
)


@router.post("/images/upload", response_model=schemas.media.ImageMedicale, status_code=status.HTTP_201_CREATED)
async def upload_image_medicale(
    file: UploadFile = File(..., description="Le fichier image Ã  uploader"),
    type_examen: str = Form(..., description="Type d'examen (ex: Radiographie)"),
    sous_type: Optional[str] = Form(None, description="Sous-type (ex: Thorax)"),
    pathologie_id: Optional[int] = Form(None, description="ID de la pathologie associÃ©e"),
    description: Optional[str] = Form(None, description="Description de l'image"),
    db: Session = Depends(get_db)
):
    """
    Uploade une image mÃ©dicale et crÃ©e l'enregistrement de ses mÃ©tadonnÃ©es.
    """
    # VÃ©rifier le type de fichier si nÃ©cessaire
    if not file.content_type.startswith("image/"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Le fichier uploadÃ© n'est pas une image."
        )

    db_image = await media_service.create_image_medicale(
        db=db,
        file=file,
        type_examen=type_examen,
        sous_type=sous_type,
        pathologie_id=pathologie_id,
        description=description
    )
    return db_image


@router.get("/images", response_model=List[schemas.media.ImageMedicale])
def read_all_images_metadata(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste des mÃ©tadonnÃ©es de toutes les images mÃ©dicales.
    """
    images = media_service.get_all_images_medicales(db, skip=skip, limit=limit)
    return images


@router.get("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def read_image_metadata(image_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re les mÃ©tadonnÃ©es d'une image mÃ©dicale spÃ©cifique par son ID.
    """
    db_image = media_service.get_image_medicale_by_id(db, image_id=image_id)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvÃ©e.")
    return db_image


@router.patch("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def update_image_metadata(
    image_id: int,
    metadata_update: schemas.media.ImageMedicaleUpdate,
    db: Session = Depends(get_db)
):
    """
    Met Ã  jour les mÃ©tadonnÃ©es d'une image mÃ©dicale existante.
    """
    db_image = media_service.update_image_medicale_metadata(db, image_id=image_id, image_update=metadata_update)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvÃ©e.")
    return db_image


@router.delete("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def delete_image(image_id: int, db: Session = Depends(get_db)):
    """
    Supprime une image mÃ©dicale (mÃ©tadonnÃ©es et fichier physique).
    """
    db_image = media_service.delete_image_medicale(db, image_id=image_id)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvÃ©e.")
    return db_image

=== Fichier: ./python_files_backup/app/api/v1/expert_strategies.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import expert_strategy_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/expert-strategies",
    tags=["Expert Strategies"]
)


@router.post("/", response_model=schemas.expert_strategy.ExpertStrategy, status_code=status.HTTP_201_CREATED)
def create_expert_strategy(strategy_data: schemas.expert_strategy.ExpertStrategyCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e une nouvelle rÃ¨gle/stratÃ©gie experte.
    """
    db_strategy = expert_strategy_service.get_strategy_by_code(db, code=strategy_data.code_regle)
    if db_strategy:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Une rÃ¨gle avec le code '{strategy_data.code_regle}' existe dÃ©jÃ ."
        )
    return expert_strategy_service.create_strategy(db=db, strategy=strategy_data)


@router.get("/", response_model=List[schemas.expert_strategy.ExpertStrategy])
def read_all_expert_strategies(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de toutes les rÃ¨gles expertes.
    """
    strategies = expert_strategy_service.get_all_strategies(db, skip=skip, limit=limit)
    return strategies


@router.get("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def read_expert_strategy(strategy_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une rÃ¨gle experte par son ID.
    """
    db_strategy = expert_strategy_service.get_strategy_by_id(db, strategy_id=strategy_id)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="RÃ¨gle non trouvÃ©e.")
    return db_strategy


@router.patch("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def update_expert_strategy(strategy_id: int, strategy_data: schemas.expert_strategy.ExpertStrategyUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour une rÃ¨gle experte.
    """
    db_strategy = expert_strategy_service.update_strategy(db, strategy_id=strategy_id, strategy_update=strategy_data)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="RÃ¨gle non trouvÃ©e.")
    return db_strategy


@router.delete("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def delete_expert_strategy(strategy_id: int, db: Session = Depends(get_db)):
    """
    Supprime une rÃ¨gle experte.
    """
    db_strategy = expert_strategy_service.delete_strategy(db, strategy_id=strategy_id)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="RÃ¨gle non trouvÃ©e.")
    return db_strategy

=== Fichier: ./python_files_backup/app/api/v1/learning_paths.py ===



=== Fichier: ./python_files_backup/app/api/v1/diseases.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import disease_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/diseases",
    tags=["Diseases"]
)


@router.post("/", response_model=schemas.disease.Disease, status_code=status.HTTP_201_CREATED)
def create_disease(disease_data: schemas.disease.DiseaseCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e une nouvelle pathologie.
    VÃ©rifie l'unicitÃ© du code CIM-10.
    """
    db_disease = disease_service.get_disease_by_icd10(db, icd10_code=disease_data.code_icd10)
    if db_disease:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Une pathologie avec le code CIM-10 '{disease_data.code_icd10}' existe dÃ©jÃ ."
        )
    return disease_service.create_disease(db=db, disease=disease_data)


@router.get("/", response_model=List[schemas.disease.Disease])
def read_diseases(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de pathologies.
    """
    diseases = disease_service.get_all_diseases(db, skip=skip, limit=limit)
    return diseases


@router.get("/{disease_id}", response_model=schemas.disease.Disease)
def read_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une pathologie par son ID.
    """
    db_disease = disease_service.get_disease_by_id(db, disease_id=disease_id)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvÃ©e.")
    return db_disease


@router.patch("/{disease_id}", response_model=schemas.disease.Disease)
def update_disease(disease_id: int, disease_data: schemas.disease.DiseaseUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour une pathologie.
    """
    db_disease = disease_service.update_disease(db, disease_id=disease_id, disease_update=disease_data)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvÃ©e.")
    return db_disease


@router.delete("/{disease_id}", response_model=schemas.disease.Disease)
def delete_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    Supprime une pathologie.
    """
    db_disease = disease_service.delete_disease(db, disease_id=disease_id)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvÃ©e.")
    return db_disease

# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/diseases.py

@router.post(
    "/{disease_id}/symptoms",
    response_model=schemas.relations.PathologieSymptome,
    status_code=status.HTTP_201_CREATED,
    tags=["Disease-Symptom Relations"] # Un nouveau tag pour l'organisation
)
def add_symptom_to_disease(
    disease_id: int, 
    association_data: schemas.relations.PathologieSymptomeCreate, 
    db: Session = Depends(get_db)
):
    """
    Associe un symptÃ´me Ã  une pathologie avec des attributs de relation
    (probabilitÃ©, importance, etc.).
    """
    # Assurer la cohÃ©rence des IDs
    if disease_id != association_data.pathologie_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="L'ID de la pathologie dans l'URL ne correspond pas Ã  celui dans le corps de la requÃªte."
        )
    
    try:
        return disease_service.add_symptom_to_disease(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))


@router.get(
    "/{disease_id}/symptoms",
    response_model=List[schemas.relations.SymptomForDiseaseDetail],
    tags=["Disease-Symptom Relations"]
)
def get_symptoms_for_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste de tous les symptÃ´mes associÃ©s Ã  une pathologie,
    avec les dÃ©tails de la relation et les dÃ©tails du symptÃ´me lui-mÃªme.
    """
    associations = disease_service.get_symptoms_for_disease(db, disease_id=disease_id)
    if not associations:
        # Ce n'est pas une erreur, la maladie peut simplement n'avoir aucun symptÃ´me associÃ© pour l'instant
        return []
    
    # Transformer les donnÃ©es pour correspondre au schÃ©ma de rÃ©ponse attendu
    response = []
    for assoc in associations:
        response.append({
            "symptome": assoc.symptome, # L'objet Symptom complet
            "probabilite": assoc.probabilite,
            "importance_diagnostique": assoc.importance_diagnostique,
            "est_pathognomonique": assoc.est_pathognomonique
        })
    return response


# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/diseases.py

@router.post(
    "/{disease_id}/treatments",
    response_model=schemas.relations.TraitementPathologie,
    status_code=status.HTTP_201_CREATED,
    tags=["Therapeutic Relations"]
)
def add_treatment_to_disease(
    disease_id: int, 
    association_data: schemas.relations.TraitementPathologieCreate, 
    db: Session = Depends(get_db)
):
    """
    Associe un mÃ©dicament Ã  une pathologie en tant que traitement.
    """
    if disease_id != association_data.pathologie_id:
        raise HTTPException(status_code=400, detail="IncohÃ©rence des IDs de pathologie.")
    
    try:
        return disease_service.add_treatment_to_disease(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get(
    "/{disease_id}/treatments",
    response_model=List[schemas.relations.MedicationForDiseaseDetail],
    tags=["Therapeutic Relations"]
)
def get_treatments_for_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste des traitements recommandÃ©s pour une pathologie.
    """
    associations = disease_service.get_treatments_for_disease(db, disease_id=disease_id)
    return [
        {
            "medicament": assoc.medicament,
            "type_traitement": assoc.type_traitement,
            "ligne_traitement": assoc.ligne_traitement,
            "rang_preference": assoc.rang_preference,
        }
        for assoc in associations
    ]

=== Fichier: ./python_files_backup/app/api/v1/diagnostic.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List, Dict, Any

from ...services import diagnostic_engine
from ...dependencies import get_db

router = APIRouter(
    prefix="/diagnostic-engine",
    tags=["Diagnostic Engine"]
)


@router.post("/run", response_model=List[Dict[str, Any]])
def run_diagnostic_engine(
    patient_facts: diagnostic_engine.DiagnosticInput,
    db: Session = Depends(get_db)
):
    """
    ExÃ©cute le moteur de raisonnement sur un ensemble de faits patient.

    Prend en entrÃ©e une liste de symptÃ´mes et de contextes, et retourne
    une liste d'actions/conclusions basÃ©es sur les rÃ¨gles expertes actives
    dans le systÃ¨me.
    """
    if not patient_facts.symptoms:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="La liste des symptÃ´mes ne peut pas Ãªtre vide."
        )

    conclusions = diagnostic_engine.run_diagnostic(db=db, patient_facts=patient_facts)
    
    return conclusions

=== Fichier: ./python_files_backup/app/api/v1/clinical_cases.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import clinical_case_service, media_service, symptom_service, disease_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/clinical-cases",
    tags=["Clinical Cases"]
)


@router.post("/", response_model=schemas.clinical_case.ClinicalCase, status_code=status.HTTP_201_CREATED)
def create_clinical_case(case_data: schemas.clinical_case.ClinicalCaseCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e un nouveau cas clinique.
    """
    db_case_by_code = clinical_case_service.get_case_by_code(db, code=case_data.code_fultang)
    if db_case_by_code:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Un cas avec le code '{case_data.code_fultang}' existe dÃ©jÃ ."
        )
    try:
        # Le service create_case retournera un objet SQLAlchemy
        db_case = clinical_case_service.create_case(db=db, case=case_data)
        # La conversion vers le schÃ©ma Pydantic se fait automatiquement par FastAPI
        return db_case
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))


@router.get("/", response_model=List[schemas.clinical_case.ClinicalCaseSimple])
def read_all_clinical_cases(skip: int = 0, limit: int = 25, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste simplifiÃ©e de cas cliniques.
    """
    cases = clinical_case_service.get_all_cases(db, skip=skip, limit=limit)
    
    # La conversion vers le schÃ©ma Pydantic gÃ¨re automatiquement la construction de la rÃ©ponse
    # en utilisant les relations SQLAlchemy et les configurations 'from_attributes'.
    # Cependant, pour des champs calculÃ©s comme 'nb_images', nous devons construire la rÃ©ponse manuellement.
    response = []
    for case in cases:
        case_simple = schemas.clinical_case.ClinicalCaseSimple(
            id=case.id,
            code_fultang=case.code_fultang,
            niveau_difficulte=case.niveau_difficulte,
            pathologie_principale=case.pathologie_principale,
            nb_images=len(case.images_associees_ids) if case.images_associees_ids else 0,
            nb_sons=len(case.sons_associes_ids) if case.sons_associes_ids else 0,
        )
        response.append(case_simple)
    return response


@router.get("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def read_clinical_case(case_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un cas clinique complet par son ID, avec tous les objets liÃ©s.
    """
    # 1. RÃ©cupÃ©rer le cas brut
    db_case = clinical_case_service.get_case_by_id(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=404, detail="Cas clinique non trouvÃ©.")
    
    # 2. Convertir en dictionnaire pour pouvoir injecter les champs enrichis
    case_dict = db_case.__dict__

    # 3. Enrichir : Pathologies Secondaires
    pathologies_secondaires = []
    if db_case.pathologies_secondaires_ids:
        for p_id in db_case.pathologies_secondaires_ids:
            p_obj = disease_service.get_disease_by_id(db, disease_id=p_id)
            if p_obj:
                pathologies_secondaires.append(p_obj)
    case_dict['pathologies_secondaires'] = pathologies_secondaires

    # 4. Enrichir : Images
    images = []
    if db_case.images_associees_ids:
        for img_id in db_case.images_associees_ids:
            img = media_service.get_image_medicale_by_id(db, image_id=img_id)
            if img:
                images.append(img)
    case_dict['images_associees'] = images

    # 5. Enrichir : PrÃ©sentation Clinique DÃ©taillÃ©e
    # Le champ 'presentation_clinique' en base contient juste des IDs.
    # Nous devons aller chercher les objets SymptÃ´mes complets.
    symptomes_details_in_case = []
    presentation_dict = db_case.presentation_clinique or {}
    
    if 'symptomes_patient' in presentation_dict:
        for item in presentation_dict['symptomes_patient']:
            # item ressemble Ã  {'symptome_id': 1, 'details': 'FiÃ¨vre forte'}
            sympt_id = item.get('symptome_id')
            sympt_obj = symptom_service.get_symptom_by_id(db, symptom_id=sympt_id)
            
            if sympt_obj:
                symptomes_details_in_case.append({
                    "symptome": sympt_obj, # L'objet complet
                    "details": item.get('details', '')
                })
    
    case_dict['presentation_clinique_detail'] = {
        "histoire_maladie": presentation_dict.get('histoire_maladie', ''),
        "symptomes_patient": symptomes_details_in_case,
        "antecedents": presentation_dict.get('antecedents')
    }

    # 6. Validation et Retour
    # On passe le dictionnaire enrichi Ã  Pydantic pour qu'il le valide et le formate
    return schemas.clinical_case.ClinicalCase.model_validate(case_dict)

@router.patch("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def update_clinical_case(case_id: int, case_data: schemas.clinical_case.ClinicalCaseUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour un cas clinique.
    """
    db_case = clinical_case_service.update_case(db, case_id=case_id, case_update=case_data)
    if db_case is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Cas clinique non trouvÃ©.")
    # La conversion vers le schÃ©ma de rÃ©ponse se fait automatiquement
    return db_case


@router.delete("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def delete_clinical_case(case_id: int, db: Session = Depends(get_db)):
    """
    Supprime un cas clinique.
    """
    db_case = clinical_case_service.delete_case(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Cas clinique non trouvÃ©.")
    # La conversion vers le schÃ©ma de rÃ©ponse se fait automatiquement
    return db_case



@router.get("/{case_id}/simple", response_model=schemas.clinical_case.ClinicalCaseSimple)
def read_clinical_case_simple(case_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un cas clinique dans une structure simplifiÃ©e avec la pathologie principale complÃ¨te.
    Retourne exactement la mÃªme structure que ClinicalCaseSimple mais avec l'objet pathologie_principale complet.
    """
    # RÃ©cupÃ©rer le cas
    db_case = clinical_case_service.get_case_by_id(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=404, detail="Cas clinique non trouvÃ©.")
    
    # Construire la rÃ©ponse simple
    case_simple = schemas.clinical_case.ClinicalCaseSimple(
        id=db_case.id,
        code_fultang=db_case.code_fultang,
        niveau_difficulte=db_case.niveau_difficulte,
        pathologie_principale=db_case.pathologie_principale,  # L'objet complet sera sÃ©rialisÃ©
        nb_images=len(db_case.images_associees_ids) if db_case.images_associees_ids else 0,
        nb_sons=len(db_case.sons_associes_ids) if db_case.sons_associes_ids else 0,
    )
    
    return case_simple

=== Fichier: ./python_files_backup/app/api/v1/knowledge_graph.py ===



=== Fichier: ./python_files_backup/app/api/v1/medications.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import medication_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/medications",
    tags=["Medications"]
)


@router.post("/", response_model=schemas.medication.Medication, status_code=status.HTTP_201_CREATED)
def create_medication(medication_data: schemas.medication.MedicationCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e un nouveau mÃ©dicament.
    VÃ©rifie l'unicitÃ© du DCI (DÃ©nomination Commune Internationale).
    """
    db_medication = medication_service.get_medication_by_dci(db, dci=medication_data.dci)
    if db_medication:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Un mÃ©dicament avec le DCI '{medication_data.dci}' existe dÃ©jÃ ."
        )
    return medication_service.create_medication(db=db, medication=medication_data)


@router.get("/", response_model=List[schemas.medication.Medication])
def read_medications(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de mÃ©dicaments.
    """
    medications = medication_service.get_all_medications(db, skip=skip, limit=limit)
    return medications


@router.get("/{medication_id}", response_model=schemas.medication.Medication)
def read_medication(medication_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un mÃ©dicament par son ID.
    """
    db_medication = medication_service.get_medication_by_id(db, medication_id=medication_id)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="MÃ©dicament non trouvÃ©.")
    return db_medication


@router.patch("/{medication_id}", response_model=schemas.medication.Medication)
def update_medication(medication_id: int, medication_data: schemas.medication.MedicationUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour un mÃ©dicament.
    """
    db_medication = medication_service.update_medication(db, medication_id=medication_id, medication_update=medication_data)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="MÃ©dicament non trouvÃ©.")
    return db_medication


@router.delete("/{medication_id}", response_model=schemas.medication.Medication)
def delete_medication(medication_id: int, db: Session = Depends(get_db)):
    """
    Supprime un mÃ©dicament.
    """
    db_medication = medication_service.delete_medication(db, medication_id=medication_id)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="MÃ©dicament non trouvÃ©.")
    return db_medication

=== Fichier: ./python_files_backup/app/api/v1/symptoms.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import symptom_service
from ...dependencies import get_db

# CrÃ©ation d'un nouveau routeur.
# C'est comme une mini-application FastAPI que l'on pourra inclure dans notre app principale.
router = APIRouter(
    prefix="/symptoms",  # Toutes les routes de ce fichier commenceront par /symptoms
    tags=["Symptoms"]      # Groupe les routes dans la documentation interactive
)


@router.post("/", response_model=schemas.Symptom, status_code=status.HTTP_201_CREATED)
def create_symptom(symptom: schemas.SymptomCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e un nouveau symptÃ´me.
    """
    # VÃ©rifie si un symptÃ´me avec le mÃªme nom existe dÃ©jÃ 
    db_symptom = symptom_service.get_symptom_by_name(db, name=symptom.nom)
    if db_symptom:
        raise HTTPException(status_code=400, detail="Un symptÃ´me avec ce nom existe dÃ©jÃ .")
    
    return symptom_service.create_symptom(db=db, symptom=symptom)


@router.get("/", response_model=List[schemas.Symptom])
def read_symptoms(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de symptÃ´mes.
    """
    symptoms = symptom_service.get_all_symptoms(db, skip=skip, limit=limit)
    return symptoms


@router.get("/{symptom_id}", response_model=schemas.Symptom)
def read_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un symptÃ´me par son ID.
    """
    db_symptom = symptom_service.get_symptom_by_id(db, symptom_id=symptom_id)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="SymptÃ´me non trouvÃ©.")
    return db_symptom


@router.patch("/{symptom_id}", response_model=schemas.Symptom)
def update_symptom(symptom_id: int, symptom: schemas.SymptomUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour un symptÃ´me.
    """
    db_symptom = symptom_service.update_symptom(db, symptom_id=symptom_id, symptom_update=symptom)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="SymptÃ´me non trouvÃ©.")
    return db_symptom


@router.delete("/{symptom_id}", response_model=schemas.Symptom)
def delete_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    Supprime un symptÃ´me.
    """
    db_symptom = symptom_service.delete_symptom(db, symptom_id=symptom_id)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="SymptÃ´me non trouvÃ©.")
    return db_symptom

# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/symptoms.py

@router.get(
    "/{symptom_id}/diseases",
    response_model=List[schemas.relations.DiseaseForSymptomDetail],
    tags=["Disease-Symptom Relations"]
)
def get_diseases_for_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste de toutes les pathologies pouvant prÃ©senter ce symptÃ´me
    (utile pour le diagnostic diffÃ©rentiel).
    """
    associations = symptom_service.get_diseases_for_symptom(db, symptom_id=symptom_id)
    if not associations:
        return []
        
    response = []
    for assoc in associations:
        response.append({
            "pathologie": assoc.pathologie,
            "probabilite": assoc.probabilite,
            "importance_diagnostique": assoc.importance_diagnostique
        })
    return response



# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/symptoms.py

@router.post(
    "/{symptom_id}/treatments",
    response_model=schemas.relations.TraitementSymptome,
    status_code=status.HTTP_201_CREATED,
    tags=["Therapeutic Relations"]
)
def add_treatment_to_symptom(
    symptom_id: int,
    association_data: schemas.relations.TraitementSymptomeCreate,
    db: Session = Depends(get_db)
):
    """
    Associe un mÃ©dicament Ã  un symptÃ´me pour un traitement symptomatique.
    """
    if symptom_id != association_data.symptome_id:
        raise HTTPException(status_code=400, detail="IncohÃ©rence des IDs de symptÃ´me.")
    
    try:
        return symptom_service.add_treatment_to_symptom(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get(
    "/{symptom_id}/treatments",
    response_model=List[schemas.relations.MedicationForSymptomDetail],
    tags=["Therapeutic Relations"]
)
def get_treatments_for_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste des traitements pour un symptÃ´me spÃ©cifique.
    """
    associations = symptom_service.get_treatments_for_symptom(db, symptom_id=symptom_id)
    return [
        {
            "medicament": assoc.medicament,
            "efficacite": assoc.efficacite,
            "rang_preference": assoc.rang_preference,
        }
        for assoc in associations
    ]

=== Fichier: ./python_files_backup/app/api/__init__.py ===



=== Fichier: ./python_files_backup/app/database.py ===

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from .config import settings

# L'objet 'engine' est le point d'entrÃ©e principal pour communiquer avec la BDD.
engine = create_engine(
    settings.DATABASE_URL,
    # pool_pre_ping=True # Option utile en production
)

# La 'SessionLocal' est une "usine" Ã  sessions de base de donnÃ©es.
# Chaque fois que nous aurons besoin de parler Ã  la BDD, nous demanderons une session Ã  cette usine.
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

=== Fichier: ./python_files_backup/app/models/tutor_models.py ===

from sqlalchemy import Column, Integer, String, Text, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean
from sqlalchemy.orm import relationship
from sqlalchemy.dialects.postgresql import UUID
from .base import Base

class LearningPath(Base):
    __tablename__ = "learning_paths"

    id = Column(Integer, primary_key=True, index=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    
    algorithme_recommandation = Column(String(100))
    ordered_case_ids = Column(JSON, comment="Liste ordonnÃ©e des IDs des cas") 
    progression = Column(Float, default=0.0)
    status = Column(String(50), default="in_progress")
    created_at = Column(TIMESTAMP, server_default=text("now()"))

    learner = relationship("Learner")


class TutorDecision(Base):
    __tablename__ = "tutor_decisions"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    trigger_event_id = Column(Integer, ForeignKey("interaction_logs.id"), nullable=True)
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    strategy_used = Column(String(100)) # Socratique, Scaffolding...
    action_choisie = Column(String(100)) # Hint, Encouragement
    intervention_content = Column(Text)
    rationale = Column(JSON) # Pourquoi j'ai fait Ã§a ?
    succes_intervention = Column(Boolean, nullable=True)

    session = relationship("SimulationSession", back_populates="tutor_decisions")


class TutorStrategiesHistory(Base):
    __tablename__ = "tutor_strategies_history"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    strategy_name = Column(String(100))
    relevance_score = Column(Float)


class TutorScaffoldingState(Base):
    __tablename__ = "tutor_scaffolding_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    competence_cible_id = Column(Integer, ForeignKey("competences_cliniques.id"))
    current_level = Column(Integer, default=0)
    indices_deja_donnes = Column(JSON)


class TutorSocraticState(Base):
    __tablename__ = "tutor_socratic_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    tactic_used = Column(String(100))
    target_concept = Column(String(255))
    step_in_dialogue = Column(Integer)


class TutorMotivationalState(Base):
    __tablename__ = "tutor_motivational_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    intervention_type = Column(String(100))
    emotional_state_before = Column(JSON)


class TutorFeedbackLog(Base):
    __tablename__ = "tutor_feedback_logs"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    feedback_type = Column(String(50))
    content = Column(Text)

=== Fichier: ./python_files_backup/app/models/symptom.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    Boolean,
    JSON,
    TIMESTAMP,
    text
)
from pgvector.sqlalchemy import Vector
from sqlalchemy.orm import relationship

from .base import Base


class Symptom(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des symptÃ´mes.

    Cette table est le catalogue central de tous les symptÃ´mes connus par le systÃ¨me expert.
    Elle inclut des informations dÃ©taillÃ©es pour permettre un raisonnement clinique fin
    et des recherches sÃ©mantiques.
    """
    __tablename__ = "symptomes"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et CatÃ©gorisation ---
    nom = Column(String(255), nullable=False, unique=True, index=True)
    nom_local = Column(String(255), comment="Nom vernaculaire ou local, ex: 'Ntou-tou' pour la toux")
    categorie = Column(String(100), index=True, comment="CatÃ©gorie fonctionnelle (ex: Respiratoire, Neurologique, Digestif)")
    type_symptome = Column(String(50), comment="Type de symptÃ´me (ex: Subjectif, Objectif, Signe clinique)")

    # --- Description et Contexte Clinique ---
    description = Column(Text, comment="Description dÃ©taillÃ©e du symptÃ´me et de sa signification clinique.")
    questions_anamnese = Column(JSON, comment="Liste structurÃ©e de questions pour explorer ce symptÃ´me (ex: PQRST)")
    signes_alarme = Column(Boolean, default=False, nullable=False, comment="Indique si ce symptÃ´me est un signe de gravitÃ© ('red flag')")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    # Relation vers la table d'association 'pathologie_symptomes'
    # 'back_populates' assure la synchronisation de la relation des deux cÃ´tÃ©s.
    # 'cascade' signifie que si un symptÃ´me est supprimÃ©, ses associations le seront aussi.
    pathologies = relationship(
        "PathologieSymptome",
        back_populates="symptome",
        cascade="all, delete-orphan"
    )
    traitements = relationship(
        "TraitementSymptome",
        back_populates="symptome",
        cascade="all, delete-orphan"
    )

    def __repr__(self) -> str:
        return f"<Symptom(id={self.id}, nom='{self.nom}')>"

=== Fichier: ./python_files_backup/app/models/medication.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    text
)
from pgvector.sqlalchemy import Vector
from sqlalchemy.orm import relationship
from .base import Base


class Medication(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des mÃ©dicaments.

    Cette table est le catalogue central de tous les mÃ©dicaments connus par le systÃ¨me,
    incluant des informations pharmacologiques et contextuelles (disponibilitÃ©, coÃ»t).
    """
    __tablename__ = "medicaments"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification ---
    nom_commercial = Column(String(255), index=True)
    dci = Column(String(255), nullable=False, index=True, comment="DÃ©nomination Commune Internationale")
    
    # --- Classification et Formulation ---
    classe_therapeutique = Column(String(255), index=True)
    forme_galenique = Column(String(100), comment="Ex: ComprimÃ©, Sirop, Injectable")
    dosage = Column(String(100))
    voie_administration = Column(String(100), comment="Ex: Orale, IV, IM, CutanÃ©e")

    # --- Informations Pharmacologiques ---
    mecanisme_action = Column(Text)
    indications = Column(JSON)
    contre_indications = Column(JSON)
    effets_secondaires = Column(JSON)
    interactions_medicamenteuses = Column(JSON)
    precautions_emploi = Column(Text)
    posologie_standard = Column(JSON, comment="Posologie standard par Ã¢ge, poids, indication")

    # --- Contexte Local (Cameroun) ---
    disponibilite_cameroun = Column(String(50), comment="Ex: Urbain, Rural, CHU_uniquement")
    cout_moyen_fcfa = Column(Integer)
    statut_prescription = Column(String(50), comment="Ex: Prescription_obligatoire, OTC")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    traitements_pathologies = relationship("TraitementPathologie", back_populates="medicament")
    traitements_symptomes = relationship("TraitementSymptome", back_populates="medicament")

    def __repr__(self) -> str:
        return f"<Medication(id={self.id}, dci='{self.dci}')>"

=== Fichier: ./python_files_backup/app/models/clinical_case.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    ForeignKey,
    ARRAY,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class ClinicalCase(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des cas cliniques enrichis.
    C'est l'objet central utilisÃ© pour les scÃ©narios d'apprentissage.
    """
    __tablename__ = "cas_cliniques_enrichis"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et IntÃ©gritÃ© ---
    code_fultang = Column(String(100), unique=True, index=True, comment="Identifiant unique provenant de Fultang (ou synthÃ©tique)")
    hash_integrite = Column(String(64), nullable=True, comment="SHA-256 pour la preuve d'intÃ©gritÃ© des donnÃ©es brutes")

    # --- Liaisons aux Connaissances de Base ---
    pathologie_principale_id = Column(Integer, ForeignKey("pathologies.id"), nullable=True, index=True)
    pathologies_secondaires_ids = Column(ARRAY(Integer), comment="Liste d'IDs de pathologies comorbides ou secondaires")

    # --- DonnÃ©es du ScÃ©nario ---
    donnees_brutes = Column(JSON, nullable=True, comment="DonnÃ©es originales (ex: de Fultang) avant traitement")
    presentation_clinique = Column(JSON, nullable=False, comment="Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.")
    donnees_paracliniques = Column(JSON, comment="RÃ©sultats des examens pour ce cas spÃ©cifique")
    evolution_patient = Column(Text, comment="Description de l'Ã©volution du patient pendant le cas")
    
    # --- Liaisons MultimÃ©dia ---
    images_associees_ids = Column(ARRAY(Integer), comment="Liste des IDs des images de la table 'images_medicales'")
    sons_associes_ids = Column(ARRAY(Integer), comment="Liste des IDs des sons de la table 'sons_medicaux'")

    # --- Liaisons ThÃ©rapeutiques ---
    medicaments_prescrits = Column(JSON, comment="Liste des mÃ©dicaments prescrits dans ce cas")

    # --- MÃ©tadonnÃ©es PÃ©dagogiques ---
    niveau_difficulte = Column(Integer, default=3, comment="DifficultÃ© du cas (1-5)")
    duree_estimee_resolution_min = Column(Integer, comment="Temps estimÃ© pour rÃ©soudre le cas")
    objectifs_apprentissage = Column(JSON, comment="Liste des compÃ©tences Ã  acquÃ©rir")
    competences_requises = Column(JSON, comment="Mapping Q-Matrix pour ce cas")

    valide_expert = Column(Boolean, default=False)
    
    # ClÃ© Ã©trangÃ¨re vers la table experts
    expert_validateur_id = Column(Integer, ForeignKey("experts.id"), nullable=True)
    
    # Relation avec ExpertUser
    expert_validateur = relationship("ExpertUser", back_populates="cas_valides")
    date_validation = Column(Date)

    qualite_donnees = Column(Integer, comment="QualitÃ© des donnÃ©es sources (1-5)")

    # --- MÃ©triques d'Utilisation ---
    nb_utilisations = Column(Integer, default=0)
    note_moyenne_apprenants = Column(DECIMAL(3, 2))
    taux_succes_diagnostic = Column(DECIMAL(5, 2))
    
    # --- Intelligence Artificielle ---
    embedding_texte = Column(Vector(384), nullable=True, comment="Embedding de la description textuelle du cas")
    embedding_global = Column(Vector(1536), nullable=True, comment="Embedding multimodal fusionnÃ© (texte+image+son)")
    
    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    pathologie_principale = relationship("Disease")

    def __repr__(self) -> str:
        return f"<ClinicalCase(id={self.id}, code='{self.code_fultang}')>"

=== Fichier: ./python_files_backup/app/models/learner_models.py ===

from sqlalchemy import Column, Integer, String, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean
from sqlalchemy.orm import relationship
from .base import Base

class Learner(Base):
    __tablename__ = "learners"

    id = Column(Integer, primary_key=True, index=True)
    matricule = Column(String(50), unique=True, index=True)
    nom = Column(String(255))
    email = Column(String(255), unique=True, index=True)
    niveau_etudes = Column(String(50)) # Med 3, Interne...
    specialite_visee = Column(String(100))
    langue_preferee = Column(String(10), default="fr")
    date_inscription = Column(TIMESTAMP, server_default=text("now()"))

    # Relations
    competency_mastery = relationship("LearnerCompetencyMastery", back_populates="learner")
    misconceptions = relationship("LearnerMisconception", back_populates="learner")
    sessions = relationship("SimulationSession", back_populates="learner")


class LearnerCompetencyMastery(Base):
    __tablename__ = "learner_competency_mastery"

    id = Column(Integer, primary_key=True, index=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    mastery_level = Column(Float, default=0.0) # ProbabilitÃ© BKT (0-1)
    confidence = Column(Float, default=0.0) # Certitude du systÃ¨me
    last_practice_date = Column(TIMESTAMP)
    nb_success = Column(Integer, default=0)
    nb_failures = Column(Integer, default=0)
    streak_correct = Column(Integer, default=0)

    learner = relationship("Learner", back_populates="competency_mastery")
    competence = relationship("Competence") # Lien vers Module Expert


class LearnerCognitiveProfile(Base):
    __tablename__ = "learner_cognitive_profiles"

    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), unique=True)
    
    vitesse_assimilation = Column(Float)
    capacite_memoire_travail = Column(Float)
    tendance_impulsivite = Column(Float) # 0 (RÃ©flÃ©chi) - 1 (Impulsif)
    prefer_visual = Column(Boolean, default=False)
    
    learner = relationship("Learner")


class LearnerMisconception(Base):
    __tablename__ = "learner_misconceptions"

    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    
    type_erreur = Column(String(255)) # ex: "Confond Virus/BactÃ©rie"
    frequence_apparition = Column(Integer, default=1)
    resistance_correction = Column(Float, default=0.0) # 0-1
    detected_at = Column(TIMESTAMP, server_default=text("now()"))
    
    learner = relationship("Learner", back_populates="misconceptions")


class LearnerGoal(Base):
    __tablename__ = "learner_goals"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    type_objectif = Column(String(100))
    domaine_cible = Column(String(100))
    date_limite = Column(TIMESTAMP)
    statut = Column(String(50)) # en_cours, atteint, abandonne


class LearnerPreference(Base):
    __tablename__ = "learner_preferences"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    cle = Column(String(100))
    valeur = Column(String(255))


class LearnerAchievement(Base):
    __tablename__ = "learner_achievements"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    badge_id = Column(String(100))
    date_obtention = Column(TIMESTAMP, server_default=text("now()"))


class LearnerStrategy(Base):
    __tablename__ = "learner_strategies"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    strategy_name = Column(String(100)) # ex: "Gaming", "Help Seeking"
    frequency = Column(Integer)
    effectiveness = Column(Float)

=== Fichier: ./python_files_backup/app/models/relations.py ===

from sqlalchemy import (
    JSON,
    Column,
    Integer,
    ForeignKey,
    DECIMAL,
    String,
    Boolean,
    Text
)
from sqlalchemy.orm import relationship

from .base import Base


class PathologieSymptome(Base):
    """
    ModÃ¨le de la table d'association entre Pathologies et SymptÃ´mes.

    Cette table matÃ©rialise la relation "plusieurs-Ã -plusieurs" et permet de stocker
    des informations contextuelles sur le lien, telles que la probabilitÃ©
    d'apparition, la spÃ©cificitÃ©, etc.
    """
    __tablename__ = "pathologie_symptomes"

    id = Column(Integer, primary_key=True)

    # --- ClÃ©s Ã‰trangÃ¨res ---
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=False)
    symptome_id = Column(Integer, ForeignKey("symptomes.id"), nullable=False)

    # --- Attributs de la Relation ---
    probabilite = Column(DECIMAL(5, 4), comment="ProbabilitÃ© d'apparition du symptÃ´me pour cette pathologie P(symptÃ´me|pathologie)")
    sensibilite = Column(DECIMAL(5, 4))
    specificite = Column(DECIMAL(5, 4))
    phase_maladie = Column(String(50), comment="Phase de la maladie oÃ¹ le symptÃ´me apparaÃ®t (ex: PrÃ©coce, Tardive)")
    frequence = Column(String(50), comment="FrÃ©quence d'apparition (ex: Constant, FrÃ©quent, Occasionnel)")
    est_pathognomonique = Column(Boolean, default=False, comment="Si True, ce symptÃ´me seul suffit presque Ã  poser le diagnostic")
    importance_diagnostique = Column(Integer, comment="Ã‰chelle de 1 Ã  5 sur l'importance de ce symptÃ´me pour le diagnostic")

    # --- Relations Inverses (Back-population) ---
    # Permet d'accÃ©der Ã  l'objet parent directement depuis une instance de cette classe.
    # ex: mon_association.pathologie -> renvoie l'objet Disease
    pathologie = relationship("Disease", back_populates="symptomes")
    symptome = relationship("Symptom", back_populates="pathologies")

    def __repr__(self) -> str:
        return f"<PathologieSymptome(pathologie_id={self.pathologie_id}, symptome_id={self.symptome_id})>"
    

# Contenu Ã  AJOUTER Ã  la fin de app/models/relations.py

class TraitementPathologie(Base):
    """
    Table d'association pour les traitements spÃ©cifiques aux pathologies.
    """
    __tablename__ = "traitements_pathologies"

    id = Column(Integer, primary_key=True)
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=False)
    medicament_id = Column(Integer, ForeignKey("medicaments.id"), nullable=False)

    type_traitement = Column(String(50), comment="Ex: Premiere_intention, Alternative, Adjuvant")
    ligne_traitement = Column(Integer, comment="Ex: 1Ã¨re ligne, 2e ligne")
    indication_precise = Column(Text)
    efficacite_taux = Column(DECIMAL(5, 2), comment="Taux de succÃ¨s en %")
    duree_traitement_jours = Column(Integer)
    posologie_detaillee = Column(JSON)
    niveau_preuve = Column(String(50), comment="Grade de recommandation (A, B, C)")
    guidelines_source = Column(String(255), comment="Source (OMS, MINSANTE Cameroun, etc.)")
    rang_preference = Column(Integer, default=99)

    pathologie = relationship("Disease", back_populates="traitements")
    medicament = relationship("Medication", back_populates="traitements_pathologies")


class TraitementSymptome(Base):
    """
    Table d'association pour les traitements symptomatiques.
    """
    __tablename__ = "traitements_symptomes"

    id = Column(Integer, primary_key=True)
    symptome_id = Column(Integer, ForeignKey("symptomes.id"), nullable=False)
    medicament_id = Column(Integer, ForeignKey("medicaments.id"), nullable=False)

    efficacite = Column(String(50), comment="Ex: Tres_efficace, Efficace, Modere")
    rapidite_action = Column(String(100), comment="Ex: Immediate, <30min")
    posologie_recommandee = Column(Text)
    rang_preference = Column(Integer, default=99)
    
    symptome = relationship("Symptom", back_populates="traitements")
    medicament = relationship("Medication", back_populates="traitements_symptomes")




=== Fichier: ./python_files_backup/app/models/tracking_models.py ===

from sqlalchemy import Column, Integer, String, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean, Text
from sqlalchemy.orm import relationship
from sqlalchemy.dialects.postgresql import UUID
import uuid
from .base import Base

class SimulationSession(Base):
    __tablename__ = "simulation_sessions"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    cas_clinique_id = Column(Integer, ForeignKey("cas_cliniques_enrichis.id"), nullable=False)
    
    start_time = Column(TIMESTAMP, server_default=text("now()"))
    end_time = Column(TIMESTAMP)
    score_final = Column(Float)
    temps_total = Column(Integer)
    cout_virtuel_genere = Column(Integer)
    statut = Column(String(50), default="en_cours")
    raison_fin = Column(String(100))
    current_stage = Column(String(50))
    context_state = Column(JSON)

    learner = relationship("Learner", back_populates="sessions")
    cas_clinique = relationship("ClinicalCase")
    
    # --- Relations ---
    messages = relationship("ChatMessage", back_populates="session", cascade="all, delete-orphan")
    tutor_decisions = relationship("TutorDecision", back_populates="session")
    
    # --- RELATION VERS INTERACTION LOG MISE EN COMMENTAIRE ---
    # Nous la rÃ©activerons quand la table 'interaction_logs' sera crÃ©Ã©e.
    # logs = relationship("InteractionLog", back_populates="session")
    # ----------------------------------------------------

class ChatMessage(Base):
    __tablename__ = "chat_messages"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"), nullable=False)
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    sender = Column(String(50), nullable=False) # student, patient, tutor
    content = Column(Text, nullable=False)
    message_metadata = Column(JSON)

    session = relationship("SimulationSession", back_populates="messages")

=== Fichier: ./python_files_backup/app/models/prerequisite.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    ForeignKey,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship

from .base import Base


class Competence(Base):
    """
    ModÃ¨le SQLAlchemy pour les compÃ©tences cliniques (Knowledge Components).
    """
    __tablename__ = "competences_cliniques"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification ---
    code_competence = Column(String(50), unique=True, nullable=False, index=True, comment="Code unique (ex: 'ANAMNESE_DOULEUR')")
    nom = Column(String(255), nullable=False)
    categorie = Column(String(100), index=True, comment="Ex: Anamnese, Examen_physique, Raisonnement, Technique")
    
    # --- PÃ©dagogie ---
    niveau_bloom = Column(Integer, comment="Niveau dans la taxonomie de Bloom (1-6)")
    description = Column(Text)
    objectifs_apprentissage = Column(JSON, comment="Liste dÃ©taillÃ©e des objectifs")
    criteres_maitrise = Column(JSON, comment="CritÃ¨res pour valider la compÃ©tence")
    
    # --- HiÃ©rarchie (Parent/Enfant) ---
    parent_competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=True)
    ordre_apprentissage = Column(Integer, default=0)

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # --- Relations ---
    children = relationship("Competence", 
                          back_populates="parent",
                          cascade="all, delete-orphan")
    
    parent = relationship("Competence", 
                        back_populates="children",
                        remote_side=[id])

    # Relation vers les prÃ©requis
    prerequis = relationship(
        "Competence",
        secondary="prerequis_competences",
        primaryjoin="Competence.id==prerequis_competences.c.competence_id",
        secondaryjoin="Competence.id==prerequis_competences.c.prerequis_id",
        backref="est_prerequis_pour"
    )

    def __repr__(self) -> str:
        return f"<Competence(code='{self.code_competence}', nom='{self.nom}')>"


class PrerequisCompetence(Base):
    """
    Table d'association pour le graphe de prÃ©requis entre compÃ©tences.
    Permet de dire : "Pour apprendre A, il faut d'abord maÃ®triser B".
    """
    __tablename__ = "prerequis_competences"

    id = Column(Integer, primary_key=True)
    
    # La compÃ©tence cible (Celle qu'on veut apprendre)
    competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    # La compÃ©tence prÃ©requise (Celle qu'on doit dÃ©jÃ  avoir)
    prerequis_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    # --- MÃ©tadonnÃ©es de la relation ---
    type_relation = Column(String(50), default="STRICT", comment="STRICT, RECOMMANDE, SUPPORTIF")
    force_relation = Column(DECIMAL(3, 2), default=1.0, comment="Force du lien (0-1)")

    def __repr__(self) -> str:
        return f"<Prerequis(target={self.competence_id}, needed={self.prerequis_id})>"

=== Fichier: ./python_files_backup/app/models/__init__.py ===

from .base import Base
from .symptom import Symptom
from .disease import Disease
from .medication import Medication
from .media import ImageMedicale
from .clinical_case import ClinicalCase
from .expert_strategy import ExpertStrategy
from .relations import PathologieSymptome, TraitementPathologie, TraitementSymptome
from .prerequisite import Competence, PrerequisCompetence

# --- AJOUTER CES LIGNES SI ELLES MANQUENT ---
from .learner_models import (
    Learner, LearnerCompetencyMastery, LearnerCognitiveProfile, 
    LearnerMisconception, LearnerGoal, LearnerPreference, 
    LearnerAchievement, LearnerStrategy
)
from .tracking_models import (
    SimulationSession, InteractionLog, ChatMessage, LearnerAffectiveState
)
from .tutor_models import (
    LearningPath, TutorDecision, TutorStrategiesHistory, 
    TutorScaffoldingState, TutorSocraticState, TutorMotivationalState, 
    TutorFeedbackLog
)
from .expert_user import ExpertUser

=== Fichier: ./python_files_backup/app/models/expert_user.py ===

from sqlalchemy import Column, Integer, String, Text, Boolean, TIMESTAMP, text
from sqlalchemy.orm import relationship
from .base import Base

class ExpertUser(Base):
    __tablename__ = "experts"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String(255), unique=True, index=True, nullable=False)
    hashed_password = Column(String(255), nullable=False)
    nom_complet = Column(String(255))
    specialite = Column(String(100))
    hopital_affiliation = Column(String(255))
    role = Column(String(50), default="validateur") # superadmin, validateur, contributeur
    
    last_login = Column(TIMESTAMP)
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # Relation avec les cas cliniques validÃ©s
    cas_valides = relationship("ClinicalCase", back_populates="expert_validateur")

=== Fichier: ./python_files_backup/app/models/expert_strategy.py ===

from sqlalchemy import (
    DECIMAL,
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    text
)
from sqlalchemy.orm import relationship

from .base import Base


class ExpertStrategy(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des rÃ¨gles de production (stratÃ©gies expertes).
    
    Cette table stocke la logique IF-THEN du systÃ¨me expert.
    """
    __tablename__ = "regles_production"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et MÃ©tadonnÃ©es ---
    code_regle = Column(String(50), unique=True, nullable=False, index=True)
    categorie = Column(String(100), index=True, comment="Ex: DIAGNOSTIC, THERAPEUTIQUE, PEDAGOGIQUE, ALERTE")
    priorite = Column(Integer, default=5, comment="PrioritÃ© d'exÃ©cution (1-10), 10 Ã©tant le plus prioritaire")
    
    # --- Structure de la RÃ¨gle (IF-THEN) ---
    conditions = Column(JSON, nullable=False, comment="Partie 'IF' de la rÃ¨gle, structurÃ©e en JSON")
    # Exemple de 'conditions':
    # {
    #   "operator": "AND",
    #   "rules": [
    #     {"fact": "symptom", "value": "FiÃ¨vre", "operator": "present"},
    #     {"fact": "symptom", "value": "Toux", "operator": "present"},
    #     {"fact": "age", "value": 65, "operator": "greater_than"}
    #   ]
    # }

    actions = Column(JSON, nullable=False, comment="Partie 'THEN' de la rÃ¨gle, structurÃ©e en JSON")
    # Exemple d' 'actions':
    # [
    #   {"action": "add_hypothesis", "pathology": "Pneumonie", "confidence": 0.8},
    #   {"action": "recommend_exam", "exam": "Radio Thorax", "urgency": "high"}
    # ]

    # --- Documentation et Validation ---
    description_naturelle = Column(Text, comment="Description de la rÃ¨gle en langage naturel")
    justification_medicale = Column(Text, comment="Source ou justification clinique de la rÃ¨gle")
    expert_auteur = Column(String(255))
    date_validation = Column(Date)
    est_active = Column(Boolean, default=True, nullable=False)

    # --- MÃ©triques ---
    nb_activations = Column(Integer, default=0)
    taux_succes = Column(DECIMAL(5, 4))

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    def __repr__(self) -> str:
        return f"<ExpertStrategy(id={self.id}, code='{self.code_regle}')>"

=== Fichier: ./python_files_backup/app/models/media.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    ForeignKey,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class ImageMedicale(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des images mÃ©dicales.
    Catalogue toutes les images (radios, scanners, etc.) avec leurs mÃ©tadonnÃ©es.
    """
    __tablename__ = "images_medicales"

    id = Column(Integer, primary_key=True, index=True)

    # --- Classification et Liaison ---
    type_examen = Column(String(100), nullable=False, index=True, comment="Ex: Radiographie, Ã‰chographie, Scanner")
    sous_type = Column(String(100), comment="Ex: Thorax, Abdomen, CrÃ¢ne")
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=True, index=True)

    # --- Gestion du Fichier ---
    fichier_url = Column(String(500), nullable=False, comment="URL vers le fichier (S3, stockage local, etc.)")
    fichier_miniature_url = Column(String(500), comment="URL vers une version miniature de l'image")
    format_image = Column(String(20), comment="Ex: DICOM, PNG, JPEG")
    taille_ko = Column(Integer)
    resolution = Column(String(50))

    # --- MÃ©tadonnÃ©es Cliniques ---
    description = Column(Text, comment="Description gÃ©nÃ©rale de l'image ou du cas")
    signes_radiologiques = Column(JSON, comment="Signes spÃ©cifiques visibles (ex: opacitÃ©, Ã©panchement)")
    annotations = Column(JSON, comment="CoordonnÃ©es et descriptions de zones d'intÃ©rÃªt")
    interpretation_experte = Column(Text, comment="Compte-rendu d'un radiologue expert")
    diagnostic_differentiel = Column(JSON, comment="Autres diagnostics possibles basÃ©s sur l'image")

    # --- MÃ©tadonnÃ©es PÃ©dagogiques ---
    niveau_difficulte = Column(Integer, comment="DifficultÃ© d'interprÃ©tation de l'image (1-5)")
    qualite_image = Column(Integer, comment="QualitÃ© technique de l'image (1-5)")

    # --- Intelligence Artificielle ---
    embedding_vision = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle")

    # --- Validation et Horodatage ---
    valide_expert = Column(Boolean, default=False)
    expert_validateur = Column(String(255))
    date_validation = Column(Date)
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # --- Relations ---
    # Permet d'accÃ©der Ã  l'objet Pathologie depuis une ImageMedicale
    pathologie = relationship("Disease") # Nous n'avons pas besoin de back_populates ici pour l'instant

    def __repr__(self) -> str:
        return f"<ImageMedicale(id={self.id}, type='{self.type_examen}')>"


=== Fichier: ./python_files_backup/app/models/knowledge_version.py ===



=== Fichier: ./python_files_backup/app/models/disease.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class Disease(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des pathologies (maladies).

    Cette table contient toutes les informations dÃ©taillÃ©es sur chaque maladie
    connue par le systÃ¨me, y compris le contexte local, les caractÃ©ristiques
    cliniques et les vecteurs pour l'IA.
    """
    __tablename__ = "pathologies"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et Classification ---
    code_icd10 = Column(String(20), unique=True, index=True, comment="Code international de la maladie (CIM-10)")
    nom_fr = Column(String(255), nullable=False, index=True)
    nom_en = Column(String(255))
    nom_local = Column(String(255), comment="Noms locaux ou courants au Cameroun")
    categorie = Column(String(100), index=True, comment="Ex: Infectieuse, Chronique, Parasitaire")

    # --- DonnÃ©es Cliniques et Ã‰pidÃ©miologiques ---
    prevalence_cameroun = Column(DECIMAL(5, 2), comment="PrÃ©valence en % dans le contexte camerounais")
    niveau_gravite = Column(Integer, comment="Ã‰chelle de 1 (bÃ©nin) Ã  5 (critique)")
    description = Column(Text)
    physiopathologie = Column(Text, comment="MÃ©canisme de la maladie")
    evolution_naturelle = Column(Text, comment="Comment la maladie Ã©volue sans traitement")
    complications = Column(JSON, comment="Complications possibles")
    facteurs_risque = Column(JSON, comment="Facteurs de risque associÃ©s")
    prevention = Column(Text, comment="Mesures de prÃ©vention")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    # Nous prÃ©parons le terrain pour la future relation avec les symptÃ´mes.
    # Pour l'instant, elle reste en commentaire pour Ã©viter les erreurs d'import circulaire.
    symptomes = relationship(
         "PathologieSymptome",
         back_populates="pathologie",
         cascade="all, delete-orphan"
    
     )
    
    traitements = relationship(
        "TraitementPathologie",
        back_populates="pathologie",
        cascade="all, delete-orphan"
    )

    def __repr__(self) -> str:
        return f"<Disease(id={self.id}, nom_fr='{self.nom_fr}')>"

=== Fichier: ./python_files_backup/app/models/diagnostic.py ===



=== Fichier: ./python_files_backup/app/models/base.py ===

from sqlalchemy.orm import declarative_base

# Cette instance de 'declarative_base' est le catalogue central oÃ¹ SQLAlchemy
# enregistrera toutes les classes de modÃ¨les que nous dÃ©finirons.
# C'est ce que Alembic utilisera pour comparer l'Ã©tat de notre code
# avec l'Ã©tat de la base de donnÃ©es.
Base = declarative_base()

=== Fichier: ./python_files_backup/app/__init__.py ===



=== Fichier: ./python_files_backup/app/services/fultang_integration/extractor.py ===



=== Fichier: ./python_files_backup/app/services/fultang_integration/validator.py ===



=== Fichier: ./python_files_backup/app/services/fultang_integration/__init__.py ===



=== Fichier: ./python_files_backup/app/services/fultang_integration/anonymizer.py ===



=== Fichier: ./python_files_backup/app/services/fultang_integration/case_generator.py ===



=== Fichier: ./python_files_backup/app/services/__init__.py ===



=== Fichier: ./python_files_backup/app/services/learning_path_service.py ===



=== Fichier: ./python_files_backup/app/services/medication_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_medication_by_id(db: Session, medication_id: int) -> Optional[models.Medication]:
    """
    RÃ©cupÃ¨re un mÃ©dicament par son ID.
    """
    return db.query(models.Medication).filter(models.Medication.id == medication_id).first()

def get_medication_by_dci(db: Session, dci: str) -> Optional[models.Medication]:
    """
    RÃ©cupÃ¨re un mÃ©dicament par son DCI (DÃ©nomination Commune Internationale).
    """
    return db.query(models.Medication).filter(models.Medication.dci == dci).first()

def get_all_medications(db: Session, skip: int = 0, limit: int = 100) -> List[models.Medication]:
    """
    RÃ©cupÃ¨re une liste de tous les mÃ©dicaments avec pagination.
    """
    return db.query(models.Medication).offset(skip).limit(limit).all()

def create_medication(db: Session, medication: schemas.MedicationCreate) -> models.Medication:
    """
    CrÃ©e un nouveau mÃ©dicament dans la base de donnÃ©es.
    """
    medication_data = medication.model_dump()
    db_medication = models.Medication(**medication_data)
    
    db.add(db_medication)
    db.commit()
    db.refresh(db_medication)
    
    return db_medication

def update_medication(db: Session, medication_id: int, medication_update: schemas.MedicationUpdate) -> Optional[models.Medication]:
    """
    Met Ã  jour un mÃ©dicament existant.
    """
    db_medication = get_medication_by_id(db, medication_id)
    if not db_medication:
        return None

    update_data = medication_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_medication, key, value)
        
    db.commit()
    db.refresh(db_medication)
    
    return db_medication

def delete_medication(db: Session, medication_id: int) -> Optional[models.Medication]:
    """
    Supprime un mÃ©dicament de la base de donnÃ©es.
    """
    db_medication = get_medication_by_id(db, medication_id)
    if not db_medication:
        return None

    db.delete(db_medication)
    db.commit()
    
    return db_medication




# Contenu Ã  AJOUTER Ã  la fin de app/services/medication_service.py

def get_diseases_treated_by_medication(db: Session, medication_id: int) -> List[models.TraitementPathologie]:
    """
    RÃ©cupÃ¨re toutes les pathologies traitÃ©es par un mÃ©dicament.
    """
    return db.query(models.TraitementPathologie).filter(models.TraitementPathologie.medicament_id == medication_id).all()


def get_symptoms_treated_by_medication(db: Session, medication_id: int) -> List[models.TraitementSymptome]:
    """
    RÃ©cupÃ¨re tous les symptÃ´mes traitÃ©s par un mÃ©dicament.
    """
    return db.query(models.TraitementSymptome).filter(models.TraitementSymptome.medicament_id == medication_id).all()

=== Fichier: ./python_files_backup/app/services/media_service.py ===

import os
from sqlalchemy.orm import Session
from typing import List, Optional
from fastapi import UploadFile
import cloudinary
import cloudinary.uploader

from .. import models, schemas
from ..config import settings

# --- CONFIGURATION CLOUDINARY ---
# Cette configuration est faite une seule fois au chargement du module.
# Elle utilise les variables chargÃ©es depuis votre fichier .env.
cloudinary.config(
    cloud_name = settings.CLOUDINARY_CLOUD_NAME,
    api_key = settings.CLOUDINARY_API_KEY,
    api_secret = settings.CLOUDINARY_API_SECRET,
    secure = True
)


async def save_upload_file_to_cloud(upload_file: UploadFile) -> str:
    """
    Fonction utilitaire pour uploader un fichier directement vers Cloudinary
    et retourner son URL sÃ©curisÃ©e.
    """
    try:
        # Lire le contenu du fichier en mÃ©moire
        content = await upload_file.read()
        
        # Envoyer le contenu Ã  Cloudinary
        upload_result = cloudinary.uploader.upload(
            content,
            folder="sti_medical_expert/uploads"  # Dossier de destination sur Cloudinary
        )
        
        # RÃ©cupÃ©rer l'URL sÃ©curisÃ©e (https://...)
        secure_url = upload_result.get("secure_url")
        if not secure_url:
            raise Exception("Ã‰chec de l'upload vers Cloudinary, URL non retournÃ©e.")
            
        return secure_url
    finally:
        # Toujours fermer le fichier aprÃ¨s lecture
        await upload_file.close()


async def create_image_medicale(
    db: Session,
    file: UploadFile,
    type_examen: str,
    sous_type: Optional[str] = None,
    pathologie_id: Optional[int] = None,
    description: Optional[str] = None
) -> models.ImageMedicale:
    """
    CrÃ©e une nouvelle entrÃ©e pour une image mÃ©dicale.
    1. Sauvegarde le fichier sur Cloudinary.
    2. CrÃ©e l'enregistrement correspondant en base de donnÃ©es avec l'URL cloud.
    """
    # 1. Sauvegarder le fichier physique sur le cloud
    cloud_url = await save_upload_file_to_cloud(file)

    # 2. CrÃ©er l'objet SQLAlchemy avec les mÃ©tadonnÃ©es et l'URL cloud
    db_image = models.ImageMedicale(
        type_examen=type_examen,
        sous_type=sous_type,
        pathologie_id=pathologie_id,
        description=description,
        fichier_url=cloud_url, # <-- C'est maintenant l'URL Cloudinary !
        format_image=file.content_type.split('/')[-1] if file.content_type else None,
        taille_ko=file.size // 1024 if file.size else None,
    )
    
    db.add(db_image)
    db.commit()
    db.refresh(db_image)
    
    return db_image


def get_image_medicale_by_id(db: Session, image_id: int) -> Optional[models.ImageMedicale]:
    """
    RÃ©cupÃ¨re une image mÃ©dicale par son ID.
    """
    return db.query(models.ImageMedicale).filter(models.ImageMedicale.id == image_id).first()


def get_all_images_medicales(db: Session, skip: int = 0, limit: int = 100) -> List[models.ImageMedicale]:
    """
    RÃ©cupÃ¨re une liste de toutes les images mÃ©dicales avec pagination.
    """
    return db.query(models.ImageMedicale).offset(skip).limit(limit).all()


def update_image_medicale_metadata(
    db: Session,
    image_id: int,
    image_update: schemas.ImageMedicaleUpdate
) -> Optional[models.ImageMedicale]:
    """
    Met Ã  jour les mÃ©tadonnÃ©es d'une image mÃ©dicale existante.
    """
    db_image = get_image_medicale_by_id(db, image_id)
    if not db_image:
        return None

    update_data = image_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_image, key, value)
        
    db.commit()
    db.refresh(db_image)
    
    return db_image


def delete_image_medicale(db: Session, image_id: int) -> Optional[models.ImageMedicale]:
    """
    Supprime une image mÃ©dicale.
    1. Supprime l'enregistrement de la base de donnÃ©es.
    2. (Optionnel) Supprime le fichier sur Cloudinary.
    """
    db_image = get_image_medicale_by_id(db, image_id)
    if not db_image:
        return None

    # Optionnel : Ajouter ici la logique pour supprimer l'image de Cloudinary
    # via cloudinary.uploader.destroy(...) si vous voulez un nettoyage complet.
    # Pour l'instant, nous nous contentons de supprimer la rÃ©fÃ©rence.

    db.delete(db_image)
    db.commit()
    
    return db_image

=== Fichier: ./python_files_backup/app/services/symptom_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas
from ..utils.exceptions import NotFoundException # Nous crÃ©erons ce fichier plus tard


def get_symptom_by_id(db: Session, symptom_id: int) -> Optional[models.Symptom]:
    """
    RÃ©cupÃ¨re un symptÃ´me par son ID.
    """
    return db.query(models.Symptom).filter(models.Symptom.id == symptom_id).first()


def get_symptom_by_name(db: Session, name: str) -> Optional[models.Symptom]:
    """
    RÃ©cupÃ¨re un symptÃ´me par son nom.
    """
    return db.query(models.Symptom).filter(models.Symptom.nom == name).first()


def get_all_symptoms(db: Session, skip: int = 0, limit: int = 100) -> List[models.Symptom]:
    """
    RÃ©cupÃ¨re une liste de tous les symptÃ´mes avec pagination.
    """
    return db.query(models.Symptom).offset(skip).limit(limit).all()


def create_symptom(db: Session, symptom: schemas.SymptomCreate) -> models.Symptom:
    """
    CrÃ©e un nouveau symptÃ´me dans la base de donnÃ©es.
    
    Prend un schÃ©ma Pydantic 'SymptomCreate' en entrÃ©e, le convertit en
    modÃ¨le SQLAlchemy 'Symptom' et l'ajoute Ã  la base de donnÃ©es.
    """
    # Convertit le schÃ©ma Pydantic en dictionnaire
    symptom_data = symptom.model_dump()
    
    # CrÃ©e une instance du modÃ¨le SQLAlchemy
    db_symptom = models.Symptom(**symptom_data)
    
    # Ajoute l'instance Ã  la session de la base de donnÃ©es
    db.add(db_symptom)
    # Valide la transaction pour l'Ã©crire en base
    db.commit()
    # RafraÃ®chit l'instance pour obtenir les valeurs gÃ©nÃ©rÃ©es par la BDD (comme l'ID)
    db.refresh(db_symptom)
    
    return db_symptom


def update_symptom(db: Session, symptom_id: int, symptom_update: schemas.SymptomUpdate) -> Optional[models.Symptom]:
    """
    Met Ã  jour un symptÃ´me existant.
    """
    db_symptom = get_symptom_by_id(db, symptom_id)
    if not db_symptom:
        # Plus tard, nous lÃ¨verons une exception personnalisÃ©e
        # raise NotFoundException(detail=f"Symptom with id {symptom_id} not found")
        return None

    # Convertit le schÃ©ma Pydantic en dictionnaire, en excluant les valeurs non dÃ©finies
    update_data = symptom_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_symptom, key, value)
        
    db.commit()
    db.refresh(db_symptom)
    
    return db_symptom


def delete_symptom(db: Session, symptom_id: int) -> Optional[models.Symptom]:
    """
    Supprime un symptÃ´me de la base de donnÃ©es.
    """
    db_symptom = get_symptom_by_id(db, symptom_id)
    if not db_symptom:
        # raise NotFoundException(detail=f"Symptom with id {symptom_id} not found")
        return None

    db.delete(db_symptom)
    db.commit()
    
    return db_symptom

def get_diseases_for_symptom(db: Session, symptom_id: int) -> List[models.PathologieSymptome]:
    """
    RÃ©cupÃ¨re toutes les pathologies associÃ©es Ã  un symptÃ´me (diagnostic diffÃ©rentiel).
    """
    return db.query(models.PathologieSymptome).filter(models.PathologieSymptome.symptome_id == symptom_id).all()





def add_treatment_to_symptom(db: Session, association_data: schemas.relations.TraitementSymptomeCreate) -> models.TraitementSymptome:
    """
    Associe un mÃ©dicament Ã  un symptÃ´me en tant que traitement symptomatique.
    """
    db_symptom = get_symptom_by_id(db, symptom_id=association_data.symptome_id)
    from . import medication_service
    db_medication = medication_service.get_medication_by_id(db, medication_id=association_data.medicament_id)

    if not db_symptom or not db_medication:
        raise ValueError("SymptÃ´me ou MÃ©dicament non trouvÃ©.")

    association = models.TraitementSymptome(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_treatments_for_symptom(db: Session, symptom_id: int) -> List[models.TraitementSymptome]:
    """
    RÃ©cupÃ¨re tous les traitements associÃ©s Ã  un symptÃ´me.
    """
    return db.query(models.TraitementSymptome).filter(models.TraitementSymptome.symptome_id == symptom_id).all()

=== Fichier: ./python_files_backup/app/services/clinical_case_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

# Importer les autres services dont nous aurons besoin
from . import disease_service
from . import media_service


def get_case_by_id(db: Session, case_id: int) -> Optional[models.ClinicalCase]:
    """
    RÃ©cupÃ¨re un cas clinique par son ID.
    """
    return db.query(models.ClinicalCase).filter(models.ClinicalCase.id == case_id).first()


def get_case_by_code(db: Session, code: str) -> Optional[models.ClinicalCase]:
    """
    RÃ©cupÃ¨re un cas clinique par son code Fultang ou synthÃ©tique.
    """
    return db.query(models.ClinicalCase).filter(models.ClinicalCase.code_fultang == code).first()


def get_all_cases(db: Session, skip: int = 0, limit: int = 100) -> List[models.ClinicalCase]:
    """
    RÃ©cupÃ¨re une liste de tous les cas cliniques avec pagination.
    """
    return db.query(models.ClinicalCase).offset(skip).limit(limit).all()


def create_case(db: Session, case: schemas.ClinicalCaseCreate) -> models.ClinicalCase:
    """
    CrÃ©e un nouveau cas clinique dans la base de donnÃ©es.
    """
    # VÃ©rifier que la pathologie principale existe, si elle est fournie
    if case.pathologie_principale_id:
        db_disease = disease_service.get_disease_by_id(db, disease_id=case.pathologie_principale_id)
        if not db_disease:
            raise ValueError(f"La pathologie avec l'ID {case.pathologie_principale_id} n'existe pas.")

    # VÃ©rifier que les images associÃ©es existent, si elles sont fournies
    if case.images_associees_ids:
        for img_id in case.images_associees_ids:
            db_image = media_service.get_image_medicale_by_id(db, image_id=img_id)
            if not db_image:
                raise ValueError(f"L'image avec l'ID {img_id} n'existe pas.")

    case_data = case.model_dump()
    db_case = models.ClinicalCase(**case_data)
    
    db.add(db_case)
    db.commit()
    db.refresh(db_case)
    
    return db_case


def update_case(db: Session, case_id: int, case_update: schemas.ClinicalCaseUpdate) -> Optional[models.ClinicalCase]:
    """
    Met Ã  jour un cas clinique existant.
    """
    db_case = get_case_by_id(db, case_id)
    if not db_case:
        return None

    update_data = case_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_case, key, value)
        
    db.commit()
    db.refresh(db_case)
    
    return db_case


def delete_case(db: Session, case_id: int) -> Optional[models.ClinicalCase]:
    """
    Supprime un cas clinique de la base de donnÃ©es.
    Note : Ne supprime pas les entitÃ©s associÃ©es (maladies, images...).
    """
    db_case = get_case_by_id(db, case_id)
    if not db_case:
        return None

    db.delete(db_case)
    db.commit()
    
    return db_case

=== Fichier: ./python_files_backup/app/services/expert_strategy_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_strategy_by_id(db: Session, strategy_id: int) -> Optional[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re une rÃ¨gle par son ID.
    """
    return db.query(models.ExpertStrategy).filter(models.ExpertStrategy.id == strategy_id).first()

def get_strategy_by_code(db: Session, code: str) -> Optional[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re une rÃ¨gle par son code unique.
    """
    return db.query(models.ExpertStrategy).filter(models.ExpertStrategy.code_regle == code).first()

def get_all_strategies(db: Session, skip: int = 0, limit: int = 100) -> List[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re une liste de toutes les rÃ¨gles avec pagination.
    """
    return db.query(models.ExpertStrategy).offset(skip).limit(limit).all()

def get_active_strategies_by_category(db: Session, category: str) -> List[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re toutes les rÃ¨gles actives pour une catÃ©gorie donnÃ©e, triÃ©es par prioritÃ©.
    Cette fonction sera trÃ¨s utile pour le moteur de raisonnement.
    """
    return db.query(models.ExpertStrategy).filter(
        models.ExpertStrategy.categorie == category,
        models.ExpertStrategy.est_active == True
    ).order_by(models.ExpertStrategy.priorite.desc()).all()


def create_strategy(db: Session, strategy: schemas.ExpertStrategyCreate) -> models.ExpertStrategy:
    """
    CrÃ©e une nouvelle rÃ¨gle dans la base de donnÃ©es.
    """
    strategy_data = strategy.model_dump()
    db_strategy = models.ExpertStrategy(**strategy_data)
    
    db.add(db_strategy)
    db.commit()
    db.refresh(db_strategy)
    
    return db_strategy

def update_strategy(db: Session, strategy_id: int, strategy_update: schemas.ExpertStrategyUpdate) -> Optional[models.ExpertStrategy]:
    """
    Met Ã  jour une rÃ¨gle existante.
    """
    db_strategy = get_strategy_by_id(db, strategy_id)
    if not db_strategy:
        return None

    update_data = strategy_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_strategy, key, value)
        
    db.commit()
    db.refresh(db_strategy)
    
    return db_strategy

def delete_strategy(db: Session, strategy_id: int) -> Optional[models.ExpertStrategy]:
    """
    Supprime une rÃ¨gle de la base de donnÃ©es.
    """
    db_strategy = get_strategy_by_id(db, strategy_id)
    if not db_strategy:
        return None

    db.delete(db_strategy)
    db.commit()
    
    return db_strategy

=== Fichier: ./python_files_backup/app/services/embedding_service.py ===

from sentence_transformers import SentenceTransformer
import logging

# Configuration du logging
logger = logging.getLogger(__name__)

class EmbeddingService:
    """
    Service pour gÃ©nÃ©rer des embeddings (vecteurs) Ã  partir de texte.
    Utilise le modÃ¨le 'all-MiniLM-L6-v2' qui est un excellent compromis
    rapiditÃ©/qualitÃ© pour l'anglais et le franÃ§ais technique.
    """
    
    _instance = None
    _model = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(EmbeddingService, cls).__new__(cls)
            logger.info("Initialisation du modÃ¨le d'embedding...")
            # Chargement du modÃ¨le. On essaie sans le prÃ©fixe 'sentence-transformers/'
            # Si cela Ã©choue encore, nous essaierons une autre approche.
            try:
                cls._model = SentenceTransformer('all-MiniLM-L6-v2')
            except Exception as e:
                logger.error(f"Erreur chargement modÃ¨le 'all-MiniLM-L6-v2': {e}")
                # Tentative de repli explicite
                cls._model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
            
            logger.info("ModÃ¨le d'embedding chargÃ© avec succÃ¨s.")
        return cls._instance

    def get_text_embedding(self, text: str) -> list:
        """
        GÃ©nÃ¨re un vecteur d'embedding pour une chaÃ®ne de caractÃ¨res donnÃ©e.
        
        :param text: Le texte Ã  vectoriser.
        :return: Une liste de flottants (le vecteur).
        """
        if not text or not isinstance(text, str):
            return None
            
        try:
            # Le modÃ¨le retourne un numpy array, on le convertit en liste simple
            # pour qu'il soit compatible avec pgvector et JSON.
            embedding = self._model.encode(text)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"Erreur lors de la vectorisation du texte : {e}")
            return None

# Instance globale prÃªte Ã  l'emploi
embedding_service = EmbeddingService()

=== Fichier: ./python_files_backup/app/services/chat_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional
from uuid import UUID

from .. import models, schemas


def create_chat_message(db: Session, session_id: UUID, message: schemas.ChatMessageCreate) -> models.ChatMessage:
    """
    CrÃ©e un nouveau message de chat et l'associe Ã  une session.
    
    :param db: Session de base de donnÃ©es.
    :param session_id: L'ID de la session de simulation Ã  laquelle le message appartient.
    :param message: Le schÃ©ma Pydantic contenant les donnÃ©es du message.
    :return: L'objet ChatMessage crÃ©Ã©.
    """
    # VÃ©rifier que la session parente existe pour garantir l'intÃ©gritÃ©
    session = db.query(models.SimulationSession).filter(models.SimulationSession.id == session_id).first()
    if not session:
        raise ValueError(f"La session avec l'ID {session_id} n'a pas Ã©tÃ© trouvÃ©e.")

    # CrÃ©er l'instance du modÃ¨le SQLAlchemy
    db_message = models.ChatMessage(
        **message.model_dump(),
        session_id=session_id
    )
    
    db.add(db_message)
    db.commit()
    db.refresh(db_message)
    
    return db_message


def get_messages_by_session(db: Session, session_id: UUID) -> List[models.ChatMessage]:
    """
    RÃ©cupÃ¨re tous les messages d'une session de simulation, triÃ©s par ordre chronologique.
    
    :param db: Session de base de donnÃ©es.
    :param session_id: L'ID de la session Ã  interroger.
    :return: Une liste d'objets ChatMessage.
    """
    return db.query(models.ChatMessage).filter(
        models.ChatMessage.session_id == session_id
    ).order_by(models.ChatMessage.timestamp.asc()).all()

=== Fichier: ./python_files_backup/app/services/diagnostic_engine.py ===

from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional

from .. import models
from ..core import reasoning_engine
from . import expert_strategy_service

# Pour le typage, nous pouvons dÃ©finir un schÃ©ma simple ici
from pydantic import BaseModel

class DiagnosticInput(BaseModel):
    """
    SchÃ©ma simple pour les donnÃ©es d'entrÃ©e du moteur de diagnostic.
    """
    symptoms: List[str]
    context: List[str] = []
    age: Optional[int] = None
    # ... d'autres faits pertinents pourraient Ãªtre ajoutÃ©s ici


def run_diagnostic(db: Session, patient_facts: DiagnosticInput) -> List[Dict[str, Any]]:
    """
    Orchestre le processus de diagnostic.

    1. RÃ©cupÃ¨re les rÃ¨gles de diagnostic actives depuis la base de donnÃ©es.
    2. Formate les faits du patient.
    3. Appelle le moteur de raisonnement.
    4. Retourne les actions/conclusions.
    """
    # 1. RÃ©cupÃ©rer les rÃ¨gles
    # On utilise la fonction 'intelligente' que nous avions crÃ©Ã©e dans le service des stratÃ©gies
    diagnostic_rules_db = expert_strategy_service.get_active_strategies_by_category(
        db, category="DIAGNOSTIC"
    )

    if not diagnostic_rules_db:
        return []

    # Convertir les objets SQLAlchemy en dictionnaires simples pour le moteur de logique pure
    rules_list = [
        {
            "code_regle": rule.code_regle,
            "conditions": rule.conditions,
            "actions": rule.actions,
        }
        for rule in diagnostic_rules_db
    ]

    # 2. Formater les faits (dÃ©jÃ  au bon format grÃ¢ce Ã  Pydantic)
    facts_dict = patient_facts.model_dump()

    # 3. Appeler le moteur de raisonnement
    conclusions = reasoning_engine.forward_chaining_engine(
        rules=rules_list,
        facts=facts_dict
    )

    # 4. Retourner les conclusions
    return conclusions

=== Fichier: ./python_files_backup/app/services/q_matrix_service.py ===



=== Fichier: ./python_files_backup/app/services/disease_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_disease_by_id(db: Session, disease_id: int) -> Optional[models.Disease]:
    """
    RÃ©cupÃ¨re une pathologie par son ID.
    """
    return db.query(models.Disease).filter(models.Disease.id == disease_id).first()

def get_disease_by_icd10(db: Session, icd10_code: str) -> Optional[models.Disease]:
    """
    RÃ©cupÃ¨re une pathologie par son code CIM-10.
    """
    return db.query(models.Disease).filter(models.Disease.code_icd10 == icd10_code).first()

def get_all_diseases(db: Session, skip: int = 0, limit: int = 100) -> List[models.Disease]:
    """
    RÃ©cupÃ¨re une liste de toutes les pathologies avec pagination.
    """
    return db.query(models.Disease).offset(skip).limit(limit).all()

def create_disease(db: Session, disease: schemas.DiseaseCreate) -> models.Disease:
    """
    CrÃ©e une nouvelle pathologie dans la base de donnÃ©es.
    """
    disease_data = disease.model_dump()
    db_disease = models.Disease(**disease_data)
    
    db.add(db_disease)
    db.commit()
    db.refresh(db_disease)
    
    return db_disease

def update_disease(db: Session, disease_id: int, disease_update: schemas.DiseaseUpdate) -> Optional[models.Disease]:
    """
    Met Ã  jour une pathologie existante.
    """
    db_disease = get_disease_by_id(db, disease_id)
    if not db_disease:
        return None

    update_data = disease_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_disease, key, value)
        
    db.commit()
    db.refresh(db_disease)
    
    return db_disease

def delete_disease(db: Session, disease_id: int) -> Optional[models.Disease]:
    """
    Supprime une pathologie de la base de donnÃ©es.
    """
    db_disease = get_disease_by_id(db, disease_id)
    if not db_disease:
        return None

    db.delete(db_disease)
    db.commit()
    
    return db_disease

def add_symptom_to_disease(db: Session, association_data: schemas.relations.PathologieSymptomeCreate) -> models.PathologieSymptome:
    """
    Associe un symptÃ´me Ã  une pathologie avec des attributs de relation.
    """
    # VÃ©rifier que la pathologie et le symptÃ´me existent
    db_disease = get_disease_by_id(db, disease_id=association_data.pathologie_id)
    # Nous aurons besoin d'importer le symptom_service pour cette vÃ©rification
    from . import symptom_service
    db_symptom = symptom_service.get_symptom_by_id(db, symptom_id=association_data.symptome_id)

    if not db_disease or not db_symptom:
        # IdÃ©alement, lever une exception plus spÃ©cifique
        raise ValueError("Pathologie ou SymptÃ´me non trouvÃ©.")

    # CrÃ©er l'objet d'association
    association = models.PathologieSymptome(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_symptoms_for_disease(db: Session, disease_id: int) -> List[models.PathologieSymptome]:
    """
    RÃ©cupÃ¨re tous les symptÃ´mes associÃ©s Ã  une pathologie, avec les dÃ©tails de la relation.
    """
    return db.query(models.PathologieSymptome).filter(models.PathologieSymptome.pathologie_id == disease_id).all()


def add_treatment_to_disease(db: Session, association_data: schemas.relations.TraitementPathologieCreate) -> models.TraitementPathologie:
    """
    Associe un mÃ©dicament Ã  une pathologie en tant que traitement.
    """
    db_disease = get_disease_by_id(db, disease_id=association_data.pathologie_id)
    from . import medication_service
    db_medication = medication_service.get_medication_by_id(db, medication_id=association_data.medicament_id)

    if not db_disease or not db_medication:
        raise ValueError("Pathologie ou MÃ©dicament non trouvÃ©.")

    association = models.TraitementPathologie(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_treatments_for_disease(db: Session, disease_id: int) -> List[models.TraitementPathologie]:
    """
    RÃ©cupÃ¨re tous les traitements associÃ©s Ã  une pathologie.
    """
    return db.query(models.TraitementPathologie).filter(models.TraitementPathologie.pathologie_id == disease_id).all()

=== Fichier: ./python_files_backup/app/dependencies.py ===

# app/dependencies.py
from .database import SessionLocal

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

=== Fichier: ./python_files_backup/app/middleware/logging_middleware.py ===



=== Fichier: ./python_files_backup/app/middleware/__init__.py ===



=== Fichier: ./python_files_backup/app/middleware/error_handler.py ===



=== Fichier: ./python_files_backup/app/middleware/cors_middleware.py ===



=== Fichier: ./python_files_backup/app/config.py ===

from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # ... (existant)
    DATABASE_URL: str
    
    # --- AJOUT ---
    CLOUDINARY_CLOUD_NAME: str
    CLOUDINARY_API_KEY: str
    CLOUDINARY_API_SECRET: str
    # -------------

    class Config:
        env_file = ".env"
        extra = "ignore"

settings = Settings()

=== Fichier: ./python_files_backup/app/utils/anonymization.py ===



=== Fichier: ./python_files_backup/app/utils/__init__.py ===



=== Fichier: ./python_files_backup/app/utils/formatters.py ===



=== Fichier: ./python_files_backup/app/utils/crypto.py ===



=== Fichier: ./python_files_backup/app/utils/validators.py ===



=== Fichier: ./python_files_backup/app/utils/exceptions.py ===

# app/utils/exceptions.py

class NotFoundException(Exception):
    """
    Exception personnalisÃ©e Ã  lever lorsque'une ressource n'est pas trouvÃ©e
    dans la base de donnÃ©es.
    """
    def __init__(self, detail: str):
        self.detail = detail

=== Fichier: ./python_files_backup/app/utils/logging.py ===



=== Fichier: ./python_files_backup/setup.py ===



=== Fichier: ./python_files_backup/llm_integration/prompt_templates/patient_simulation.py ===



=== Fichier: ./python_files_backup/llm_integration/prompt_templates/__init__.py ===



=== Fichier: ./python_files_backup/llm_integration/prompt_templates/diagnostic_guidance.py ===



=== Fichier: ./python_files_backup/llm_integration/prompt_templates/feedback_generation.py ===



=== Fichier: ./python_files_backup/llm_integration/rag/__init__.py ===



=== Fichier: ./python_files_backup/llm_integration/rag/response_generator.py ===



=== Fichier: ./python_files_backup/llm_integration/rag/retriever.py ===



=== Fichier: ./python_files_backup/llm_integration/__init__.py ===



=== Fichier: ./python_files_backup/llm_integration/training/conversation_extractor.py ===



=== Fichier: ./python_files_backup/llm_integration/training/__init__.py ===



=== Fichier: ./python_files_backup/llm_integration/training/dataset_preparation.py ===



=== Fichier: ./python_files_backup/llm_integration/training/finetuning_pipeline.py ===



=== Fichier: ./python_files_backup/llm_integration/conversation/__init__.py ===



=== Fichier: ./python_files_backup/llm_integration/conversation/patient_agent.py ===



=== Fichier: ./python_files_backup/llm_integration/conversation/dialogue_manager.py ===



=== Fichier: ./python_files_backup/llm_integration/conversation/tutor_agent.py ===



=== Fichier: ./python_files_backup/alembic/versions/7108003f9629_add_cas_symptomes_association_and_.py ===

"""Add cas_symptomes association and update models

Revision ID: 7108003f9629
Revises: 4f66bc9b6081
Create Date: 2025-11-07 10:04:10.734115+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '7108003f9629'
down_revision = '4f66bc9b6081'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('cas_symptomes')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_symptomes',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('cas_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('symptome_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('details_contextuels', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True, comment="Description narrative du symptÃ´me dans ce cas (ex: 'FiÃ¨vre Ã  40Â°C depuis 3 jours')"),
    sa.ForeignKeyConstraint(['cas_id'], ['cas_cliniques_enrichis.id'], name=op.f('cas_symptomes_cas_id_fkey')),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], name=op.f('cas_symptomes_symptome_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('cas_symptomes_pkey'))
    )
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/b6afb34f22d7_add_publication_status_to_clinical_cases.py ===

"""Add publication status to clinical cases

Revision ID: b6afb34f22d7
Revises: a0ee48d62174
Create Date: 2026-01-11 22:28:01.220042+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'b6afb34f22d7'
down_revision = 'a0ee48d62174'
branch_labels = None
depends_on = None


def upgrade() -> None:
    print("\n--- [LOG] DÃ‰BUT de la migration 'b6afb34f22d7' (upgrade) ---")
    
    try:
        print("    -> Tentative de suppression de la contrainte 'learner_knowledge_concept_id_fkey'")
        op.drop_constraint(
            'learner_knowledge_concept_id_fkey',
            'learner_knowledge',
            type_='foreignkey'
        )
        print("    -> âœ… Contrainte supprimÃ©e.")
    except Exception as e:
        print(f"    -> âš ï¸ Ã‰chec de la suppression de la contrainte (peut-Ãªtre dÃ©jÃ  supprimÃ©e) : {e}")

    try:
        print("    -> Tentative de suppression de la table 'concepts'")
        op.drop_table('concepts')
        print("    -> âœ… Table supprimÃ©e.")
    except Exception as e:
        print(f"    -> âš ï¸ Ã‰chec de la suppression de la table (peut-Ãªtre dÃ©jÃ  supprimÃ©e) : {e}")
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_learning_histories_id'), table_name='learning_histories')
    op.drop_table('learning_histories')
    op.drop_index(op.f('ix_learner_performances_id'), table_name='learner_performances')
    op.drop_table('learner_performances')
    op.drop_index(op.f('ix_learner_behaviors_id'), table_name='learner_behaviors')
    op.drop_table('learner_behaviors')
    op.drop_index(op.f('ix_concepts_id'), table_name='concepts')
    op.drop_table('concepts')
    op.drop_index(op.f('ix_learner_knowledge_id'), table_name='learner_knowledge')
    op.drop_table('learner_knowledge')
    op.add_column('cas_cliniques_enrichis', sa.Column('statut_publication', sa.String(length=50), nullable=False, comment='Statut du cas: brouillon, en_revision, valide, archive'))
    op.create_index(op.f('ix_cas_cliniques_enrichis_statut_publication'), 'cas_cliniques_enrichis', ['statut_publication'], unique=False)
    op.drop_index(op.f('ix_tutor_decisions_case_id'), table_name='tutor_decisions')
    op.drop_index(op.f('ix_tutor_decisions_learner_id'), table_name='tutor_decisions')
    op.drop_column('tutor_decisions', 'learner_id')
    op.drop_column('tutor_decisions', 'case_id')
    op.drop_column('tutor_decisions', 'metadata_snapshot')
    op.drop_column('tutor_socratic_state', 'updated_at')
    op.drop_column('tutor_socratic_state', 'current_step_focus')
    op.drop_column('tutor_socratic_state', 'last_question_asked')
    op.drop_column('tutor_socratic_state', 'dialogue_history')

    op.drop_constraint(
        'learner_knowledge_concept_id_fkey', # Le nom de la contrainte
        'learner_knowledge',                 # La table oÃ¹ elle se trouve
        type_='foreignkey'
    )
    # --------------------

    # 2. Maintenant, on peut supprimer la table
    op.drop_table('concepts')

    # ... reste du fichier (probablement l'ajout de la colonne 'statut_publication')
    op.add_column('cas_cliniques_enrichis', sa.Column('statut_publication', sa.String(length=50), nullable=False, server_default='brouillon'))
    
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('tutor_socratic_state', sa.Column('dialogue_history', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'[]'::jsonb"), autoincrement=False, nullable=True))
    op.add_column('tutor_socratic_state', sa.Column('last_question_asked', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('tutor_socratic_state', sa.Column('current_step_focus', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('tutor_socratic_state', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True))
    op.add_column('tutor_decisions', sa.Column('metadata_snapshot', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=True))
    op.add_column('tutor_decisions', sa.Column('case_id', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('tutor_decisions', sa.Column('learner_id', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.create_index(op.f('ix_tutor_decisions_learner_id'), 'tutor_decisions', ['learner_id'], unique=False)
    op.create_index(op.f('ix_tutor_decisions_case_id'), 'tutor_decisions', ['case_id'], unique=False)
    op.drop_index(op.f('ix_cas_cliniques_enrichis_statut_publication'), table_name='cas_cliniques_enrichis')
    op.drop_column('cas_cliniques_enrichis', 'statut_publication')
    op.create_table('learner_knowledge',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('concept_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('mastery_level', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['concept_id'], ['concepts.id'], name=op.f('learner_knowledge_concept_id_fkey')),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learner_knowledge_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learner_knowledge_pkey'))
    )
    op.create_index(op.f('ix_learner_knowledge_id'), 'learner_knowledge', ['id'], unique=False)
    op.create_table('concepts',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('concepts_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('p_init', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('p_transit', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('p_guess', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('p_slip', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='concepts_pkey'),
    sa.UniqueConstraint('name', name='concepts_name_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('ix_concepts_id'), 'concepts', ['id'], unique=False)
    op.create_table('learner_behaviors',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('sessions_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('activities_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('total_time_spent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('engagement_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learner_behaviors_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learner_behaviors_pkey'))
    )
    op.create_index(op.f('ix_learner_behaviors_id'), 'learner_behaviors', ['id'], unique=False)
    op.create_table('learner_performances',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('concept_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('activity_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('time_spent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('attempts', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['concept_id'], ['concepts.id'], name=op.f('learner_performances_concept_id_fkey')),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learner_performances_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learner_performances_pkey'))
    )
    op.create_index(op.f('ix_learner_performances_id'), 'learner_performances', ['id'], unique=False)
    op.create_table('learning_histories',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('activity_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('activity_ref', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('success', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('score', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('time_spent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learning_histories_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learning_histories_pkey'))
    )
    op.create_index(op.f('ix_learning_histories_id'), 'learning_histories', ['id'], unique=False)
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/994203ee2537_add_cas_symptomes_association_table.py ===

"""Add cas_symptomes association table

Revision ID: 994203ee2537
Revises: a6bc48307908
Create Date: 2025-11-07 09:49:25.031773+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '994203ee2537'
down_revision = 'a6bc48307908'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('cas_id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('details_contextuels', sa.JSON(), nullable=True, comment="Description narrative du symptÃ´me dans ce cas (ex: 'FiÃ¨vre Ã  40Â°C depuis 3 jours')"),
    sa.ForeignKeyConstraint(['cas_id'], ['cas_cliniques_enrichis.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_nullable=False)
    op.drop_table('cas_symptomes')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/bc127903e3d2_add_expert_validateur_id_to_clinicalcase.py ===

"""Add expert_validateur_id to ClinicalCase

Revision ID: bc127903e3d2
Revises: 16068309bdb8
Create Date: 2025-12-25 00:23:58.911118+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector


# revision identifiers, used by Alembic.
revision = 'bc127903e3d2'
down_revision = '16068309bdb8'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('expert_validateur_id', sa.Integer(), nullable=True))
    op.create_foreign_key(None, 'cas_cliniques_enrichis', 'experts', ['expert_validateur_id'], ['id'])
    op.drop_column('cas_cliniques_enrichis', 'expert_validateur')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('expert_validateur', sa.VARCHAR(length=255), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'cas_cliniques_enrichis', type_='foreignkey')
    op.drop_column('cas_cliniques_enrichis', 'expert_validateur_id')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/bc4cda91a030_add_learner_tracking_and_tutor_tables.py ===

"""Add Learner, Tracking and Tutor tables

Revision ID: bc4cda91a030
Revises: afeac86179db
Create Date: 2025-12-19 10:03:40.038591+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'bc4cda91a030'
down_revision = 'afeac86179db'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/a6bc48307908_create_clinical_cases_table.py ===

"""Create clinical_cases table

Revision ID: a6bc48307908
Revises: b2699b90c4a9
Create Date: 2025-11-07 09:29:53.852125+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'a6bc48307908'
down_revision = 'b2699b90c4a9'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_cliniques_enrichis',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_fultang', sa.String(length=100), nullable=True, comment='Identifiant unique provenant de Fultang (ou synthÃ©tique)'),
    sa.Column('hash_integrite', sa.String(length=64), nullable=True, comment="SHA-256 pour la preuve d'intÃ©gritÃ© des donnÃ©es brutes"),
    sa.Column('pathologie_principale_id', sa.Integer(), nullable=True),
    sa.Column('donnees_brutes', sa.JSON(), nullable=True, comment='DonnÃ©es originales (ex: de Fultang) avant traitement'),
    sa.Column('presentation_clinique', sa.JSON(), nullable=False, comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.'),
    sa.Column('donnees_paracliniques', sa.JSON(), nullable=True, comment='RÃ©sultats des examens pour ce cas spÃ©cifique'),
    sa.Column('evolution_patient', sa.Text(), nullable=True, comment="Description de l'Ã©volution du patient pendant le cas"),
    sa.Column('images_associees_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste des IDs des images de la table 'images_medicales'"),
    sa.Column('sons_associes_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste des IDs des sons de la table 'sons_medicaux'"),
    sa.Column('medicaments_prescrits', sa.JSON(), nullable=True, comment='Liste des mÃ©dicaments prescrits dans ce cas'),
    sa.Column('niveau_difficulte', sa.Integer(), nullable=True, comment='DifficultÃ© du cas (1-5)'),
    sa.Column('duree_estimee_resolution_min', sa.Integer(), nullable=True, comment='Temps estimÃ© pour rÃ©soudre le cas'),
    sa.Column('objectifs_apprentissage', sa.JSON(), nullable=True, comment='Liste des compÃ©tences Ã  acquÃ©rir'),
    sa.Column('competences_requises', sa.JSON(), nullable=True, comment='Mapping Q-Matrix pour ce cas'),
    sa.Column('valide_expert', sa.Boolean(), nullable=True),
    sa.Column('expert_validateur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('qualite_donnees', sa.Integer(), nullable=True, comment='QualitÃ© des donnÃ©es sources (1-5)'),
    sa.Column('nb_utilisations', sa.Integer(), nullable=True),
    sa.Column('note_moyenne_apprenants', sa.DECIMAL(precision=3, scale=2), nullable=True),
    sa.Column('taux_succes_diagnostic', sa.DECIMAL(precision=5, scale=2), nullable=True),
    sa.Column('embedding_texte', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment='Embedding de la description textuelle du cas'),
    sa.Column('embedding_global', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True, comment='Embedding multimodal fusionnÃ© (texte+image+son)'),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['pathologie_principale_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_cas_cliniques_enrichis_code_fultang'), 'cas_cliniques_enrichis', ['code_fultang'], unique=True)
    op.create_index(op.f('ix_cas_cliniques_enrichis_id'), 'cas_cliniques_enrichis', ['id'], unique=False)
    op.create_index(op.f('ix_cas_cliniques_enrichis_pathologie_principale_id'), 'cas_cliniques_enrichis', ['pathologie_principale_id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_cas_cliniques_enrichis_pathologie_principale_id'), table_name='cas_cliniques_enrichis')
    op.drop_index(op.f('ix_cas_cliniques_enrichis_id'), table_name='cas_cliniques_enrichis')
    op.drop_index(op.f('ix_cas_cliniques_enrichis_code_fultang'), table_name='cas_cliniques_enrichis')
    op.drop_table('cas_cliniques_enrichis')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/4f66bc9b6081_add_cas_symptomes_association_and_.py ===

"""Add cas_symptomes association and update models

Revision ID: 4f66bc9b6081
Revises: 994203ee2537
Create Date: 2025-11-07 10:03:23.727581+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '4f66bc9b6081'
down_revision = '994203ee2537'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_nullable=False)
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/eb403e41e275_fix_expert_validateur_relationship.py ===

"""fix expert_validateur relationship

Revision ID: eb403e41e275
Revises: bc127903e3d2
Create Date: 2025-12-25 00:30:17.468368+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector


# revision identifiers, used by Alembic.
revision = 'eb403e41e275'
down_revision = 'bc127903e3d2'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/5c3894aa1b50_change_embedding_dimensions_to_384.py ===

"""change embedding dimensions to 384

Revision ID: 5c3894aa1b50
Revises: eb403e41e275
Create Date: 2025-12-26 00:14:27.010127+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '5c3894aa1b50'
down_revision = 'eb403e41e275'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'embedding_texte',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment='Embedding de la description textuelle du cas',
               existing_nullable=True)
    op.alter_column('images_medicales', 'embedding_vision',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle",
               existing_nullable=True)
    op.alter_column('medicaments', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires",
               existing_nullable=True)
    op.alter_column('pathologies', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique",
               existing_nullable=True)
    op.alter_column('symptomes', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)",
               existing_nullable=True)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('symptomes', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)",
               existing_nullable=True)
    op.alter_column('pathologies', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique",
               existing_nullable=True)
    op.alter_column('medicaments', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires",
               existing_nullable=True)
    op.alter_column('images_medicales', 'embedding_vision',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle",
               existing_nullable=True)
    op.alter_column('cas_cliniques_enrichis', 'embedding_texte',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment='Embedding de la description textuelle du cas',
               existing_nullable=True)
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/de1d3372f456_add_secondary_pathologies_to_clinical_.py ===

"""Add secondary pathologies to clinical cases

Revision ID: de1d3372f456
Revises: 7108003f9629
Create Date: 2025-11-07 13:38:16.973024+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'de1d3372f456'
down_revision = '7108003f9629'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('pathologies_secondaires_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste d'IDs de pathologies comorbides ou secondaires"))
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('cas_cliniques_enrichis', 'pathologies_secondaires_ids')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/f29ac6884d1c_create_medications_table.py ===

"""Create medications table

Revision ID: f29ac6884d1c
Revises: 8e5b38bb2891
Create Date: 2025-11-06 20:17:47.401019+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'f29ac6884d1c'
down_revision = '8e5b38bb2891'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('medicaments',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('nom_commercial', sa.String(length=255), nullable=True),
    sa.Column('dci', sa.String(length=255), nullable=False, comment='DÃ©nomination Commune Internationale'),
    sa.Column('classe_therapeutique', sa.String(length=255), nullable=True),
    sa.Column('forme_galenique', sa.String(length=100), nullable=True, comment='Ex: ComprimÃ©, Sirop, Injectable'),
    sa.Column('dosage', sa.String(length=100), nullable=True),
    sa.Column('voie_administration', sa.String(length=100), nullable=True, comment='Ex: Orale, IV, IM, CutanÃ©e'),
    sa.Column('mecanisme_action', sa.Text(), nullable=True),
    sa.Column('indications', sa.JSON(), nullable=True),
    sa.Column('contre_indications', sa.JSON(), nullable=True),
    sa.Column('effets_secondaires', sa.JSON(), nullable=True),
    sa.Column('interactions_medicamenteuses', sa.JSON(), nullable=True),
    sa.Column('precautions_emploi', sa.Text(), nullable=True),
    sa.Column('posologie_standard', sa.JSON(), nullable=True, comment='Posologie standard par Ã¢ge, poids, indication'),
    sa.Column('disponibilite_cameroun', sa.String(length=50), nullable=True, comment='Ex: Urbain, Rural, CHU_uniquement'),
    sa.Column('cout_moyen_fcfa', sa.Integer(), nullable=True),
    sa.Column('statut_prescription', sa.String(length=50), nullable=True, comment='Ex: Prescription_obligatoire, OTC'),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_medicaments_classe_therapeutique'), 'medicaments', ['classe_therapeutique'], unique=False)
    op.create_index(op.f('ix_medicaments_dci'), 'medicaments', ['dci'], unique=False)
    op.create_index(op.f('ix_medicaments_id'), 'medicaments', ['id'], unique=False)
    op.create_index(op.f('ix_medicaments_nom_commercial'), 'medicaments', ['nom_commercial'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_medicaments_nom_commercial'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_id'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_dci'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_classe_therapeutique'), table_name='medicaments')
    op.drop_table('medicaments')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/8e5b38bb2891_create_symptoms_table.py ===

"""Create symptoms table

Revision ID: 8e5b38bb2891
Revises: 6eb5a7dba20c
Create Date: 2025-11-06 19:31:00.822591+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '8e5b38bb2891'
down_revision = '6eb5a7dba20c'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('pathologie_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('pathologie_id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('probabilite', sa.DECIMAL(precision=5, scale=4), nullable=True, comment="ProbabilitÃ© d'apparition du symptÃ´me pour cette pathologie P(symptÃ´me|pathologie)"),
    sa.Column('sensibilite', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('specificite', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('phase_maladie', sa.String(length=50), nullable=True, comment='Phase de la maladie oÃ¹ le symptÃ´me apparaÃ®t (ex: PrÃ©coce, Tardive)'),
    sa.Column('frequence', sa.String(length=50), nullable=True, comment="FrÃ©quence d'apparition (ex: Constant, FrÃ©quent, Occasionnel)"),
    sa.Column('est_pathognomonique', sa.Boolean(), nullable=True, comment='Si True, ce symptÃ´me seul suffit presque Ã  poser le diagnostic'),
    sa.Column('importance_diagnostique', sa.Integer(), nullable=True, comment="Ã‰chelle de 1 Ã  5 sur l'importance de ce symptÃ´me pour le diagnostic"),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('pathologie_symptomes')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/4b1e2599b918_initial_empty_migration.py ===

"""Initial empty migration

Revision ID: 4b1e2599b918
Revises: 
Create Date: 2025-11-06 11:09:36.525928+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '4b1e2599b918'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    pass


def downgrade():
    pass


=== Fichier: ./python_files_backup/alembic/versions/b2699b90c4a9_create_media_table.py ===

"""Create media table

Revision ID: b2699b90c4a9
Revises: 9aed193ba8b7
Create Date: 2025-11-07 07:45:54.209466+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'b2699b90c4a9'
down_revision = '9aed193ba8b7'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('images_medicales',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('type_examen', sa.String(length=100), nullable=False, comment='Ex: Radiographie, Ã‰chographie, Scanner'),
    sa.Column('sous_type', sa.String(length=100), nullable=True, comment='Ex: Thorax, Abdomen, CrÃ¢ne'),
    sa.Column('pathologie_id', sa.Integer(), nullable=True),
    sa.Column('fichier_url', sa.String(length=500), nullable=False, comment='URL vers le fichier (S3, stockage local, etc.)'),
    sa.Column('fichier_miniature_url', sa.String(length=500), nullable=True, comment="URL vers une version miniature de l'image"),
    sa.Column('format_image', sa.String(length=20), nullable=True, comment='Ex: DICOM, PNG, JPEG'),
    sa.Column('taille_ko', sa.Integer(), nullable=True),
    sa.Column('resolution', sa.String(length=50), nullable=True),
    sa.Column('description', sa.Text(), nullable=True, comment="Description gÃ©nÃ©rale de l'image ou du cas"),
    sa.Column('signes_radiologiques', sa.JSON(), nullable=True, comment='Signes spÃ©cifiques visibles (ex: opacitÃ©, Ã©panchement)'),
    sa.Column('annotations', sa.JSON(), nullable=True, comment="CoordonnÃ©es et descriptions de zones d'intÃ©rÃªt"),
    sa.Column('interpretation_experte', sa.Text(), nullable=True, comment="Compte-rendu d'un radiologue expert"),
    sa.Column('diagnostic_differentiel', sa.JSON(), nullable=True, comment="Autres diagnostics possibles basÃ©s sur l'image"),
    sa.Column('niveau_difficulte', sa.Integer(), nullable=True, comment="DifficultÃ© d'interprÃ©tation de l'image (1-5)"),
    sa.Column('qualite_image', sa.Integer(), nullable=True, comment="QualitÃ© technique de l'image (1-5)"),
    sa.Column('embedding_vision', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle"),
    sa.Column('valide_expert', sa.Boolean(), nullable=True),
    sa.Column('expert_validateur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_images_medicales_id'), 'images_medicales', ['id'], unique=False)
    op.create_index(op.f('ix_images_medicales_pathologie_id'), 'images_medicales', ['pathologie_id'], unique=False)
    op.create_index(op.f('ix_images_medicales_type_examen'), 'images_medicales', ['type_examen'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_images_medicales_type_examen'), table_name='images_medicales')
    op.drop_index(op.f('ix_images_medicales_pathologie_id'), table_name='images_medicales')
    op.drop_index(op.f('ix_images_medicales_id'), table_name='images_medicales')
    op.drop_table('images_medicales')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/afeac86179db_create_competencies_and_prerequisites_.py ===

"""Create competencies and prerequisites tables

Revision ID: afeac86179db
Revises: 03d192a5f522
Create Date: 2025-11-29 20:23:29.605930+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'afeac86179db'
down_revision = '03d192a5f522'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('competences_cliniques',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_competence', sa.String(length=50), nullable=False, comment="Code unique (ex: 'ANAMNESE_DOULEUR')"),
    sa.Column('nom', sa.String(length=255), nullable=False),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: Anamnese, Examen_physique, Raisonnement, Technique'),
    sa.Column('niveau_bloom', sa.Integer(), nullable=True, comment='Niveau dans la taxonomie de Bloom (1-6)'),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('objectifs_apprentissage', sa.JSON(), nullable=True, comment='Liste dÃ©taillÃ©e des objectifs'),
    sa.Column('criteres_maitrise', sa.JSON(), nullable=True, comment='CritÃ¨res pour valider la compÃ©tence'),
    sa.Column('parent_competence_id', sa.Integer(), nullable=True),
    sa.Column('ordre_apprentissage', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['parent_competence_id'], ['competences_cliniques.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_competences_cliniques_categorie'), 'competences_cliniques', ['categorie'], unique=False)
    op.create_index(op.f('ix_competences_cliniques_code_competence'), 'competences_cliniques', ['code_competence'], unique=True)
    op.create_index(op.f('ix_competences_cliniques_id'), 'competences_cliniques', ['id'], unique=False)
    op.create_table('prerequis_competences',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('competence_id', sa.Integer(), nullable=False),
    sa.Column('prerequis_id', sa.Integer(), nullable=False),
    sa.Column('type_relation', sa.String(length=50), nullable=True, comment='STRICT, RECOMMANDE, SUPPORTIF'),
    sa.Column('force_relation', sa.DECIMAL(precision=3, scale=2), nullable=True, comment='Force du lien (0-1)'),
    sa.ForeignKeyConstraint(['competence_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['prerequis_id'], ['competences_cliniques.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('prerequis_competences')
    op.drop_index(op.f('ix_competences_cliniques_id'), table_name='competences_cliniques')
    op.drop_index(op.f('ix_competences_cliniques_code_competence'), table_name='competences_cliniques')
    op.drop_index(op.f('ix_competences_cliniques_categorie'), table_name='competences_cliniques')
    op.drop_table('competences_cliniques')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/7995e67f8833_create_symptoms_table.py ===

"""Create symptoms table

Revision ID: 7995e67f8833
Revises: 4b1e2599b918
Create Date: 2025-11-06 12:48:47.725270+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '7995e67f8833'
down_revision = '4b1e2599b918'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('nom', sa.String(length=255), nullable=False),
    sa.Column('nom_local', sa.String(length=255), nullable=True, comment="Nom vernaculaire ou local, ex: 'Ntou-tou' pour la toux"),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='CatÃ©gorie fonctionnelle (ex: Respiratoire, Neurologique, Digestif)'),
    sa.Column('type_symptome', sa.String(length=50), nullable=True, comment='Type de symptÃ´me (ex: Subjectif, Objectif, Signe clinique)'),
    sa.Column('description', sa.Text(), nullable=True, comment='Description dÃ©taillÃ©e du symptÃ´me et de sa signification clinique.'),
    sa.Column('questions_anamnese', sa.JSON(), nullable=True, comment='Liste structurÃ©e de questions pour explorer ce symptÃ´me (ex: PQRST)'),
    sa.Column('signes_alarme', sa.Boolean(), nullable=False, comment="Indique si ce symptÃ´me est un signe de gravitÃ© ('red flag')"),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_symptomes_categorie'), 'symptomes', ['categorie'], unique=False)
    op.create_index(op.f('ix_symptomes_id'), 'symptomes', ['id'], unique=False)
    op.create_index(op.f('ix_symptomes_nom'), 'symptomes', ['nom'], unique=True)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_symptomes_nom'), table_name='symptomes')
    op.drop_index(op.f('ix_symptomes_id'), table_name='symptomes')
    op.drop_index(op.f('ix_symptomes_categorie'), table_name='symptomes')
    op.drop_table('symptomes')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/16068309bdb8_add_learner_tracking_tutor_and_.py ===

"""Add Learner, Tracking, Tutor and ExpertUser tables

Revision ID: 16068309bdb8
Revises: bc4cda91a030
Create Date: 2025-12-23 02:00:58.044928+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '16068309bdb8'
down_revision = 'bc4cda91a030'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('experts',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('email', sa.String(length=255), nullable=False),
    sa.Column('hashed_password', sa.String(length=255), nullable=False),
    sa.Column('nom_complet', sa.String(length=255), nullable=True),
    sa.Column('specialite', sa.String(length=100), nullable=True),
    sa.Column('hopital_affiliation', sa.String(length=255), nullable=True),
    sa.Column('role', sa.String(length=50), nullable=True),
    sa.Column('last_login', sa.TIMESTAMP(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_experts_email'), 'experts', ['email'], unique=True)
    op.create_index(op.f('ix_experts_id'), 'experts', ['id'], unique=False)
    op.create_table('learners',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('matricule', sa.String(length=50), nullable=True),
    sa.Column('nom', sa.String(length=255), nullable=True),
    sa.Column('email', sa.String(length=255), nullable=True),
    sa.Column('niveau_etudes', sa.String(length=50), nullable=True),
    sa.Column('specialite_visee', sa.String(length=100), nullable=True),
    sa.Column('langue_preferee', sa.String(length=10), nullable=True),
    sa.Column('date_inscription', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learners_email'), 'learners', ['email'], unique=True)
    op.create_index(op.f('ix_learners_id'), 'learners', ['id'], unique=False)
    op.create_index(op.f('ix_learners_matricule'), 'learners', ['matricule'], unique=True)
    op.create_table('learner_achievements',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('badge_id', sa.String(length=100), nullable=True),
    sa.Column('date_obtention', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_cognitive_profiles',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('vitesse_assimilation', sa.Float(), nullable=True),
    sa.Column('capacite_memoire_travail', sa.Float(), nullable=True),
    sa.Column('tendance_impulsivite', sa.Float(), nullable=True),
    sa.Column('prefer_visual', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('learner_id')
    )
    op.create_table('learner_competency_mastery',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('competence_id', sa.Integer(), nullable=False),
    sa.Column('mastery_level', sa.Float(), nullable=True),
    sa.Column('confidence', sa.Float(), nullable=True),
    sa.Column('last_practice_date', sa.TIMESTAMP(), nullable=True),
    sa.Column('nb_success', sa.Integer(), nullable=True),
    sa.Column('nb_failures', sa.Integer(), nullable=True),
    sa.Column('streak_correct', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['competence_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learner_competency_mastery_id'), 'learner_competency_mastery', ['id'], unique=False)
    op.create_table('learner_goals',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('type_objectif', sa.String(length=100), nullable=True),
    sa.Column('domaine_cible', sa.String(length=100), nullable=True),
    sa.Column('date_limite', sa.TIMESTAMP(), nullable=True),
    sa.Column('statut', sa.String(length=50), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_misconceptions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('type_erreur', sa.String(length=255), nullable=True),
    sa.Column('frequence_apparition', sa.Integer(), nullable=True),
    sa.Column('resistance_correction', sa.Float(), nullable=True),
    sa.Column('detected_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_preferences',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('cle', sa.String(length=100), nullable=True),
    sa.Column('valeur', sa.String(length=255), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_strategies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('strategy_name', sa.String(length=100), nullable=True),
    sa.Column('frequency', sa.Integer(), nullable=True),
    sa.Column('effectiveness', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learning_paths',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('algorithme_recommandation', sa.String(length=100), nullable=True),
    sa.Column('ordered_case_ids', sa.JSON(), nullable=True, comment='Liste ordonnÃ©e des IDs des cas'),
    sa.Column('progression', sa.Float(), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learning_paths_id'), 'learning_paths', ['id'], unique=False)
    op.create_table('simulation_sessions',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('cas_clinique_id', sa.Integer(), nullable=False),
    sa.Column('start_time', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('end_time', sa.TIMESTAMP(), nullable=True),
    sa.Column('score_final', sa.Float(), nullable=True),
    sa.Column('temps_total', sa.Integer(), nullable=True),
    sa.Column('cout_virtuel_genere', sa.Integer(), nullable=True),
    sa.Column('statut', sa.String(length=50), nullable=True),
    sa.Column('raison_fin', sa.String(length=100), nullable=True),
    sa.Column('current_stage', sa.String(length=50), nullable=True),
    sa.Column('context_state', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['cas_clinique_id'], ['cas_cliniques_enrichis.id'], ),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('chat_messages',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('sender', sa.String(length=50), nullable=True),
    sa.Column('content', sa.Text(), nullable=True),
    sa.Column('intention_detectee', sa.String(length=100), nullable=True),
    sa.Column('sentiment_analyse', sa.String(length=50), nullable=True),
    sa.Column('message_metadata', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_chat_messages_id'), 'chat_messages', ['id'], unique=False)
    op.create_table('interaction_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('action_category', sa.String(length=50), nullable=True),
    sa.Column('action_type', sa.String(length=100), nullable=True),
    sa.Column('action_content', sa.JSON(), nullable=True),
    sa.Column('response_latency', sa.Integer(), nullable=True),
    sa.Column('charge_cognitive_estimee', sa.Float(), nullable=True),
    sa.Column('est_pertinent', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_interaction_logs_id'), 'interaction_logs', ['id'], unique=False)
    op.create_table('learner_affective_states',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('stress_level', sa.Float(), nullable=True),
    sa.Column('confidence_level', sa.Float(), nullable=True),
    sa.Column('motivation_level', sa.Float(), nullable=True),
    sa.Column('frustration_level', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('tutor_feedback_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('feedback_type', sa.String(length=50), nullable=True),
    sa.Column('content', sa.Text(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_feedback_logs_id'), 'tutor_feedback_logs', ['id'], unique=False)
    op.create_table('tutor_motivational_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('intervention_type', sa.String(length=100), nullable=True),
    sa.Column('emotional_state_before', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_motivational_state_id'), 'tutor_motivational_state', ['id'], unique=False)
    op.create_table('tutor_scaffolding_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('competence_cible_id', sa.Integer(), nullable=True),
    sa.Column('current_level', sa.Integer(), nullable=True),
    sa.Column('indices_deja_donnes', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['competence_cible_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_scaffolding_state_id'), 'tutor_scaffolding_state', ['id'], unique=False)
    op.create_table('tutor_socratic_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('tactic_used', sa.String(length=100), nullable=True),
    sa.Column('target_concept', sa.String(length=255), nullable=True),
    sa.Column('step_in_dialogue', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_socratic_state_id'), 'tutor_socratic_state', ['id'], unique=False)
    op.create_table('tutor_strategies_history',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('strategy_name', sa.String(length=100), nullable=True),
    sa.Column('relevance_score', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_strategies_history_id'), 'tutor_strategies_history', ['id'], unique=False)
    op.create_table('tutor_decisions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('trigger_event_id', sa.Integer(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('strategy_used', sa.String(length=100), nullable=True),
    sa.Column('action_choisie', sa.String(length=100), nullable=True),
    sa.Column('intervention_content', sa.Text(), nullable=True),
    sa.Column('rationale', sa.JSON(), nullable=True),
    sa.Column('succes_intervention', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.ForeignKeyConstraint(['trigger_event_id'], ['interaction_logs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_decisions_id'), 'tutor_decisions', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_tutor_decisions_id'), table_name='tutor_decisions')
    op.drop_table('tutor_decisions')
    op.drop_index(op.f('ix_tutor_strategies_history_id'), table_name='tutor_strategies_history')
    op.drop_table('tutor_strategies_history')
    op.drop_index(op.f('ix_tutor_socratic_state_id'), table_name='tutor_socratic_state')
    op.drop_table('tutor_socratic_state')
    op.drop_index(op.f('ix_tutor_scaffolding_state_id'), table_name='tutor_scaffolding_state')
    op.drop_table('tutor_scaffolding_state')
    op.drop_index(op.f('ix_tutor_motivational_state_id'), table_name='tutor_motivational_state')
    op.drop_table('tutor_motivational_state')
    op.drop_index(op.f('ix_tutor_feedback_logs_id'), table_name='tutor_feedback_logs')
    op.drop_table('tutor_feedback_logs')
    op.drop_table('learner_affective_states')
    op.drop_index(op.f('ix_interaction_logs_id'), table_name='interaction_logs')
    op.drop_table('interaction_logs')
    op.drop_index(op.f('ix_chat_messages_id'), table_name='chat_messages')
    op.drop_table('chat_messages')
    op.drop_table('simulation_sessions')
    op.drop_index(op.f('ix_learning_paths_id'), table_name='learning_paths')
    op.drop_table('learning_paths')
    op.drop_table('learner_strategies')
    op.drop_table('learner_preferences')
    op.drop_table('learner_misconceptions')
    op.drop_table('learner_goals')
    op.drop_index(op.f('ix_learner_competency_mastery_id'), table_name='learner_competency_mastery')
    op.drop_table('learner_competency_mastery')
    op.drop_table('learner_cognitive_profiles')
    op.drop_table('learner_achievements')
    op.drop_index(op.f('ix_learners_matricule'), table_name='learners')
    op.drop_index(op.f('ix_learners_id'), table_name='learners')
    op.drop_index(op.f('ix_learners_email'), table_name='learners')
    op.drop_table('learners')
    op.drop_index(op.f('ix_experts_id'), table_name='experts')
    op.drop_index(op.f('ix_experts_email'), table_name='experts')
    op.drop_table('experts')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/6eb5a7dba20c_create_symptoms_table.py ===

"""Create symptoms table

Revision ID: 6eb5a7dba20c
Revises: 7995e67f8833
Create Date: 2025-11-06 19:20:35.224401+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '6eb5a7dba20c'
down_revision = '7995e67f8833'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('pathologies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_icd10', sa.String(length=20), nullable=True, comment='Code international de la maladie (CIM-10)'),
    sa.Column('nom_fr', sa.String(length=255), nullable=False),
    sa.Column('nom_en', sa.String(length=255), nullable=True),
    sa.Column('nom_local', sa.String(length=255), nullable=True, comment='Noms locaux ou courants au Cameroun'),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: Infectieuse, Chronique, Parasitaire'),
    sa.Column('prevalence_cameroun', sa.DECIMAL(precision=5, scale=2), nullable=True, comment='PrÃ©valence en % dans le contexte camerounais'),
    sa.Column('niveau_gravite', sa.Integer(), nullable=True, comment='Ã‰chelle de 1 (bÃ©nin) Ã  5 (critique)'),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('physiopathologie', sa.Text(), nullable=True, comment='MÃ©canisme de la maladie'),
    sa.Column('evolution_naturelle', sa.Text(), nullable=True, comment='Comment la maladie Ã©volue sans traitement'),
    sa.Column('complications', sa.JSON(), nullable=True, comment='Complications possibles'),
    sa.Column('facteurs_risque', sa.JSON(), nullable=True, comment='Facteurs de risque associÃ©s'),
    sa.Column('prevention', sa.Text(), nullable=True, comment='Mesures de prÃ©vention'),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_pathologies_categorie'), 'pathologies', ['categorie'], unique=False)
    op.create_index(op.f('ix_pathologies_code_icd10'), 'pathologies', ['code_icd10'], unique=True)
    op.create_index(op.f('ix_pathologies_id'), 'pathologies', ['id'], unique=False)
    op.create_index(op.f('ix_pathologies_nom_fr'), 'pathologies', ['nom_fr'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_pathologies_nom_fr'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_id'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_code_icd10'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_categorie'), table_name='pathologies')
    op.drop_table('pathologies')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/a0ee48d62174_change_embedding_dimensions_to_384.py ===

"""change embedding dimensions to 384

Revision ID: a0ee48d62174
Revises: 5c3894aa1b50
Create Date: 2025-12-26 00:19:52.135785+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'a0ee48d62174'
down_revision = '5c3894aa1b50'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/9aed193ba8b7_create_therapeutic_relations_tables.py ===

"""Create therapeutic relations tables

Revision ID: 9aed193ba8b7
Revises: f29ac6884d1c
Create Date: 2025-11-06 20:44:30.949745+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '9aed193ba8b7'
down_revision = 'f29ac6884d1c'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('traitements_pathologies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('pathologie_id', sa.Integer(), nullable=False),
    sa.Column('medicament_id', sa.Integer(), nullable=False),
    sa.Column('type_traitement', sa.String(length=50), nullable=True, comment='Ex: Premiere_intention, Alternative, Adjuvant'),
    sa.Column('ligne_traitement', sa.Integer(), nullable=True, comment='Ex: 1Ã¨re ligne, 2e ligne'),
    sa.Column('indication_precise', sa.Text(), nullable=True),
    sa.Column('efficacite_taux', sa.DECIMAL(precision=5, scale=2), nullable=True, comment='Taux de succÃ¨s en %'),
    sa.Column('duree_traitement_jours', sa.Integer(), nullable=True),
    sa.Column('posologie_detaillee', sa.JSON(), nullable=True),
    sa.Column('niveau_preuve', sa.String(length=50), nullable=True, comment='Grade de recommandation (A, B, C)'),
    sa.Column('guidelines_source', sa.String(length=255), nullable=True, comment='Source (OMS, MINSANTE Cameroun, etc.)'),
    sa.Column('rang_preference', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['medicament_id'], ['medicaments.id'], ),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('traitements_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('medicament_id', sa.Integer(), nullable=False),
    sa.Column('efficacite', sa.String(length=50), nullable=True, comment='Ex: Tres_efficace, Efficace, Modere'),
    sa.Column('rapidite_action', sa.String(length=100), nullable=True, comment='Ex: Immediate, <30min'),
    sa.Column('posologie_recommandee', sa.Text(), nullable=True),
    sa.Column('rang_preference', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['medicament_id'], ['medicaments.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('traitements_symptomes')
    op.drop_table('traitements_pathologies')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/alembic/versions/03d192a5f522_add_expert_intelligence.py ===

"""Add expert intelligence

Revision ID: 03d192a5f522
Revises: de1d3372f456
Create Date: 2025-11-07 14:06:32.502322+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '03d192a5f522'
down_revision = 'de1d3372f456'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('regles_production',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_regle', sa.String(length=50), nullable=False),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: DIAGNOSTIC, THERAPEUTIQUE, PEDAGOGIQUE, ALERTE'),
    sa.Column('priorite', sa.Integer(), nullable=True, comment="PrioritÃ© d'exÃ©cution (1-10), 10 Ã©tant le plus prioritaire"),
    sa.Column('conditions', sa.JSON(), nullable=False, comment="Partie 'IF' de la rÃ¨gle, structurÃ©e en JSON"),
    sa.Column('actions', sa.JSON(), nullable=False, comment="Partie 'THEN' de la rÃ¨gle, structurÃ©e en JSON"),
    sa.Column('description_naturelle', sa.Text(), nullable=True, comment='Description de la rÃ¨gle en langage naturel'),
    sa.Column('justification_medicale', sa.Text(), nullable=True, comment='Source ou justification clinique de la rÃ¨gle'),
    sa.Column('expert_auteur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('est_active', sa.Boolean(), nullable=False),
    sa.Column('nb_activations', sa.Integer(), nullable=True),
    sa.Column('taux_succes', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_regles_production_categorie'), 'regles_production', ['categorie'], unique=False)
    op.create_index(op.f('ix_regles_production_code_regle'), 'regles_production', ['code_regle'], unique=True)
    op.create_index(op.f('ix_regles_production_id'), 'regles_production', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_regles_production_id'), table_name='regles_production')
    op.drop_index(op.f('ix_regles_production_code_regle'), table_name='regles_production')
    op.drop_index(op.f('ix_regles_production_categorie'), table_name='regles_production')
    op.drop_table('regles_production')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/scripts/run_dataset_import.py ===

import sys
import os

# Le sys.path.insert n'est plus nÃ©cessaire si on lance avec 'python -m'
# Mais on le garde au cas oÃ¹, en le sÃ©curisant
if __name__ == "__main__" and __package__ is None:
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from datasets.integrators.mimic3_dics_integrator import MIMIC3DictionariesIntegrator
from datasets.integrators.mimic3_integrator import MIMIC3RelationsIntegrator
from datasets.assembler.case_assembler import CaseAssembler
from datasets.integrators.manual_images_integrator import ManualImagesIntegrator

# --- CONFIGURATION DES CHEMINS D'ACCÃˆS ---
MIMIC_BASE_PATH = "/home/clement/TÃ©lÃ©chargements/archive (1)/mimic-iii-clinical-database-demo-1.4"
SOURCE_IMAGES_DIR = "/home/clement/TÃ©lÃ©chargements/imgradio" 
MAPPING_CSV_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'datasets/mapping/images_mapping.csv'))

MIMIC_FILES_PATHS = {
    "d_icd_diagnoses": os.path.join(MIMIC_BASE_PATH, "D_ICD_DIAGNOSES.csv"),
    "d_labitems": os.path.join(MIMIC_BASE_PATH, "D_LABITEMS.csv"),
    "d_items": os.path.join(MIMIC_BASE_PATH, "D_ITEMS.csv"),
    "prescriptions": os.path.join(MIMIC_BASE_PATH, "PRESCRIPTIONS.csv"),
    "diagnoses_icd": os.path.join(MIMIC_BASE_PATH, "DIAGNOSES_ICD.csv"),
    "labevents": os.path.join(MIMIC_BASE_PATH, "LABEVENTS.csv"),
    "admissions": os.path.join(MIMIC_BASE_PATH, "ADMISSIONS.csv"),
}

def check_paths(paths: dict):
    all_found = True
    for key, path in paths.items():
        if not os.path.exists(path):
            print(f"âŒ ERREUR: Fichier non trouvÃ© pour '{key}': {path}")
            all_found = False
    return all_found

def main():
    print("--- DÃ©marrage du script d'importation complet ---")
    
    if not check_paths(MIMIC_FILES_PATHS):
        print("\nAttention: Fichiers MIMIC manquants.")
        # On continue quand mÃªme pour tester les autres intÃ©grateurs si besoin
    
    db_session = SessionLocal()
    
    try:
        print("\n" + "="*50)
        print("Ã‰TAPE 1: PEUPLEMENT DES DICTIONNAIRES")
        dics_integrator = MIMIC3DictionariesIntegrator(db_session=db_session, paths=MIMIC_FILES_PATHS)
        dics_integrator.run_all()

        print("\n" + "="*50)
        print("Ã‰TAPE 2: CRÃ‰ATION DES RELATIONS")
        relations_integrator = MIMIC3RelationsIntegrator(db_session=db_session, paths=MIMIC_FILES_PATHS)
        relations_integrator.run()

        print("\n" + "="*50)
        print("Ã‰TAPE 3: ASSEMBLAGE DES CAS CLINIQUES")
        case_assembler = CaseAssembler(db_session=db_session, paths=MIMIC_FILES_PATHS)
        case_assembler.run()

        print("\n" + "="*50)
        print("Ã‰TAPE 4: IMPORTATION DES IMAGES MANUELLES")
        if not os.path.exists(MAPPING_CSV_PATH):
            print(f"âŒ ERREUR: Fichier de mapping non trouvÃ© : {MAPPING_CSV_PATH}")
        else:
            images_integrator = ManualImagesIntegrator(
                db_session=db_session,
                mapping_csv_path=MAPPING_CSV_PATH,
                source_images_dir="" 
            )
            images_integrator.run()

    except Exception as e:
        print(f"\nâŒ UNE ERREUR CRITIQUE EST SURVENUE : {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        print("\nFermeture de la session de base de donnÃ©es.")
        db_session.close()

if __name__ == "__main__":
    main()

=== Fichier: ./python_files_backup/scripts/run_assembler.py ===



=== Fichier: ./python_files_backup/scripts/generate_q_matrix.py ===

import sys
import os

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app import models

def generate_matrix():
    db = SessionLocal()
    print("--- GÃ©nÃ©ration de la Q-Matrix (Lien Cas <-> CompÃ©tences) ---")

    # 1. Charger toutes les compÃ©tences pour avoir leurs IDs et codes
    competencies = db.query(models.Competence).all()
    comp_map = {c.code_competence: c.id for c in competencies}
    
    if not comp_map:
        print("âŒ Aucune compÃ©tence trouvÃ©e. Veuillez lancer populate_competencies.py d'abord.")
        return

    # 2. RÃ©cupÃ©rer tous les cas cliniques
    cases = db.query(models.ClinicalCase).all()
    print(f"Traitement de {len(cases)} cas cliniques...")

    count_updated = 0
    for case in cases:
        required_skills = {} # Dictionnaire pour stocker les compÃ©tences requises {code: id}

        # --- RÃˆGLES D'ATTRIBUTION DES COMPÃ‰TENCES ---

        # RÃ¨gle 1 : Socle commun (Tout cas nÃ©cessite ces bases)
        # Bloom 1-2
        common_skills = ["IDENTIFIER_MOTIF", "EMPATHIE", "ANAMNESE_HISTOIRE"]
        for code in common_skills:
            if code in comp_map:
                required_skills[code] = comp_map[code]

        # RÃ¨gle 2 : Si le cas a des symptÃ´mes biologiques (Labo)
        # Bloom 4
        if case.donnees_paracliniques and "lab_results" in case.donnees_paracliniques:
            if len(case.donnees_paracliniques["lab_results"]) > 0:
                if "INTERPRETATION_BIOLOGIE" in comp_map:
                    required_skills["INTERPRETATION_BIOLOGIE"] = comp_map["INTERPRETATION_BIOLOGIE"]

        # RÃ¨gle 3 : Si le cas a des images
        # Bloom 4
        if case.images_associees_ids and len(case.images_associees_ids) > 0:
            if "INTERPRETATION_IMAGERIE" in comp_map:
                required_skills["INTERPRETATION_IMAGERIE"] = comp_map["INTERPRETATION_IMAGERIE"]

        # RÃ¨gle 4 : Si le cas a des mÃ©dicaments prescrits
        # Bloom 6
        if case.medicaments_prescrits and len(case.medicaments_prescrits) > 0:
            if "PRESCRIPTION_THERAPEUTIQUE" in comp_map:
                required_skills["PRESCRIPTION_THERAPEUTIQUE"] = comp_map["PRESCRIPTION_THERAPEUTIQUE"]
        
        # RÃ¨gle 5 : CompÃ©tences de Raisonnement (Toujours nÃ©cessaires pour un cas complet)
        # Bloom 4-5
        reasoning_skills = ["GENERATION_HYPOTHESES", "DIAGNOSTIC_DIFFERENTIEL", "SYNTHESE_CLINIQUE"]
        for code in reasoning_skills:
            if code in comp_map:
                required_skills[code] = comp_map[code]

        # --- MISE Ã€ JOUR DU CAS ---
        
        # On sauvegarde le rÃ©sultat sous forme de JSON { "CODE_COMPETENCE": ID_COMPETENCE }
        case.competences_requises = required_skills
        
        # On calcule un niveau de difficultÃ© suggÃ©rÃ© basÃ© sur la richesse du cas
        # Base: 1. +1 si labo, +1 si images, +1 si mÃ©dicaments, +1 si comorbiditÃ©s
        difficulty = 1
        if "INTERPRETATION_BIOLOGIE" in required_skills: difficulty += 1
        if "INTERPRETATION_IMAGERIE" in required_skills: difficulty += 1
        if "PRESCRIPTION_THERAPEUTIQUE" in required_skills: difficulty += 1
        if case.pathologies_secondaires_ids: difficulty += 1
        
        case.niveau_difficulte = min(difficulty, 5) # Max 5

        count_updated += 1

    db.commit()
    db.close()
    print(f"âœ¨ TerminÃ©. {count_updated} cas cliniques mis Ã  jour avec leur Q-Matrix.")

if __name__ == "__main__":
    generate_matrix()

=== Fichier: ./python_files_backup/scripts/backup_restore.py ===



=== Fichier: ./python_files_backup/scripts/populate_from_datasets.py ===



=== Fichier: ./python_files_backup/scripts/migrate_fultang_data.py ===



=== Fichier: ./python_files_backup/scripts/export_training_data.py ===



=== Fichier: ./python_files_backup/scripts/migration_img.py ===

import sys
import os
import cloudinary
import cloudinary.uploader
from sqlalchemy.orm import Session
from datetime import datetime

# Configuration du chemin pour les imports de l'application
# Permet au script de "voir" le dossier app/ mÃªme s'il est dans scripts/
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app.models.media import ImageMedicale
from app.config import settings

# 1. Configuration Cloudinary
# Les clÃ©s sont chargÃ©es depuis votre fichier .env via settings
cloudinary.config( 
    cloud_name = settings.CLOUDINARY_CLOUD_NAME, 
    api_key = settings.CLOUDINARY_API_KEY, 
    api_secret = settings.CLOUDINARY_API_SECRET,
    secure = True
)

OUTPUT_LOG_FILE = "migration_mapping_log.txt"

def migrate_images():
    print("ğŸš€ DÃ©marrage de la migration des images vers Cloudinary...")
    print(f"ğŸ“„ Un rapport sera gÃ©nÃ©rÃ© dans : {OUTPUT_LOG_FILE}")
    
    db = SessionLocal()
    mapping_log = [] # Liste pour stocker les correspondances
    
    try:
        # 2. RÃ©cupÃ©rer les images locales
        # On filtre celles qui ne commencent PAS par 'http'
        images_to_migrate = db.query(ImageMedicale).filter(
            ~ImageMedicale.fichier_url.like('http%')
        ).all()
        
        total_images = len(images_to_migrate)
        print(f"ğŸ“Š {total_images} images trouvÃ©es Ã  migrer.")
        
        # En-tÃªte du fichier de log
        mapping_log.append(f"--- RAPPORT DE MIGRATION DU {datetime.now()} ---")
        mapping_log.append(f"Total Ã  traiter : {total_images}\n")
        mapping_log.append(f"{'ID':<5} | {'ANCIEN CHEMIN LOCAL':<60} | {'NOUVELLE URL CLOUDINARY'}")
        mapping_log.append("-" * 150)
        
        success_count = 0
        error_count = 0
        
        for img in images_to_migrate:
            # Reconstruire le chemin absolu du fichier sur votre machine
            # On suppose que le chemin en BDD est relatif Ã  la racine du projet
            # ex: "storage/media/images/radio.jpg"
            local_rel_path = img.fichier_url
            local_abs_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', local_rel_path))
            
            print(f"  -> Traitement ID {img.id}...")
            
            if os.path.exists(local_abs_path):
                try:
                    # 3. Upload vers Cloudinary
                    # folder="sti_medical/radiology" permet de ranger les fichiers dans le cloud
                    upload_result = cloudinary.uploader.upload(
                        local_abs_path, 
                        folder="sti_medical_expert/radiology",
                        public_id=f"img_{img.id}_{os.path.basename(local_abs_path).split('.')[0]}" 
                    )
                    
                    new_url = upload_result.get("secure_url")
                    
                    # 4. Mise Ã  jour de la Base de DonnÃ©es
                    img.fichier_url = new_url
                    
                    # Ajout au rapport
                    log_line = f"{img.id:<5} | {local_rel_path:<60} | {new_url}"
                    mapping_log.append(log_line)
                    
                    success_count += 1
                    print(f"     âœ… SuccÃ¨s.")
                    
                except Exception as e:
                    error_msg = f"ERREUR UPLOAD: {str(e)}"
                    print(f"     âŒ {error_msg}")
                    mapping_log.append(f"{img.id:<5} | {local_rel_path:<60} | {error_msg}")
                    error_count += 1
            else:
                error_msg = "FICHIER LOCAL INTROUVABLE"
                print(f"     âš ï¸ {error_msg} : {local_abs_path}")
                mapping_log.append(f"{img.id:<5} | {local_rel_path:<60} | {error_msg}")
                error_count += 1
        
        # Validation finale des changements en BDD
        db.commit()
        
        # Ã‰criture du fichier de log
        mapping_log.append("\n" + "-" * 150)
        mapping_log.append(f"RÃ‰SUMÃ‰ : SuccÃ¨s {success_count} / Erreurs {error_count}")
        
        with open(OUTPUT_LOG_FILE, "w", encoding="utf-8") as f:
            f.write("\n".join(mapping_log))
            
        print(f"\nâœ¨ Migration terminÃ©e.")
        print(f"âœ… SuccÃ¨s : {success_count}")
        print(f"âŒ Erreurs : {error_count}")
        print(f"ğŸ“„ Rapport sauvegardÃ© : {os.path.abspath(OUTPUT_LOG_FILE)}")
        
    except Exception as e:
        print(f"âŒ Erreur critique du script : {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    migrate_images()

=== Fichier: ./python_files_backup/scripts/check_relations.py ===

import sys
import os
from sqlalchemy import inspect

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import engine
# Importez tous les modÃ¨les pour Ãªtre sÃ»r qu'ils sont enregistrÃ©s
from app import models 

def check_db_relations():
    inspector = inspect(engine)
    table_names = inspector.get_table_names()
    
    print(f"\n--- AUDIT DE LA BASE DE DONNÃ‰ES ({len(table_names)} tables trouvÃ©es) ---\n")
    
    # 1. VÃ©rification des Tables
    print("ğŸ“‹ LISTE DES TABLES :")
    for table in sorted(table_names):
        print(f"  - {table}")
        
    print("\nğŸ”— VÃ‰RIFICATION DES RELATIONS (ClÃ©s Ã‰trangÃ¨res) :")
    
    # 2. VÃ©rification des ClÃ©s Ã‰trangÃ¨res
    relations_found = 0
    for table_name in sorted(table_names):
        fks = inspector.get_foreign_keys(table_name)
        if fks:
            print(f"\n  TABLE '{table_name}' est liÃ©e Ã  :")
            for fk in fks:
                referred_table = fk.get('referred_table')
                constrained_columns = fk['constrained_columns'] # La colonne source (ex: learner_id)
                referred_columns = fk['referred_columns'] # La colonne cible (ex: id)
                
                print(f"    -> {referred_table} (via {constrained_columns[0]} -> {referred_columns[0]})")
                relations_found += 1
    
    print(f"\nâœ¨ Total de {relations_found} relations de clÃ© Ã©trangÃ¨re trouvÃ©es.")
    
    if relations_found > 10: # On en attend beaucoup
        print("âœ… La structure relationnelle semble riche et interconnectÃ©e.")
    else:
        print("âš ï¸ Attention : Peu de relations trouvÃ©es. VÃ©rifiez vos modÃ¨les.")

if __name__ == "__main__":
    check_db_relations()

=== Fichier: ./python_files_backup/scripts/validate_cases.py ===



=== Fichier: ./python_files_backup/scripts/init_db.py ===



=== Fichier: ./python_files_backup/scripts/populate_competencies.py ===

import sys
import os

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app import models

def populate():
    db = SessionLocal()
    print("--- Peuplement des CompÃ©tences Cliniques (Structure Consultation & Bloom) ---")

    # ---------------------------------------------------------
    # 1. CompÃ©tences Racines (Les Grandes Ã‰tapes de la Consultation)
    # ---------------------------------------------------------
    root_skills = [
        {"code": "RELATION", "nom": "1. Accueil et Relation Patient", "cat": "Communication", "bloom": 2},
        {"code": "ANAMNESE", "nom": "2. AnamnÃ¨se (Interrogatoire)", "cat": "EnquÃªte", "bloom": 3},
        {"code": "EXAMEN_PHYSIQUE", "nom": "3. Examen Clinique", "cat": "Observation", "bloom": 3},
        {"code": "RAISONNEMENT", "nom": "4. Raisonnement Diagnostique", "cat": "Raisonnement", "bloom": 4},
        {"code": "PARACLINIQUE", "nom": "5. Examens ComplÃ©mentaires", "cat": "Investigation", "bloom": 4},
        {"code": "SYNTHESE", "nom": "6. Diagnostic et Explication", "cat": "SynthÃ¨se", "bloom": 5},
        {"code": "PRISE_EN_CHARGE", "nom": "7. Traitement et Suivi", "cat": "Action", "bloom": 6},
    ]

    roots = {}
    for skill in root_skills:
        existing = db.query(models.Competence).filter(models.Competence.code_competence == skill["code"]).first()
        if not existing:
            new_skill = models.Competence(
                code_competence=skill["code"],
                nom=skill["nom"],
                categorie=skill["cat"],
                niveau_bloom=skill["bloom"],
                description=f"CompÃ©tence racine pour l'Ã©tape : {skill['nom']}"
            )
            db.add(new_skill)
            db.commit()
            db.refresh(new_skill)
            roots[skill["code"]] = new_skill
            print(f"âœ… Racine crÃ©Ã©e : {skill['nom']} (Bloom {skill['bloom']})")
        else:
            roots[skill["code"]] = existing
            print(f"â„¹ï¸ Racine existante : {skill['nom']}")

    # ---------------------------------------------------------
    # 2. Sous-CompÃ©tences SpÃ©cifiques (DÃ©tails opÃ©ratoires)
    # ---------------------------------------------------------
    specific_skills = [
        # 1. Accueil
        {"code": "IDENTIFIER_MOTIF", "nom": "Identifier le motif de consultation", "parent": "RELATION", "bloom": 1},
        {"code": "EMPATHIE", "nom": "Communication empathique", "parent": "RELATION", "bloom": 2},

        # 2. AnamnÃ¨se
        {"code": "ANAMNESE_HISTOIRE", "nom": "CaractÃ©riser l'histoire de la maladie (PQRST)", "parent": "ANAMNESE", "bloom": 3},
        {"code": "ANAMNESE_ANTECEDENTS", "nom": "Recueillir les antÃ©cÃ©dents (perso/famille)", "parent": "ANAMNESE", "bloom": 2},
        {"code": "ANAMNESE_TRAITEMENTS", "nom": "Recenser traitements et allergies", "parent": "ANAMNESE", "bloom": 2},
        {"code": "ANAMNESE_MODE_VIE", "nom": "Identifier les facteurs de mode de vie", "parent": "ANAMNESE", "bloom": 2},

        # 3. Examen Physique
        {"code": "SIGNES_VITAUX", "nom": "Mesurer et interprÃ©ter les constantes", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},
        {"code": "EXAMEN_CIBLE", "nom": "RÃ©aliser l'examen physique ciblÃ©", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},
        {"code": "RECONNAISSANCE_SIGNES", "nom": "ReconnaÃ®tre les signes physiques d'alerte", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},

        # 4. Raisonnement
        {"code": "GENERATION_HYPOTHESES", "nom": "Formuler des hypothÃ¨ses diagnostiques", "parent": "RAISONNEMENT", "bloom": 4},
        {"code": "DIAGNOSTIC_DIFFERENTIEL", "nom": "Mener un diagnostic diffÃ©rentiel", "parent": "RAISONNEMENT", "bloom": 5},

        # 5. Paraclinique
        {"code": "PRESCRIPTION_PERTINENTE", "nom": "Prescrire les examens pertinents", "parent": "PARACLINIQUE", "bloom": 5},
        {"code": "INTERPRETATION_BIOLOGIE", "nom": "InterprÃ©ter les rÃ©sultats biologiques", "parent": "PARACLINIQUE", "bloom": 4},
        {"code": "INTERPRETATION_IMAGERIE", "nom": "InterprÃ©ter l'imagerie mÃ©dicale", "parent": "PARACLINIQUE", "bloom": 4},

        # 6. SynthÃ¨se
        {"code": "SYNTHESE_CLINIQUE", "nom": "IntÃ©grer les donnÃ©es pour conclure", "parent": "SYNTHESE", "bloom": 5},
        {"code": "ANNONCE_DIAGNOSTIC", "nom": "Expliquer le diagnostic au patient", "parent": "SYNTHESE", "bloom": 3},

        # 7. Prise en charge
        {"code": "PRESCRIPTION_THERAPEUTIQUE", "nom": "Ã‰tablir le plan thÃ©rapeutique", "parent": "PRISE_EN_CHARGE", "bloom": 6},
        {"code": "EDUCATION_PATIENT", "nom": "Ã‰duquer le patient sur sa maladie", "parent": "PRISE_EN_CHARGE", "bloom": 3},
        {"code": "SUIVI_EVOLUTION", "nom": "Planifier le suivi et la surveillance", "parent": "PRISE_EN_CHARGE", "bloom": 5},
    ]

    created_skills = {}
    for skill in specific_skills:
        existing = db.query(models.Competence).filter(models.Competence.code_competence == skill["code"]).first()
        if not existing:
            parent = roots.get(skill["parent"])
            new_skill = models.Competence(
                code_competence=skill["code"],
                nom=skill["nom"],
                categorie=parent.categorie if parent else "Autre",
                parent_competence_id=parent.id if parent else None,
                niveau_bloom=skill["bloom"],
                description=f"Sous-compÃ©tence de : {parent.nom if parent else 'Racine'}"
            )
            db.add(new_skill)
            db.commit()
            db.refresh(new_skill)
            created_skills[skill["code"]] = new_skill
            print(f"  -> Sous-compÃ©tence crÃ©Ã©e : {skill['nom']} (Bloom {skill['bloom']})")
        else:
            created_skills[skill["code"]] = existing

    # ---------------------------------------------------------
    # 3. CrÃ©ation des PrÃ©requis (Le Graphe de DÃ©pendance)
    # ---------------------------------------------------------
    # Logique : "Pour faire B, il faut savoir faire A"
    prerequisites = [
        # Logique interne Ã  l'AnamnÃ¨se
        ("ANAMNESE_HISTOIRE", "IDENTIFIER_MOTIF"), # On ne peut pas creuser l'histoire si on n'a pas le motif
        
        # Logique AnamnÃ¨se -> Examen
        ("EXAMEN_CIBLE", "ANAMNESE_HISTOIRE"), # L'examen est guidÃ© par l'histoire
        
        # Logique vers Raisonnement
        ("GENERATION_HYPOTHESES", "ANAMNESE_HISTOIRE"),
        ("GENERATION_HYPOTHESES", "SIGNES_VITAUX"),
        
        # Logique vers Paraclinique
        ("PRESCRIPTION_PERTINENTE", "GENERATION_HYPOTHESES"), # On prescrit pour tester une hypothÃ¨se
        
        # Logique vers SynthÃ¨se
        ("SYNTHESE_CLINIQUE", "INTERPRETATION_BIOLOGIE"),
        ("SYNTHESE_CLINIQUE", "DIAGNOSTIC_DIFFERENTIEL"),
        
        # Logique vers Traitement (Le sommet)
        ("PRESCRIPTION_THERAPEUTIQUE", "SYNTHESE_CLINIQUE"), # Pas de traitement sans diagnostic
        ("EDUCATION_PATIENT", "SYNTHESE_CLINIQUE"),
    ]

    for target_code, req_code in prerequisites:
        target = created_skills.get(target_code)
        req = created_skills.get(req_code)

        if target and req:
            # VÃ©rifier si le lien existe dÃ©jÃ 
            link_exists = db.query(models.PrerequisCompetence).filter(
                models.PrerequisCompetence.competence_id == target.id,
                models.PrerequisCompetence.prerequis_id == req.id
            ).first()

            if not link_exists:
                new_link = models.PrerequisCompetence(
                    competence_id=target.id,
                    prerequis_id=req.id,
                    type_relation="STRICT"
                )
                db.add(new_link)
                print(f"    ğŸ”— PrÃ©requis crÃ©Ã© : {req.nom} -> {target.nom}")

    db.commit()
    db.close()
    print("âœ¨ Peuplement des compÃ©tences pÃ©dagogiques terminÃ©.")

if __name__ == "__main__":
    populate()

=== Fichier: ./python_files_backup/testembedding.py ===

from app.services.embedding_service import embedding_service

text = "Pneumonie avec fiÃ¨vre Ã©levÃ©e"
vector = embedding_service.get_text_embedding(text)

print(f"Texte : {text}")
print(f"Taille du vecteur : {len(vector)}")
print(f"AperÃ§u : {vector[:5]}...")

=== Fichier: ./python_files_backup/tests/conftest.py ===



=== Fichier: ./python_files_backup/tests/fixtures/__init__.py ===



=== Fichier: ./python_files_backup/tests/__init__.py ===



=== Fichier: ./python_files_backup/tests/integration/__init__.py ===



=== Fichier: ./python_files_backup/tests/unit/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/main.py ===

from fastapi import FastAPI
from .api.v1 import symptoms,diseases,medications,media,clinical_cases,expert_strategies,diagnostic,chat

app = FastAPI(
    title="STI Medical Expert Module",
    description="Base de connaissances et moteur de raisonnement pour le STI mÃ©dical.",
    version="0.1.0"
)


app.include_router(symptoms.router, prefix="/api/v1")
app.include_router(diseases.router, prefix="/api/v1")
app.include_router(medications.router, prefix="/api/v1")
app.include_router(media.router, prefix="/api/v1")
app.include_router(clinical_cases.router, prefix="/api/v1")
app.include_router(expert_strategies.router, prefix="/api/v1")
app.include_router(diagnostic.router, prefix="/api/v1")

app.include_router(chat.router, prefix="/api/v1")


@app.get("/")
def read_root():
    """
    Endpoint racine pour vÃ©rifier que le service est en ligne.
    """
    return {"status": "Service is running"}

=== Fichier: ./python_files_backup/python_files_backup/app/core/cognitive_diagnosis.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/core/prerequisite_graph.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/core/htn_planner.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/core/integrity_validator.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/core/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/core/q_matrix_solver.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/core/reasoning_engine.py ===

from typing import List, Dict, Any

def evaluate_condition(condition: Dict[str, Any], facts: Dict[str, Any]) -> bool:
    """
    Ã‰value une seule condition par rapport Ã  un ensemble de faits.
    Version trÃ¨s simple pour commencer.
    """
    fact_type = condition.get("fact")
    fact_value = condition.get("value")
    operator = condition.get("operator")

    if fact_type == "symptom" and operator == "present":
        return fact_value in facts.get("symptoms", [])
    
    if fact_type == "context" and operator == "is":
        return fact_value in facts.get("context", [])
    
    # Ajouter d'autres logiques d'Ã©valuation ici plus tard (ex: age > 65)
    
    return False


def forward_chaining_engine(rules: List[Dict[str, Any]], facts: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Moteur de raisonnement simple en chaÃ®nage avant.

    :param rules: Une liste de rÃ¨gles, oÃ¹ chaque rÃ¨gle est un dictionnaire
                  avec les clÃ©s 'conditions' et 'actions'.
    :param facts: Un dictionnaire reprÃ©sentant les faits connus sur le patient
                  (ex: {"symptoms": ["FiÃ¨vre", "Toux"], "context": ["zone_endemique"]}).
    :return: Une liste de toutes les actions des rÃ¨gles qui ont Ã©tÃ© dÃ©clenchÃ©es.
    """
    triggered_actions = []

    for rule in rules:
        conditions = rule.get("conditions", {})
        
        # Pour l'instant, nous ne gÃ©rons que l'opÃ©rateur "AND"
        if conditions.get("operator") == "AND":
            all_conditions_met = True
            for condition in conditions.get("rules", []):
                if not evaluate_condition(condition, facts):
                    all_conditions_met = False
                    break  # Inutile de vÃ©rifier les autres conditions de cette rÃ¨gle
            
            if all_conditions_met:
                # Toutes les conditions sont remplies, on ajoute les actions
                triggered_actions.extend(rule.get("actions", []))

    return triggered_actions

"""""
# Ajoutez ce bloc Ã  la fin du fichier pour tester
if __name__ == "__main__":
    # DÃ©finir une rÃ¨gle de test (copiÃ©e de notre exemple prÃ©cÃ©dent)
    test_rule = {
        "code_regle": "DIAG_PALU_SIMPLE_01",
        "conditions": {
            "operator": "AND",
            "rules": [
                {"fact": "symptom", "value": "FiÃ¨vre", "operator": "present"},
                {"fact": "context", "value": "zone_endemique", "operator": "is"}
            ]
        },
        "actions": [
            {"action": "add_hypothesis", "pathology": "Paludisme simple", "confidence": 0.7}
        ]
    }
    
    # DÃ©finir des faits qui devraient dÃ©clencher la rÃ¨gle
    patient_facts = {
        "symptoms": ["FiÃ¨vre", "Toux"],
        "context": ["zone_endemique"]
    }
    
    print("Test du moteur de raisonnement...")
    conclusions = forward_chaining_engine(rules=[test_rule], facts=patient_facts)
    
    print(f"Faits: {patient_facts}")
    print(f"RÃ¨gles: {[test_rule['code_regle']]}")
    print(f"Conclusions: {conclusions}")
    
    # VÃ©rification du test
    assert len(conclusions) == 1
    assert conclusions[0]['pathology'] == 'Paludisme simple'
    print("\nâœ… Test rÃ©ussi !")
    
    """

=== Fichier: ./python_files_backup/python_files_backup/app/core/knowledge_graph.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/ml/embeddings.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/ml/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/ml/clustering.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/ml/recommendation.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/ml/similarity.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/schemas/symptom.py ===

from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from datetime import datetime

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class SymptomBase(BaseModel):
    """
    SchÃ©ma de base pour un symptÃ´me.
    Contient les champs communs Ã  la crÃ©ation et Ã  la lecture.
    """
    nom: str
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    type_symptome: Optional[str] = None
    description: Optional[str] = None
    questions_anamnese: Optional[Dict[str, Any]] = None
    signes_alarme: bool = False


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation (ce que l'API attend dans un POST)
# ==============================================================================
class SymptomCreate(SymptomBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau symptÃ´me via l'API.
    HÃ©rite de SymptomBase et n'ajoute aucun champ supplÃ©mentaire pour l'instant.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour (ce que l'API attend dans un PATCH)
# ==============================================================================
class SymptomUpdate(BaseModel):
    """
    SchÃ©ma utilisÃ© pour mettre Ã  jour un symptÃ´me existant.
    Tous les champs sont optionnels pour permettre des mises Ã  jour partielles.
    """
    nom: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    type_symptome: Optional[str] = None
    description: Optional[str] = None
    questions_anamnese: Optional[Dict[str, Any]] = None
    signes_alarme: Optional[bool] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class Symptom(SymptomBase):
    """
    SchÃ©ma complet pour reprÃ©senter un symptÃ´me, y compris les champs
    gÃ©nÃ©rÃ©s par la base de donnÃ©es comme 'id' et 'created_at'.
    Ce sera le modÃ¨le de rÃ©ponse de l'API.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        """
        Configuration pour Pydantic.
        'from_attributes = True' (anciennement 'orm_mode') permet au modÃ¨le Pydantic
        de lire les donnÃ©es directement depuis un objet SQLAlchemy.
        C'est le lien magique entre notre modÃ¨le de BDD et notre schÃ©ma d'API.
        """
        from_attributes = True

=== Fichier: ./python_files_backup/python_files_backup/app/schemas/medication.py ===

from pydantic import BaseModel
from typing import Optional, Dict, Any
from datetime import datetime

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class MedicationBase(BaseModel):
    """
    SchÃ©ma de base pour un mÃ©dicament, contenant les champs modifiables.
    """
    dci: str
    nom_commercial: Optional[str] = None
    classe_therapeutique: Optional[str] = None
    forme_galenique: Optional[str] = None
    dosage: Optional[str] = None
    voie_administration: Optional[str] = None
    mecanisme_action: Optional[str] = None
    indications: Optional[Dict[str, Any]] = None
    contre_indications: Optional[Dict[str, Any]] = None
    effets_secondaires: Optional[Dict[str, Any]] = None
    interactions_medicamenteuses: Optional[Dict[str, Any]] = None
    precautions_emploi: Optional[str] = None
    posologie_standard: Optional[Dict[str, Any]] = None
    disponibilite_cameroun: Optional[str] = None
    cout_moyen_fcfa: Optional[int] = None
    statut_prescription: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation
# ==============================================================================
class MedicationCreate(MedicationBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau mÃ©dicament.
    'dci' est le seul champ strictement requis.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour
# ==============================================================================
class MedicationUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'un mÃ©dicament.
    """
    dci: Optional[str] = None
    nom_commercial: Optional[str] = None
    classe_therapeutique: Optional[str] = None
    # ... (tous les autres champs de MedicationBase en optionnel)
    forme_galenique: Optional[str] = None
    dosage: Optional[str] = None
    voie_administration: Optional[str] = None
    mecanisme_action: Optional[str] = None
    indications: Optional[Dict[str, Any]] = None
    contre_indications: Optional[Dict[str, Any]] = None
    effets_secondaires: Optional[Dict[str, Any]] = None
    interactions_medicamenteuses: Optional[Dict[str, Any]] = None
    precautions_emploi: Optional[str] = None
    posologie_standard: Optional[Dict[str, Any]] = None
    disponibilite_cameroun: Optional[str] = None
    cout_moyen_fcfa: Optional[int] = None
    statut_prescription: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (RÃ©ponse API)
# ==============================================================================
class Medication(MedicationBase):
    """
    SchÃ©ma complet pour reprÃ©senter un mÃ©dicament en rÃ©ponse d'API.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

=== Fichier: ./python_files_backup/python_files_backup/app/schemas/clinical_case.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date
from decimal import Decimal

# Importer les autres schÃ©mas pour les rÃ©ponses imbriquÃ©es
from .disease import Disease
from .media import ImageMedicale
from .symptom import Symptom






# --- NOUVEAUX SOUS-SCHÃ‰MAS ---
class SymptomInCase(BaseModel):
    symptome_id: int
    details: str # Ex: "FiÃ¨vre Ã©levÃ©e (40Â°C) apparue brutalement il y a 48h"

class PresentationClinique(BaseModel):
    histoire_maladie: str
    symptomes_patient: List[SymptomInCase]
    antecedents: Optional[Dict[str, Any]] = None
# ==============================================================================
# SchÃ©ma de Base et de CrÃ©ation
# ==============================================================================
class ClinicalCaseBase(BaseModel):
    """
    SchÃ©ma de base pour un cas clinique, contenant les champs Ã©ditables.
    """
    code_fultang: str = Field(..., description="Identifiant unique (Fultang ou synthÃ©tique)")
    pathologie_principale_id: Optional[int] = None
    pathologies_secondaires_ids: Optional[List[int]] = []
    presentation_clinique: PresentationClinique
    donnees_paracliniques: Optional[Dict[str, Any]] = None
    evolution_patient: Optional[str] = None
    images_associees_ids: Optional[List[int]] = []
    sons_associes_ids: Optional[List[int]] = []
    medicaments_prescrits: Optional[List[Dict[str, Any]]] = []
    niveau_difficulte: int = Field(default=3, ge=1, le=101)
    duree_estimee_resolution_min: Optional[int] = None
    objectifs_apprentissage: Optional[List[str]] = []
    competences_requises: Optional[Dict[str, Any]] = {}


class ClinicalCaseCreate(ClinicalCaseBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau cas clinique via l'API.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour
# ==============================================================================
class ClinicalCaseUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'un cas clinique.
    """
    code_fultang: Optional[str] = None
    pathologie_principale_id: Optional[int] = None
    presentation_clinique: Optional[Dict[str, Any]] = None
    donnees_paracliniques: Optional[Dict[str, Any]] = None
    evolution_patient: Optional[str] = None
    images_associees_ids: Optional[List[int]] = None
    sons_associes_ids: Optional[List[int]] = None
    medicaments_prescrits: Optional[List[Dict[str, Any]]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=101)
    duree_estimee_resolution_min: Optional[int] = None
    objectifs_apprentissage: Optional[List[str]] = None
    competences_requises: Optional[Dict[str, Any]] = None
    valide_expert: Optional[bool] = None
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# SchÃ©mas pour la Lecture (RÃ©ponse API)
# ==============================================================================
class ClinicalCaseSimple(BaseModel):
    """
    SchÃ©ma simplifiÃ© pour les listes de cas cliniques.
    """
    id: int
    code_fultang: str
    niveau_difficulte: int
    pathologie_principale: Optional[Disease] = None # Affiche l'objet maladie complet
    nb_images: int
    nb_sons: int

    class Config:
        from_attributes = True


# --- NOUVEAU SCHÃ‰MA DE LECTURE ENRICHI ---
class SymptomDetailInCase(BaseModel):
    symptome: Symptom # L'objet symptÃ´me complet
    details: str # Les dÃ©tails spÃ©cifiques au cas

class PresentationCliniqueDetail(BaseModel):
    histoire_maladie: str
    symptomes_patient: List[SymptomDetailInCase]
    antecedents: Optional[Dict[str, Any]] = None


class ClinicalCase(ClinicalCaseBase):
    id: int
    created_at: datetime
    updated_at: datetime
    
    pathologie_principale: Optional[Disease] = None
    pathologies_secondaires: List[Disease] = [] # <- AJOUTER
    images_associees: List[ImageMedicale] = []
    
    # --- ENRICHISSEMENT DE LA PRÃ‰SENTATION CLINIQUE ---
    presentation_clinique_detail: Optional[PresentationCliniqueDetail] = None

    class Config:
        from_attributes = True



=== Fichier: ./python_files_backup/python_files_backup/app/schemas/relations.py ===

from pydantic import BaseModel, Field
from typing import Any, Dict, Optional
from decimal import Decimal

# Importer les schÃ©mas de base pour l'affichage
from .symptom import Symptom
from .disease import Disease
from .medication import Medication


# ==============================================================================
# SchÃ©ma de Base et de CrÃ©ation pour l'Association
# ==============================================================================
class PathologieSymptomeBase(BaseModel):
    """
    SchÃ©ma de base pour l'association Pathologie-SymptÃ´me.
    Contient les champs nÃ©cessaires pour crÃ©er ou mettre Ã  jour le lien.
    """
    pathologie_id: int
    symptome_id: int
    probabilite: Optional[Decimal] = Field(None, ge=0, le=1)
    sensibilite: Optional[Decimal] = Field(None, ge=0, le=1)
    specificite: Optional[Decimal] = Field(None, ge=0, le=1)
    phase_maladie: Optional[str] = None
    frequence: Optional[str] = None
    est_pathognomonique: bool = False
    importance_diagnostique: Optional[int] = Field(None, ge=1, le=5)

class PathologieSymptomeCreate(PathologieSymptomeBase):
    """
    SchÃ©ma utilisÃ© spÃ©cifiquement pour crÃ©er une nouvelle association.
    """
    pass


# ==============================================================================
# SchÃ©mas pour la Lecture (RÃ©ponse de l'API)
# ==============================================================================
class PathologieSymptome(PathologieSymptomeBase):
    """
    SchÃ©ma complet pour la rÃ©ponse de l'API, incluant l'ID de l'association.
    """
    id: int

    class Config:
        from_attributes = True


class SymptomForDiseaseDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'un symptÃ´me DANS le contexte d'une pathologie.
    """
    symptome: Symptom
    probabilite: Optional[Decimal]
    importance_diagnostique: Optional[int]
    est_pathognomonique: bool

    class Config:
        from_attributes = True


class DiseaseForSymptomDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'une pathologie DANS le contexte d'un symptÃ´me
    (utile pour le diagnostic diffÃ©rentiel).
    """
    pathologie: Disease
    probabilite: Optional[Decimal]
    importance_diagnostique: Optional[int]

    class Config:
        from_attributes = True



# Contenu Ã  AJOUTER Ã  la fin de app/schemas/relations.py

# Importer le schÃ©ma de base pour l'affichage


# ==============================================================================
# SchÃ©mas pour l'Association Traitement-Pathologie
# ==============================================================================
class TraitementPathologieBase(BaseModel):
    pathologie_id: int
    medicament_id: int
    type_traitement: Optional[str] = None
    ligne_traitement: Optional[int] = None
    indication_precise: Optional[str] = None
    efficacite_taux: Optional[Decimal] = Field(None, ge=0, le=100)
    duree_traitement_jours: Optional[int] = None
    posologie_detaillee: Optional[Dict[str, Any]] = None
    niveau_preuve: Optional[str] = None
    guidelines_source: Optional[str] = None
    rang_preference: Optional[int] = 99

class TraitementPathologieCreate(TraitementPathologieBase):
    pass

class TraitementPathologie(TraitementPathologieBase):
    id: int
    class Config:
        from_attributes = True

class MedicationForDiseaseDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'un mÃ©dicament DANS le contexte d'une pathologie.
    """
    medicament: Medication
    type_traitement: Optional[str]
    ligne_traitement: Optional[int]
    rang_preference: Optional[int]
    
    class Config:
        from_attributes = True

# ==============================================================================
# SchÃ©mas pour l'Association Traitement-SymptÃ´me
# ==============================================================================
class TraitementSymptomeBase(BaseModel):
    symptome_id: int
    medicament_id: int
    efficacite: Optional[str] = None
    rapidite_action: Optional[str] = None
    posologie_recommandee: Optional[str] = None
    rang_preference: Optional[int] = 99

class TraitementSymptomeCreate(TraitementSymptomeBase):
    pass

class TraitementSymptome(TraitementSymptomeBase):
    id: int
    class Config:
        from_attributes = True

class MedicationForSymptomDetail(BaseModel):
    """
    SchÃ©ma pour afficher les dÃ©tails d'un mÃ©dicament DANS le contexte d'un symptÃ´me.
    """
    medicament: Medication
    efficacite: Optional[str]
    rang_preference: Optional[int]

    class Config:
        from_attributes = True

=== Fichier: ./python_files_backup/python_files_backup/app/schemas/tracking_models.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/schemas/__init__.py ===

from .symptom import SymptomCreate,SymptomBase,SymptomUpdate, Symptom
from .disease import DiseaseCreate,DiseaseBase,DiseaseUpdate, Disease
from . import relations
from .medication import MedicationCreate,MedicationBase,MedicationUpdate, Medication
from .media import ImageMedicaleBase,ImageMedicaleUpdate, ImageMedicale
from .clinical_case import ClinicalCaseCreate,ClinicalCaseBase,ClinicalCaseUpdate, ClinicalCase
from .expert_strategy import ExpertStrategyCreate,ExpertStrategyBase,ExpertStrategyUpdate, ExpertStrategy

=== Fichier: ./python_files_backup/python_files_backup/app/schemas/expert_strategy.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date
from decimal import Decimal

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class ExpertStrategyBase(BaseModel):
    """
    SchÃ©ma de base pour une rÃ¨gle/stratÃ©gie experte.
    """
    code_regle: str = Field(..., max_length=50)
    categorie: str
    priorite: int = Field(default=5, ge=1, le=10)
    conditions: Dict[str, Any]
    actions: List[Dict[str, Any]]
    description_naturelle: Optional[str] = None
    justification_medicale: Optional[str] = None
    expert_auteur: Optional[str] = None
    date_validation: Optional[date] = None
    est_active: bool = True


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation
# ==============================================================================
class ExpertStrategyCreate(ExpertStrategyBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er une nouvelle rÃ¨gle.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour
# ==============================================================================
class ExpertStrategyUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'une rÃ¨gle.
    """
    code_regle: Optional[str] = Field(None, max_length=50)
    categorie: Optional[str] = None
    priorite: Optional[int] = Field(None, ge=1, le=10)
    conditions: Optional[Dict[str, Any]] = None
    actions: Optional[List[Dict[str, Any]]] = None
    description_naturelle: Optional[str] = None
    justification_medicale: Optional[str] = None
    expert_auteur: Optional[str] = None
    date_validation: Optional[date] = None
    est_active: Optional[bool] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (RÃ©ponse API)
# ==============================================================================
class ExpertStrategy(ExpertStrategyBase):
    """
    SchÃ©ma complet pour reprÃ©senter une rÃ¨gle en rÃ©ponse d'API.
    """
    id: int
    nb_activations: int
    taux_succes: Optional[Decimal] = None
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

=== Fichier: ./python_files_backup/python_files_backup/app/schemas/response.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/schemas/media.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date

# ==============================================================================
# SchÃ©ma de Base pour les MÃ©tadonnÃ©es d'une Image
# ==============================================================================
class ImageMedicaleBase(BaseModel):
    """
    SchÃ©ma de base contenant les mÃ©tadonnÃ©es modifiables d'une image mÃ©dicale.
    """
    type_examen: str
    sous_type: Optional[str] = None
    pathologie_id: Optional[int] = None
    description: Optional[str] = None
    signes_radiologiques: Optional[Dict[str, Any]] = None
    annotations: Optional[List[Dict[str, Any]]] = None
    interpretation_experte: Optional[str] = None
    diagnostic_differentiel: Optional[List[str]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=5)
    qualite_image: Optional[int] = Field(None, ge=1, le=5)
    valide_expert: Optional[bool] = False
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour des MÃ©tadonnÃ©es
# ==============================================================================
class ImageMedicaleUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle des mÃ©tadonnÃ©es d'une image.
    Tous les champs sont optionnels.
    """
    type_examen: Optional[str] = None
    sous_type: Optional[str] = None
    pathologie_id: Optional[int] = None
    description: Optional[str] = None
    signes_radiologiques: Optional[Dict[str, Any]] = None
    annotations: Optional[List[Dict[str, Any]]] = None
    interpretation_experte: Optional[str] = None
    diagnostic_differentiel: Optional[List[str]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=5)
    qualite_image: Optional[int] = Field(None, ge=1, le=5)
    valide_expert: Optional[bool] = None
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (RÃ©ponse API)
# ==============================================================================
class ImageMedicale(ImageMedicaleBase):
    """
    SchÃ©ma complet pour reprÃ©senter les mÃ©tadonnÃ©es d'une image en rÃ©ponse d'API.
    """
    id: int
    fichier_url: str
    fichier_miniature_url: Optional[str] = None
    format_image: Optional[str] = None
    taille_ko: Optional[int] = None
    resolution: Optional[str] = None
    created_at: datetime

    class Config:
        from_attributes = True

# Nous ajouterons les schÃ©mas pour SonMedical ici plus tard.

=== Fichier: ./python_files_backup/python_files_backup/app/schemas/disease.py ===

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime
from decimal import Decimal

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class DiseaseBase(BaseModel):
    """
    SchÃ©ma de base pour une pathologie, contenant les champs modifiables.
    """
    nom_fr: str
    code_icd10: str
    nom_en: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    prevalence_cameroun: Optional[Decimal] = Field(None, ge=0, le=100)
    niveau_gravite: Optional[int] = Field(None, ge=1, le=5)
    description: Optional[str] = None
    physiopathologie: Optional[str] = None
    evolution_naturelle: Optional[str] = None
    complications: Optional[Dict[str, Any]] = None
    facteurs_risque: Optional[Dict[str, Any]] = None
    prevention: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation (ce que l'API attend dans un POST)
# ==============================================================================
class DiseaseCreate(DiseaseBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er une nouvelle pathologie.
    """
    pass


# ==============================================================================
# SchÃ©ma pour la Mise Ã  Jour (ce que l'API attend dans un PATCH)
# ==============================================================================
class DiseaseUpdate(BaseModel):
    """
    SchÃ©ma pour la mise Ã  jour partielle d'une pathologie.
    Tous les champs sont optionnels.
    """
    nom_fr: Optional[str] = None
    code_icd10: Optional[str] = None
    nom_en: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    prevalence_cameroun: Optional[Decimal] = Field(None, ge=0, le=100)
    niveau_gravite: Optional[int] = Field(None, ge=1, le=5)
    description: Optional[str] = None
    physiopathologie: Optional[str] = None
    evolution_naturelle: Optional[str] = None
    complications: Optional[Dict[str, Any]] = None
    facteurs_risque: Optional[Dict[str, Any]] = None
    prevention: Optional[str] = None


# ==============================================================================
# SchÃ©ma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class Disease(DiseaseBase):
    """
    SchÃ©ma complet pour reprÃ©senter une pathologie en rÃ©ponse d'API.
    Inclut les champs non modifiables comme 'id' et les horodatages.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        """
        Permet la conversion automatique depuis un objet SQLAlchemy.
        """
        from_attributes = True

=== Fichier: ./python_files_backup/python_files_backup/app/schemas/diagnostic.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/schemas/chat_message.py ===

from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
from datetime import datetime
from uuid import UUID

# ==============================================================================
# SchÃ©ma de Base
# ==============================================================================
class ChatMessageBase(BaseModel):
    """
    SchÃ©ma de base pour un message de chat.
    Contient les champs communs.
    """
    sender: str = Field(..., description="Qui envoie le message (ex: 'student', 'patient_llm', 'tutor_system')")
    content: str = Field(..., description="Le contenu textuel du message.")


# ==============================================================================
# SchÃ©ma pour la CrÃ©ation (ce que le Frontend envoie)
# ==============================================================================
class ChatMessageCreate(ChatMessageBase):
    """
    SchÃ©ma utilisÃ© pour crÃ©er un nouveau message de chat via l'API.
    La session_id sera fournie dans l'URL, pas dans le corps.
    """
    message_metadata: Optional[Dict[str, Any]] = Field(None, description="MÃ©tadonnÃ©es optionnelles (ex: intention dÃ©tectÃ©e)")


# ==============================================================================
# SchÃ©ma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class ChatMessage(ChatMessageBase):
    """
    SchÃ©ma complet pour reprÃ©senter un message de chat en rÃ©ponse d'API.
    """
    id: int
    session_id: UUID
    timestamp: datetime
    message_metadata: Optional[Dict[str, Any]] = None

    class Config:
        """
        Permet la conversion automatique depuis un objet SQLAlchemy.
        """
        from_attributes = True

=== Fichier: ./python_files_backup/python_files_backup/app/schemas/base.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/schemas/request.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/chat.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List
from uuid import UUID

from ... import schemas, models  # Import global des packages
from ...services import chat_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/chat",
    tags=["Chat"]
)

@router.post("/sessions/{session_id}/messages", response_model=schemas.chat_message.ChatMessage, status_code=status.HTTP_201_CREATED)
def post_chat_message(
    session_id: UUID,
    message_data: schemas.chat_message.ChatMessageCreate,
    db: Session = Depends(get_db)
):
    """Poste un nouveau message dans le chat d'une session de simulation."""
    try:
        return chat_service.create_chat_message(db=db, session_id=session_id, message=message_data)
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))

@router.get("/sessions/{session_id}/messages", response_model=List[schemas.chat_message.ChatMessage])
def get_chat_history(session_id: UUID, db: Session = Depends(get_db)):
    """RÃ©cupÃ¨re l'historique complet des messages pour une session."""
    session = db.query(models.SimulationSession).filter(models.SimulationSession.id == session_id).first()
    if not session:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"La session avec l'ID {session_id} n'a pas Ã©tÃ© trouvÃ©e.")
        
    messages = chat_service.get_messages_by_session(db=db, session_id=session_id)
    return messages

=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/q_matrix.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/fultang.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/media.py ===

from fastapi import (
    APIRouter,
    Depends,
    HTTPException,
    status,
    UploadFile,
    File,
    Form
)
from sqlalchemy.orm import Session
from typing import List, Optional

from ... import schemas, models
from ...services import media_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/media",
    tags=["Media"]
)


@router.post("/images/upload", response_model=schemas.media.ImageMedicale, status_code=status.HTTP_201_CREATED)
async def upload_image_medicale(
    file: UploadFile = File(..., description="Le fichier image Ã  uploader"),
    type_examen: str = Form(..., description="Type d'examen (ex: Radiographie)"),
    sous_type: Optional[str] = Form(None, description="Sous-type (ex: Thorax)"),
    pathologie_id: Optional[int] = Form(None, description="ID de la pathologie associÃ©e"),
    description: Optional[str] = Form(None, description="Description de l'image"),
    db: Session = Depends(get_db)
):
    """
    Uploade une image mÃ©dicale et crÃ©e l'enregistrement de ses mÃ©tadonnÃ©es.
    """
    # VÃ©rifier le type de fichier si nÃ©cessaire
    if not file.content_type.startswith("image/"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Le fichier uploadÃ© n'est pas une image."
        )

    db_image = await media_service.create_image_medicale(
        db=db,
        file=file,
        type_examen=type_examen,
        sous_type=sous_type,
        pathologie_id=pathologie_id,
        description=description
    )
    return db_image


@router.get("/images", response_model=List[schemas.media.ImageMedicale])
def read_all_images_metadata(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste des mÃ©tadonnÃ©es de toutes les images mÃ©dicales.
    """
    images = media_service.get_all_images_medicales(db, skip=skip, limit=limit)
    return images


@router.get("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def read_image_metadata(image_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re les mÃ©tadonnÃ©es d'une image mÃ©dicale spÃ©cifique par son ID.
    """
    db_image = media_service.get_image_medicale_by_id(db, image_id=image_id)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvÃ©e.")
    return db_image


@router.patch("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def update_image_metadata(
    image_id: int,
    metadata_update: schemas.media.ImageMedicaleUpdate,
    db: Session = Depends(get_db)
):
    """
    Met Ã  jour les mÃ©tadonnÃ©es d'une image mÃ©dicale existante.
    """
    db_image = media_service.update_image_medicale_metadata(db, image_id=image_id, image_update=metadata_update)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvÃ©e.")
    return db_image


@router.delete("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def delete_image(image_id: int, db: Session = Depends(get_db)):
    """
    Supprime une image mÃ©dicale (mÃ©tadonnÃ©es et fichier physique).
    """
    db_image = media_service.delete_image_medicale(db, image_id=image_id)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvÃ©e.")
    return db_image

=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/expert_strategies.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import expert_strategy_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/expert-strategies",
    tags=["Expert Strategies"]
)


@router.post("/", response_model=schemas.expert_strategy.ExpertStrategy, status_code=status.HTTP_201_CREATED)
def create_expert_strategy(strategy_data: schemas.expert_strategy.ExpertStrategyCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e une nouvelle rÃ¨gle/stratÃ©gie experte.
    """
    db_strategy = expert_strategy_service.get_strategy_by_code(db, code=strategy_data.code_regle)
    if db_strategy:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Une rÃ¨gle avec le code '{strategy_data.code_regle}' existe dÃ©jÃ ."
        )
    return expert_strategy_service.create_strategy(db=db, strategy=strategy_data)


@router.get("/", response_model=List[schemas.expert_strategy.ExpertStrategy])
def read_all_expert_strategies(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de toutes les rÃ¨gles expertes.
    """
    strategies = expert_strategy_service.get_all_strategies(db, skip=skip, limit=limit)
    return strategies


@router.get("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def read_expert_strategy(strategy_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une rÃ¨gle experte par son ID.
    """
    db_strategy = expert_strategy_service.get_strategy_by_id(db, strategy_id=strategy_id)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="RÃ¨gle non trouvÃ©e.")
    return db_strategy


@router.patch("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def update_expert_strategy(strategy_id: int, strategy_data: schemas.expert_strategy.ExpertStrategyUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour une rÃ¨gle experte.
    """
    db_strategy = expert_strategy_service.update_strategy(db, strategy_id=strategy_id, strategy_update=strategy_data)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="RÃ¨gle non trouvÃ©e.")
    return db_strategy


@router.delete("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def delete_expert_strategy(strategy_id: int, db: Session = Depends(get_db)):
    """
    Supprime une rÃ¨gle experte.
    """
    db_strategy = expert_strategy_service.delete_strategy(db, strategy_id=strategy_id)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="RÃ¨gle non trouvÃ©e.")
    return db_strategy

=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/learning_paths.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/diseases.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import disease_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/diseases",
    tags=["Diseases"]
)


@router.post("/", response_model=schemas.disease.Disease, status_code=status.HTTP_201_CREATED)
def create_disease(disease_data: schemas.disease.DiseaseCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e une nouvelle pathologie.
    VÃ©rifie l'unicitÃ© du code CIM-10.
    """
    db_disease = disease_service.get_disease_by_icd10(db, icd10_code=disease_data.code_icd10)
    if db_disease:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Une pathologie avec le code CIM-10 '{disease_data.code_icd10}' existe dÃ©jÃ ."
        )
    return disease_service.create_disease(db=db, disease=disease_data)


@router.get("/", response_model=List[schemas.disease.Disease])
def read_diseases(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de pathologies.
    """
    diseases = disease_service.get_all_diseases(db, skip=skip, limit=limit)
    return diseases


@router.get("/{disease_id}", response_model=schemas.disease.Disease)
def read_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une pathologie par son ID.
    """
    db_disease = disease_service.get_disease_by_id(db, disease_id=disease_id)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvÃ©e.")
    return db_disease


@router.patch("/{disease_id}", response_model=schemas.disease.Disease)
def update_disease(disease_id: int, disease_data: schemas.disease.DiseaseUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour une pathologie.
    """
    db_disease = disease_service.update_disease(db, disease_id=disease_id, disease_update=disease_data)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvÃ©e.")
    return db_disease


@router.delete("/{disease_id}", response_model=schemas.disease.Disease)
def delete_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    Supprime une pathologie.
    """
    db_disease = disease_service.delete_disease(db, disease_id=disease_id)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvÃ©e.")
    return db_disease

# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/diseases.py

@router.post(
    "/{disease_id}/symptoms",
    response_model=schemas.relations.PathologieSymptome,
    status_code=status.HTTP_201_CREATED,
    tags=["Disease-Symptom Relations"] # Un nouveau tag pour l'organisation
)
def add_symptom_to_disease(
    disease_id: int, 
    association_data: schemas.relations.PathologieSymptomeCreate, 
    db: Session = Depends(get_db)
):
    """
    Associe un symptÃ´me Ã  une pathologie avec des attributs de relation
    (probabilitÃ©, importance, etc.).
    """
    # Assurer la cohÃ©rence des IDs
    if disease_id != association_data.pathologie_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="L'ID de la pathologie dans l'URL ne correspond pas Ã  celui dans le corps de la requÃªte."
        )
    
    try:
        return disease_service.add_symptom_to_disease(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))


@router.get(
    "/{disease_id}/symptoms",
    response_model=List[schemas.relations.SymptomForDiseaseDetail],
    tags=["Disease-Symptom Relations"]
)
def get_symptoms_for_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste de tous les symptÃ´mes associÃ©s Ã  une pathologie,
    avec les dÃ©tails de la relation et les dÃ©tails du symptÃ´me lui-mÃªme.
    """
    associations = disease_service.get_symptoms_for_disease(db, disease_id=disease_id)
    if not associations:
        # Ce n'est pas une erreur, la maladie peut simplement n'avoir aucun symptÃ´me associÃ© pour l'instant
        return []
    
    # Transformer les donnÃ©es pour correspondre au schÃ©ma de rÃ©ponse attendu
    response = []
    for assoc in associations:
        response.append({
            "symptome": assoc.symptome, # L'objet Symptom complet
            "probabilite": assoc.probabilite,
            "importance_diagnostique": assoc.importance_diagnostique,
            "est_pathognomonique": assoc.est_pathognomonique
        })
    return response


# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/diseases.py

@router.post(
    "/{disease_id}/treatments",
    response_model=schemas.relations.TraitementPathologie,
    status_code=status.HTTP_201_CREATED,
    tags=["Therapeutic Relations"]
)
def add_treatment_to_disease(
    disease_id: int, 
    association_data: schemas.relations.TraitementPathologieCreate, 
    db: Session = Depends(get_db)
):
    """
    Associe un mÃ©dicament Ã  une pathologie en tant que traitement.
    """
    if disease_id != association_data.pathologie_id:
        raise HTTPException(status_code=400, detail="IncohÃ©rence des IDs de pathologie.")
    
    try:
        return disease_service.add_treatment_to_disease(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get(
    "/{disease_id}/treatments",
    response_model=List[schemas.relations.MedicationForDiseaseDetail],
    tags=["Therapeutic Relations"]
)
def get_treatments_for_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste des traitements recommandÃ©s pour une pathologie.
    """
    associations = disease_service.get_treatments_for_disease(db, disease_id=disease_id)
    return [
        {
            "medicament": assoc.medicament,
            "type_traitement": assoc.type_traitement,
            "ligne_traitement": assoc.ligne_traitement,
            "rang_preference": assoc.rang_preference,
        }
        for assoc in associations
    ]

=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/diagnostic.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List, Dict, Any

from ...services import diagnostic_engine
from ...dependencies import get_db

router = APIRouter(
    prefix="/diagnostic-engine",
    tags=["Diagnostic Engine"]
)


@router.post("/run", response_model=List[Dict[str, Any]])
def run_diagnostic_engine(
    patient_facts: diagnostic_engine.DiagnosticInput,
    db: Session = Depends(get_db)
):
    """
    ExÃ©cute le moteur de raisonnement sur un ensemble de faits patient.

    Prend en entrÃ©e une liste de symptÃ´mes et de contextes, et retourne
    une liste d'actions/conclusions basÃ©es sur les rÃ¨gles expertes actives
    dans le systÃ¨me.
    """
    if not patient_facts.symptoms:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="La liste des symptÃ´mes ne peut pas Ãªtre vide."
        )

    conclusions = diagnostic_engine.run_diagnostic(db=db, patient_facts=patient_facts)
    
    return conclusions

=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/clinical_cases.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import clinical_case_service, media_service, symptom_service, disease_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/clinical-cases",
    tags=["Clinical Cases"]
)


@router.post("/", response_model=schemas.clinical_case.ClinicalCase, status_code=status.HTTP_201_CREATED)
def create_clinical_case(case_data: schemas.clinical_case.ClinicalCaseCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e un nouveau cas clinique.
    """
    db_case_by_code = clinical_case_service.get_case_by_code(db, code=case_data.code_fultang)
    if db_case_by_code:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Un cas avec le code '{case_data.code_fultang}' existe dÃ©jÃ ."
        )
    try:
        # Le service create_case retournera un objet SQLAlchemy
        db_case = clinical_case_service.create_case(db=db, case=case_data)
        # La conversion vers le schÃ©ma Pydantic se fait automatiquement par FastAPI
        return db_case
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))


@router.get("/", response_model=List[schemas.clinical_case.ClinicalCaseSimple])
def read_all_clinical_cases(skip: int = 0, limit: int = 25, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste simplifiÃ©e de cas cliniques.
    """
    cases = clinical_case_service.get_all_cases(db, skip=skip, limit=limit)
    
    # La conversion vers le schÃ©ma Pydantic gÃ¨re automatiquement la construction de la rÃ©ponse
    # en utilisant les relations SQLAlchemy et les configurations 'from_attributes'.
    # Cependant, pour des champs calculÃ©s comme 'nb_images', nous devons construire la rÃ©ponse manuellement.
    response = []
    for case in cases:
        case_simple = schemas.clinical_case.ClinicalCaseSimple(
            id=case.id,
            code_fultang=case.code_fultang,
            niveau_difficulte=case.niveau_difficulte,
            pathologie_principale=case.pathologie_principale,
            nb_images=len(case.images_associees_ids) if case.images_associees_ids else 0,
            nb_sons=len(case.sons_associes_ids) if case.sons_associes_ids else 0,
        )
        response.append(case_simple)
    return response


@router.get("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def read_clinical_case(case_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un cas clinique complet par son ID, avec tous les objets liÃ©s.
    """
    # 1. RÃ©cupÃ©rer le cas brut
    db_case = clinical_case_service.get_case_by_id(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=404, detail="Cas clinique non trouvÃ©.")
    
    # 2. Convertir en dictionnaire pour pouvoir injecter les champs enrichis
    case_dict = db_case.__dict__

    # 3. Enrichir : Pathologies Secondaires
    pathologies_secondaires = []
    if db_case.pathologies_secondaires_ids:
        for p_id in db_case.pathologies_secondaires_ids:
            p_obj = disease_service.get_disease_by_id(db, disease_id=p_id)
            if p_obj:
                pathologies_secondaires.append(p_obj)
    case_dict['pathologies_secondaires'] = pathologies_secondaires

    # 4. Enrichir : Images
    images = []
    if db_case.images_associees_ids:
        for img_id in db_case.images_associees_ids:
            img = media_service.get_image_medicale_by_id(db, image_id=img_id)
            if img:
                images.append(img)
    case_dict['images_associees'] = images

    # 5. Enrichir : PrÃ©sentation Clinique DÃ©taillÃ©e
    # Le champ 'presentation_clinique' en base contient juste des IDs.
    # Nous devons aller chercher les objets SymptÃ´mes complets.
    symptomes_details_in_case = []
    presentation_dict = db_case.presentation_clinique or {}
    
    if 'symptomes_patient' in presentation_dict:
        for item in presentation_dict['symptomes_patient']:
            # item ressemble Ã  {'symptome_id': 1, 'details': 'FiÃ¨vre forte'}
            sympt_id = item.get('symptome_id')
            sympt_obj = symptom_service.get_symptom_by_id(db, symptom_id=sympt_id)
            
            if sympt_obj:
                symptomes_details_in_case.append({
                    "symptome": sympt_obj, # L'objet complet
                    "details": item.get('details', '')
                })
    
    case_dict['presentation_clinique_detail'] = {
        "histoire_maladie": presentation_dict.get('histoire_maladie', ''),
        "symptomes_patient": symptomes_details_in_case,
        "antecedents": presentation_dict.get('antecedents')
    }

    # 6. Validation et Retour
    # On passe le dictionnaire enrichi Ã  Pydantic pour qu'il le valide et le formate
    return schemas.clinical_case.ClinicalCase.model_validate(case_dict)

@router.patch("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def update_clinical_case(case_id: int, case_data: schemas.clinical_case.ClinicalCaseUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour un cas clinique.
    """
    db_case = clinical_case_service.update_case(db, case_id=case_id, case_update=case_data)
    if db_case is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Cas clinique non trouvÃ©.")
    # La conversion vers le schÃ©ma de rÃ©ponse se fait automatiquement
    return db_case


@router.delete("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def delete_clinical_case(case_id: int, db: Session = Depends(get_db)):
    """
    Supprime un cas clinique.
    """
    db_case = clinical_case_service.delete_case(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Cas clinique non trouvÃ©.")
    # La conversion vers le schÃ©ma de rÃ©ponse se fait automatiquement
    return db_case



@router.get("/{case_id}/simple", response_model=schemas.clinical_case.ClinicalCaseSimple)
def read_clinical_case_simple(case_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un cas clinique dans une structure simplifiÃ©e avec la pathologie principale complÃ¨te.
    Retourne exactement la mÃªme structure que ClinicalCaseSimple mais avec l'objet pathologie_principale complet.
    """
    # RÃ©cupÃ©rer le cas
    db_case = clinical_case_service.get_case_by_id(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=404, detail="Cas clinique non trouvÃ©.")
    
    # Construire la rÃ©ponse simple
    case_simple = schemas.clinical_case.ClinicalCaseSimple(
        id=db_case.id,
        code_fultang=db_case.code_fultang,
        niveau_difficulte=db_case.niveau_difficulte,
        pathologie_principale=db_case.pathologie_principale,  # L'objet complet sera sÃ©rialisÃ©
        nb_images=len(db_case.images_associees_ids) if db_case.images_associees_ids else 0,
        nb_sons=len(db_case.sons_associes_ids) if db_case.sons_associes_ids else 0,
    )
    
    return case_simple

=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/knowledge_graph.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/medications.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import medication_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/medications",
    tags=["Medications"]
)


@router.post("/", response_model=schemas.medication.Medication, status_code=status.HTTP_201_CREATED)
def create_medication(medication_data: schemas.medication.MedicationCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e un nouveau mÃ©dicament.
    VÃ©rifie l'unicitÃ© du DCI (DÃ©nomination Commune Internationale).
    """
    db_medication = medication_service.get_medication_by_dci(db, dci=medication_data.dci)
    if db_medication:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Un mÃ©dicament avec le DCI '{medication_data.dci}' existe dÃ©jÃ ."
        )
    return medication_service.create_medication(db=db, medication=medication_data)


@router.get("/", response_model=List[schemas.medication.Medication])
def read_medications(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de mÃ©dicaments.
    """
    medications = medication_service.get_all_medications(db, skip=skip, limit=limit)
    return medications


@router.get("/{medication_id}", response_model=schemas.medication.Medication)
def read_medication(medication_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un mÃ©dicament par son ID.
    """
    db_medication = medication_service.get_medication_by_id(db, medication_id=medication_id)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="MÃ©dicament non trouvÃ©.")
    return db_medication


@router.patch("/{medication_id}", response_model=schemas.medication.Medication)
def update_medication(medication_id: int, medication_data: schemas.medication.MedicationUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour un mÃ©dicament.
    """
    db_medication = medication_service.update_medication(db, medication_id=medication_id, medication_update=medication_data)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="MÃ©dicament non trouvÃ©.")
    return db_medication


@router.delete("/{medication_id}", response_model=schemas.medication.Medication)
def delete_medication(medication_id: int, db: Session = Depends(get_db)):
    """
    Supprime un mÃ©dicament.
    """
    db_medication = medication_service.delete_medication(db, medication_id=medication_id)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="MÃ©dicament non trouvÃ©.")
    return db_medication

=== Fichier: ./python_files_backup/python_files_backup/app/api/v1/symptoms.py ===

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import symptom_service
from ...dependencies import get_db

# CrÃ©ation d'un nouveau routeur.
# C'est comme une mini-application FastAPI que l'on pourra inclure dans notre app principale.
router = APIRouter(
    prefix="/symptoms",  # Toutes les routes de ce fichier commenceront par /symptoms
    tags=["Symptoms"]      # Groupe les routes dans la documentation interactive
)


@router.post("/", response_model=schemas.Symptom, status_code=status.HTTP_201_CREATED)
def create_symptom(symptom: schemas.SymptomCreate, db: Session = Depends(get_db)):
    """
    CrÃ©e un nouveau symptÃ´me.
    """
    # VÃ©rifie si un symptÃ´me avec le mÃªme nom existe dÃ©jÃ 
    db_symptom = symptom_service.get_symptom_by_name(db, name=symptom.nom)
    if db_symptom:
        raise HTTPException(status_code=400, detail="Un symptÃ´me avec ce nom existe dÃ©jÃ .")
    
    return symptom_service.create_symptom(db=db, symptom=symptom)


@router.get("/", response_model=List[schemas.Symptom])
def read_symptoms(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re une liste de symptÃ´mes.
    """
    symptoms = symptom_service.get_all_symptoms(db, skip=skip, limit=limit)
    return symptoms


@router.get("/{symptom_id}", response_model=schemas.Symptom)
def read_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re un symptÃ´me par son ID.
    """
    db_symptom = symptom_service.get_symptom_by_id(db, symptom_id=symptom_id)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="SymptÃ´me non trouvÃ©.")
    return db_symptom


@router.patch("/{symptom_id}", response_model=schemas.Symptom)
def update_symptom(symptom_id: int, symptom: schemas.SymptomUpdate, db: Session = Depends(get_db)):
    """
    Met Ã  jour un symptÃ´me.
    """
    db_symptom = symptom_service.update_symptom(db, symptom_id=symptom_id, symptom_update=symptom)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="SymptÃ´me non trouvÃ©.")
    return db_symptom


@router.delete("/{symptom_id}", response_model=schemas.Symptom)
def delete_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    Supprime un symptÃ´me.
    """
    db_symptom = symptom_service.delete_symptom(db, symptom_id=symptom_id)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="SymptÃ´me non trouvÃ©.")
    return db_symptom

# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/symptoms.py

@router.get(
    "/{symptom_id}/diseases",
    response_model=List[schemas.relations.DiseaseForSymptomDetail],
    tags=["Disease-Symptom Relations"]
)
def get_diseases_for_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste de toutes les pathologies pouvant prÃ©senter ce symptÃ´me
    (utile pour le diagnostic diffÃ©rentiel).
    """
    associations = symptom_service.get_diseases_for_symptom(db, symptom_id=symptom_id)
    if not associations:
        return []
        
    response = []
    for assoc in associations:
        response.append({
            "pathologie": assoc.pathologie,
            "probabilite": assoc.probabilite,
            "importance_diagnostique": assoc.importance_diagnostique
        })
    return response



# Contenu Ã  AJOUTER Ã  la fin de app/api/v1/symptoms.py

@router.post(
    "/{symptom_id}/treatments",
    response_model=schemas.relations.TraitementSymptome,
    status_code=status.HTTP_201_CREATED,
    tags=["Therapeutic Relations"]
)
def add_treatment_to_symptom(
    symptom_id: int,
    association_data: schemas.relations.TraitementSymptomeCreate,
    db: Session = Depends(get_db)
):
    """
    Associe un mÃ©dicament Ã  un symptÃ´me pour un traitement symptomatique.
    """
    if symptom_id != association_data.symptome_id:
        raise HTTPException(status_code=400, detail="IncohÃ©rence des IDs de symptÃ´me.")
    
    try:
        return symptom_service.add_treatment_to_symptom(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get(
    "/{symptom_id}/treatments",
    response_model=List[schemas.relations.MedicationForSymptomDetail],
    tags=["Therapeutic Relations"]
)
def get_treatments_for_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    RÃ©cupÃ¨re la liste des traitements pour un symptÃ´me spÃ©cifique.
    """
    associations = symptom_service.get_treatments_for_symptom(db, symptom_id=symptom_id)
    return [
        {
            "medicament": assoc.medicament,
            "efficacite": assoc.efficacite,
            "rang_preference": assoc.rang_preference,
        }
        for assoc in associations
    ]

=== Fichier: ./python_files_backup/python_files_backup/app/api/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/database.py ===

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from .config import settings

# L'objet 'engine' est le point d'entrÃ©e principal pour communiquer avec la BDD.
engine = create_engine(
    settings.DATABASE_URL,
    # pool_pre_ping=True # Option utile en production
)

# La 'SessionLocal' est une "usine" Ã  sessions de base de donnÃ©es.
# Chaque fois que nous aurons besoin de parler Ã  la BDD, nous demanderons une session Ã  cette usine.
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

=== Fichier: ./python_files_backup/python_files_backup/app/models/tutor_models.py ===

from sqlalchemy import Column, Integer, String, Text, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean
from sqlalchemy.orm import relationship
from sqlalchemy.dialects.postgresql import UUID
from .base import Base

class LearningPath(Base):
    __tablename__ = "learning_paths"

    id = Column(Integer, primary_key=True, index=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    
    algorithme_recommandation = Column(String(100))
    ordered_case_ids = Column(JSON, comment="Liste ordonnÃ©e des IDs des cas") 
    progression = Column(Float, default=0.0)
    status = Column(String(50), default="in_progress")
    created_at = Column(TIMESTAMP, server_default=text("now()"))

    learner = relationship("Learner")


class TutorDecision(Base):
    __tablename__ = "tutor_decisions"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    trigger_event_id = Column(Integer, ForeignKey("interaction_logs.id"), nullable=True)
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    strategy_used = Column(String(100)) # Socratique, Scaffolding...
    action_choisie = Column(String(100)) # Hint, Encouragement
    intervention_content = Column(Text)
    rationale = Column(JSON) # Pourquoi j'ai fait Ã§a ?
    succes_intervention = Column(Boolean, nullable=True)

    session = relationship("SimulationSession", back_populates="tutor_decisions")


class TutorStrategiesHistory(Base):
    __tablename__ = "tutor_strategies_history"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    strategy_name = Column(String(100))
    relevance_score = Column(Float)


class TutorScaffoldingState(Base):
    __tablename__ = "tutor_scaffolding_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    competence_cible_id = Column(Integer, ForeignKey("competences_cliniques.id"))
    current_level = Column(Integer, default=0)
    indices_deja_donnes = Column(JSON)


class TutorSocraticState(Base):
    __tablename__ = "tutor_socratic_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    tactic_used = Column(String(100))
    target_concept = Column(String(255))
    step_in_dialogue = Column(Integer)


class TutorMotivationalState(Base):
    __tablename__ = "tutor_motivational_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    intervention_type = Column(String(100))
    emotional_state_before = Column(JSON)


class TutorFeedbackLog(Base):
    __tablename__ = "tutor_feedback_logs"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    feedback_type = Column(String(50))
    content = Column(Text)

=== Fichier: ./python_files_backup/python_files_backup/app/models/symptom.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    Boolean,
    JSON,
    TIMESTAMP,
    text
)
from pgvector.sqlalchemy import Vector
from sqlalchemy.orm import relationship

from .base import Base


class Symptom(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des symptÃ´mes.

    Cette table est le catalogue central de tous les symptÃ´mes connus par le systÃ¨me expert.
    Elle inclut des informations dÃ©taillÃ©es pour permettre un raisonnement clinique fin
    et des recherches sÃ©mantiques.
    """
    __tablename__ = "symptomes"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et CatÃ©gorisation ---
    nom = Column(String(255), nullable=False, unique=True, index=True)
    nom_local = Column(String(255), comment="Nom vernaculaire ou local, ex: 'Ntou-tou' pour la toux")
    categorie = Column(String(100), index=True, comment="CatÃ©gorie fonctionnelle (ex: Respiratoire, Neurologique, Digestif)")
    type_symptome = Column(String(50), comment="Type de symptÃ´me (ex: Subjectif, Objectif, Signe clinique)")

    # --- Description et Contexte Clinique ---
    description = Column(Text, comment="Description dÃ©taillÃ©e du symptÃ´me et de sa signification clinique.")
    questions_anamnese = Column(JSON, comment="Liste structurÃ©e de questions pour explorer ce symptÃ´me (ex: PQRST)")
    signes_alarme = Column(Boolean, default=False, nullable=False, comment="Indique si ce symptÃ´me est un signe de gravitÃ© ('red flag')")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    # Relation vers la table d'association 'pathologie_symptomes'
    # 'back_populates' assure la synchronisation de la relation des deux cÃ´tÃ©s.
    # 'cascade' signifie que si un symptÃ´me est supprimÃ©, ses associations le seront aussi.
    pathologies = relationship(
        "PathologieSymptome",
        back_populates="symptome",
        cascade="all, delete-orphan"
    )
    traitements = relationship(
        "TraitementSymptome",
        back_populates="symptome",
        cascade="all, delete-orphan"
    )

    def __repr__(self) -> str:
        return f"<Symptom(id={self.id}, nom='{self.nom}')>"

=== Fichier: ./python_files_backup/python_files_backup/app/models/medication.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    text
)
from pgvector.sqlalchemy import Vector
from sqlalchemy.orm import relationship
from .base import Base


class Medication(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des mÃ©dicaments.

    Cette table est le catalogue central de tous les mÃ©dicaments connus par le systÃ¨me,
    incluant des informations pharmacologiques et contextuelles (disponibilitÃ©, coÃ»t).
    """
    __tablename__ = "medicaments"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification ---
    nom_commercial = Column(String(255), index=True)
    dci = Column(String(255), nullable=False, index=True, comment="DÃ©nomination Commune Internationale")
    
    # --- Classification et Formulation ---
    classe_therapeutique = Column(String(255), index=True)
    forme_galenique = Column(String(100), comment="Ex: ComprimÃ©, Sirop, Injectable")
    dosage = Column(String(100))
    voie_administration = Column(String(100), comment="Ex: Orale, IV, IM, CutanÃ©e")

    # --- Informations Pharmacologiques ---
    mecanisme_action = Column(Text)
    indications = Column(JSON)
    contre_indications = Column(JSON)
    effets_secondaires = Column(JSON)
    interactions_medicamenteuses = Column(JSON)
    precautions_emploi = Column(Text)
    posologie_standard = Column(JSON, comment="Posologie standard par Ã¢ge, poids, indication")

    # --- Contexte Local (Cameroun) ---
    disponibilite_cameroun = Column(String(50), comment="Ex: Urbain, Rural, CHU_uniquement")
    cout_moyen_fcfa = Column(Integer)
    statut_prescription = Column(String(50), comment="Ex: Prescription_obligatoire, OTC")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    traitements_pathologies = relationship("TraitementPathologie", back_populates="medicament")
    traitements_symptomes = relationship("TraitementSymptome", back_populates="medicament")

    def __repr__(self) -> str:
        return f"<Medication(id={self.id}, dci='{self.dci}')>"

=== Fichier: ./python_files_backup/python_files_backup/app/models/clinical_case.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    ForeignKey,
    ARRAY,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class ClinicalCase(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des cas cliniques enrichis.
    C'est l'objet central utilisÃ© pour les scÃ©narios d'apprentissage.
    """
    __tablename__ = "cas_cliniques_enrichis"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et IntÃ©gritÃ© ---
    code_fultang = Column(String(100), unique=True, index=True, comment="Identifiant unique provenant de Fultang (ou synthÃ©tique)")
    hash_integrite = Column(String(64), nullable=True, comment="SHA-256 pour la preuve d'intÃ©gritÃ© des donnÃ©es brutes")

    # --- Liaisons aux Connaissances de Base ---
    pathologie_principale_id = Column(Integer, ForeignKey("pathologies.id"), nullable=True, index=True)
    pathologies_secondaires_ids = Column(ARRAY(Integer), comment="Liste d'IDs de pathologies comorbides ou secondaires")

    # --- DonnÃ©es du ScÃ©nario ---
    donnees_brutes = Column(JSON, nullable=True, comment="DonnÃ©es originales (ex: de Fultang) avant traitement")
    presentation_clinique = Column(JSON, nullable=False, comment="Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.")
    donnees_paracliniques = Column(JSON, comment="RÃ©sultats des examens pour ce cas spÃ©cifique")
    evolution_patient = Column(Text, comment="Description de l'Ã©volution du patient pendant le cas")
    
    # --- Liaisons MultimÃ©dia ---
    images_associees_ids = Column(ARRAY(Integer), comment="Liste des IDs des images de la table 'images_medicales'")
    sons_associes_ids = Column(ARRAY(Integer), comment="Liste des IDs des sons de la table 'sons_medicaux'")

    # --- Liaisons ThÃ©rapeutiques ---
    medicaments_prescrits = Column(JSON, comment="Liste des mÃ©dicaments prescrits dans ce cas")

    # --- MÃ©tadonnÃ©es PÃ©dagogiques ---
    niveau_difficulte = Column(Integer, default=3, comment="DifficultÃ© du cas (1-5)")
    duree_estimee_resolution_min = Column(Integer, comment="Temps estimÃ© pour rÃ©soudre le cas")
    objectifs_apprentissage = Column(JSON, comment="Liste des compÃ©tences Ã  acquÃ©rir")
    competences_requises = Column(JSON, comment="Mapping Q-Matrix pour ce cas")

    valide_expert = Column(Boolean, default=False)
    
    # ClÃ© Ã©trangÃ¨re vers la table experts
    expert_validateur_id = Column(Integer, ForeignKey("experts.id"), nullable=True)
    
    # Relation avec ExpertUser
    expert_validateur = relationship("ExpertUser", back_populates="cas_valides")
    date_validation = Column(Date)

    qualite_donnees = Column(Integer, comment="QualitÃ© des donnÃ©es sources (1-5)")

    # --- MÃ©triques d'Utilisation ---
    nb_utilisations = Column(Integer, default=0)
    note_moyenne_apprenants = Column(DECIMAL(3, 2))
    taux_succes_diagnostic = Column(DECIMAL(5, 2))
    
    # --- Intelligence Artificielle ---
    embedding_texte = Column(Vector(384), nullable=True, comment="Embedding de la description textuelle du cas")
    embedding_global = Column(Vector(1536), nullable=True, comment="Embedding multimodal fusionnÃ© (texte+image+son)")
    
    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    pathologie_principale = relationship("Disease")

    def __repr__(self) -> str:
        return f"<ClinicalCase(id={self.id}, code='{self.code_fultang}')>"

=== Fichier: ./python_files_backup/python_files_backup/app/models/learner_models.py ===

from sqlalchemy import Column, Integer, String, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean
from sqlalchemy.orm import relationship
from .base import Base

class Learner(Base):
    __tablename__ = "learners"

    id = Column(Integer, primary_key=True, index=True)
    matricule = Column(String(50), unique=True, index=True)
    nom = Column(String(255))
    email = Column(String(255), unique=True, index=True)
    niveau_etudes = Column(String(50)) # Med 3, Interne...
    specialite_visee = Column(String(100))
    langue_preferee = Column(String(10), default="fr")
    date_inscription = Column(TIMESTAMP, server_default=text("now()"))

    # Relations
    competency_mastery = relationship("LearnerCompetencyMastery", back_populates="learner")
    misconceptions = relationship("LearnerMisconception", back_populates="learner")
    sessions = relationship("SimulationSession", back_populates="learner")


class LearnerCompetencyMastery(Base):
    __tablename__ = "learner_competency_mastery"

    id = Column(Integer, primary_key=True, index=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    mastery_level = Column(Float, default=0.0) # ProbabilitÃ© BKT (0-1)
    confidence = Column(Float, default=0.0) # Certitude du systÃ¨me
    last_practice_date = Column(TIMESTAMP)
    nb_success = Column(Integer, default=0)
    nb_failures = Column(Integer, default=0)
    streak_correct = Column(Integer, default=0)

    learner = relationship("Learner", back_populates="competency_mastery")
    competence = relationship("Competence") # Lien vers Module Expert


class LearnerCognitiveProfile(Base):
    __tablename__ = "learner_cognitive_profiles"

    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), unique=True)
    
    vitesse_assimilation = Column(Float)
    capacite_memoire_travail = Column(Float)
    tendance_impulsivite = Column(Float) # 0 (RÃ©flÃ©chi) - 1 (Impulsif)
    prefer_visual = Column(Boolean, default=False)
    
    learner = relationship("Learner")


class LearnerMisconception(Base):
    __tablename__ = "learner_misconceptions"

    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    
    type_erreur = Column(String(255)) # ex: "Confond Virus/BactÃ©rie"
    frequence_apparition = Column(Integer, default=1)
    resistance_correction = Column(Float, default=0.0) # 0-1
    detected_at = Column(TIMESTAMP, server_default=text("now()"))
    
    learner = relationship("Learner", back_populates="misconceptions")


class LearnerGoal(Base):
    __tablename__ = "learner_goals"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    type_objectif = Column(String(100))
    domaine_cible = Column(String(100))
    date_limite = Column(TIMESTAMP)
    statut = Column(String(50)) # en_cours, atteint, abandonne


class LearnerPreference(Base):
    __tablename__ = "learner_preferences"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    cle = Column(String(100))
    valeur = Column(String(255))


class LearnerAchievement(Base):
    __tablename__ = "learner_achievements"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    badge_id = Column(String(100))
    date_obtention = Column(TIMESTAMP, server_default=text("now()"))


class LearnerStrategy(Base):
    __tablename__ = "learner_strategies"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    strategy_name = Column(String(100)) # ex: "Gaming", "Help Seeking"
    frequency = Column(Integer)
    effectiveness = Column(Float)

=== Fichier: ./python_files_backup/python_files_backup/app/models/relations.py ===

from sqlalchemy import (
    JSON,
    Column,
    Integer,
    ForeignKey,
    DECIMAL,
    String,
    Boolean,
    Text
)
from sqlalchemy.orm import relationship

from .base import Base


class PathologieSymptome(Base):
    """
    ModÃ¨le de la table d'association entre Pathologies et SymptÃ´mes.

    Cette table matÃ©rialise la relation "plusieurs-Ã -plusieurs" et permet de stocker
    des informations contextuelles sur le lien, telles que la probabilitÃ©
    d'apparition, la spÃ©cificitÃ©, etc.
    """
    __tablename__ = "pathologie_symptomes"

    id = Column(Integer, primary_key=True)

    # --- ClÃ©s Ã‰trangÃ¨res ---
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=False)
    symptome_id = Column(Integer, ForeignKey("symptomes.id"), nullable=False)

    # --- Attributs de la Relation ---
    probabilite = Column(DECIMAL(5, 4), comment="ProbabilitÃ© d'apparition du symptÃ´me pour cette pathologie P(symptÃ´me|pathologie)")
    sensibilite = Column(DECIMAL(5, 4))
    specificite = Column(DECIMAL(5, 4))
    phase_maladie = Column(String(50), comment="Phase de la maladie oÃ¹ le symptÃ´me apparaÃ®t (ex: PrÃ©coce, Tardive)")
    frequence = Column(String(50), comment="FrÃ©quence d'apparition (ex: Constant, FrÃ©quent, Occasionnel)")
    est_pathognomonique = Column(Boolean, default=False, comment="Si True, ce symptÃ´me seul suffit presque Ã  poser le diagnostic")
    importance_diagnostique = Column(Integer, comment="Ã‰chelle de 1 Ã  5 sur l'importance de ce symptÃ´me pour le diagnostic")

    # --- Relations Inverses (Back-population) ---
    # Permet d'accÃ©der Ã  l'objet parent directement depuis une instance de cette classe.
    # ex: mon_association.pathologie -> renvoie l'objet Disease
    pathologie = relationship("Disease", back_populates="symptomes")
    symptome = relationship("Symptom", back_populates="pathologies")

    def __repr__(self) -> str:
        return f"<PathologieSymptome(pathologie_id={self.pathologie_id}, symptome_id={self.symptome_id})>"
    

# Contenu Ã  AJOUTER Ã  la fin de app/models/relations.py

class TraitementPathologie(Base):
    """
    Table d'association pour les traitements spÃ©cifiques aux pathologies.
    """
    __tablename__ = "traitements_pathologies"

    id = Column(Integer, primary_key=True)
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=False)
    medicament_id = Column(Integer, ForeignKey("medicaments.id"), nullable=False)

    type_traitement = Column(String(50), comment="Ex: Premiere_intention, Alternative, Adjuvant")
    ligne_traitement = Column(Integer, comment="Ex: 1Ã¨re ligne, 2e ligne")
    indication_precise = Column(Text)
    efficacite_taux = Column(DECIMAL(5, 2), comment="Taux de succÃ¨s en %")
    duree_traitement_jours = Column(Integer)
    posologie_detaillee = Column(JSON)
    niveau_preuve = Column(String(50), comment="Grade de recommandation (A, B, C)")
    guidelines_source = Column(String(255), comment="Source (OMS, MINSANTE Cameroun, etc.)")
    rang_preference = Column(Integer, default=99)

    pathologie = relationship("Disease", back_populates="traitements")
    medicament = relationship("Medication", back_populates="traitements_pathologies")


class TraitementSymptome(Base):
    """
    Table d'association pour les traitements symptomatiques.
    """
    __tablename__ = "traitements_symptomes"

    id = Column(Integer, primary_key=True)
    symptome_id = Column(Integer, ForeignKey("symptomes.id"), nullable=False)
    medicament_id = Column(Integer, ForeignKey("medicaments.id"), nullable=False)

    efficacite = Column(String(50), comment="Ex: Tres_efficace, Efficace, Modere")
    rapidite_action = Column(String(100), comment="Ex: Immediate, <30min")
    posologie_recommandee = Column(Text)
    rang_preference = Column(Integer, default=99)
    
    symptome = relationship("Symptom", back_populates="traitements")
    medicament = relationship("Medication", back_populates="traitements_symptomes")




=== Fichier: ./python_files_backup/python_files_backup/app/models/tracking_models.py ===

from sqlalchemy import Column, Integer, String, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean, Text
from sqlalchemy.orm import relationship
from sqlalchemy.dialects.postgresql import UUID
import uuid
from .base import Base

class SimulationSession(Base):
    __tablename__ = "simulation_sessions"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    cas_clinique_id = Column(Integer, ForeignKey("cas_cliniques_enrichis.id"), nullable=False)
    
    start_time = Column(TIMESTAMP, server_default=text("now()"))
    end_time = Column(TIMESTAMP)
    score_final = Column(Float)
    temps_total = Column(Integer)
    cout_virtuel_genere = Column(Integer)
    statut = Column(String(50), default="en_cours")
    raison_fin = Column(String(100))
    current_stage = Column(String(50))
    context_state = Column(JSON)

    learner = relationship("Learner", back_populates="sessions")
    cas_clinique = relationship("ClinicalCase")
    
    # --- Relations ---
    messages = relationship("ChatMessage", back_populates="session", cascade="all, delete-orphan")
    tutor_decisions = relationship("TutorDecision", back_populates="session")
    
    # --- RELATION VERS INTERACTION LOG MISE EN COMMENTAIRE ---
    # Nous la rÃ©activerons quand la table 'interaction_logs' sera crÃ©Ã©e.
    # logs = relationship("InteractionLog", back_populates="session")
    # ----------------------------------------------------

class ChatMessage(Base):
    __tablename__ = "chat_messages"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"), nullable=False)
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    sender = Column(String(50), nullable=False) # student, patient, tutor
    content = Column(Text, nullable=False)
    message_metadata = Column(JSON)

    session = relationship("SimulationSession", back_populates="messages")

=== Fichier: ./python_files_backup/python_files_backup/app/models/prerequisite.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    ForeignKey,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship

from .base import Base


class Competence(Base):
    """
    ModÃ¨le SQLAlchemy pour les compÃ©tences cliniques (Knowledge Components).
    """
    __tablename__ = "competences_cliniques"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification ---
    code_competence = Column(String(50), unique=True, nullable=False, index=True, comment="Code unique (ex: 'ANAMNESE_DOULEUR')")
    nom = Column(String(255), nullable=False)
    categorie = Column(String(100), index=True, comment="Ex: Anamnese, Examen_physique, Raisonnement, Technique")
    
    # --- PÃ©dagogie ---
    niveau_bloom = Column(Integer, comment="Niveau dans la taxonomie de Bloom (1-6)")
    description = Column(Text)
    objectifs_apprentissage = Column(JSON, comment="Liste dÃ©taillÃ©e des objectifs")
    criteres_maitrise = Column(JSON, comment="CritÃ¨res pour valider la compÃ©tence")
    
    # --- HiÃ©rarchie (Parent/Enfant) ---
    parent_competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=True)
    ordre_apprentissage = Column(Integer, default=0)

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # --- Relations ---
    children = relationship("Competence", 
                          back_populates="parent",
                          cascade="all, delete-orphan")
    
    parent = relationship("Competence", 
                        back_populates="children",
                        remote_side=[id])

    # Relation vers les prÃ©requis
    prerequis = relationship(
        "Competence",
        secondary="prerequis_competences",
        primaryjoin="Competence.id==prerequis_competences.c.competence_id",
        secondaryjoin="Competence.id==prerequis_competences.c.prerequis_id",
        backref="est_prerequis_pour"
    )

    def __repr__(self) -> str:
        return f"<Competence(code='{self.code_competence}', nom='{self.nom}')>"


class PrerequisCompetence(Base):
    """
    Table d'association pour le graphe de prÃ©requis entre compÃ©tences.
    Permet de dire : "Pour apprendre A, il faut d'abord maÃ®triser B".
    """
    __tablename__ = "prerequis_competences"

    id = Column(Integer, primary_key=True)
    
    # La compÃ©tence cible (Celle qu'on veut apprendre)
    competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    # La compÃ©tence prÃ©requise (Celle qu'on doit dÃ©jÃ  avoir)
    prerequis_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    # --- MÃ©tadonnÃ©es de la relation ---
    type_relation = Column(String(50), default="STRICT", comment="STRICT, RECOMMANDE, SUPPORTIF")
    force_relation = Column(DECIMAL(3, 2), default=1.0, comment="Force du lien (0-1)")

    def __repr__(self) -> str:
        return f"<Prerequis(target={self.competence_id}, needed={self.prerequis_id})>"

=== Fichier: ./python_files_backup/python_files_backup/app/models/__init__.py ===

from .base import Base
from .symptom import Symptom
from .disease import Disease
from .medication import Medication
from .media import ImageMedicale
from .clinical_case import ClinicalCase
from .expert_strategy import ExpertStrategy
from .relations import PathologieSymptome, TraitementPathologie, TraitementSymptome
from .prerequisite import Competence, PrerequisCompetence

# --- AJOUTER CES LIGNES SI ELLES MANQUENT ---
from .learner_models import (
    Learner, LearnerCompetencyMastery, LearnerCognitiveProfile, 
    LearnerMisconception, LearnerGoal, LearnerPreference, 
    LearnerAchievement, LearnerStrategy
)
from .tracking_models import (
    SimulationSession, InteractionLog, ChatMessage, LearnerAffectiveState
)
from .tutor_models import (
    LearningPath, TutorDecision, TutorStrategiesHistory, 
    TutorScaffoldingState, TutorSocraticState, TutorMotivationalState, 
    TutorFeedbackLog
)
from .expert_user import ExpertUser

=== Fichier: ./python_files_backup/python_files_backup/app/models/expert_user.py ===

from sqlalchemy import Column, Integer, String, Text, Boolean, TIMESTAMP, text
from sqlalchemy.orm import relationship
from .base import Base

class ExpertUser(Base):
    __tablename__ = "experts"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String(255), unique=True, index=True, nullable=False)
    hashed_password = Column(String(255), nullable=False)
    nom_complet = Column(String(255))
    specialite = Column(String(100))
    hopital_affiliation = Column(String(255))
    role = Column(String(50), default="validateur") # superadmin, validateur, contributeur
    
    last_login = Column(TIMESTAMP)
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # Relation avec les cas cliniques validÃ©s
    cas_valides = relationship("ClinicalCase", back_populates="expert_validateur")

=== Fichier: ./python_files_backup/python_files_backup/app/models/expert_strategy.py ===

from sqlalchemy import (
    DECIMAL,
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    text
)
from sqlalchemy.orm import relationship

from .base import Base


class ExpertStrategy(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des rÃ¨gles de production (stratÃ©gies expertes).
    
    Cette table stocke la logique IF-THEN du systÃ¨me expert.
    """
    __tablename__ = "regles_production"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et MÃ©tadonnÃ©es ---
    code_regle = Column(String(50), unique=True, nullable=False, index=True)
    categorie = Column(String(100), index=True, comment="Ex: DIAGNOSTIC, THERAPEUTIQUE, PEDAGOGIQUE, ALERTE")
    priorite = Column(Integer, default=5, comment="PrioritÃ© d'exÃ©cution (1-10), 10 Ã©tant le plus prioritaire")
    
    # --- Structure de la RÃ¨gle (IF-THEN) ---
    conditions = Column(JSON, nullable=False, comment="Partie 'IF' de la rÃ¨gle, structurÃ©e en JSON")
    # Exemple de 'conditions':
    # {
    #   "operator": "AND",
    #   "rules": [
    #     {"fact": "symptom", "value": "FiÃ¨vre", "operator": "present"},
    #     {"fact": "symptom", "value": "Toux", "operator": "present"},
    #     {"fact": "age", "value": 65, "operator": "greater_than"}
    #   ]
    # }

    actions = Column(JSON, nullable=False, comment="Partie 'THEN' de la rÃ¨gle, structurÃ©e en JSON")
    # Exemple d' 'actions':
    # [
    #   {"action": "add_hypothesis", "pathology": "Pneumonie", "confidence": 0.8},
    #   {"action": "recommend_exam", "exam": "Radio Thorax", "urgency": "high"}
    # ]

    # --- Documentation et Validation ---
    description_naturelle = Column(Text, comment="Description de la rÃ¨gle en langage naturel")
    justification_medicale = Column(Text, comment="Source ou justification clinique de la rÃ¨gle")
    expert_auteur = Column(String(255))
    date_validation = Column(Date)
    est_active = Column(Boolean, default=True, nullable=False)

    # --- MÃ©triques ---
    nb_activations = Column(Integer, default=0)
    taux_succes = Column(DECIMAL(5, 4))

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    def __repr__(self) -> str:
        return f"<ExpertStrategy(id={self.id}, code='{self.code_regle}')>"

=== Fichier: ./python_files_backup/python_files_backup/app/models/media.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    ForeignKey,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class ImageMedicale(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des images mÃ©dicales.
    Catalogue toutes les images (radios, scanners, etc.) avec leurs mÃ©tadonnÃ©es.
    """
    __tablename__ = "images_medicales"

    id = Column(Integer, primary_key=True, index=True)

    # --- Classification et Liaison ---
    type_examen = Column(String(100), nullable=False, index=True, comment="Ex: Radiographie, Ã‰chographie, Scanner")
    sous_type = Column(String(100), comment="Ex: Thorax, Abdomen, CrÃ¢ne")
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=True, index=True)

    # --- Gestion du Fichier ---
    fichier_url = Column(String(500), nullable=False, comment="URL vers le fichier (S3, stockage local, etc.)")
    fichier_miniature_url = Column(String(500), comment="URL vers une version miniature de l'image")
    format_image = Column(String(20), comment="Ex: DICOM, PNG, JPEG")
    taille_ko = Column(Integer)
    resolution = Column(String(50))

    # --- MÃ©tadonnÃ©es Cliniques ---
    description = Column(Text, comment="Description gÃ©nÃ©rale de l'image ou du cas")
    signes_radiologiques = Column(JSON, comment="Signes spÃ©cifiques visibles (ex: opacitÃ©, Ã©panchement)")
    annotations = Column(JSON, comment="CoordonnÃ©es et descriptions de zones d'intÃ©rÃªt")
    interpretation_experte = Column(Text, comment="Compte-rendu d'un radiologue expert")
    diagnostic_differentiel = Column(JSON, comment="Autres diagnostics possibles basÃ©s sur l'image")

    # --- MÃ©tadonnÃ©es PÃ©dagogiques ---
    niveau_difficulte = Column(Integer, comment="DifficultÃ© d'interprÃ©tation de l'image (1-5)")
    qualite_image = Column(Integer, comment="QualitÃ© technique de l'image (1-5)")

    # --- Intelligence Artificielle ---
    embedding_vision = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle")

    # --- Validation et Horodatage ---
    valide_expert = Column(Boolean, default=False)
    expert_validateur = Column(String(255))
    date_validation = Column(Date)
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # --- Relations ---
    # Permet d'accÃ©der Ã  l'objet Pathologie depuis une ImageMedicale
    pathologie = relationship("Disease") # Nous n'avons pas besoin de back_populates ici pour l'instant

    def __repr__(self) -> str:
        return f"<ImageMedicale(id={self.id}, type='{self.type_examen}')>"


=== Fichier: ./python_files_backup/python_files_backup/app/models/knowledge_version.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/models/disease.py ===

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class Disease(Base):
    """
    ModÃ¨le SQLAlchemy pour la table des pathologies (maladies).

    Cette table contient toutes les informations dÃ©taillÃ©es sur chaque maladie
    connue par le systÃ¨me, y compris le contexte local, les caractÃ©ristiques
    cliniques et les vecteurs pour l'IA.
    """
    __tablename__ = "pathologies"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et Classification ---
    code_icd10 = Column(String(20), unique=True, index=True, comment="Code international de la maladie (CIM-10)")
    nom_fr = Column(String(255), nullable=False, index=True)
    nom_en = Column(String(255))
    nom_local = Column(String(255), comment="Noms locaux ou courants au Cameroun")
    categorie = Column(String(100), index=True, comment="Ex: Infectieuse, Chronique, Parasitaire")

    # --- DonnÃ©es Cliniques et Ã‰pidÃ©miologiques ---
    prevalence_cameroun = Column(DECIMAL(5, 2), comment="PrÃ©valence en % dans le contexte camerounais")
    niveau_gravite = Column(Integer, comment="Ã‰chelle de 1 (bÃ©nin) Ã  5 (critique)")
    description = Column(Text)
    physiopathologie = Column(Text, comment="MÃ©canisme de la maladie")
    evolution_naturelle = Column(Text, comment="Comment la maladie Ã©volue sans traitement")
    complications = Column(JSON, comment="Complications possibles")
    facteurs_risque = Column(JSON, comment="Facteurs de risque associÃ©s")
    prevention = Column(Text, comment="Mesures de prÃ©vention")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    # Nous prÃ©parons le terrain pour la future relation avec les symptÃ´mes.
    # Pour l'instant, elle reste en commentaire pour Ã©viter les erreurs d'import circulaire.
    symptomes = relationship(
         "PathologieSymptome",
         back_populates="pathologie",
         cascade="all, delete-orphan"
    
     )
    
    traitements = relationship(
        "TraitementPathologie",
        back_populates="pathologie",
        cascade="all, delete-orphan"
    )

    def __repr__(self) -> str:
        return f"<Disease(id={self.id}, nom_fr='{self.nom_fr}')>"

=== Fichier: ./python_files_backup/python_files_backup/app/models/diagnostic.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/models/base.py ===

from sqlalchemy.orm import declarative_base

# Cette instance de 'declarative_base' est le catalogue central oÃ¹ SQLAlchemy
# enregistrera toutes les classes de modÃ¨les que nous dÃ©finirons.
# C'est ce que Alembic utilisera pour comparer l'Ã©tat de notre code
# avec l'Ã©tat de la base de donnÃ©es.
Base = declarative_base()

=== Fichier: ./python_files_backup/python_files_backup/app/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/services/fultang_integration/extractor.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/services/fultang_integration/validator.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/services/fultang_integration/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/services/fultang_integration/anonymizer.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/services/fultang_integration/case_generator.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/services/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/services/learning_path_service.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/services/medication_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_medication_by_id(db: Session, medication_id: int) -> Optional[models.Medication]:
    """
    RÃ©cupÃ¨re un mÃ©dicament par son ID.
    """
    return db.query(models.Medication).filter(models.Medication.id == medication_id).first()

def get_medication_by_dci(db: Session, dci: str) -> Optional[models.Medication]:
    """
    RÃ©cupÃ¨re un mÃ©dicament par son DCI (DÃ©nomination Commune Internationale).
    """
    return db.query(models.Medication).filter(models.Medication.dci == dci).first()

def get_all_medications(db: Session, skip: int = 0, limit: int = 100) -> List[models.Medication]:
    """
    RÃ©cupÃ¨re une liste de tous les mÃ©dicaments avec pagination.
    """
    return db.query(models.Medication).offset(skip).limit(limit).all()

def create_medication(db: Session, medication: schemas.MedicationCreate) -> models.Medication:
    """
    CrÃ©e un nouveau mÃ©dicament dans la base de donnÃ©es.
    """
    medication_data = medication.model_dump()
    db_medication = models.Medication(**medication_data)
    
    db.add(db_medication)
    db.commit()
    db.refresh(db_medication)
    
    return db_medication

def update_medication(db: Session, medication_id: int, medication_update: schemas.MedicationUpdate) -> Optional[models.Medication]:
    """
    Met Ã  jour un mÃ©dicament existant.
    """
    db_medication = get_medication_by_id(db, medication_id)
    if not db_medication:
        return None

    update_data = medication_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_medication, key, value)
        
    db.commit()
    db.refresh(db_medication)
    
    return db_medication

def delete_medication(db: Session, medication_id: int) -> Optional[models.Medication]:
    """
    Supprime un mÃ©dicament de la base de donnÃ©es.
    """
    db_medication = get_medication_by_id(db, medication_id)
    if not db_medication:
        return None

    db.delete(db_medication)
    db.commit()
    
    return db_medication




# Contenu Ã  AJOUTER Ã  la fin de app/services/medication_service.py

def get_diseases_treated_by_medication(db: Session, medication_id: int) -> List[models.TraitementPathologie]:
    """
    RÃ©cupÃ¨re toutes les pathologies traitÃ©es par un mÃ©dicament.
    """
    return db.query(models.TraitementPathologie).filter(models.TraitementPathologie.medicament_id == medication_id).all()


def get_symptoms_treated_by_medication(db: Session, medication_id: int) -> List[models.TraitementSymptome]:
    """
    RÃ©cupÃ¨re tous les symptÃ´mes traitÃ©s par un mÃ©dicament.
    """
    return db.query(models.TraitementSymptome).filter(models.TraitementSymptome.medicament_id == medication_id).all()

=== Fichier: ./python_files_backup/python_files_backup/app/services/media_service.py ===

import os
from sqlalchemy.orm import Session
from typing import List, Optional
from fastapi import UploadFile
import cloudinary
import cloudinary.uploader

from .. import models, schemas
from ..config import settings

# --- CONFIGURATION CLOUDINARY ---
# Cette configuration est faite une seule fois au chargement du module.
# Elle utilise les variables chargÃ©es depuis votre fichier .env.
cloudinary.config(
    cloud_name = settings.CLOUDINARY_CLOUD_NAME,
    api_key = settings.CLOUDINARY_API_KEY,
    api_secret = settings.CLOUDINARY_API_SECRET,
    secure = True
)


async def save_upload_file_to_cloud(upload_file: UploadFile) -> str:
    """
    Fonction utilitaire pour uploader un fichier directement vers Cloudinary
    et retourner son URL sÃ©curisÃ©e.
    """
    try:
        # Lire le contenu du fichier en mÃ©moire
        content = await upload_file.read()
        
        # Envoyer le contenu Ã  Cloudinary
        upload_result = cloudinary.uploader.upload(
            content,
            folder="sti_medical_expert/uploads"  # Dossier de destination sur Cloudinary
        )
        
        # RÃ©cupÃ©rer l'URL sÃ©curisÃ©e (https://...)
        secure_url = upload_result.get("secure_url")
        if not secure_url:
            raise Exception("Ã‰chec de l'upload vers Cloudinary, URL non retournÃ©e.")
            
        return secure_url
    finally:
        # Toujours fermer le fichier aprÃ¨s lecture
        await upload_file.close()


async def create_image_medicale(
    db: Session,
    file: UploadFile,
    type_examen: str,
    sous_type: Optional[str] = None,
    pathologie_id: Optional[int] = None,
    description: Optional[str] = None
) -> models.ImageMedicale:
    """
    CrÃ©e une nouvelle entrÃ©e pour une image mÃ©dicale.
    1. Sauvegarde le fichier sur Cloudinary.
    2. CrÃ©e l'enregistrement correspondant en base de donnÃ©es avec l'URL cloud.
    """
    # 1. Sauvegarder le fichier physique sur le cloud
    cloud_url = await save_upload_file_to_cloud(file)

    # 2. CrÃ©er l'objet SQLAlchemy avec les mÃ©tadonnÃ©es et l'URL cloud
    db_image = models.ImageMedicale(
        type_examen=type_examen,
        sous_type=sous_type,
        pathologie_id=pathologie_id,
        description=description,
        fichier_url=cloud_url, # <-- C'est maintenant l'URL Cloudinary !
        format_image=file.content_type.split('/')[-1] if file.content_type else None,
        taille_ko=file.size // 1024 if file.size else None,
    )
    
    db.add(db_image)
    db.commit()
    db.refresh(db_image)
    
    return db_image


def get_image_medicale_by_id(db: Session, image_id: int) -> Optional[models.ImageMedicale]:
    """
    RÃ©cupÃ¨re une image mÃ©dicale par son ID.
    """
    return db.query(models.ImageMedicale).filter(models.ImageMedicale.id == image_id).first()


def get_all_images_medicales(db: Session, skip: int = 0, limit: int = 100) -> List[models.ImageMedicale]:
    """
    RÃ©cupÃ¨re une liste de toutes les images mÃ©dicales avec pagination.
    """
    return db.query(models.ImageMedicale).offset(skip).limit(limit).all()


def update_image_medicale_metadata(
    db: Session,
    image_id: int,
    image_update: schemas.ImageMedicaleUpdate
) -> Optional[models.ImageMedicale]:
    """
    Met Ã  jour les mÃ©tadonnÃ©es d'une image mÃ©dicale existante.
    """
    db_image = get_image_medicale_by_id(db, image_id)
    if not db_image:
        return None

    update_data = image_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_image, key, value)
        
    db.commit()
    db.refresh(db_image)
    
    return db_image


def delete_image_medicale(db: Session, image_id: int) -> Optional[models.ImageMedicale]:
    """
    Supprime une image mÃ©dicale.
    1. Supprime l'enregistrement de la base de donnÃ©es.
    2. (Optionnel) Supprime le fichier sur Cloudinary.
    """
    db_image = get_image_medicale_by_id(db, image_id)
    if not db_image:
        return None

    # Optionnel : Ajouter ici la logique pour supprimer l'image de Cloudinary
    # via cloudinary.uploader.destroy(...) si vous voulez un nettoyage complet.
    # Pour l'instant, nous nous contentons de supprimer la rÃ©fÃ©rence.

    db.delete(db_image)
    db.commit()
    
    return db_image

=== Fichier: ./python_files_backup/python_files_backup/app/services/symptom_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas
from ..utils.exceptions import NotFoundException # Nous crÃ©erons ce fichier plus tard


def get_symptom_by_id(db: Session, symptom_id: int) -> Optional[models.Symptom]:
    """
    RÃ©cupÃ¨re un symptÃ´me par son ID.
    """
    return db.query(models.Symptom).filter(models.Symptom.id == symptom_id).first()


def get_symptom_by_name(db: Session, name: str) -> Optional[models.Symptom]:
    """
    RÃ©cupÃ¨re un symptÃ´me par son nom.
    """
    return db.query(models.Symptom).filter(models.Symptom.nom == name).first()


def get_all_symptoms(db: Session, skip: int = 0, limit: int = 100) -> List[models.Symptom]:
    """
    RÃ©cupÃ¨re une liste de tous les symptÃ´mes avec pagination.
    """
    return db.query(models.Symptom).offset(skip).limit(limit).all()


def create_symptom(db: Session, symptom: schemas.SymptomCreate) -> models.Symptom:
    """
    CrÃ©e un nouveau symptÃ´me dans la base de donnÃ©es.
    
    Prend un schÃ©ma Pydantic 'SymptomCreate' en entrÃ©e, le convertit en
    modÃ¨le SQLAlchemy 'Symptom' et l'ajoute Ã  la base de donnÃ©es.
    """
    # Convertit le schÃ©ma Pydantic en dictionnaire
    symptom_data = symptom.model_dump()
    
    # CrÃ©e une instance du modÃ¨le SQLAlchemy
    db_symptom = models.Symptom(**symptom_data)
    
    # Ajoute l'instance Ã  la session de la base de donnÃ©es
    db.add(db_symptom)
    # Valide la transaction pour l'Ã©crire en base
    db.commit()
    # RafraÃ®chit l'instance pour obtenir les valeurs gÃ©nÃ©rÃ©es par la BDD (comme l'ID)
    db.refresh(db_symptom)
    
    return db_symptom


def update_symptom(db: Session, symptom_id: int, symptom_update: schemas.SymptomUpdate) -> Optional[models.Symptom]:
    """
    Met Ã  jour un symptÃ´me existant.
    """
    db_symptom = get_symptom_by_id(db, symptom_id)
    if not db_symptom:
        # Plus tard, nous lÃ¨verons une exception personnalisÃ©e
        # raise NotFoundException(detail=f"Symptom with id {symptom_id} not found")
        return None

    # Convertit le schÃ©ma Pydantic en dictionnaire, en excluant les valeurs non dÃ©finies
    update_data = symptom_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_symptom, key, value)
        
    db.commit()
    db.refresh(db_symptom)
    
    return db_symptom


def delete_symptom(db: Session, symptom_id: int) -> Optional[models.Symptom]:
    """
    Supprime un symptÃ´me de la base de donnÃ©es.
    """
    db_symptom = get_symptom_by_id(db, symptom_id)
    if not db_symptom:
        # raise NotFoundException(detail=f"Symptom with id {symptom_id} not found")
        return None

    db.delete(db_symptom)
    db.commit()
    
    return db_symptom

def get_diseases_for_symptom(db: Session, symptom_id: int) -> List[models.PathologieSymptome]:
    """
    RÃ©cupÃ¨re toutes les pathologies associÃ©es Ã  un symptÃ´me (diagnostic diffÃ©rentiel).
    """
    return db.query(models.PathologieSymptome).filter(models.PathologieSymptome.symptome_id == symptom_id).all()





def add_treatment_to_symptom(db: Session, association_data: schemas.relations.TraitementSymptomeCreate) -> models.TraitementSymptome:
    """
    Associe un mÃ©dicament Ã  un symptÃ´me en tant que traitement symptomatique.
    """
    db_symptom = get_symptom_by_id(db, symptom_id=association_data.symptome_id)
    from . import medication_service
    db_medication = medication_service.get_medication_by_id(db, medication_id=association_data.medicament_id)

    if not db_symptom or not db_medication:
        raise ValueError("SymptÃ´me ou MÃ©dicament non trouvÃ©.")

    association = models.TraitementSymptome(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_treatments_for_symptom(db: Session, symptom_id: int) -> List[models.TraitementSymptome]:
    """
    RÃ©cupÃ¨re tous les traitements associÃ©s Ã  un symptÃ´me.
    """
    return db.query(models.TraitementSymptome).filter(models.TraitementSymptome.symptome_id == symptom_id).all()

=== Fichier: ./python_files_backup/python_files_backup/app/services/clinical_case_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

# Importer les autres services dont nous aurons besoin
from . import disease_service
from . import media_service


def get_case_by_id(db: Session, case_id: int) -> Optional[models.ClinicalCase]:
    """
    RÃ©cupÃ¨re un cas clinique par son ID.
    """
    return db.query(models.ClinicalCase).filter(models.ClinicalCase.id == case_id).first()


def get_case_by_code(db: Session, code: str) -> Optional[models.ClinicalCase]:
    """
    RÃ©cupÃ¨re un cas clinique par son code Fultang ou synthÃ©tique.
    """
    return db.query(models.ClinicalCase).filter(models.ClinicalCase.code_fultang == code).first()


def get_all_cases(db: Session, skip: int = 0, limit: int = 100) -> List[models.ClinicalCase]:
    """
    RÃ©cupÃ¨re une liste de tous les cas cliniques avec pagination.
    """
    return db.query(models.ClinicalCase).offset(skip).limit(limit).all()


def create_case(db: Session, case: schemas.ClinicalCaseCreate) -> models.ClinicalCase:
    """
    CrÃ©e un nouveau cas clinique dans la base de donnÃ©es.
    """
    # VÃ©rifier que la pathologie principale existe, si elle est fournie
    if case.pathologie_principale_id:
        db_disease = disease_service.get_disease_by_id(db, disease_id=case.pathologie_principale_id)
        if not db_disease:
            raise ValueError(f"La pathologie avec l'ID {case.pathologie_principale_id} n'existe pas.")

    # VÃ©rifier que les images associÃ©es existent, si elles sont fournies
    if case.images_associees_ids:
        for img_id in case.images_associees_ids:
            db_image = media_service.get_image_medicale_by_id(db, image_id=img_id)
            if not db_image:
                raise ValueError(f"L'image avec l'ID {img_id} n'existe pas.")

    case_data = case.model_dump()
    db_case = models.ClinicalCase(**case_data)
    
    db.add(db_case)
    db.commit()
    db.refresh(db_case)
    
    return db_case


def update_case(db: Session, case_id: int, case_update: schemas.ClinicalCaseUpdate) -> Optional[models.ClinicalCase]:
    """
    Met Ã  jour un cas clinique existant.
    """
    db_case = get_case_by_id(db, case_id)
    if not db_case:
        return None

    update_data = case_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_case, key, value)
        
    db.commit()
    db.refresh(db_case)
    
    return db_case


def delete_case(db: Session, case_id: int) -> Optional[models.ClinicalCase]:
    """
    Supprime un cas clinique de la base de donnÃ©es.
    Note : Ne supprime pas les entitÃ©s associÃ©es (maladies, images...).
    """
    db_case = get_case_by_id(db, case_id)
    if not db_case:
        return None

    db.delete(db_case)
    db.commit()
    
    return db_case

=== Fichier: ./python_files_backup/python_files_backup/app/services/expert_strategy_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_strategy_by_id(db: Session, strategy_id: int) -> Optional[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re une rÃ¨gle par son ID.
    """
    return db.query(models.ExpertStrategy).filter(models.ExpertStrategy.id == strategy_id).first()

def get_strategy_by_code(db: Session, code: str) -> Optional[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re une rÃ¨gle par son code unique.
    """
    return db.query(models.ExpertStrategy).filter(models.ExpertStrategy.code_regle == code).first()

def get_all_strategies(db: Session, skip: int = 0, limit: int = 100) -> List[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re une liste de toutes les rÃ¨gles avec pagination.
    """
    return db.query(models.ExpertStrategy).offset(skip).limit(limit).all()

def get_active_strategies_by_category(db: Session, category: str) -> List[models.ExpertStrategy]:
    """
    RÃ©cupÃ¨re toutes les rÃ¨gles actives pour une catÃ©gorie donnÃ©e, triÃ©es par prioritÃ©.
    Cette fonction sera trÃ¨s utile pour le moteur de raisonnement.
    """
    return db.query(models.ExpertStrategy).filter(
        models.ExpertStrategy.categorie == category,
        models.ExpertStrategy.est_active == True
    ).order_by(models.ExpertStrategy.priorite.desc()).all()


def create_strategy(db: Session, strategy: schemas.ExpertStrategyCreate) -> models.ExpertStrategy:
    """
    CrÃ©e une nouvelle rÃ¨gle dans la base de donnÃ©es.
    """
    strategy_data = strategy.model_dump()
    db_strategy = models.ExpertStrategy(**strategy_data)
    
    db.add(db_strategy)
    db.commit()
    db.refresh(db_strategy)
    
    return db_strategy

def update_strategy(db: Session, strategy_id: int, strategy_update: schemas.ExpertStrategyUpdate) -> Optional[models.ExpertStrategy]:
    """
    Met Ã  jour une rÃ¨gle existante.
    """
    db_strategy = get_strategy_by_id(db, strategy_id)
    if not db_strategy:
        return None

    update_data = strategy_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_strategy, key, value)
        
    db.commit()
    db.refresh(db_strategy)
    
    return db_strategy

def delete_strategy(db: Session, strategy_id: int) -> Optional[models.ExpertStrategy]:
    """
    Supprime une rÃ¨gle de la base de donnÃ©es.
    """
    db_strategy = get_strategy_by_id(db, strategy_id)
    if not db_strategy:
        return None

    db.delete(db_strategy)
    db.commit()
    
    return db_strategy

=== Fichier: ./python_files_backup/python_files_backup/app/services/embedding_service.py ===

from sentence_transformers import SentenceTransformer
import logging

# Configuration du logging
logger = logging.getLogger(__name__)

class EmbeddingService:
    """
    Service pour gÃ©nÃ©rer des embeddings (vecteurs) Ã  partir de texte.
    Utilise le modÃ¨le 'all-MiniLM-L6-v2' qui est un excellent compromis
    rapiditÃ©/qualitÃ© pour l'anglais et le franÃ§ais technique.
    """
    
    _instance = None
    _model = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(EmbeddingService, cls).__new__(cls)
            logger.info("Initialisation du modÃ¨le d'embedding...")
            # Chargement du modÃ¨le. On essaie sans le prÃ©fixe 'sentence-transformers/'
            # Si cela Ã©choue encore, nous essaierons une autre approche.
            try:
                cls._model = SentenceTransformer('all-MiniLM-L6-v2')
            except Exception as e:
                logger.error(f"Erreur chargement modÃ¨le 'all-MiniLM-L6-v2': {e}")
                # Tentative de repli explicite
                cls._model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
            
            logger.info("ModÃ¨le d'embedding chargÃ© avec succÃ¨s.")
        return cls._instance

    def get_text_embedding(self, text: str) -> list:
        """
        GÃ©nÃ¨re un vecteur d'embedding pour une chaÃ®ne de caractÃ¨res donnÃ©e.
        
        :param text: Le texte Ã  vectoriser.
        :return: Une liste de flottants (le vecteur).
        """
        if not text or not isinstance(text, str):
            return None
            
        try:
            # Le modÃ¨le retourne un numpy array, on le convertit en liste simple
            # pour qu'il soit compatible avec pgvector et JSON.
            embedding = self._model.encode(text)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"Erreur lors de la vectorisation du texte : {e}")
            return None

# Instance globale prÃªte Ã  l'emploi
embedding_service = EmbeddingService()

=== Fichier: ./python_files_backup/python_files_backup/app/services/chat_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional
from uuid import UUID

from .. import models, schemas


def create_chat_message(db: Session, session_id: UUID, message: schemas.ChatMessageCreate) -> models.ChatMessage:
    """
    CrÃ©e un nouveau message de chat et l'associe Ã  une session.
    
    :param db: Session de base de donnÃ©es.
    :param session_id: L'ID de la session de simulation Ã  laquelle le message appartient.
    :param message: Le schÃ©ma Pydantic contenant les donnÃ©es du message.
    :return: L'objet ChatMessage crÃ©Ã©.
    """
    # VÃ©rifier que la session parente existe pour garantir l'intÃ©gritÃ©
    session = db.query(models.SimulationSession).filter(models.SimulationSession.id == session_id).first()
    if not session:
        raise ValueError(f"La session avec l'ID {session_id} n'a pas Ã©tÃ© trouvÃ©e.")

    # CrÃ©er l'instance du modÃ¨le SQLAlchemy
    db_message = models.ChatMessage(
        **message.model_dump(),
        session_id=session_id
    )
    
    db.add(db_message)
    db.commit()
    db.refresh(db_message)
    
    return db_message


def get_messages_by_session(db: Session, session_id: UUID) -> List[models.ChatMessage]:
    """
    RÃ©cupÃ¨re tous les messages d'une session de simulation, triÃ©s par ordre chronologique.
    
    :param db: Session de base de donnÃ©es.
    :param session_id: L'ID de la session Ã  interroger.
    :return: Une liste d'objets ChatMessage.
    """
    return db.query(models.ChatMessage).filter(
        models.ChatMessage.session_id == session_id
    ).order_by(models.ChatMessage.timestamp.asc()).all()

=== Fichier: ./python_files_backup/python_files_backup/app/services/diagnostic_engine.py ===

from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional

from .. import models
from ..core import reasoning_engine
from . import expert_strategy_service

# Pour le typage, nous pouvons dÃ©finir un schÃ©ma simple ici
from pydantic import BaseModel

class DiagnosticInput(BaseModel):
    """
    SchÃ©ma simple pour les donnÃ©es d'entrÃ©e du moteur de diagnostic.
    """
    symptoms: List[str]
    context: List[str] = []
    age: Optional[int] = None
    # ... d'autres faits pertinents pourraient Ãªtre ajoutÃ©s ici


def run_diagnostic(db: Session, patient_facts: DiagnosticInput) -> List[Dict[str, Any]]:
    """
    Orchestre le processus de diagnostic.

    1. RÃ©cupÃ¨re les rÃ¨gles de diagnostic actives depuis la base de donnÃ©es.
    2. Formate les faits du patient.
    3. Appelle le moteur de raisonnement.
    4. Retourne les actions/conclusions.
    """
    # 1. RÃ©cupÃ©rer les rÃ¨gles
    # On utilise la fonction 'intelligente' que nous avions crÃ©Ã©e dans le service des stratÃ©gies
    diagnostic_rules_db = expert_strategy_service.get_active_strategies_by_category(
        db, category="DIAGNOSTIC"
    )

    if not diagnostic_rules_db:
        return []

    # Convertir les objets SQLAlchemy en dictionnaires simples pour le moteur de logique pure
    rules_list = [
        {
            "code_regle": rule.code_regle,
            "conditions": rule.conditions,
            "actions": rule.actions,
        }
        for rule in diagnostic_rules_db
    ]

    # 2. Formater les faits (dÃ©jÃ  au bon format grÃ¢ce Ã  Pydantic)
    facts_dict = patient_facts.model_dump()

    # 3. Appeler le moteur de raisonnement
    conclusions = reasoning_engine.forward_chaining_engine(
        rules=rules_list,
        facts=facts_dict
    )

    # 4. Retourner les conclusions
    return conclusions

=== Fichier: ./python_files_backup/python_files_backup/app/services/q_matrix_service.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/services/disease_service.py ===

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_disease_by_id(db: Session, disease_id: int) -> Optional[models.Disease]:
    """
    RÃ©cupÃ¨re une pathologie par son ID.
    """
    return db.query(models.Disease).filter(models.Disease.id == disease_id).first()

def get_disease_by_icd10(db: Session, icd10_code: str) -> Optional[models.Disease]:
    """
    RÃ©cupÃ¨re une pathologie par son code CIM-10.
    """
    return db.query(models.Disease).filter(models.Disease.code_icd10 == icd10_code).first()

def get_all_diseases(db: Session, skip: int = 0, limit: int = 100) -> List[models.Disease]:
    """
    RÃ©cupÃ¨re une liste de toutes les pathologies avec pagination.
    """
    return db.query(models.Disease).offset(skip).limit(limit).all()

def create_disease(db: Session, disease: schemas.DiseaseCreate) -> models.Disease:
    """
    CrÃ©e une nouvelle pathologie dans la base de donnÃ©es.
    """
    disease_data = disease.model_dump()
    db_disease = models.Disease(**disease_data)
    
    db.add(db_disease)
    db.commit()
    db.refresh(db_disease)
    
    return db_disease

def update_disease(db: Session, disease_id: int, disease_update: schemas.DiseaseUpdate) -> Optional[models.Disease]:
    """
    Met Ã  jour une pathologie existante.
    """
    db_disease = get_disease_by_id(db, disease_id)
    if not db_disease:
        return None

    update_data = disease_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_disease, key, value)
        
    db.commit()
    db.refresh(db_disease)
    
    return db_disease

def delete_disease(db: Session, disease_id: int) -> Optional[models.Disease]:
    """
    Supprime une pathologie de la base de donnÃ©es.
    """
    db_disease = get_disease_by_id(db, disease_id)
    if not db_disease:
        return None

    db.delete(db_disease)
    db.commit()
    
    return db_disease

def add_symptom_to_disease(db: Session, association_data: schemas.relations.PathologieSymptomeCreate) -> models.PathologieSymptome:
    """
    Associe un symptÃ´me Ã  une pathologie avec des attributs de relation.
    """
    # VÃ©rifier que la pathologie et le symptÃ´me existent
    db_disease = get_disease_by_id(db, disease_id=association_data.pathologie_id)
    # Nous aurons besoin d'importer le symptom_service pour cette vÃ©rification
    from . import symptom_service
    db_symptom = symptom_service.get_symptom_by_id(db, symptom_id=association_data.symptome_id)

    if not db_disease or not db_symptom:
        # IdÃ©alement, lever une exception plus spÃ©cifique
        raise ValueError("Pathologie ou SymptÃ´me non trouvÃ©.")

    # CrÃ©er l'objet d'association
    association = models.PathologieSymptome(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_symptoms_for_disease(db: Session, disease_id: int) -> List[models.PathologieSymptome]:
    """
    RÃ©cupÃ¨re tous les symptÃ´mes associÃ©s Ã  une pathologie, avec les dÃ©tails de la relation.
    """
    return db.query(models.PathologieSymptome).filter(models.PathologieSymptome.pathologie_id == disease_id).all()


def add_treatment_to_disease(db: Session, association_data: schemas.relations.TraitementPathologieCreate) -> models.TraitementPathologie:
    """
    Associe un mÃ©dicament Ã  une pathologie en tant que traitement.
    """
    db_disease = get_disease_by_id(db, disease_id=association_data.pathologie_id)
    from . import medication_service
    db_medication = medication_service.get_medication_by_id(db, medication_id=association_data.medicament_id)

    if not db_disease or not db_medication:
        raise ValueError("Pathologie ou MÃ©dicament non trouvÃ©.")

    association = models.TraitementPathologie(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_treatments_for_disease(db: Session, disease_id: int) -> List[models.TraitementPathologie]:
    """
    RÃ©cupÃ¨re tous les traitements associÃ©s Ã  une pathologie.
    """
    return db.query(models.TraitementPathologie).filter(models.TraitementPathologie.pathologie_id == disease_id).all()

=== Fichier: ./python_files_backup/python_files_backup/app/dependencies.py ===

# app/dependencies.py
from .database import SessionLocal

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

=== Fichier: ./python_files_backup/python_files_backup/app/middleware/logging_middleware.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/middleware/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/middleware/error_handler.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/middleware/cors_middleware.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/config.py ===

from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # ... (existant)
    DATABASE_URL: str
    
    # --- AJOUT ---
    CLOUDINARY_CLOUD_NAME: str
    CLOUDINARY_API_KEY: str
    CLOUDINARY_API_SECRET: str
    # -------------

    class Config:
        env_file = ".env"
        extra = "ignore"

settings = Settings()

=== Fichier: ./python_files_backup/python_files_backup/app/utils/anonymization.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/utils/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/utils/formatters.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/utils/crypto.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/utils/validators.py ===



=== Fichier: ./python_files_backup/python_files_backup/app/utils/exceptions.py ===

# app/utils/exceptions.py

class NotFoundException(Exception):
    """
    Exception personnalisÃ©e Ã  lever lorsque'une ressource n'est pas trouvÃ©e
    dans la base de donnÃ©es.
    """
    def __init__(self, detail: str):
        self.detail = detail

=== Fichier: ./python_files_backup/python_files_backup/app/utils/logging.py ===



=== Fichier: ./python_files_backup/python_files_backup/setup.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/prompt_templates/patient_simulation.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/prompt_templates/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/prompt_templates/diagnostic_guidance.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/prompt_templates/feedback_generation.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/rag/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/rag/response_generator.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/rag/retriever.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/training/conversation_extractor.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/training/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/training/dataset_preparation.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/training/finetuning_pipeline.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/conversation/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/conversation/patient_agent.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/conversation/dialogue_manager.py ===



=== Fichier: ./python_files_backup/python_files_backup/llm_integration/conversation/tutor_agent.py ===



=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/7108003f9629_add_cas_symptomes_association_and_.py ===

"""Add cas_symptomes association and update models

Revision ID: 7108003f9629
Revises: 4f66bc9b6081
Create Date: 2025-11-07 10:04:10.734115+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '7108003f9629'
down_revision = '4f66bc9b6081'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('cas_symptomes')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_symptomes',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('cas_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('symptome_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('details_contextuels', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True, comment="Description narrative du symptÃ´me dans ce cas (ex: 'FiÃ¨vre Ã  40Â°C depuis 3 jours')"),
    sa.ForeignKeyConstraint(['cas_id'], ['cas_cliniques_enrichis.id'], name=op.f('cas_symptomes_cas_id_fkey')),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], name=op.f('cas_symptomes_symptome_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('cas_symptomes_pkey'))
    )
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/b6afb34f22d7_add_publication_status_to_clinical_cases.py ===

"""Add publication status to clinical cases

Revision ID: b6afb34f22d7
Revises: a0ee48d62174
Create Date: 2026-01-11 22:28:01.220042+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'b6afb34f22d7'
down_revision = 'a0ee48d62174'
branch_labels = None
depends_on = None


def upgrade() -> None:
    print("\n--- [LOG] DÃ‰BUT de la migration 'b6afb34f22d7' (upgrade) ---")
    
    try:
        print("    -> Tentative de suppression de la contrainte 'learner_knowledge_concept_id_fkey'")
        op.drop_constraint(
            'learner_knowledge_concept_id_fkey',
            'learner_knowledge',
            type_='foreignkey'
        )
        print("    -> âœ… Contrainte supprimÃ©e.")
    except Exception as e:
        print(f"    -> âš ï¸ Ã‰chec de la suppression de la contrainte (peut-Ãªtre dÃ©jÃ  supprimÃ©e) : {e}")

    try:
        print("    -> Tentative de suppression de la table 'concepts'")
        op.drop_table('concepts')
        print("    -> âœ… Table supprimÃ©e.")
    except Exception as e:
        print(f"    -> âš ï¸ Ã‰chec de la suppression de la table (peut-Ãªtre dÃ©jÃ  supprimÃ©e) : {e}")
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_learning_histories_id'), table_name='learning_histories')
    op.drop_table('learning_histories')
    op.drop_index(op.f('ix_learner_performances_id'), table_name='learner_performances')
    op.drop_table('learner_performances')
    op.drop_index(op.f('ix_learner_behaviors_id'), table_name='learner_behaviors')
    op.drop_table('learner_behaviors')
    op.drop_index(op.f('ix_concepts_id'), table_name='concepts')
    op.drop_table('concepts')
    op.drop_index(op.f('ix_learner_knowledge_id'), table_name='learner_knowledge')
    op.drop_table('learner_knowledge')
    op.add_column('cas_cliniques_enrichis', sa.Column('statut_publication', sa.String(length=50), nullable=False, comment='Statut du cas: brouillon, en_revision, valide, archive'))
    op.create_index(op.f('ix_cas_cliniques_enrichis_statut_publication'), 'cas_cliniques_enrichis', ['statut_publication'], unique=False)
    op.drop_index(op.f('ix_tutor_decisions_case_id'), table_name='tutor_decisions')
    op.drop_index(op.f('ix_tutor_decisions_learner_id'), table_name='tutor_decisions')
    op.drop_column('tutor_decisions', 'learner_id')
    op.drop_column('tutor_decisions', 'case_id')
    op.drop_column('tutor_decisions', 'metadata_snapshot')
    op.drop_column('tutor_socratic_state', 'updated_at')
    op.drop_column('tutor_socratic_state', 'current_step_focus')
    op.drop_column('tutor_socratic_state', 'last_question_asked')
    op.drop_column('tutor_socratic_state', 'dialogue_history')

    op.drop_constraint(
        'learner_knowledge_concept_id_fkey', # Le nom de la contrainte
        'learner_knowledge',                 # La table oÃ¹ elle se trouve
        type_='foreignkey'
    )
    # --------------------

    # 2. Maintenant, on peut supprimer la table
    op.drop_table('concepts')

    # ... reste du fichier (probablement l'ajout de la colonne 'statut_publication')
    op.add_column('cas_cliniques_enrichis', sa.Column('statut_publication', sa.String(length=50), nullable=False, server_default='brouillon'))
    
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('tutor_socratic_state', sa.Column('dialogue_history', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'[]'::jsonb"), autoincrement=False, nullable=True))
    op.add_column('tutor_socratic_state', sa.Column('last_question_asked', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('tutor_socratic_state', sa.Column('current_step_focus', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('tutor_socratic_state', sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True))
    op.add_column('tutor_decisions', sa.Column('metadata_snapshot', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=True))
    op.add_column('tutor_decisions', sa.Column('case_id', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('tutor_decisions', sa.Column('learner_id', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.create_index(op.f('ix_tutor_decisions_learner_id'), 'tutor_decisions', ['learner_id'], unique=False)
    op.create_index(op.f('ix_tutor_decisions_case_id'), 'tutor_decisions', ['case_id'], unique=False)
    op.drop_index(op.f('ix_cas_cliniques_enrichis_statut_publication'), table_name='cas_cliniques_enrichis')
    op.drop_column('cas_cliniques_enrichis', 'statut_publication')
    op.create_table('learner_knowledge',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('concept_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('mastery_level', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['concept_id'], ['concepts.id'], name=op.f('learner_knowledge_concept_id_fkey')),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learner_knowledge_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learner_knowledge_pkey'))
    )
    op.create_index(op.f('ix_learner_knowledge_id'), 'learner_knowledge', ['id'], unique=False)
    op.create_table('concepts',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('concepts_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('p_init', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('p_transit', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('p_guess', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('p_slip', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='concepts_pkey'),
    sa.UniqueConstraint('name', name='concepts_name_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('ix_concepts_id'), 'concepts', ['id'], unique=False)
    op.create_table('learner_behaviors',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('sessions_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('activities_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('total_time_spent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('engagement_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learner_behaviors_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learner_behaviors_pkey'))
    )
    op.create_index(op.f('ix_learner_behaviors_id'), 'learner_behaviors', ['id'], unique=False)
    op.create_table('learner_performances',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('concept_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('activity_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('time_spent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('attempts', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['concept_id'], ['concepts.id'], name=op.f('learner_performances_concept_id_fkey')),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learner_performances_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learner_performances_pkey'))
    )
    op.create_index(op.f('ix_learner_performances_id'), 'learner_performances', ['id'], unique=False)
    op.create_table('learning_histories',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('learner_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('activity_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('activity_ref', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('success', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('score', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('time_spent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], name=op.f('learning_histories_learner_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('learning_histories_pkey'))
    )
    op.create_index(op.f('ix_learning_histories_id'), 'learning_histories', ['id'], unique=False)
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/994203ee2537_add_cas_symptomes_association_table.py ===

"""Add cas_symptomes association table

Revision ID: 994203ee2537
Revises: a6bc48307908
Create Date: 2025-11-07 09:49:25.031773+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '994203ee2537'
down_revision = 'a6bc48307908'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('cas_id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('details_contextuels', sa.JSON(), nullable=True, comment="Description narrative du symptÃ´me dans ce cas (ex: 'FiÃ¨vre Ã  40Â°C depuis 3 jours')"),
    sa.ForeignKeyConstraint(['cas_id'], ['cas_cliniques_enrichis.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_nullable=False)
    op.drop_table('cas_symptomes')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/bc127903e3d2_add_expert_validateur_id_to_clinicalcase.py ===

"""Add expert_validateur_id to ClinicalCase

Revision ID: bc127903e3d2
Revises: 16068309bdb8
Create Date: 2025-12-25 00:23:58.911118+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector


# revision identifiers, used by Alembic.
revision = 'bc127903e3d2'
down_revision = '16068309bdb8'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('expert_validateur_id', sa.Integer(), nullable=True))
    op.create_foreign_key(None, 'cas_cliniques_enrichis', 'experts', ['expert_validateur_id'], ['id'])
    op.drop_column('cas_cliniques_enrichis', 'expert_validateur')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('expert_validateur', sa.VARCHAR(length=255), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'cas_cliniques_enrichis', type_='foreignkey')
    op.drop_column('cas_cliniques_enrichis', 'expert_validateur_id')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/bc4cda91a030_add_learner_tracking_and_tutor_tables.py ===

"""Add Learner, Tracking and Tutor tables

Revision ID: bc4cda91a030
Revises: afeac86179db
Create Date: 2025-12-19 10:03:40.038591+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'bc4cda91a030'
down_revision = 'afeac86179db'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/a6bc48307908_create_clinical_cases_table.py ===

"""Create clinical_cases table

Revision ID: a6bc48307908
Revises: b2699b90c4a9
Create Date: 2025-11-07 09:29:53.852125+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'a6bc48307908'
down_revision = 'b2699b90c4a9'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_cliniques_enrichis',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_fultang', sa.String(length=100), nullable=True, comment='Identifiant unique provenant de Fultang (ou synthÃ©tique)'),
    sa.Column('hash_integrite', sa.String(length=64), nullable=True, comment="SHA-256 pour la preuve d'intÃ©gritÃ© des donnÃ©es brutes"),
    sa.Column('pathologie_principale_id', sa.Integer(), nullable=True),
    sa.Column('donnees_brutes', sa.JSON(), nullable=True, comment='DonnÃ©es originales (ex: de Fultang) avant traitement'),
    sa.Column('presentation_clinique', sa.JSON(), nullable=False, comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.'),
    sa.Column('donnees_paracliniques', sa.JSON(), nullable=True, comment='RÃ©sultats des examens pour ce cas spÃ©cifique'),
    sa.Column('evolution_patient', sa.Text(), nullable=True, comment="Description de l'Ã©volution du patient pendant le cas"),
    sa.Column('images_associees_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste des IDs des images de la table 'images_medicales'"),
    sa.Column('sons_associes_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste des IDs des sons de la table 'sons_medicaux'"),
    sa.Column('medicaments_prescrits', sa.JSON(), nullable=True, comment='Liste des mÃ©dicaments prescrits dans ce cas'),
    sa.Column('niveau_difficulte', sa.Integer(), nullable=True, comment='DifficultÃ© du cas (1-5)'),
    sa.Column('duree_estimee_resolution_min', sa.Integer(), nullable=True, comment='Temps estimÃ© pour rÃ©soudre le cas'),
    sa.Column('objectifs_apprentissage', sa.JSON(), nullable=True, comment='Liste des compÃ©tences Ã  acquÃ©rir'),
    sa.Column('competences_requises', sa.JSON(), nullable=True, comment='Mapping Q-Matrix pour ce cas'),
    sa.Column('valide_expert', sa.Boolean(), nullable=True),
    sa.Column('expert_validateur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('qualite_donnees', sa.Integer(), nullable=True, comment='QualitÃ© des donnÃ©es sources (1-5)'),
    sa.Column('nb_utilisations', sa.Integer(), nullable=True),
    sa.Column('note_moyenne_apprenants', sa.DECIMAL(precision=3, scale=2), nullable=True),
    sa.Column('taux_succes_diagnostic', sa.DECIMAL(precision=5, scale=2), nullable=True),
    sa.Column('embedding_texte', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment='Embedding de la description textuelle du cas'),
    sa.Column('embedding_global', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True, comment='Embedding multimodal fusionnÃ© (texte+image+son)'),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['pathologie_principale_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_cas_cliniques_enrichis_code_fultang'), 'cas_cliniques_enrichis', ['code_fultang'], unique=True)
    op.create_index(op.f('ix_cas_cliniques_enrichis_id'), 'cas_cliniques_enrichis', ['id'], unique=False)
    op.create_index(op.f('ix_cas_cliniques_enrichis_pathologie_principale_id'), 'cas_cliniques_enrichis', ['pathologie_principale_id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_cas_cliniques_enrichis_pathologie_principale_id'), table_name='cas_cliniques_enrichis')
    op.drop_index(op.f('ix_cas_cliniques_enrichis_id'), table_name='cas_cliniques_enrichis')
    op.drop_index(op.f('ix_cas_cliniques_enrichis_code_fultang'), table_name='cas_cliniques_enrichis')
    op.drop_table('cas_cliniques_enrichis')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/4f66bc9b6081_add_cas_symptomes_association_and_.py ===

"""Add cas_symptomes association and update models

Revision ID: 4f66bc9b6081
Revises: 994203ee2537
Create Date: 2025-11-07 10:03:23.727581+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '4f66bc9b6081'
down_revision = '994203ee2537'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire gÃ©nÃ©rale du patient, antÃ©cÃ©dents, etc. (SANS la liste des symptÃ´mes)',
               existing_comment='Histoire du patient, symptÃ´mes prÃ©sentÃ©s, etc.',
               existing_nullable=False)
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/eb403e41e275_fix_expert_validateur_relationship.py ===

"""fix expert_validateur relationship

Revision ID: eb403e41e275
Revises: bc127903e3d2
Create Date: 2025-12-25 00:30:17.468368+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector


# revision identifiers, used by Alembic.
revision = 'eb403e41e275'
down_revision = 'bc127903e3d2'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/5c3894aa1b50_change_embedding_dimensions_to_384.py ===

"""change embedding dimensions to 384

Revision ID: 5c3894aa1b50
Revises: eb403e41e275
Create Date: 2025-12-26 00:14:27.010127+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '5c3894aa1b50'
down_revision = 'eb403e41e275'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'embedding_texte',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment='Embedding de la description textuelle du cas',
               existing_nullable=True)
    op.alter_column('images_medicales', 'embedding_vision',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle",
               existing_nullable=True)
    op.alter_column('medicaments', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires",
               existing_nullable=True)
    op.alter_column('pathologies', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique",
               existing_nullable=True)
    op.alter_column('symptomes', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)",
               existing_nullable=True)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('symptomes', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)",
               existing_nullable=True)
    op.alter_column('pathologies', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche sÃ©mantique",
               existing_nullable=True)
    op.alter_column('medicaments', 'embedding_vector',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires",
               existing_nullable=True)
    op.alter_column('images_medicales', 'embedding_vision',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle",
               existing_nullable=True)
    op.alter_column('cas_cliniques_enrichis', 'embedding_texte',
               existing_type=pgvector.sqlalchemy.vector.VECTOR(dim=384),
               type_=pgvector.sqlalchemy.vector.VECTOR(dim=768),
               existing_comment='Embedding de la description textuelle du cas',
               existing_nullable=True)
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/de1d3372f456_add_secondary_pathologies_to_clinical_.py ===

"""Add secondary pathologies to clinical cases

Revision ID: de1d3372f456
Revises: 7108003f9629
Create Date: 2025-11-07 13:38:16.973024+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'de1d3372f456'
down_revision = '7108003f9629'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('pathologies_secondaires_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste d'IDs de pathologies comorbides ou secondaires"))
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('cas_cliniques_enrichis', 'pathologies_secondaires_ids')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/f29ac6884d1c_create_medications_table.py ===

"""Create medications table

Revision ID: f29ac6884d1c
Revises: 8e5b38bb2891
Create Date: 2025-11-06 20:17:47.401019+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'f29ac6884d1c'
down_revision = '8e5b38bb2891'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('medicaments',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('nom_commercial', sa.String(length=255), nullable=True),
    sa.Column('dci', sa.String(length=255), nullable=False, comment='DÃ©nomination Commune Internationale'),
    sa.Column('classe_therapeutique', sa.String(length=255), nullable=True),
    sa.Column('forme_galenique', sa.String(length=100), nullable=True, comment='Ex: ComprimÃ©, Sirop, Injectable'),
    sa.Column('dosage', sa.String(length=100), nullable=True),
    sa.Column('voie_administration', sa.String(length=100), nullable=True, comment='Ex: Orale, IV, IM, CutanÃ©e'),
    sa.Column('mecanisme_action', sa.Text(), nullable=True),
    sa.Column('indications', sa.JSON(), nullable=True),
    sa.Column('contre_indications', sa.JSON(), nullable=True),
    sa.Column('effets_secondaires', sa.JSON(), nullable=True),
    sa.Column('interactions_medicamenteuses', sa.JSON(), nullable=True),
    sa.Column('precautions_emploi', sa.Text(), nullable=True),
    sa.Column('posologie_standard', sa.JSON(), nullable=True, comment='Posologie standard par Ã¢ge, poids, indication'),
    sa.Column('disponibilite_cameroun', sa.String(length=50), nullable=True, comment='Ex: Urbain, Rural, CHU_uniquement'),
    sa.Column('cout_moyen_fcfa', sa.Integer(), nullable=True),
    sa.Column('statut_prescription', sa.String(length=50), nullable=True, comment='Ex: Prescription_obligatoire, OTC'),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche de mÃ©dicaments similaires"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_medicaments_classe_therapeutique'), 'medicaments', ['classe_therapeutique'], unique=False)
    op.create_index(op.f('ix_medicaments_dci'), 'medicaments', ['dci'], unique=False)
    op.create_index(op.f('ix_medicaments_id'), 'medicaments', ['id'], unique=False)
    op.create_index(op.f('ix_medicaments_nom_commercial'), 'medicaments', ['nom_commercial'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_medicaments_nom_commercial'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_id'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_dci'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_classe_therapeutique'), table_name='medicaments')
    op.drop_table('medicaments')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/8e5b38bb2891_create_symptoms_table.py ===

"""Create symptoms table

Revision ID: 8e5b38bb2891
Revises: 6eb5a7dba20c
Create Date: 2025-11-06 19:31:00.822591+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '8e5b38bb2891'
down_revision = '6eb5a7dba20c'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('pathologie_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('pathologie_id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('probabilite', sa.DECIMAL(precision=5, scale=4), nullable=True, comment="ProbabilitÃ© d'apparition du symptÃ´me pour cette pathologie P(symptÃ´me|pathologie)"),
    sa.Column('sensibilite', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('specificite', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('phase_maladie', sa.String(length=50), nullable=True, comment='Phase de la maladie oÃ¹ le symptÃ´me apparaÃ®t (ex: PrÃ©coce, Tardive)'),
    sa.Column('frequence', sa.String(length=50), nullable=True, comment="FrÃ©quence d'apparition (ex: Constant, FrÃ©quent, Occasionnel)"),
    sa.Column('est_pathognomonique', sa.Boolean(), nullable=True, comment='Si True, ce symptÃ´me seul suffit presque Ã  poser le diagnostic'),
    sa.Column('importance_diagnostique', sa.Integer(), nullable=True, comment="Ã‰chelle de 1 Ã  5 sur l'importance de ce symptÃ´me pour le diagnostic"),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('pathologie_symptomes')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/4b1e2599b918_initial_empty_migration.py ===

"""Initial empty migration

Revision ID: 4b1e2599b918
Revises: 
Create Date: 2025-11-06 11:09:36.525928+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '4b1e2599b918'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    pass


def downgrade():
    pass


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/b2699b90c4a9_create_media_table.py ===

"""Create media table

Revision ID: b2699b90c4a9
Revises: 9aed193ba8b7
Create Date: 2025-11-07 07:45:54.209466+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'b2699b90c4a9'
down_revision = '9aed193ba8b7'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('images_medicales',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('type_examen', sa.String(length=100), nullable=False, comment='Ex: Radiographie, Ã‰chographie, Scanner'),
    sa.Column('sous_type', sa.String(length=100), nullable=True, comment='Ex: Thorax, Abdomen, CrÃ¢ne'),
    sa.Column('pathologie_id', sa.Integer(), nullable=True),
    sa.Column('fichier_url', sa.String(length=500), nullable=False, comment='URL vers le fichier (S3, stockage local, etc.)'),
    sa.Column('fichier_miniature_url', sa.String(length=500), nullable=True, comment="URL vers une version miniature de l'image"),
    sa.Column('format_image', sa.String(length=20), nullable=True, comment='Ex: DICOM, PNG, JPEG'),
    sa.Column('taille_ko', sa.Integer(), nullable=True),
    sa.Column('resolution', sa.String(length=50), nullable=True),
    sa.Column('description', sa.Text(), nullable=True, comment="Description gÃ©nÃ©rale de l'image ou du cas"),
    sa.Column('signes_radiologiques', sa.JSON(), nullable=True, comment='Signes spÃ©cifiques visibles (ex: opacitÃ©, Ã©panchement)'),
    sa.Column('annotations', sa.JSON(), nullable=True, comment="CoordonnÃ©es et descriptions de zones d'intÃ©rÃªt"),
    sa.Column('interpretation_experte', sa.Text(), nullable=True, comment="Compte-rendu d'un radiologue expert"),
    sa.Column('diagnostic_differentiel', sa.JSON(), nullable=True, comment="Autres diagnostics possibles basÃ©s sur l'image"),
    sa.Column('niveau_difficulte', sa.Integer(), nullable=True, comment="DifficultÃ© d'interprÃ©tation de l'image (1-5)"),
    sa.Column('qualite_image', sa.Integer(), nullable=True, comment="QualitÃ© technique de l'image (1-5)"),
    sa.Column('embedding_vision', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche par similaritÃ© visuelle"),
    sa.Column('valide_expert', sa.Boolean(), nullable=True),
    sa.Column('expert_validateur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_images_medicales_id'), 'images_medicales', ['id'], unique=False)
    op.create_index(op.f('ix_images_medicales_pathologie_id'), 'images_medicales', ['pathologie_id'], unique=False)
    op.create_index(op.f('ix_images_medicales_type_examen'), 'images_medicales', ['type_examen'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_images_medicales_type_examen'), table_name='images_medicales')
    op.drop_index(op.f('ix_images_medicales_pathologie_id'), table_name='images_medicales')
    op.drop_index(op.f('ix_images_medicales_id'), table_name='images_medicales')
    op.drop_table('images_medicales')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/afeac86179db_create_competencies_and_prerequisites_.py ===

"""Create competencies and prerequisites tables

Revision ID: afeac86179db
Revises: 03d192a5f522
Create Date: 2025-11-29 20:23:29.605930+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'afeac86179db'
down_revision = '03d192a5f522'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('competences_cliniques',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_competence', sa.String(length=50), nullable=False, comment="Code unique (ex: 'ANAMNESE_DOULEUR')"),
    sa.Column('nom', sa.String(length=255), nullable=False),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: Anamnese, Examen_physique, Raisonnement, Technique'),
    sa.Column('niveau_bloom', sa.Integer(), nullable=True, comment='Niveau dans la taxonomie de Bloom (1-6)'),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('objectifs_apprentissage', sa.JSON(), nullable=True, comment='Liste dÃ©taillÃ©e des objectifs'),
    sa.Column('criteres_maitrise', sa.JSON(), nullable=True, comment='CritÃ¨res pour valider la compÃ©tence'),
    sa.Column('parent_competence_id', sa.Integer(), nullable=True),
    sa.Column('ordre_apprentissage', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['parent_competence_id'], ['competences_cliniques.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_competences_cliniques_categorie'), 'competences_cliniques', ['categorie'], unique=False)
    op.create_index(op.f('ix_competences_cliniques_code_competence'), 'competences_cliniques', ['code_competence'], unique=True)
    op.create_index(op.f('ix_competences_cliniques_id'), 'competences_cliniques', ['id'], unique=False)
    op.create_table('prerequis_competences',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('competence_id', sa.Integer(), nullable=False),
    sa.Column('prerequis_id', sa.Integer(), nullable=False),
    sa.Column('type_relation', sa.String(length=50), nullable=True, comment='STRICT, RECOMMANDE, SUPPORTIF'),
    sa.Column('force_relation', sa.DECIMAL(precision=3, scale=2), nullable=True, comment='Force du lien (0-1)'),
    sa.ForeignKeyConstraint(['competence_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['prerequis_id'], ['competences_cliniques.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('prerequis_competences')
    op.drop_index(op.f('ix_competences_cliniques_id'), table_name='competences_cliniques')
    op.drop_index(op.f('ix_competences_cliniques_code_competence'), table_name='competences_cliniques')
    op.drop_index(op.f('ix_competences_cliniques_categorie'), table_name='competences_cliniques')
    op.drop_table('competences_cliniques')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/7995e67f8833_create_symptoms_table.py ===

"""Create symptoms table

Revision ID: 7995e67f8833
Revises: 4b1e2599b918
Create Date: 2025-11-06 12:48:47.725270+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '7995e67f8833'
down_revision = '4b1e2599b918'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('nom', sa.String(length=255), nullable=False),
    sa.Column('nom_local', sa.String(length=255), nullable=True, comment="Nom vernaculaire ou local, ex: 'Ntou-tou' pour la toux"),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='CatÃ©gorie fonctionnelle (ex: Respiratoire, Neurologique, Digestif)'),
    sa.Column('type_symptome', sa.String(length=50), nullable=True, comment='Type de symptÃ´me (ex: Subjectif, Objectif, Signe clinique)'),
    sa.Column('description', sa.Text(), nullable=True, comment='Description dÃ©taillÃ©e du symptÃ´me et de sa signification clinique.'),
    sa.Column('questions_anamnese', sa.JSON(), nullable=True, comment='Liste structurÃ©e de questions pour explorer ce symptÃ´me (ex: PQRST)'),
    sa.Column('signes_alarme', sa.Boolean(), nullable=False, comment="Indique si ce symptÃ´me est un signe de gravitÃ© ('red flag')"),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique (ex: BioBERT)"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_symptomes_categorie'), 'symptomes', ['categorie'], unique=False)
    op.create_index(op.f('ix_symptomes_id'), 'symptomes', ['id'], unique=False)
    op.create_index(op.f('ix_symptomes_nom'), 'symptomes', ['nom'], unique=True)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_symptomes_nom'), table_name='symptomes')
    op.drop_index(op.f('ix_symptomes_id'), table_name='symptomes')
    op.drop_index(op.f('ix_symptomes_categorie'), table_name='symptomes')
    op.drop_table('symptomes')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/16068309bdb8_add_learner_tracking_tutor_and_.py ===

"""Add Learner, Tracking, Tutor and ExpertUser tables

Revision ID: 16068309bdb8
Revises: bc4cda91a030
Create Date: 2025-12-23 02:00:58.044928+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '16068309bdb8'
down_revision = 'bc4cda91a030'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('experts',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('email', sa.String(length=255), nullable=False),
    sa.Column('hashed_password', sa.String(length=255), nullable=False),
    sa.Column('nom_complet', sa.String(length=255), nullable=True),
    sa.Column('specialite', sa.String(length=100), nullable=True),
    sa.Column('hopital_affiliation', sa.String(length=255), nullable=True),
    sa.Column('role', sa.String(length=50), nullable=True),
    sa.Column('last_login', sa.TIMESTAMP(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_experts_email'), 'experts', ['email'], unique=True)
    op.create_index(op.f('ix_experts_id'), 'experts', ['id'], unique=False)
    op.create_table('learners',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('matricule', sa.String(length=50), nullable=True),
    sa.Column('nom', sa.String(length=255), nullable=True),
    sa.Column('email', sa.String(length=255), nullable=True),
    sa.Column('niveau_etudes', sa.String(length=50), nullable=True),
    sa.Column('specialite_visee', sa.String(length=100), nullable=True),
    sa.Column('langue_preferee', sa.String(length=10), nullable=True),
    sa.Column('date_inscription', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learners_email'), 'learners', ['email'], unique=True)
    op.create_index(op.f('ix_learners_id'), 'learners', ['id'], unique=False)
    op.create_index(op.f('ix_learners_matricule'), 'learners', ['matricule'], unique=True)
    op.create_table('learner_achievements',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('badge_id', sa.String(length=100), nullable=True),
    sa.Column('date_obtention', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_cognitive_profiles',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('vitesse_assimilation', sa.Float(), nullable=True),
    sa.Column('capacite_memoire_travail', sa.Float(), nullable=True),
    sa.Column('tendance_impulsivite', sa.Float(), nullable=True),
    sa.Column('prefer_visual', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('learner_id')
    )
    op.create_table('learner_competency_mastery',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('competence_id', sa.Integer(), nullable=False),
    sa.Column('mastery_level', sa.Float(), nullable=True),
    sa.Column('confidence', sa.Float(), nullable=True),
    sa.Column('last_practice_date', sa.TIMESTAMP(), nullable=True),
    sa.Column('nb_success', sa.Integer(), nullable=True),
    sa.Column('nb_failures', sa.Integer(), nullable=True),
    sa.Column('streak_correct', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['competence_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learner_competency_mastery_id'), 'learner_competency_mastery', ['id'], unique=False)
    op.create_table('learner_goals',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('type_objectif', sa.String(length=100), nullable=True),
    sa.Column('domaine_cible', sa.String(length=100), nullable=True),
    sa.Column('date_limite', sa.TIMESTAMP(), nullable=True),
    sa.Column('statut', sa.String(length=50), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_misconceptions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('type_erreur', sa.String(length=255), nullable=True),
    sa.Column('frequence_apparition', sa.Integer(), nullable=True),
    sa.Column('resistance_correction', sa.Float(), nullable=True),
    sa.Column('detected_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_preferences',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('cle', sa.String(length=100), nullable=True),
    sa.Column('valeur', sa.String(length=255), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_strategies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('strategy_name', sa.String(length=100), nullable=True),
    sa.Column('frequency', sa.Integer(), nullable=True),
    sa.Column('effectiveness', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learning_paths',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('algorithme_recommandation', sa.String(length=100), nullable=True),
    sa.Column('ordered_case_ids', sa.JSON(), nullable=True, comment='Liste ordonnÃ©e des IDs des cas'),
    sa.Column('progression', sa.Float(), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learning_paths_id'), 'learning_paths', ['id'], unique=False)
    op.create_table('simulation_sessions',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('cas_clinique_id', sa.Integer(), nullable=False),
    sa.Column('start_time', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('end_time', sa.TIMESTAMP(), nullable=True),
    sa.Column('score_final', sa.Float(), nullable=True),
    sa.Column('temps_total', sa.Integer(), nullable=True),
    sa.Column('cout_virtuel_genere', sa.Integer(), nullable=True),
    sa.Column('statut', sa.String(length=50), nullable=True),
    sa.Column('raison_fin', sa.String(length=100), nullable=True),
    sa.Column('current_stage', sa.String(length=50), nullable=True),
    sa.Column('context_state', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['cas_clinique_id'], ['cas_cliniques_enrichis.id'], ),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('chat_messages',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('sender', sa.String(length=50), nullable=True),
    sa.Column('content', sa.Text(), nullable=True),
    sa.Column('intention_detectee', sa.String(length=100), nullable=True),
    sa.Column('sentiment_analyse', sa.String(length=50), nullable=True),
    sa.Column('message_metadata', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_chat_messages_id'), 'chat_messages', ['id'], unique=False)
    op.create_table('interaction_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('action_category', sa.String(length=50), nullable=True),
    sa.Column('action_type', sa.String(length=100), nullable=True),
    sa.Column('action_content', sa.JSON(), nullable=True),
    sa.Column('response_latency', sa.Integer(), nullable=True),
    sa.Column('charge_cognitive_estimee', sa.Float(), nullable=True),
    sa.Column('est_pertinent', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_interaction_logs_id'), 'interaction_logs', ['id'], unique=False)
    op.create_table('learner_affective_states',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('stress_level', sa.Float(), nullable=True),
    sa.Column('confidence_level', sa.Float(), nullable=True),
    sa.Column('motivation_level', sa.Float(), nullable=True),
    sa.Column('frustration_level', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('tutor_feedback_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('feedback_type', sa.String(length=50), nullable=True),
    sa.Column('content', sa.Text(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_feedback_logs_id'), 'tutor_feedback_logs', ['id'], unique=False)
    op.create_table('tutor_motivational_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('intervention_type', sa.String(length=100), nullable=True),
    sa.Column('emotional_state_before', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_motivational_state_id'), 'tutor_motivational_state', ['id'], unique=False)
    op.create_table('tutor_scaffolding_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('competence_cible_id', sa.Integer(), nullable=True),
    sa.Column('current_level', sa.Integer(), nullable=True),
    sa.Column('indices_deja_donnes', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['competence_cible_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_scaffolding_state_id'), 'tutor_scaffolding_state', ['id'], unique=False)
    op.create_table('tutor_socratic_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('tactic_used', sa.String(length=100), nullable=True),
    sa.Column('target_concept', sa.String(length=255), nullable=True),
    sa.Column('step_in_dialogue', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_socratic_state_id'), 'tutor_socratic_state', ['id'], unique=False)
    op.create_table('tutor_strategies_history',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('strategy_name', sa.String(length=100), nullable=True),
    sa.Column('relevance_score', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_strategies_history_id'), 'tutor_strategies_history', ['id'], unique=False)
    op.create_table('tutor_decisions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('trigger_event_id', sa.Integer(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('strategy_used', sa.String(length=100), nullable=True),
    sa.Column('action_choisie', sa.String(length=100), nullable=True),
    sa.Column('intervention_content', sa.Text(), nullable=True),
    sa.Column('rationale', sa.JSON(), nullable=True),
    sa.Column('succes_intervention', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.ForeignKeyConstraint(['trigger_event_id'], ['interaction_logs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_decisions_id'), 'tutor_decisions', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_tutor_decisions_id'), table_name='tutor_decisions')
    op.drop_table('tutor_decisions')
    op.drop_index(op.f('ix_tutor_strategies_history_id'), table_name='tutor_strategies_history')
    op.drop_table('tutor_strategies_history')
    op.drop_index(op.f('ix_tutor_socratic_state_id'), table_name='tutor_socratic_state')
    op.drop_table('tutor_socratic_state')
    op.drop_index(op.f('ix_tutor_scaffolding_state_id'), table_name='tutor_scaffolding_state')
    op.drop_table('tutor_scaffolding_state')
    op.drop_index(op.f('ix_tutor_motivational_state_id'), table_name='tutor_motivational_state')
    op.drop_table('tutor_motivational_state')
    op.drop_index(op.f('ix_tutor_feedback_logs_id'), table_name='tutor_feedback_logs')
    op.drop_table('tutor_feedback_logs')
    op.drop_table('learner_affective_states')
    op.drop_index(op.f('ix_interaction_logs_id'), table_name='interaction_logs')
    op.drop_table('interaction_logs')
    op.drop_index(op.f('ix_chat_messages_id'), table_name='chat_messages')
    op.drop_table('chat_messages')
    op.drop_table('simulation_sessions')
    op.drop_index(op.f('ix_learning_paths_id'), table_name='learning_paths')
    op.drop_table('learning_paths')
    op.drop_table('learner_strategies')
    op.drop_table('learner_preferences')
    op.drop_table('learner_misconceptions')
    op.drop_table('learner_goals')
    op.drop_index(op.f('ix_learner_competency_mastery_id'), table_name='learner_competency_mastery')
    op.drop_table('learner_competency_mastery')
    op.drop_table('learner_cognitive_profiles')
    op.drop_table('learner_achievements')
    op.drop_index(op.f('ix_learners_matricule'), table_name='learners')
    op.drop_index(op.f('ix_learners_id'), table_name='learners')
    op.drop_index(op.f('ix_learners_email'), table_name='learners')
    op.drop_table('learners')
    op.drop_index(op.f('ix_experts_id'), table_name='experts')
    op.drop_index(op.f('ix_experts_email'), table_name='experts')
    op.drop_table('experts')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/6eb5a7dba20c_create_symptoms_table.py ===

"""Create symptoms table

Revision ID: 6eb5a7dba20c
Revises: 7995e67f8833
Create Date: 2025-11-06 19:20:35.224401+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '6eb5a7dba20c'
down_revision = '7995e67f8833'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('pathologies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_icd10', sa.String(length=20), nullable=True, comment='Code international de la maladie (CIM-10)'),
    sa.Column('nom_fr', sa.String(length=255), nullable=False),
    sa.Column('nom_en', sa.String(length=255), nullable=True),
    sa.Column('nom_local', sa.String(length=255), nullable=True, comment='Noms locaux ou courants au Cameroun'),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: Infectieuse, Chronique, Parasitaire'),
    sa.Column('prevalence_cameroun', sa.DECIMAL(precision=5, scale=2), nullable=True, comment='PrÃ©valence en % dans le contexte camerounais'),
    sa.Column('niveau_gravite', sa.Integer(), nullable=True, comment='Ã‰chelle de 1 (bÃ©nin) Ã  5 (critique)'),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('physiopathologie', sa.Text(), nullable=True, comment='MÃ©canisme de la maladie'),
    sa.Column('evolution_naturelle', sa.Text(), nullable=True, comment='Comment la maladie Ã©volue sans traitement'),
    sa.Column('complications', sa.JSON(), nullable=True, comment='Complications possibles'),
    sa.Column('facteurs_risque', sa.JSON(), nullable=True, comment='Facteurs de risque associÃ©s'),
    sa.Column('prevention', sa.Text(), nullable=True, comment='Mesures de prÃ©vention'),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=768), nullable=True, comment="Vecteur d'embedding pour la recherche sÃ©mantique"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_pathologies_categorie'), 'pathologies', ['categorie'], unique=False)
    op.create_index(op.f('ix_pathologies_code_icd10'), 'pathologies', ['code_icd10'], unique=True)
    op.create_index(op.f('ix_pathologies_id'), 'pathologies', ['id'], unique=False)
    op.create_index(op.f('ix_pathologies_nom_fr'), 'pathologies', ['nom_fr'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_pathologies_nom_fr'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_id'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_code_icd10'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_categorie'), table_name='pathologies')
    op.drop_table('pathologies')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/a0ee48d62174_change_embedding_dimensions_to_384.py ===

"""change embedding dimensions to 384

Revision ID: a0ee48d62174
Revises: 5c3894aa1b50
Create Date: 2025-12-26 00:19:52.135785+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'a0ee48d62174'
down_revision = '5c3894aa1b50'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/9aed193ba8b7_create_therapeutic_relations_tables.py ===

"""Create therapeutic relations tables

Revision ID: 9aed193ba8b7
Revises: f29ac6884d1c
Create Date: 2025-11-06 20:44:30.949745+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '9aed193ba8b7'
down_revision = 'f29ac6884d1c'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('traitements_pathologies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('pathologie_id', sa.Integer(), nullable=False),
    sa.Column('medicament_id', sa.Integer(), nullable=False),
    sa.Column('type_traitement', sa.String(length=50), nullable=True, comment='Ex: Premiere_intention, Alternative, Adjuvant'),
    sa.Column('ligne_traitement', sa.Integer(), nullable=True, comment='Ex: 1Ã¨re ligne, 2e ligne'),
    sa.Column('indication_precise', sa.Text(), nullable=True),
    sa.Column('efficacite_taux', sa.DECIMAL(precision=5, scale=2), nullable=True, comment='Taux de succÃ¨s en %'),
    sa.Column('duree_traitement_jours', sa.Integer(), nullable=True),
    sa.Column('posologie_detaillee', sa.JSON(), nullable=True),
    sa.Column('niveau_preuve', sa.String(length=50), nullable=True, comment='Grade de recommandation (A, B, C)'),
    sa.Column('guidelines_source', sa.String(length=255), nullable=True, comment='Source (OMS, MINSANTE Cameroun, etc.)'),
    sa.Column('rang_preference', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['medicament_id'], ['medicaments.id'], ),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('traitements_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('medicament_id', sa.Integer(), nullable=False),
    sa.Column('efficacite', sa.String(length=50), nullable=True, comment='Ex: Tres_efficace, Efficace, Modere'),
    sa.Column('rapidite_action', sa.String(length=100), nullable=True, comment='Ex: Immediate, <30min'),
    sa.Column('posologie_recommandee', sa.Text(), nullable=True),
    sa.Column('rang_preference', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['medicament_id'], ['medicaments.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('traitements_symptomes')
    op.drop_table('traitements_pathologies')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/alembic/versions/03d192a5f522_add_expert_intelligence.py ===

"""Add expert intelligence

Revision ID: 03d192a5f522
Revises: de1d3372f456
Create Date: 2025-11-07 14:06:32.502322+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '03d192a5f522'
down_revision = 'de1d3372f456'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('regles_production',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_regle', sa.String(length=50), nullable=False),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: DIAGNOSTIC, THERAPEUTIQUE, PEDAGOGIQUE, ALERTE'),
    sa.Column('priorite', sa.Integer(), nullable=True, comment="PrioritÃ© d'exÃ©cution (1-10), 10 Ã©tant le plus prioritaire"),
    sa.Column('conditions', sa.JSON(), nullable=False, comment="Partie 'IF' de la rÃ¨gle, structurÃ©e en JSON"),
    sa.Column('actions', sa.JSON(), nullable=False, comment="Partie 'THEN' de la rÃ¨gle, structurÃ©e en JSON"),
    sa.Column('description_naturelle', sa.Text(), nullable=True, comment='Description de la rÃ¨gle en langage naturel'),
    sa.Column('justification_medicale', sa.Text(), nullable=True, comment='Source ou justification clinique de la rÃ¨gle'),
    sa.Column('expert_auteur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('est_active', sa.Boolean(), nullable=False),
    sa.Column('nb_activations', sa.Integer(), nullable=True),
    sa.Column('taux_succes', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_regles_production_categorie'), 'regles_production', ['categorie'], unique=False)
    op.create_index(op.f('ix_regles_production_code_regle'), 'regles_production', ['code_regle'], unique=True)
    op.create_index(op.f('ix_regles_production_id'), 'regles_production', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_regles_production_id'), table_name='regles_production')
    op.drop_index(op.f('ix_regles_production_code_regle'), table_name='regles_production')
    op.drop_index(op.f('ix_regles_production_categorie'), table_name='regles_production')
    op.drop_table('regles_production')
    # ### end Alembic commands ###


=== Fichier: ./python_files_backup/python_files_backup/scripts/run_dataset_import.py ===

import sys
import os

# Le sys.path.insert n'est plus nÃ©cessaire si on lance avec 'python -m'
# Mais on le garde au cas oÃ¹, en le sÃ©curisant
if __name__ == "__main__" and __package__ is None:
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from datasets.integrators.mimic3_dics_integrator import MIMIC3DictionariesIntegrator
from datasets.integrators.mimic3_integrator import MIMIC3RelationsIntegrator
from datasets.assembler.case_assembler import CaseAssembler
from datasets.integrators.manual_images_integrator import ManualImagesIntegrator

# --- CONFIGURATION DES CHEMINS D'ACCÃˆS ---
MIMIC_BASE_PATH = "/home/clement/TÃ©lÃ©chargements/archive (1)/mimic-iii-clinical-database-demo-1.4"
SOURCE_IMAGES_DIR = "/home/clement/TÃ©lÃ©chargements/imgradio" 
MAPPING_CSV_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'datasets/mapping/images_mapping.csv'))

MIMIC_FILES_PATHS = {
    "d_icd_diagnoses": os.path.join(MIMIC_BASE_PATH, "D_ICD_DIAGNOSES.csv"),
    "d_labitems": os.path.join(MIMIC_BASE_PATH, "D_LABITEMS.csv"),
    "d_items": os.path.join(MIMIC_BASE_PATH, "D_ITEMS.csv"),
    "prescriptions": os.path.join(MIMIC_BASE_PATH, "PRESCRIPTIONS.csv"),
    "diagnoses_icd": os.path.join(MIMIC_BASE_PATH, "DIAGNOSES_ICD.csv"),
    "labevents": os.path.join(MIMIC_BASE_PATH, "LABEVENTS.csv"),
    "admissions": os.path.join(MIMIC_BASE_PATH, "ADMISSIONS.csv"),
}

def check_paths(paths: dict):
    all_found = True
    for key, path in paths.items():
        if not os.path.exists(path):
            print(f"âŒ ERREUR: Fichier non trouvÃ© pour '{key}': {path}")
            all_found = False
    return all_found

def main():
    print("--- DÃ©marrage du script d'importation complet ---")
    
    if not check_paths(MIMIC_FILES_PATHS):
        print("\nAttention: Fichiers MIMIC manquants.")
        # On continue quand mÃªme pour tester les autres intÃ©grateurs si besoin
    
    db_session = SessionLocal()
    
    try:
        print("\n" + "="*50)
        print("Ã‰TAPE 1: PEUPLEMENT DES DICTIONNAIRES")
        dics_integrator = MIMIC3DictionariesIntegrator(db_session=db_session, paths=MIMIC_FILES_PATHS)
        dics_integrator.run_all()

        print("\n" + "="*50)
        print("Ã‰TAPE 2: CRÃ‰ATION DES RELATIONS")
        relations_integrator = MIMIC3RelationsIntegrator(db_session=db_session, paths=MIMIC_FILES_PATHS)
        relations_integrator.run()

        print("\n" + "="*50)
        print("Ã‰TAPE 3: ASSEMBLAGE DES CAS CLINIQUES")
        case_assembler = CaseAssembler(db_session=db_session, paths=MIMIC_FILES_PATHS)
        case_assembler.run()

        print("\n" + "="*50)
        print("Ã‰TAPE 4: IMPORTATION DES IMAGES MANUELLES")
        if not os.path.exists(MAPPING_CSV_PATH):
            print(f"âŒ ERREUR: Fichier de mapping non trouvÃ© : {MAPPING_CSV_PATH}")
        else:
            images_integrator = ManualImagesIntegrator(
                db_session=db_session,
                mapping_csv_path=MAPPING_CSV_PATH,
                source_images_dir="" 
            )
            images_integrator.run()

    except Exception as e:
        print(f"\nâŒ UNE ERREUR CRITIQUE EST SURVENUE : {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        print("\nFermeture de la session de base de donnÃ©es.")
        db_session.close()

if __name__ == "__main__":
    main()

=== Fichier: ./python_files_backup/python_files_backup/scripts/run_assembler.py ===



=== Fichier: ./python_files_backup/python_files_backup/scripts/generate_q_matrix.py ===

import sys
import os

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app import models

def generate_matrix():
    db = SessionLocal()
    print("--- GÃ©nÃ©ration de la Q-Matrix (Lien Cas <-> CompÃ©tences) ---")

    # 1. Charger toutes les compÃ©tences pour avoir leurs IDs et codes
    competencies = db.query(models.Competence).all()
    comp_map = {c.code_competence: c.id for c in competencies}
    
    if not comp_map:
        print("âŒ Aucune compÃ©tence trouvÃ©e. Veuillez lancer populate_competencies.py d'abord.")
        return

    # 2. RÃ©cupÃ©rer tous les cas cliniques
    cases = db.query(models.ClinicalCase).all()
    print(f"Traitement de {len(cases)} cas cliniques...")

    count_updated = 0
    for case in cases:
        required_skills = {} # Dictionnaire pour stocker les compÃ©tences requises {code: id}

        # --- RÃˆGLES D'ATTRIBUTION DES COMPÃ‰TENCES ---

        # RÃ¨gle 1 : Socle commun (Tout cas nÃ©cessite ces bases)
        # Bloom 1-2
        common_skills = ["IDENTIFIER_MOTIF", "EMPATHIE", "ANAMNESE_HISTOIRE"]
        for code in common_skills:
            if code in comp_map:
                required_skills[code] = comp_map[code]

        # RÃ¨gle 2 : Si le cas a des symptÃ´mes biologiques (Labo)
        # Bloom 4
        if case.donnees_paracliniques and "lab_results" in case.donnees_paracliniques:
            if len(case.donnees_paracliniques["lab_results"]) > 0:
                if "INTERPRETATION_BIOLOGIE" in comp_map:
                    required_skills["INTERPRETATION_BIOLOGIE"] = comp_map["INTERPRETATION_BIOLOGIE"]

        # RÃ¨gle 3 : Si le cas a des images
        # Bloom 4
        if case.images_associees_ids and len(case.images_associees_ids) > 0:
            if "INTERPRETATION_IMAGERIE" in comp_map:
                required_skills["INTERPRETATION_IMAGERIE"] = comp_map["INTERPRETATION_IMAGERIE"]

        # RÃ¨gle 4 : Si le cas a des mÃ©dicaments prescrits
        # Bloom 6
        if case.medicaments_prescrits and len(case.medicaments_prescrits) > 0:
            if "PRESCRIPTION_THERAPEUTIQUE" in comp_map:
                required_skills["PRESCRIPTION_THERAPEUTIQUE"] = comp_map["PRESCRIPTION_THERAPEUTIQUE"]
        
        # RÃ¨gle 5 : CompÃ©tences de Raisonnement (Toujours nÃ©cessaires pour un cas complet)
        # Bloom 4-5
        reasoning_skills = ["GENERATION_HYPOTHESES", "DIAGNOSTIC_DIFFERENTIEL", "SYNTHESE_CLINIQUE"]
        for code in reasoning_skills:
            if code in comp_map:
                required_skills[code] = comp_map[code]

        # --- MISE Ã€ JOUR DU CAS ---
        
        # On sauvegarde le rÃ©sultat sous forme de JSON { "CODE_COMPETENCE": ID_COMPETENCE }
        case.competences_requises = required_skills
        
        # On calcule un niveau de difficultÃ© suggÃ©rÃ© basÃ© sur la richesse du cas
        # Base: 1. +1 si labo, +1 si images, +1 si mÃ©dicaments, +1 si comorbiditÃ©s
        difficulty = 1
        if "INTERPRETATION_BIOLOGIE" in required_skills: difficulty += 1
        if "INTERPRETATION_IMAGERIE" in required_skills: difficulty += 1
        if "PRESCRIPTION_THERAPEUTIQUE" in required_skills: difficulty += 1
        if case.pathologies_secondaires_ids: difficulty += 1
        
        case.niveau_difficulte = min(difficulty, 5) # Max 5

        count_updated += 1

    db.commit()
    db.close()
    print(f"âœ¨ TerminÃ©. {count_updated} cas cliniques mis Ã  jour avec leur Q-Matrix.")

if __name__ == "__main__":
    generate_matrix()

=== Fichier: ./python_files_backup/python_files_backup/scripts/backup_restore.py ===



=== Fichier: ./python_files_backup/python_files_backup/scripts/populate_from_datasets.py ===



=== Fichier: ./python_files_backup/python_files_backup/scripts/migrate_fultang_data.py ===



=== Fichier: ./python_files_backup/python_files_backup/scripts/export_training_data.py ===



=== Fichier: ./python_files_backup/python_files_backup/scripts/migration_img.py ===

import sys
import os
import cloudinary
import cloudinary.uploader
from sqlalchemy.orm import Session
from datetime import datetime

# Configuration du chemin pour les imports de l'application
# Permet au script de "voir" le dossier app/ mÃªme s'il est dans scripts/
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app.models.media import ImageMedicale
from app.config import settings

# 1. Configuration Cloudinary
# Les clÃ©s sont chargÃ©es depuis votre fichier .env via settings
cloudinary.config( 
    cloud_name = settings.CLOUDINARY_CLOUD_NAME, 
    api_key = settings.CLOUDINARY_API_KEY, 
    api_secret = settings.CLOUDINARY_API_SECRET,
    secure = True
)

OUTPUT_LOG_FILE = "migration_mapping_log.txt"

def migrate_images():
    print("ğŸš€ DÃ©marrage de la migration des images vers Cloudinary...")
    print(f"ğŸ“„ Un rapport sera gÃ©nÃ©rÃ© dans : {OUTPUT_LOG_FILE}")
    
    db = SessionLocal()
    mapping_log = [] # Liste pour stocker les correspondances
    
    try:
        # 2. RÃ©cupÃ©rer les images locales
        # On filtre celles qui ne commencent PAS par 'http'
        images_to_migrate = db.query(ImageMedicale).filter(
            ~ImageMedicale.fichier_url.like('http%')
        ).all()
        
        total_images = len(images_to_migrate)
        print(f"ğŸ“Š {total_images} images trouvÃ©es Ã  migrer.")
        
        # En-tÃªte du fichier de log
        mapping_log.append(f"--- RAPPORT DE MIGRATION DU {datetime.now()} ---")
        mapping_log.append(f"Total Ã  traiter : {total_images}\n")
        mapping_log.append(f"{'ID':<5} | {'ANCIEN CHEMIN LOCAL':<60} | {'NOUVELLE URL CLOUDINARY'}")
        mapping_log.append("-" * 150)
        
        success_count = 0
        error_count = 0
        
        for img in images_to_migrate:
            # Reconstruire le chemin absolu du fichier sur votre machine
            # On suppose que le chemin en BDD est relatif Ã  la racine du projet
            # ex: "storage/media/images/radio.jpg"
            local_rel_path = img.fichier_url
            local_abs_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', local_rel_path))
            
            print(f"  -> Traitement ID {img.id}...")
            
            if os.path.exists(local_abs_path):
                try:
                    # 3. Upload vers Cloudinary
                    # folder="sti_medical/radiology" permet de ranger les fichiers dans le cloud
                    upload_result = cloudinary.uploader.upload(
                        local_abs_path, 
                        folder="sti_medical_expert/radiology",
                        public_id=f"img_{img.id}_{os.path.basename(local_abs_path).split('.')[0]}" 
                    )
                    
                    new_url = upload_result.get("secure_url")
                    
                    # 4. Mise Ã  jour de la Base de DonnÃ©es
                    img.fichier_url = new_url
                    
                    # Ajout au rapport
                    log_line = f"{img.id:<5} | {local_rel_path:<60} | {new_url}"
                    mapping_log.append(log_line)
                    
                    success_count += 1
                    print(f"     âœ… SuccÃ¨s.")
                    
                except Exception as e:
                    error_msg = f"ERREUR UPLOAD: {str(e)}"
                    print(f"     âŒ {error_msg}")
                    mapping_log.append(f"{img.id:<5} | {local_rel_path:<60} | {error_msg}")
                    error_count += 1
            else:
                error_msg = "FICHIER LOCAL INTROUVABLE"
                print(f"     âš ï¸ {error_msg} : {local_abs_path}")
                mapping_log.append(f"{img.id:<5} | {local_rel_path:<60} | {error_msg}")
                error_count += 1
        
        # Validation finale des changements en BDD
        db.commit()
        
        # Ã‰criture du fichier de log
        mapping_log.append("\n" + "-" * 150)
        mapping_log.append(f"RÃ‰SUMÃ‰ : SuccÃ¨s {success_count} / Erreurs {error_count}")
        
        with open(OUTPUT_LOG_FILE, "w", encoding="utf-8") as f:
            f.write("\n".join(mapping_log))
            
        print(f"\nâœ¨ Migration terminÃ©e.")
        print(f"âœ… SuccÃ¨s : {success_count}")
        print(f"âŒ Erreurs : {error_count}")
        print(f"ğŸ“„ Rapport sauvegardÃ© : {os.path.abspath(OUTPUT_LOG_FILE)}")
        
    except Exception as e:
        print(f"âŒ Erreur critique du script : {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    migrate_images()

=== Fichier: ./python_files_backup/python_files_backup/scripts/check_relations.py ===

import sys
import os
from sqlalchemy import inspect

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import engine
# Importez tous les modÃ¨les pour Ãªtre sÃ»r qu'ils sont enregistrÃ©s
from app import models 

def check_db_relations():
    inspector = inspect(engine)
    table_names = inspector.get_table_names()
    
    print(f"\n--- AUDIT DE LA BASE DE DONNÃ‰ES ({len(table_names)} tables trouvÃ©es) ---\n")
    
    # 1. VÃ©rification des Tables
    print("ğŸ“‹ LISTE DES TABLES :")
    for table in sorted(table_names):
        print(f"  - {table}")
        
    print("\nğŸ”— VÃ‰RIFICATION DES RELATIONS (ClÃ©s Ã‰trangÃ¨res) :")
    
    # 2. VÃ©rification des ClÃ©s Ã‰trangÃ¨res
    relations_found = 0
    for table_name in sorted(table_names):
        fks = inspector.get_foreign_keys(table_name)
        if fks:
            print(f"\n  TABLE '{table_name}' est liÃ©e Ã  :")
            for fk in fks:
                referred_table = fk.get('referred_table')
                constrained_columns = fk['constrained_columns'] # La colonne source (ex: learner_id)
                referred_columns = fk['referred_columns'] # La colonne cible (ex: id)
                
                print(f"    -> {referred_table} (via {constrained_columns[0]} -> {referred_columns[0]})")
                relations_found += 1
    
    print(f"\nâœ¨ Total de {relations_found} relations de clÃ© Ã©trangÃ¨re trouvÃ©es.")
    
    if relations_found > 10: # On en attend beaucoup
        print("âœ… La structure relationnelle semble riche et interconnectÃ©e.")
    else:
        print("âš ï¸ Attention : Peu de relations trouvÃ©es. VÃ©rifiez vos modÃ¨les.")

if __name__ == "__main__":
    check_db_relations()

=== Fichier: ./python_files_backup/python_files_backup/scripts/validate_cases.py ===



=== Fichier: ./python_files_backup/python_files_backup/scripts/init_db.py ===



=== Fichier: ./python_files_backup/python_files_backup/scripts/populate_competencies.py ===

import sys
import os

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app import models

def populate():
    db = SessionLocal()
    print("--- Peuplement des CompÃ©tences Cliniques (Structure Consultation & Bloom) ---")

    # ---------------------------------------------------------
    # 1. CompÃ©tences Racines (Les Grandes Ã‰tapes de la Consultation)
    # ---------------------------------------------------------
    root_skills = [
        {"code": "RELATION", "nom": "1. Accueil et Relation Patient", "cat": "Communication", "bloom": 2},
        {"code": "ANAMNESE", "nom": "2. AnamnÃ¨se (Interrogatoire)", "cat": "EnquÃªte", "bloom": 3},
        {"code": "EXAMEN_PHYSIQUE", "nom": "3. Examen Clinique", "cat": "Observation", "bloom": 3},
        {"code": "RAISONNEMENT", "nom": "4. Raisonnement Diagnostique", "cat": "Raisonnement", "bloom": 4},
        {"code": "PARACLINIQUE", "nom": "5. Examens ComplÃ©mentaires", "cat": "Investigation", "bloom": 4},
        {"code": "SYNTHESE", "nom": "6. Diagnostic et Explication", "cat": "SynthÃ¨se", "bloom": 5},
        {"code": "PRISE_EN_CHARGE", "nom": "7. Traitement et Suivi", "cat": "Action", "bloom": 6},
    ]

    roots = {}
    for skill in root_skills:
        existing = db.query(models.Competence).filter(models.Competence.code_competence == skill["code"]).first()
        if not existing:
            new_skill = models.Competence(
                code_competence=skill["code"],
                nom=skill["nom"],
                categorie=skill["cat"],
                niveau_bloom=skill["bloom"],
                description=f"CompÃ©tence racine pour l'Ã©tape : {skill['nom']}"
            )
            db.add(new_skill)
            db.commit()
            db.refresh(new_skill)
            roots[skill["code"]] = new_skill
            print(f"âœ… Racine crÃ©Ã©e : {skill['nom']} (Bloom {skill['bloom']})")
        else:
            roots[skill["code"]] = existing
            print(f"â„¹ï¸ Racine existante : {skill['nom']}")

    # ---------------------------------------------------------
    # 2. Sous-CompÃ©tences SpÃ©cifiques (DÃ©tails opÃ©ratoires)
    # ---------------------------------------------------------
    specific_skills = [
        # 1. Accueil
        {"code": "IDENTIFIER_MOTIF", "nom": "Identifier le motif de consultation", "parent": "RELATION", "bloom": 1},
        {"code": "EMPATHIE", "nom": "Communication empathique", "parent": "RELATION", "bloom": 2},

        # 2. AnamnÃ¨se
        {"code": "ANAMNESE_HISTOIRE", "nom": "CaractÃ©riser l'histoire de la maladie (PQRST)", "parent": "ANAMNESE", "bloom": 3},
        {"code": "ANAMNESE_ANTECEDENTS", "nom": "Recueillir les antÃ©cÃ©dents (perso/famille)", "parent": "ANAMNESE", "bloom": 2},
        {"code": "ANAMNESE_TRAITEMENTS", "nom": "Recenser traitements et allergies", "parent": "ANAMNESE", "bloom": 2},
        {"code": "ANAMNESE_MODE_VIE", "nom": "Identifier les facteurs de mode de vie", "parent": "ANAMNESE", "bloom": 2},

        # 3. Examen Physique
        {"code": "SIGNES_VITAUX", "nom": "Mesurer et interprÃ©ter les constantes", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},
        {"code": "EXAMEN_CIBLE", "nom": "RÃ©aliser l'examen physique ciblÃ©", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},
        {"code": "RECONNAISSANCE_SIGNES", "nom": "ReconnaÃ®tre les signes physiques d'alerte", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},

        # 4. Raisonnement
        {"code": "GENERATION_HYPOTHESES", "nom": "Formuler des hypothÃ¨ses diagnostiques", "parent": "RAISONNEMENT", "bloom": 4},
        {"code": "DIAGNOSTIC_DIFFERENTIEL", "nom": "Mener un diagnostic diffÃ©rentiel", "parent": "RAISONNEMENT", "bloom": 5},

        # 5. Paraclinique
        {"code": "PRESCRIPTION_PERTINENTE", "nom": "Prescrire les examens pertinents", "parent": "PARACLINIQUE", "bloom": 5},
        {"code": "INTERPRETATION_BIOLOGIE", "nom": "InterprÃ©ter les rÃ©sultats biologiques", "parent": "PARACLINIQUE", "bloom": 4},
        {"code": "INTERPRETATION_IMAGERIE", "nom": "InterprÃ©ter l'imagerie mÃ©dicale", "parent": "PARACLINIQUE", "bloom": 4},

        # 6. SynthÃ¨se
        {"code": "SYNTHESE_CLINIQUE", "nom": "IntÃ©grer les donnÃ©es pour conclure", "parent": "SYNTHESE", "bloom": 5},
        {"code": "ANNONCE_DIAGNOSTIC", "nom": "Expliquer le diagnostic au patient", "parent": "SYNTHESE", "bloom": 3},

        # 7. Prise en charge
        {"code": "PRESCRIPTION_THERAPEUTIQUE", "nom": "Ã‰tablir le plan thÃ©rapeutique", "parent": "PRISE_EN_CHARGE", "bloom": 6},
        {"code": "EDUCATION_PATIENT", "nom": "Ã‰duquer le patient sur sa maladie", "parent": "PRISE_EN_CHARGE", "bloom": 3},
        {"code": "SUIVI_EVOLUTION", "nom": "Planifier le suivi et la surveillance", "parent": "PRISE_EN_CHARGE", "bloom": 5},
    ]

    created_skills = {}
    for skill in specific_skills:
        existing = db.query(models.Competence).filter(models.Competence.code_competence == skill["code"]).first()
        if not existing:
            parent = roots.get(skill["parent"])
            new_skill = models.Competence(
                code_competence=skill["code"],
                nom=skill["nom"],
                categorie=parent.categorie if parent else "Autre",
                parent_competence_id=parent.id if parent else None,
                niveau_bloom=skill["bloom"],
                description=f"Sous-compÃ©tence de : {parent.nom if parent else 'Racine'}"
            )
            db.add(new_skill)
            db.commit()
            db.refresh(new_skill)
            created_skills[skill["code"]] = new_skill
            print(f"  -> Sous-compÃ©tence crÃ©Ã©e : {skill['nom']} (Bloom {skill['bloom']})")
        else:
            created_skills[skill["code"]] = existing

    # ---------------------------------------------------------
    # 3. CrÃ©ation des PrÃ©requis (Le Graphe de DÃ©pendance)
    # ---------------------------------------------------------
    # Logique : "Pour faire B, il faut savoir faire A"
    prerequisites = [
        # Logique interne Ã  l'AnamnÃ¨se
        ("ANAMNESE_HISTOIRE", "IDENTIFIER_MOTIF"), # On ne peut pas creuser l'histoire si on n'a pas le motif
        
        # Logique AnamnÃ¨se -> Examen
        ("EXAMEN_CIBLE", "ANAMNESE_HISTOIRE"), # L'examen est guidÃ© par l'histoire
        
        # Logique vers Raisonnement
        ("GENERATION_HYPOTHESES", "ANAMNESE_HISTOIRE"),
        ("GENERATION_HYPOTHESES", "SIGNES_VITAUX"),
        
        # Logique vers Paraclinique
        ("PRESCRIPTION_PERTINENTE", "GENERATION_HYPOTHESES"), # On prescrit pour tester une hypothÃ¨se
        
        # Logique vers SynthÃ¨se
        ("SYNTHESE_CLINIQUE", "INTERPRETATION_BIOLOGIE"),
        ("SYNTHESE_CLINIQUE", "DIAGNOSTIC_DIFFERENTIEL"),
        
        # Logique vers Traitement (Le sommet)
        ("PRESCRIPTION_THERAPEUTIQUE", "SYNTHESE_CLINIQUE"), # Pas de traitement sans diagnostic
        ("EDUCATION_PATIENT", "SYNTHESE_CLINIQUE"),
    ]

    for target_code, req_code in prerequisites:
        target = created_skills.get(target_code)
        req = created_skills.get(req_code)

        if target and req:
            # VÃ©rifier si le lien existe dÃ©jÃ 
            link_exists = db.query(models.PrerequisCompetence).filter(
                models.PrerequisCompetence.competence_id == target.id,
                models.PrerequisCompetence.prerequis_id == req.id
            ).first()

            if not link_exists:
                new_link = models.PrerequisCompetence(
                    competence_id=target.id,
                    prerequis_id=req.id,
                    type_relation="STRICT"
                )
                db.add(new_link)
                print(f"    ğŸ”— PrÃ©requis crÃ©Ã© : {req.nom} -> {target.nom}")

    db.commit()
    db.close()
    print("âœ¨ Peuplement des compÃ©tences pÃ©dagogiques terminÃ©.")

if __name__ == "__main__":
    populate()

=== Fichier: ./python_files_backup/python_files_backup/testembedding.py ===

from app.services.embedding_service import embedding_service

text = "Pneumonie avec fiÃ¨vre Ã©levÃ©e"
vector = embedding_service.get_text_embedding(text)

print(f"Texte : {text}")
print(f"Taille du vecteur : {len(vector)}")
print(f"AperÃ§u : {vector[:5]}...")

=== Fichier: ./python_files_backup/python_files_backup/tests/conftest.py ===



=== Fichier: ./python_files_backup/python_files_backup/tests/fixtures/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/tests/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/tests/integration/__init__.py ===



=== Fichier: ./python_files_backup/python_files_backup/tests/unit/__init__.py ===



=== Fichier: ./python_files_backup/datasets/integrators/open_medic_integrator.py ===



=== Fichier: ./python_files_backup/datasets/integrators/physionet_integrator.py ===



=== Fichier: ./python_files_backup/datasets/integrators/open_bio_integrator.py ===



=== Fichier: ./python_files_backup/datasets/integrators/__init__.py ===



=== Fichier: ./python_files_backup/datasets/integrators/eicu_integrator.py ===



=== Fichier: ./python_files_backup/datasets/integrators/chexpert_integrator.py ===



=== Fichier: ./python_files_backup/datasets/integrators/mimic3_symptom_relation_integrator.py ===



=== Fichier: ./python_files_backup/datasets/integrators/manual_images_integrator.py ===

import pandas as pd
import os
import shutil
from sqlalchemy.orm import Session
from typing import List

from app import models
from ..base_integrator import BaseIntegrator

# Chemin relatif oÃ¹ vous avez mis vos images
STORAGE_REL_PATH = "storage/media/images" 

class ManualImagesIntegrator(BaseIntegrator):
    """
    IntÃ©grateur pour cataloguer les images manuelles dÃ©jÃ  prÃ©sentes dans le dossier storage.
    """

    def __init__(self, db_session: Session, mapping_csv_path: str, source_images_dir: str = None):
        super().__init__(db_session, mapping_csv_path)
        self.storage_dir = os.path.abspath(STORAGE_REL_PATH)
        print(f"--- Initialisation de l'intÃ©grateur d'images ---")
        print(f"Dossier des images : {self.storage_dir}")

    def extract(self):
        """Lit le fichier de mapping."""
        return pd.read_csv(self.path, chunksize=1000)

    def transform(self, data_chunk: pd.DataFrame) -> List[dict]:
        """PrÃ©pare les donnÃ©es."""
        actions = []
        for _, row in data_chunk.iterrows():
            filename = str(row['filename']).strip()
            file_path = os.path.join(self.storage_dir, filename)
            
            if not os.path.exists(file_path):
                print(f"âš ï¸ Fichier manquant dans storage : {filename}")
                continue

            # Nettoyage et parsing des IDs
            raw_ids = str(row['cas_ids'])
            cas_ids_str = raw_ids.replace('"', '').replace("'", "")
            cas_ids = []
            for x in cas_ids_str.split(','):
                x = x.strip()
                if x.isdigit():
                    cas_ids.append(int(x))
            
            # Log de dÃ©bogage
            # print(f"[DEBUG] Image {filename} -> IDs cibles : {cas_ids}")

            actions.append({
                "filename": filename,
                "file_path": file_path,
                "cas_ids": cas_ids,
                "type_examen": row['type_examen'],
                "description": row['description']
            })
        return actions

    def load(self, actions: List[dict]):
        """CrÃ©e les entrÃ©es en base."""
        for action in actions:
            filename = action['filename']
            file_url = os.path.join(STORAGE_REL_PATH, filename)
            
            existing_img = self.db.query(models.ImageMedicale).filter(
                models.ImageMedicale.fichier_url == file_url
            ).first()

            if not existing_img:
                new_image = models.ImageMedicale(
                    type_examen=action['type_examen'],
                    description=action['description'],
                    fichier_url=file_url,
                    format_image=filename.split('.')[-1].lower()
                )
                self.db.add(new_image)
                self.db.flush()
                image_id = new_image.id
                print(f"    -> Image cataloguÃ©e : {filename} (ID: {image_id})")
            else:
                image_id = existing_img.id

            # Lier aux Cas Cliniques
            for case_id_csv in action['cas_ids']: 
                
                # Pour chaque ID de la liste, on applique le dÃ©calage
                case_id_db = case_id_csv + 908  
                
                # On cherche le cas correspondant en base
                case = self.db.query(models.ClinicalCase).filter(models.ClinicalCase.id == case_id_db).first()
                if case:
                    # ... (le reste du code utilise 'case', donc c'est bon)
                    if case.images_associees_ids is None:
                        case.images_associees_ids = []
                    
                    current_ids = list(case.images_associees_ids)
                    if image_id not in current_ids:
                        current_ids.append(image_id)
                        case.images_associees_ids = current_ids
                        print(f"       -> âœ… LiÃ©e au cas {case_id_db} ({case.code_fultang})")

        try:
            self.db.commit()
        except Exception as e:
            print(f"âŒ Erreur commit : {e}")
            self.db.rollback()

=== Fichier: ./python_files_backup/datasets/integrators/mimic3_integrator.py ===

import pandas as pd
from sqlalchemy.orm import Session
from typing import Dict, Set

from app import models

class MIMIC3RelationsIntegrator:
    """
    IntÃ©grateur pour dÃ©duire et crÃ©er les relations entre pathologies,
    symptÃ´mes et mÃ©dicaments avec des probabilitÃ©s rÃ©elles (basÃ©es sur les patients uniques).
    """

    def __init__(self, db_session: Session, paths: Dict[str, str]):
        self.db = db_session
        self.paths = paths
        self.disease_map: Dict[str, int] = {}
        self.symptom_map: Dict[str, int] = {}
        self.medication_map: Dict[str, int] = {}
        print("--- Initialisation de l'intÃ©grateur de relations MIMIC-III ---")

    def _preload_dictionaries(self):
        print("  -> PrÃ©-chargement des dictionnaires...")
        diseases = self.db.query(models.Disease.id, models.Disease.code_icd10).all()
        self.disease_map = {str(code).strip(): id for id, code in diseases}
        
        symptoms = self.db.query(models.Symptom.id, models.Symptom.nom).all()
        self.symptom_map = {nom: id for id, nom in symptoms}

        meds = self.db.query(models.Medication.id, models.Medication.nom_commercial).all()
        self.medication_map = {nom: id for id, nom in meds}

    def run(self):
        self._preload_dictionaries()

        # --- Ã‰tape 1: Carte des diagnostics et COMPTAGE ---
        print("\nğŸš€ Ã‰tape 1: Carte des diagnostics et calcul des totaux...")
        diagnoses_path = self.paths.get('diagnoses_icd')
        if not diagnoses_path: return
            
        admissions_diagnoses = {}
        disease_counts: Dict[str, int] = {} 

        df_diag = pd.read_csv(diagnoses_path, usecols=['hadm_id', 'icd9_code'], dtype={'icd9_code': str})
        for _, row in df_diag.iterrows():
            hadm_id = row['hadm_id']
            icd9_code = str(row['icd9_code']).strip()
            
            normalized_code = icd9_code.lstrip('0')
            if not normalized_code and icd9_code.isnumeric(): normalized_code = '0'
            elif not normalized_code: normalized_code = icd9_code

            if normalized_code in self.disease_map:
                code_to_use = normalized_code
            elif icd9_code in self.disease_map:
                code_to_use = icd9_code
            else:
                continue

            if hadm_id not in admissions_diagnoses:
                admissions_diagnoses[hadm_id] = set()
            
            if code_to_use not in admissions_diagnoses[hadm_id]:
                admissions_diagnoses[hadm_id].add(code_to_use)
                disease_counts[code_to_use] = disease_counts.get(code_to_use, 0) + 1
        
        print(f"  -> Carte construite. {len(disease_counts)} maladies diffÃ©rentes trouvÃ©es.")

        # --- Ã‰tape 2: Analyse des rÃ©sultats (CORRECTION LOGIQUE) ---
        print("\nğŸš€ Ã‰tape 2: Analyse des rÃ©sultats de laboratoire anormaux...")
        labevents_path = self.paths.get('labevents')
        d_labitems_path = self.paths.get('d_labitems')
        if not labevents_path or not d_labitems_path: return

        df_labitems = pd.read_csv(d_labitems_path, usecols=['itemid', 'label'])
        itemid_to_label = pd.Series(df_labitems.label.values, index=df_labitems.itemid).to_dict()

        # CORRECTION : Utiliser un Set pour stocker les hadm_id uniques
        co_occurrences: Dict[str, Dict[str, Set[int]]] = {} 

        chunk_iterator = pd.read_csv(labevents_path, chunksize=100000, usecols=['hadm_id', 'itemid', 'flag'])
        
        for chunk in chunk_iterator:
            abnormal_events = chunk[chunk['flag'] == 'abnormal'].dropna()
            for _, event in abnormal_events.iterrows():
                hadm_id = event['hadm_id']
                itemid = event['itemid']
                diagnoses = admissions_diagnoses.get(hadm_id)
                symptom_name = itemid_to_label.get(itemid)

                if diagnoses and symptom_name and symptom_name in self.symptom_map:
                    for icd9_code in diagnoses:
                        if icd9_code not in co_occurrences:
                            co_occurrences[icd9_code] = {}
                        
                        if symptom_name not in co_occurrences[icd9_code]:
                            co_occurrences[icd9_code][symptom_name] = set() # Initialiser un Set
                        
                        # Ajouter l'ID de l'admission (les doublons sont ignorÃ©s par le Set)
                        co_occurrences[icd9_code][symptom_name].add(hadm_id)
        
        # --- Ã‰tape 3: Chargement des relations ---
        print("\nğŸš€ Ã‰tape 3: Chargement des relations (ProbabilitÃ©s rÃ©elles)...")
        new_relations = []
        
        log_limit = 10 
        current_log = 0

        for icd9_code, symptom_sets in co_occurrences.items():
            disease_id = self.disease_map.get(icd9_code)
            total_cases = disease_counts.get(icd9_code, 1)

            if not disease_id: continue

            for symptom_name, unique_patients_set in symptom_sets.items():
                symptom_id = self.symptom_map.get(symptom_name)
                if not symptom_id: continue
                
                # CORRECTION : Compter la taille du Set (nombre de patients uniques)
                unique_count = len(unique_patients_set)
                
                # Calcul correct : (Nb patients uniques avec symptÃ´me) / (Nb total patients avec maladie)
                prob = unique_count / total_cases 
            
            # Logs de vÃ©rification
                if current_log < 120: # Augmentons la limite Ã  20 pour voir plus de cas
                    print(f"  [LOG] Maladie {icd9_code} (ID BDD: {disease_id})")
                    print(f"        SymptÃ´me: {symptom_name}")
                    # Afficher clairement si c'est un cas unique ou non
                    if total_cases == 1:
                        print(f"        -> âš ï¸ UN SEUL PATIENT connu pour cette maladie dans le dataset.")
                    else:
                        print(f"        -> âœ… PLUSIEURS PATIENTS ({total_cases}).")
                    
                    print(f"        -> Calcul: {unique_count}/{total_cases} = {prob:.4f}")
                    print("        --------------------------------------------------")
                    current_log += 1

                if prob > 0.05:
                    new_relations.append(models.PathologieSymptome(
                        pathologie_id=disease_id,
                        symptome_id=symptom_id,
                        probabilite=prob,
                        frequence=f"{prob*100:.1f}%",
                        importance_diagnostique=3
                    ))

        if new_relations:
            try:
                self.db.bulk_save_objects(new_relations)
                self.db.commit()
                print(f"âœ¨ Chargement de {len(new_relations)} relations pathologie-symptÃ´me.")
            except Exception:
                self.db.rollback()

        # --- Ã‰tape 4 & 5: Relations ThÃ©rapeutiques (MÃªme logique de correction) ---
        print("\nğŸš€ Ã‰tape 4: Analyse des prescriptions...")
        prescriptions_path = self.paths.get('prescriptions')
        if not prescriptions_path: return

        # CORRECTION : Utiliser un Set pour les mÃ©dicaments aussi
        med_co_occurrences: Dict[str, Dict[str, Set[int]]] = {}

        chunk_iterator = pd.read_csv(prescriptions_path, chunksize=10000, usecols=['hadm_id', 'drug'], dtype=str)
        for chunk in chunk_iterator:
            for _, row in chunk.iterrows():
                hadm_id = int(row['hadm_id']) if pd.notna(row['hadm_id']) else None
                drug_name = str(row['drug']).strip()
                diagnoses = admissions_diagnoses.get(hadm_id)
                
                if diagnoses and drug_name in self.medication_map:
                    for icd9_code in diagnoses:
                        if icd9_code not in med_co_occurrences:
                            med_co_occurrences[icd9_code] = {}
                        
                        if drug_name not in med_co_occurrences[icd9_code]:
                            med_co_occurrences[icd9_code][drug_name] = set()
                        
                        med_co_occurrences[icd9_code][drug_name].add(hadm_id)

        print("\nğŸš€ Ã‰tape 5: Chargement des relations thÃ©rapeutiques...")
        new_treatments = []
        for icd9_code, drug_sets in med_co_occurrences.items():
            disease_id = self.disease_map.get(icd9_code)
            total_cases = disease_counts.get(icd9_code, 1)

            if not disease_id: continue

            # Trier par nombre de patients uniques
            top_drugs = sorted(drug_sets.items(), key=lambda x: len(x[1]), reverse=True)[:10]

            for drug_name, unique_patients_set in top_drugs:
                med_id = self.medication_map.get(drug_name)
                if not med_id: continue
                
                unique_count = len(unique_patients_set)
                frequence = (unique_count / total_cases) * 100
                
                new_treatments.append(models.TraitementPathologie(
                    pathologie_id=disease_id,
                    medicament_id=med_id,
                    efficacite_taux=frequence,
                    type_traitement=f"Prescrit dans {frequence:.1f}% des cas"
                ))

        if new_treatments:
            try:
                self.db.bulk_save_objects(new_treatments)
                self.db.commit()
                print(f"âœ¨ Chargement de {len(new_treatments)} relations thÃ©rapeutiques.")
            except Exception:
                self.db.rollback()

=== Fichier: ./python_files_backup/datasets/integrators/mimic3_dics_integrator.py ===

import pandas as pd
from sqlalchemy.orm import Session
from typing import Dict, Set

from app import models

class MIMIC3DictionariesIntegrator:
    """
    IntÃ©grateur spÃ©cialisÃ© pour peupler les tables de rÃ©fÃ©rence (dictionnaires)
    de notre base de donnÃ©es Ã  partir des fichiers correspondants de MIMIC-III.
    """

    def __init__(self, db_session: Session, paths: Dict[str, str]):
        """
        Initialise l'intÃ©grateur avec une session de base de donnÃ©es et un
        dictionnaire des chemins vers les fichiers CSV nÃ©cessaires.
        """
        self.db = db_session
        self.paths = paths
        print("--- Initialisation de l'intÃ©grateur de dictionnaires MIMIC-III ---")

    def populate_pathologies(self):
        """
        Peuple la table 'pathologies' depuis D_ICD_DIAGNOSES.csv.
        """
        print("\nğŸš€ DÃ©marrage du peuplement de la table 'pathologies'...")
        path = self.paths.get('d_icd_diagnoses')
        if not path:
            print("âŒ Chemin pour D_ICD_DIAGNOSES.csv non fourni. Ã‰tape ignorÃ©e.")
            return

        existing_codes = {c[0] for c in self.db.query(models.Disease.code_icd10).all()}
        print(f"  -> {len(existing_codes)} pathologies dÃ©jÃ  en base.")
        
        chunk_iterator = pd.read_csv(
            path, 
            chunksize=5000, 
            usecols=['icd9_code', 'long_title'], 
            encoding='latin1',
            dtype={'icd9_code': str}
        )
        
        total_added = 0
        for chunk in chunk_iterator:
            new_diseases = []
            for _, row in chunk.iterrows():
                code = str(row['icd9_code']).strip()
                if code and code not in existing_codes:
                    existing_codes.add(code)
                    new_diseases.append(models.Disease(
                        code_icd10=code,
                        nom_fr=str(row['long_title']).strip()[:255],
                        categorie="ImportÃ© de MIMIC-III"
                    ))
            
            if new_diseases:
                self.db.bulk_save_objects(new_diseases)
                total_added += len(new_diseases)

        self.db.commit()
        print(f"âœ¨ Peuplement terminÃ©. {total_added} nouvelles pathologies ajoutÃ©es.")

    def populate_symptoms_from_items(self):
        """
        Peuple la table 'symptomes' depuis D_LABITEMS.csv et D_ITEMS.csv.
        """
        print("\nğŸš€ DÃ©marrage du peuplement de la table 'symptomes'...")
        files_to_process = {
            'd_labitems': {'categorie': 'Biologique'},
            'd_items': {'categorie': 'Signe Vital/Clinique'}
        }
        
        existing_symptoms = {s[0] for s in self.db.query(models.Symptom.nom).all()}
        print(f"  -> {len(existing_symptoms)} symptÃ´mes dÃ©jÃ  en base.")

        total_added = 0
        for key, info in files_to_process.items():
            path = self.paths.get(key)
            if not path:
                print(f"âš ï¸ Chemin pour {key}.csv non fourni. Ã‰tape ignorÃ©e.")
                continue
            
            print(f"  -> Traitement de {path}...")
            # Utiliser un chunksize pour Ã©viter de charger tout le fichier en mÃ©moire
            chunk_iterator = pd.read_csv(path, usecols=['label'], encoding='latin1', chunksize=10000)
            
            for chunk in chunk_iterator:
                new_symptoms = []
                unique_labels = chunk['label'].dropna().unique()

                for label in unique_labels:
                    clean_label = str(label).strip()
                    if clean_label and clean_label not in existing_symptoms:
                        existing_symptoms.add(clean_label)
                        new_symptoms.append(models.Symptom(
                            nom=clean_label[:255],
                            categorie=info['categorie']
                        ))
                
                if new_symptoms:
                    self.db.bulk_save_objects(new_symptoms)
                    total_added += len(new_symptoms)
        
        self.db.commit()
        print(f"âœ¨ Peuplement terminÃ©. {total_added} nouveaux symptÃ´mes ajoutÃ©s.")

    def populate_medications(self):
        """
        Peuple la table 'medicaments' depuis PRESCRIPTIONS.csv.
        Utilise la colonne 'drug' (nom commercial) et 'formulary_drug_cd' (comme proxy DCI pour l'instant).
        """
        print("\nğŸš€ DÃ©marrage du peuplement de la table 'medicaments'...")
        path = self.paths.get('prescriptions')
        if not path:
            print("âŒ Chemin pour PRESCRIPTIONS.csv non fourni. Ã‰tape ignorÃ©e.")
            return

        existing_meds = {m[0] for m in self.db.query(models.Medication.nom_commercial).all()}
        print(f"  -> {len(existing_meds)} mÃ©dicaments dÃ©jÃ  en base.")
        
        # Lecture par lots car PRESCRIPTIONS.csv peut Ãªtre trÃ¨s gros
        chunk_iterator = pd.read_csv(
            path, 
            chunksize=10000, 
            usecols=['drug', 'drug_type', 'formulary_drug_cd', 'prod_strength', 'dose_val_rx', 'dose_unit_rx', 'route'],
            dtype=str # Tout lire en string pour Ã©viter les erreurs de type
        )
        
        total_added = 0
        for chunk in chunk_iterator:
            new_meds = []
            # On ne garde que les noms de mÃ©dicaments uniques dans ce lot
            unique_drugs = chunk.drop_duplicates(subset=['drug'])
            
            for _, row in unique_drugs.iterrows():
                drug_name = str(row['drug']).strip()
                
                if drug_name and drug_name not in existing_meds:
                    existing_meds.add(drug_name)
                    
                    # Construction de l'objet MÃ©dicament
                    # Note: Dans MIMIC, 'drug' est souvent le nom commercial.
                    # 'formulary_drug_cd' est un code interne, on l'utilise comme DCI temporaire
                    # si 'drug_name_generic' n'est pas dispo (ce qui est le cas dans la dÃ©mo parfois).
                    new_meds.append(models.Medication(
                        nom_commercial=drug_name,
                        dci=str(row['formulary_drug_cd']).strip()[:255], 
                        classe_therapeutique="ImportÃ© de MIMIC-III",
                        dosage=str(row['prod_strength']).strip()[:100] if pd.notna(row['prod_strength']) else None,
                        voie_administration=str(row['route']).strip()[:100] if pd.notna(row['route']) else None,
                        disponibilite_cameroun="Inconnue"
                    ))
            
            if new_meds:
                self.db.bulk_save_objects(new_meds)
                total_added += len(new_meds)

        self.db.commit()
        print(f"âœ¨ Peuplement terminÃ©. {total_added} nouveaux mÃ©dicaments ajoutÃ©s.")

    def run_all(self):
        """
        ExÃ©cute toutes les Ã©tapes de peuplement des dictionnaires.
        """
        self.populate_pathologies()
        self.populate_symptoms_from_items()
        self.populate_medications() # <- NOUVELLE Ã‰TAPE

=== Fichier: ./python_files_backup/datasets/adapters/medication_adapter.py ===



=== Fichier: ./python_files_backup/datasets/adapters/prevalence_adapter.py ===



=== Fichier: ./python_files_backup/datasets/adapters/__init__.py ===



=== Fichier: ./python_files_backup/datasets/adapters/cameroon_adapter.py ===



=== Fichier: ./python_files_backup/datasets/validators/quality_checker.py ===



=== Fichier: ./python_files_backup/datasets/validators/__init__.py ===



=== Fichier: ./python_files_backup/datasets/validators/clinical_validator.py ===



=== Fichier: ./python_files_backup/datasets/__init__.py ===



=== Fichier: ./python_files_backup/datasets/assembler/intelligent_assembler.py ===



=== Fichier: ./python_files_backup/datasets/assembler/case_assembler.py ===

import pandas as pd
from sqlalchemy.orm import Session
from typing import Dict, List, Any
import math
import random

from app import models
from app.services.embedding_service import embedding_service # <-- IMPORT

def clean_nan(value: Any) -> Any:
    """Remplace les valeurs NaN par None."""
    if value is None: return None
    if isinstance(value, float) and math.isnan(value): return None
    if isinstance(value, str) and value.lower() == 'nan': return None
    return value


class CaseAssembler:
    """
    Assemble des cas cliniques enrichis Ã  partir de MIMIC-III.
    """
    def __init__(self, db_session: Session, paths: Dict[str, str]):
        self.db = db_session
        self.paths = paths
        self.disease_map: Dict[str, int] = {}
        self.symptom_map: Dict[str, int] = {}
        self.medication_map: Dict[str, int] = {}
        self.images_by_disease: Dict[int, List[int]] = {} 
        print("--- Initialisation de l'assembleur de cas cliniques ---")

    def _preload_data(self):
        print("  -> PrÃ©-chargement des dictionnaires...")
        
        diseases = self.db.query(models.Disease.id, models.Disease.code_icd10).all()
        self.disease_map = {str(code).strip(): id for id, code in diseases}
        
        symptoms = self.db.query(models.Symptom.id, models.Symptom.nom).all()
        self.symptom_map = {nom: id for id, nom in symptoms}

        meds = self.db.query(models.Medication.id, models.Medication.nom_commercial).all()
        self.medication_map = {nom: id for id, nom in meds}

        # Images
        images = self.db.query(models.ImageMedicale.id, models.ImageMedicale.pathologie_id).filter(models.ImageMedicale.pathologie_id != None).all()
        for img_id, path_id in images:
            if path_id not in self.images_by_disease:
                self.images_by_disease[path_id] = []
            self.images_by_disease[path_id].append(img_id)

        # CSVs
        self.df_diagnoses = pd.read_csv(
            self.paths['diagnoses_icd'],
            usecols=['hadm_id', 'icd9_code', 'seq_num'],
            dtype={'icd9_code': str}
        )
        
        self.df_labitems = pd.read_csv(self.paths['d_labitems'], usecols=['itemid', 'label'])
        self.itemid_to_label = pd.Series(self.df_labitems.label.values, index=self.df_labitems.itemid).to_dict()

    def run(self):
        self._preload_data()

        admissions_path = self.paths.get('admissions')
        if not admissions_path: return

        print("\nğŸš€ DÃ©marrage de l'assemblage des cas cliniques...")
        df_admissions = pd.read_csv(admissions_path)
        
        # --- AgrÃ©gation Labos ---
        print("  -> AgrÃ©gation des rÃ©sultats de laboratoire...")
        labevents_chunk_iterator = pd.read_csv(self.paths['labevents'], chunksize=100000, usecols=['hadm_id', 'itemid', 'valuenum', 'valueuom', 'flag'])
        admission_labs: Dict[int, Dict[str, Any]] = {}
        for chunk in labevents_chunk_iterator:
            chunk['valuenum'].fillna(0, inplace=True)
            chunk['valueuom'].fillna('', inplace=True)
            chunk['flag'].fillna('', inplace=True)
            abnormal_events = chunk[chunk['flag'] == 'abnormal'].dropna(subset=['hadm_id'])
            for _, event in abnormal_events.iterrows():
                hadm_id = int(event['hadm_id'])
                if hadm_id not in admission_labs: admission_labs[hadm_id] = {}
                symptom_name = self.itemid_to_label.get(event['itemid'])
                if symptom_name and symptom_name not in admission_labs[hadm_id]:
                    admission_labs[hadm_id][symptom_name] = {
                        "nom": symptom_name, "valeur": event['valuenum'], "unite": event['valueuom']
                    }
        
        # --- AgrÃ©gation MÃ©dicaments ---
        print("  -> AgrÃ©gation des prescriptions mÃ©dicamenteuses...")
        prescriptions_path = self.paths.get('prescriptions')
        admission_meds: Dict[int, List[Dict[str, Any]]] = {}
        if prescriptions_path:
            presc_chunk_iterator = pd.read_csv(prescriptions_path, chunksize=50000, usecols=['hadm_id', 'drug', 'dose_val_rx', 'dose_unit_rx'], dtype=str)
            for chunk in presc_chunk_iterator:
                chunk = chunk.dropna(subset=['hadm_id', 'drug'])
                for _, row in chunk.iterrows():
                    hadm_id = int(float(row['hadm_id']))
                    if hadm_id not in admission_meds: admission_meds[hadm_id] = []
                    drug_name = str(row['drug']).strip()
                    med_id = self.medication_map.get(drug_name)
                    if med_id:
                        admission_meds[hadm_id].append({
                            "medicament_id": med_id, "nom": drug_name, "dose": f"{row['dose_val_rx']} {row['dose_unit_rx']}"
                        })

        # --- Assemblage ---
        new_cases = []
        existing_case_codes = {c[0] for c in self.db.query(models.ClinicalCase.code_fultang).all()}

        for _, admission in df_admissions.iterrows():
            hadm_id = admission['hadm_id']
            case_code = f"MIMIC_{hadm_id}"

            if case_code in existing_case_codes: continue

            diagnoses_for_admission = self.df_diagnoses[self.df_diagnoses['hadm_id'] == hadm_id].sort_values('seq_num')
            if diagnoses_for_admission.empty: continue

            main_diag_id = None
            secondary_diag_ids = []
            for _, diag_row in diagnoses_for_admission.iterrows():
                raw_diag_code = str(diag_row['icd9_code']).strip()
                normalized_diag_code = raw_diag_code.lstrip('0')
                if not normalized_diag_code and raw_diag_code.isnumeric(): normalized_diag_code = '0'
                elif not normalized_diag_code: normalized_diag_code = raw_diag_code
                diag_id = self.disease_map.get(normalized_diag_code) or self.disease_map.get(raw_diag_code)

                if diag_id:
                    if diag_row['seq_num'] == 1:
                        main_diag_id = diag_id
                    else:
                        secondary_diag_ids.append(diag_id)
            
            if not main_diag_id: continue

            # SymptÃ´mes
            lab_results_dict = admission_labs.get(hadm_id, {})
            lab_results_list = list(lab_results_dict.values())
            symptomes_patient = []
            symptoms_text_list = [] # Pour le vecteur
            
            for lab_res in lab_results_list:
                symptom_id = self.symptom_map.get(lab_res['nom'])
                if symptom_id:
                    symptomes_patient.append({
                        "symptome_id": symptom_id, "details": f"Valeur: {lab_res.get('valeur')} {lab_res.get('unite') or ''}".strip()
                    })
                    symptoms_text_list.append(f"{lab_res['nom']} {lab_res.get('valeur')}")

            history_text = f"Admission pour : {admission['diagnosis']}"
            presentation = {
                "histoire_maladie": history_text,
                "symptomes_patient": symptomes_patient
            }
            
            meds_list = admission_meds.get(hadm_id, [])

            # Images
            images_ids = []
            if main_diag_id in self.images_by_disease:
                available_images = self.images_by_disease[main_diag_id]
                if available_images:
                    images_ids.append(random.choice(available_images))

            # --- VECTORISATION ---
            # On vectorise l'histoire clinique combinÃ©e aux symptÃ´mes principaux
            # C'est ce texte que le RAG utilisera pour trouver des cas similaires
            full_case_text = f"{history_text}. SymptÃ´mes biologiques notables : {', '.join(symptoms_text_list[:10])}"
            vector = embedding_service.get_text_embedding(full_case_text)

            new_case = models.ClinicalCase(
                code_fultang=case_code,
                pathologie_principale_id=main_diag_id,
                pathologies_secondaires_ids=secondary_diag_ids,
                presentation_clinique=presentation,
                donnees_paracliniques={"lab_results": lab_results_list},
                medicaments_prescrits=meds_list,
                images_associees_ids=images_ids,
                niveau_difficulte=2 + len(secondary_diag_ids),
                embedding_texte=vector # <-- AJOUT
            )
            new_cases.append(new_case)

        print(f"  -> {len(new_cases)} cas cliniques assemblÃ©s.")

        if new_cases:
            try:
                self.db.bulk_save_objects(new_cases)
                self.db.commit()
                print(f"âœ¨ Chargement de {len(new_cases)} nouveaux cas cliniques rÃ©ussi.")

                print("\n--- AperÃ§u des 10 premiers cas cliniques chargÃ©s ---")
                first_10_cases = self.db.query(models.ClinicalCase).order_by(models.ClinicalCase.id.desc()).limit(10).all()
                for i, case_from_db in enumerate(reversed(first_10_cases)):
                    disease_name = case_from_db.pathologie_principale.nom_fr if case_from_db.pathologie_principale else "Inconnue"
                    # VÃ©rifier si le vecteur est prÃ©sent (pour le log)
                    has_vector = "OUI" if case_from_db.embedding_texte is not None else "NON"
                    
                    print(f"\n[{i+1}] Cas: {case_from_db.code_fultang}")
                    print(f"    Pathologie: {disease_name}")
                    print(f"    Vecteur IA gÃ©nÃ©rÃ©: {has_vector}") # <-- Affichage validation

            except Exception as e:
                print(f"âŒ Erreur lors du chargement des cas : {e}")
                self.db.rollback()
        else:
            print("âœ¨ Aucun nouveau cas clinique Ã  ajouter.")

=== Fichier: ./python_files_backup/datasets/assembler/__init__.py ===



=== Fichier: ./python_files_backup/datasets/assembler/enrichment_engine.py ===



=== Fichier: ./python_files_backup/datasets/base_integrator.py ===

from abc import ABC, abstractmethod
from sqlalchemy.orm import Session

class BaseIntegrator(ABC):
    """
    Classe de base abstraite (blueprint) pour tous les intÃ©grateurs de datasets.
    
    Elle impose une structure ETL (Extract, Transform, Load) cohÃ©rente pour
    garantir que chaque script d'importation fonctionne de la mÃªme maniÃ¨re.
    """

    def __init__(self, db_session: Session, dataset_path: str):
        """
        Initialise l'intÃ©grateur avec une session de base de donnÃ©es et le chemin
        vers le dataset.
        
        :param db_session: La session SQLAlchemy pour interagir avec la BDD.
        :param dataset_path: Le chemin vers le dossier ou le fichier du dataset.
        """
        self.db = db_session
        self.path = dataset_path
        print(f"--- Initialisation de {self.__class__.__name__} ---")
        print(f"Source des donnÃ©es : {self.path}")

    @abstractmethod
    def extract(self):
        """
        Ã‰tape d'Extraction (E) : Lire les donnÃ©es depuis la source.
        
        Cette mÃ©thode DOIT Ãªtre implÃ©mentÃ©e par chaque sous-classe.
        Elle doit retourner un itÃ©rateur qui produit des lots (chunks) de donnÃ©es
        (par exemple, un TextFileReader de pandas).
        """
        pass

    @abstractmethod
    def transform(self, data_chunk: any):
        """
        Ã‰tape de Transformation (T) : Nettoyer, mapper et prÃ©parer les donnÃ©es.
        
        Cette mÃ©thode DOIT Ãªtre implÃ©mentÃ©e par chaque sous-classe.
        Elle prend un lot de donnÃ©es extraites et retourne une liste d'objets
        SQLAlchemy prÃªts Ã  Ãªtre insÃ©rÃ©s.
        """
        pass

    @abstractmethod
    def load(self, transformed_data: list):
        """
        Ã‰tape de Chargement (L) : InsÃ©rer les donnÃ©es transformÃ©es en BDD.
        
        Cette mÃ©thode DOIT Ãªtre implÃ©mentÃ©e par chaque sous-classe.
        """
        pass

    def run(self):
        """
        Orchestre le processus ETL complet.
        
        Cette mÃ©thode est dÃ©jÃ  implÃ©mentÃ©e et ne devrait pas Ãªtre modifiÃ©e.
        Elle appelle successivement extract, transform, et load pour chaque lot.
        """
        print(f"\nğŸš€ DÃ©marrage du processus ETL pour {self.__class__.__name__}...")
        
        try:
            extracted_data_iterator = self.extract()
            
            total_items_loaded = 0
            chunk_count = 0
            for chunk in extracted_data_iterator:
                chunk_count += 1
                print(f"  [{chunk_count}] Extraction d'un lot de {len(chunk)} lignes.")
                
                transformed_chunk = self.transform(chunk)
                
                if transformed_chunk:
                    print(f"    -> Transformation rÃ©ussie : {len(transformed_chunk)} objets prÃªts Ã  Ãªtre chargÃ©s.")
                    self.load(transformed_chunk)
                    total_items_loaded += len(transformed_chunk)
                else:
                    print("    -> Aucun nouvel objet Ã  charger dans ce lot.")
            
            print(f"\nâœ¨ Processus ETL terminÃ©. {total_items_loaded} objets uniques chargÃ©s au total.")
        except FileNotFoundError:
            print(f"âŒ ERREUR: Le fichier ou dossier du dataset n'a pas Ã©tÃ© trouvÃ© Ã  l'emplacement : {self.path}")
        except Exception as e:
            print(f"âŒ ERREUR inattendue pendant le processus ETL : {e}")
            # En production, on utiliserait un logger plus sophistiquÃ©.

=== Fichier: ./datasets/integrators/open_medic_integrator.py ===



=== Fichier: ./datasets/integrators/physionet_integrator.py ===



=== Fichier: ./datasets/integrators/open_bio_integrator.py ===



=== Fichier: ./datasets/integrators/__init__.py ===



=== Fichier: ./datasets/integrators/eicu_integrator.py ===



=== Fichier: ./datasets/integrators/chexpert_integrator.py ===



=== Fichier: ./datasets/integrators/mimic3_symptom_relation_integrator.py ===



=== Fichier: ./datasets/integrators/manual_images_integrator.py ===

import pandas as pd
import os
import shutil
from sqlalchemy.orm import Session
from typing import List

from app import models
from ..base_integrator import BaseIntegrator

# Chemin relatif oÃ¹ vous avez mis vos images
STORAGE_REL_PATH = "storage/media/images" 

class ManualImagesIntegrator(BaseIntegrator):
    """
    IntÃ©grateur pour cataloguer les images manuelles dÃ©jÃ  prÃ©sentes dans le dossier storage.
    """

    def __init__(self, db_session: Session, mapping_csv_path: str, source_images_dir: str = None):
        super().__init__(db_session, mapping_csv_path)
        self.storage_dir = os.path.abspath(STORAGE_REL_PATH)
        print(f"--- Initialisation de l'intÃ©grateur d'images ---")
        print(f"Dossier des images : {self.storage_dir}")

    def extract(self):
        """Lit le fichier de mapping."""
        return pd.read_csv(self.path, chunksize=1000)

    def transform(self, data_chunk: pd.DataFrame) -> List[dict]:
        """PrÃ©pare les donnÃ©es."""
        actions = []
        for _, row in data_chunk.iterrows():
            filename = str(row['filename']).strip()
            file_path = os.path.join(self.storage_dir, filename)
            
            if not os.path.exists(file_path):
                print(f"âš ï¸ Fichier manquant dans storage : {filename}")
                continue

            # Nettoyage et parsing des IDs
            raw_ids = str(row['cas_ids'])
            cas_ids_str = raw_ids.replace('"', '').replace("'", "")
            cas_ids = []
            for x in cas_ids_str.split(','):
                x = x.strip()
                if x.isdigit():
                    cas_ids.append(int(x))
            
            # Log de dÃ©bogage
            # print(f"[DEBUG] Image {filename} -> IDs cibles : {cas_ids}")

            actions.append({
                "filename": filename,
                "file_path": file_path,
                "cas_ids": cas_ids,
                "type_examen": row['type_examen'],
                "description": row['description']
            })
        return actions

    def load(self, actions: List[dict]):
        """CrÃ©e les entrÃ©es en base."""
        for action in actions:
            filename = action['filename']
            file_url = os.path.join(STORAGE_REL_PATH, filename)
            
            existing_img = self.db.query(models.ImageMedicale).filter(
                models.ImageMedicale.fichier_url == file_url
            ).first()

            if not existing_img:
                new_image = models.ImageMedicale(
                    type_examen=action['type_examen'],
                    description=action['description'],
                    fichier_url=file_url,
                    format_image=filename.split('.')[-1].lower()
                )
                self.db.add(new_image)
                self.db.flush()
                image_id = new_image.id
                print(f"    -> Image cataloguÃ©e : {filename} (ID: {image_id})")
            else:
                image_id = existing_img.id

            # Lier aux Cas Cliniques
            for case_id_csv in action['cas_ids']: 
                
                # Pour chaque ID de la liste, on applique le dÃ©calage
                case_id_db = case_id_csv + 908  
                
                # On cherche le cas correspondant en base
                case = self.db.query(models.ClinicalCase).filter(models.ClinicalCase.id == case_id_db).first()
                if case:
                    # ... (le reste du code utilise 'case', donc c'est bon)
                    if case.images_associees_ids is None:
                        case.images_associees_ids = []
                    
                    current_ids = list(case.images_associees_ids)
                    if image_id not in current_ids:
                        current_ids.append(image_id)
                        case.images_associees_ids = current_ids
                        print(f"       -> âœ… LiÃ©e au cas {case_id_db} ({case.code_fultang})")

        try:
            self.db.commit()
        except Exception as e:
            print(f"âŒ Erreur commit : {e}")
            self.db.rollback()

=== Fichier: ./datasets/integrators/mimic3_integrator.py ===

import pandas as pd
from sqlalchemy.orm import Session
from typing import Dict, Set

from app import models

class MIMIC3RelationsIntegrator:
    """
    IntÃ©grateur pour dÃ©duire et crÃ©er les relations entre pathologies,
    symptÃ´mes et mÃ©dicaments avec des probabilitÃ©s rÃ©elles (basÃ©es sur les patients uniques).
    """

    def __init__(self, db_session: Session, paths: Dict[str, str]):
        self.db = db_session
        self.paths = paths
        self.disease_map: Dict[str, int] = {}
        self.symptom_map: Dict[str, int] = {}
        self.medication_map: Dict[str, int] = {}
        print("--- Initialisation de l'intÃ©grateur de relations MIMIC-III ---")

    def _preload_dictionaries(self):
        print("  -> PrÃ©-chargement des dictionnaires...")
        diseases = self.db.query(models.Disease.id, models.Disease.code_icd10).all()
        self.disease_map = {str(code).strip(): id for id, code in diseases}
        
        symptoms = self.db.query(models.Symptom.id, models.Symptom.nom).all()
        self.symptom_map = {nom: id for id, nom in symptoms}

        meds = self.db.query(models.Medication.id, models.Medication.nom_commercial).all()
        self.medication_map = {nom: id for id, nom in meds}

    def run(self):
        self._preload_dictionaries()

        # --- Ã‰tape 1: Carte des diagnostics et COMPTAGE ---
        print("\nğŸš€ Ã‰tape 1: Carte des diagnostics et calcul des totaux...")
        diagnoses_path = self.paths.get('diagnoses_icd')
        if not diagnoses_path: return
            
        admissions_diagnoses = {}
        disease_counts: Dict[str, int] = {} 

        df_diag = pd.read_csv(diagnoses_path, usecols=['hadm_id', 'icd9_code'], dtype={'icd9_code': str})
        for _, row in df_diag.iterrows():
            hadm_id = row['hadm_id']
            icd9_code = str(row['icd9_code']).strip()
            
            normalized_code = icd9_code.lstrip('0')
            if not normalized_code and icd9_code.isnumeric(): normalized_code = '0'
            elif not normalized_code: normalized_code = icd9_code

            if normalized_code in self.disease_map:
                code_to_use = normalized_code
            elif icd9_code in self.disease_map:
                code_to_use = icd9_code
            else:
                continue

            if hadm_id not in admissions_diagnoses:
                admissions_diagnoses[hadm_id] = set()
            
            if code_to_use not in admissions_diagnoses[hadm_id]:
                admissions_diagnoses[hadm_id].add(code_to_use)
                disease_counts[code_to_use] = disease_counts.get(code_to_use, 0) + 1
        
        print(f"  -> Carte construite. {len(disease_counts)} maladies diffÃ©rentes trouvÃ©es.")

        # --- Ã‰tape 2: Analyse des rÃ©sultats (CORRECTION LOGIQUE) ---
        print("\nğŸš€ Ã‰tape 2: Analyse des rÃ©sultats de laboratoire anormaux...")
        labevents_path = self.paths.get('labevents')
        d_labitems_path = self.paths.get('d_labitems')
        if not labevents_path or not d_labitems_path: return

        df_labitems = pd.read_csv(d_labitems_path, usecols=['itemid', 'label'])
        itemid_to_label = pd.Series(df_labitems.label.values, index=df_labitems.itemid).to_dict()

        # CORRECTION : Utiliser un Set pour stocker les hadm_id uniques
        co_occurrences: Dict[str, Dict[str, Set[int]]] = {} 

        chunk_iterator = pd.read_csv(labevents_path, chunksize=100000, usecols=['hadm_id', 'itemid', 'flag'])
        
        for chunk in chunk_iterator:
            abnormal_events = chunk[chunk['flag'] == 'abnormal'].dropna()
            for _, event in abnormal_events.iterrows():
                hadm_id = event['hadm_id']
                itemid = event['itemid']
                diagnoses = admissions_diagnoses.get(hadm_id)
                symptom_name = itemid_to_label.get(itemid)

                if diagnoses and symptom_name and symptom_name in self.symptom_map:
                    for icd9_code in diagnoses:
                        if icd9_code not in co_occurrences:
                            co_occurrences[icd9_code] = {}
                        
                        if symptom_name not in co_occurrences[icd9_code]:
                            co_occurrences[icd9_code][symptom_name] = set() # Initialiser un Set
                        
                        # Ajouter l'ID de l'admission (les doublons sont ignorÃ©s par le Set)
                        co_occurrences[icd9_code][symptom_name].add(hadm_id)
        
        # --- Ã‰tape 3: Chargement des relations ---
        print("\nğŸš€ Ã‰tape 3: Chargement des relations (ProbabilitÃ©s rÃ©elles)...")
        new_relations = []
        
        log_limit = 10 
        current_log = 0

        for icd9_code, symptom_sets in co_occurrences.items():
            disease_id = self.disease_map.get(icd9_code)
            total_cases = disease_counts.get(icd9_code, 1)

            if not disease_id: continue

            for symptom_name, unique_patients_set in symptom_sets.items():
                symptom_id = self.symptom_map.get(symptom_name)
                if not symptom_id: continue
                
                # CORRECTION : Compter la taille du Set (nombre de patients uniques)
                unique_count = len(unique_patients_set)
                
                # Calcul correct : (Nb patients uniques avec symptÃ´me) / (Nb total patients avec maladie)
                prob = unique_count / total_cases 
            
            # Logs de vÃ©rification
                if current_log < 120: # Augmentons la limite Ã  20 pour voir plus de cas
                    print(f"  [LOG] Maladie {icd9_code} (ID BDD: {disease_id})")
                    print(f"        SymptÃ´me: {symptom_name}")
                    # Afficher clairement si c'est un cas unique ou non
                    if total_cases == 1:
                        print(f"        -> âš ï¸ UN SEUL PATIENT connu pour cette maladie dans le dataset.")
                    else:
                        print(f"        -> âœ… PLUSIEURS PATIENTS ({total_cases}).")
                    
                    print(f"        -> Calcul: {unique_count}/{total_cases} = {prob:.4f}")
                    print("        --------------------------------------------------")
                    current_log += 1

                if prob > 0.05:
                    new_relations.append(models.PathologieSymptome(
                        pathologie_id=disease_id,
                        symptome_id=symptom_id,
                        probabilite=prob,
                        frequence=f"{prob*100:.1f}%",
                        importance_diagnostique=3
                    ))

        if new_relations:
            try:
                self.db.bulk_save_objects(new_relations)
                self.db.commit()
                print(f"âœ¨ Chargement de {len(new_relations)} relations pathologie-symptÃ´me.")
            except Exception:
                self.db.rollback()

        # --- Ã‰tape 4 & 5: Relations ThÃ©rapeutiques (MÃªme logique de correction) ---
        print("\nğŸš€ Ã‰tape 4: Analyse des prescriptions...")
        prescriptions_path = self.paths.get('prescriptions')
        if not prescriptions_path: return

        # CORRECTION : Utiliser un Set pour les mÃ©dicaments aussi
        med_co_occurrences: Dict[str, Dict[str, Set[int]]] = {}

        chunk_iterator = pd.read_csv(prescriptions_path, chunksize=10000, usecols=['hadm_id', 'drug'], dtype=str)
        for chunk in chunk_iterator:
            for _, row in chunk.iterrows():
                hadm_id = int(row['hadm_id']) if pd.notna(row['hadm_id']) else None
                drug_name = str(row['drug']).strip()
                diagnoses = admissions_diagnoses.get(hadm_id)
                
                if diagnoses and drug_name in self.medication_map:
                    for icd9_code in diagnoses:
                        if icd9_code not in med_co_occurrences:
                            med_co_occurrences[icd9_code] = {}
                        
                        if drug_name not in med_co_occurrences[icd9_code]:
                            med_co_occurrences[icd9_code][drug_name] = set()
                        
                        med_co_occurrences[icd9_code][drug_name].add(hadm_id)

        print("\nğŸš€ Ã‰tape 5: Chargement des relations thÃ©rapeutiques...")
        new_treatments = []
        for icd9_code, drug_sets in med_co_occurrences.items():
            disease_id = self.disease_map.get(icd9_code)
            total_cases = disease_counts.get(icd9_code, 1)

            if not disease_id: continue

            # Trier par nombre de patients uniques
            top_drugs = sorted(drug_sets.items(), key=lambda x: len(x[1]), reverse=True)[:10]

            for drug_name, unique_patients_set in top_drugs:
                med_id = self.medication_map.get(drug_name)
                if not med_id: continue
                
                unique_count = len(unique_patients_set)
                frequence = (unique_count / total_cases) * 100
                
                new_treatments.append(models.TraitementPathologie(
                    pathologie_id=disease_id,
                    medicament_id=med_id,
                    efficacite_taux=frequence,
                    type_traitement=f"Prescrit dans {frequence:.1f}% des cas"
                ))

        if new_treatments:
            try:
                self.db.bulk_save_objects(new_treatments)
                self.db.commit()
                print(f"âœ¨ Chargement de {len(new_treatments)} relations thÃ©rapeutiques.")
            except Exception:
                self.db.rollback()

=== Fichier: ./datasets/integrators/mimic3_dics_integrator.py ===

import pandas as pd
from sqlalchemy.orm import Session
from typing import Dict, Set

from app import models

class MIMIC3DictionariesIntegrator:
    """
    IntÃ©grateur spÃ©cialisÃ© pour peupler les tables de rÃ©fÃ©rence (dictionnaires)
    de notre base de donnÃ©es Ã  partir des fichiers correspondants de MIMIC-III.
    """

    def __init__(self, db_session: Session, paths: Dict[str, str]):
        """
        Initialise l'intÃ©grateur avec une session de base de donnÃ©es et un
        dictionnaire des chemins vers les fichiers CSV nÃ©cessaires.
        """
        self.db = db_session
        self.paths = paths
        print("--- Initialisation de l'intÃ©grateur de dictionnaires MIMIC-III ---")

    def populate_pathologies(self):
        """
        Peuple la table 'pathologies' depuis D_ICD_DIAGNOSES.csv.
        """
        print("\nğŸš€ DÃ©marrage du peuplement de la table 'pathologies'...")
        path = self.paths.get('d_icd_diagnoses')
        if not path:
            print("âŒ Chemin pour D_ICD_DIAGNOSES.csv non fourni. Ã‰tape ignorÃ©e.")
            return

        existing_codes = {c[0] for c in self.db.query(models.Disease.code_icd10).all()}
        print(f"  -> {len(existing_codes)} pathologies dÃ©jÃ  en base.")
        
        chunk_iterator = pd.read_csv(
            path, 
            chunksize=5000, 
            usecols=['icd9_code', 'long_title'], 
            encoding='latin1',
            dtype={'icd9_code': str}
        )
        
        total_added = 0
        for chunk in chunk_iterator:
            new_diseases = []
            for _, row in chunk.iterrows():
                code = str(row['icd9_code']).strip()
                if code and code not in existing_codes:
                    existing_codes.add(code)
                    new_diseases.append(models.Disease(
                        code_icd10=code,
                        nom_fr=str(row['long_title']).strip()[:255],
                        categorie="ImportÃ© de MIMIC-III"
                    ))
            
            if new_diseases:
                self.db.bulk_save_objects(new_diseases)
                total_added += len(new_diseases)

        self.db.commit()
        print(f"âœ¨ Peuplement terminÃ©. {total_added} nouvelles pathologies ajoutÃ©es.")

    def populate_symptoms_from_items(self):
        """
        Peuple la table 'symptomes' depuis D_LABITEMS.csv et D_ITEMS.csv.
        """
        print("\nğŸš€ DÃ©marrage du peuplement de la table 'symptomes'...")
        files_to_process = {
            'd_labitems': {'categorie': 'Biologique'},
            'd_items': {'categorie': 'Signe Vital/Clinique'}
        }
        
        existing_symptoms = {s[0] for s in self.db.query(models.Symptom.nom).all()}
        print(f"  -> {len(existing_symptoms)} symptÃ´mes dÃ©jÃ  en base.")

        total_added = 0
        for key, info in files_to_process.items():
            path = self.paths.get(key)
            if not path:
                print(f"âš ï¸ Chemin pour {key}.csv non fourni. Ã‰tape ignorÃ©e.")
                continue
            
            print(f"  -> Traitement de {path}...")
            # Utiliser un chunksize pour Ã©viter de charger tout le fichier en mÃ©moire
            chunk_iterator = pd.read_csv(path, usecols=['label'], encoding='latin1', chunksize=10000)
            
            for chunk in chunk_iterator:
                new_symptoms = []
                unique_labels = chunk['label'].dropna().unique()

                for label in unique_labels:
                    clean_label = str(label).strip()
                    if clean_label and clean_label not in existing_symptoms:
                        existing_symptoms.add(clean_label)
                        new_symptoms.append(models.Symptom(
                            nom=clean_label[:255],
                            categorie=info['categorie']
                        ))
                
                if new_symptoms:
                    self.db.bulk_save_objects(new_symptoms)
                    total_added += len(new_symptoms)
        
        self.db.commit()
        print(f"âœ¨ Peuplement terminÃ©. {total_added} nouveaux symptÃ´mes ajoutÃ©s.")

    def populate_medications(self):
        """
        Peuple la table 'medicaments' depuis PRESCRIPTIONS.csv.
        Utilise la colonne 'drug' (nom commercial) et 'formulary_drug_cd' (comme proxy DCI pour l'instant).
        """
        print("\nğŸš€ DÃ©marrage du peuplement de la table 'medicaments'...")
        path = self.paths.get('prescriptions')
        if not path:
            print("âŒ Chemin pour PRESCRIPTIONS.csv non fourni. Ã‰tape ignorÃ©e.")
            return

        existing_meds = {m[0] for m in self.db.query(models.Medication.nom_commercial).all()}
        print(f"  -> {len(existing_meds)} mÃ©dicaments dÃ©jÃ  en base.")
        
        # Lecture par lots car PRESCRIPTIONS.csv peut Ãªtre trÃ¨s gros
        chunk_iterator = pd.read_csv(
            path, 
            chunksize=10000, 
            usecols=['drug', 'drug_type', 'formulary_drug_cd', 'prod_strength', 'dose_val_rx', 'dose_unit_rx', 'route'],
            dtype=str # Tout lire en string pour Ã©viter les erreurs de type
        )
        
        total_added = 0
        for chunk in chunk_iterator:
            new_meds = []
            # On ne garde que les noms de mÃ©dicaments uniques dans ce lot
            unique_drugs = chunk.drop_duplicates(subset=['drug'])
            
            for _, row in unique_drugs.iterrows():
                drug_name = str(row['drug']).strip()
                
                if drug_name and drug_name not in existing_meds:
                    existing_meds.add(drug_name)
                    
                    # Construction de l'objet MÃ©dicament
                    # Note: Dans MIMIC, 'drug' est souvent le nom commercial.
                    # 'formulary_drug_cd' est un code interne, on l'utilise comme DCI temporaire
                    # si 'drug_name_generic' n'est pas dispo (ce qui est le cas dans la dÃ©mo parfois).
                    new_meds.append(models.Medication(
                        nom_commercial=drug_name,
                        dci=str(row['formulary_drug_cd']).strip()[:255], 
                        classe_therapeutique="ImportÃ© de MIMIC-III",
                        dosage=str(row['prod_strength']).strip()[:100] if pd.notna(row['prod_strength']) else None,
                        voie_administration=str(row['route']).strip()[:100] if pd.notna(row['route']) else None,
                        disponibilite_cameroun="Inconnue"
                    ))
            
            if new_meds:
                self.db.bulk_save_objects(new_meds)
                total_added += len(new_meds)

        self.db.commit()
        print(f"âœ¨ Peuplement terminÃ©. {total_added} nouveaux mÃ©dicaments ajoutÃ©s.")

    def run_all(self):
        """
        ExÃ©cute toutes les Ã©tapes de peuplement des dictionnaires.
        """
        self.populate_pathologies()
        self.populate_symptoms_from_items()
        self.populate_medications() # <- NOUVELLE Ã‰TAPE

=== Fichier: ./datasets/adapters/medication_adapter.py ===



=== Fichier: ./datasets/adapters/prevalence_adapter.py ===



=== Fichier: ./datasets/adapters/__init__.py ===



=== Fichier: ./datasets/adapters/cameroon_adapter.py ===



=== Fichier: ./datasets/validators/quality_checker.py ===



=== Fichier: ./datasets/validators/__init__.py ===



=== Fichier: ./datasets/validators/clinical_validator.py ===



=== Fichier: ./datasets/__init__.py ===



=== Fichier: ./datasets/assembler/intelligent_assembler.py ===



=== Fichier: ./datasets/assembler/case_assembler.py ===

import pandas as pd
from sqlalchemy.orm import Session
from typing import Dict, List, Any
import math
import random

from app import models
from app.services.embedding_service import embedding_service # <-- IMPORT

def clean_nan(value: Any) -> Any:
    """Remplace les valeurs NaN par None."""
    if value is None: return None
    if isinstance(value, float) and math.isnan(value): return None
    if isinstance(value, str) and value.lower() == 'nan': return None
    return value


class CaseAssembler:
    """
    Assemble des cas cliniques enrichis Ã  partir de MIMIC-III.
    """
    def __init__(self, db_session: Session, paths: Dict[str, str]):
        self.db = db_session
        self.paths = paths
        self.disease_map: Dict[str, int] = {}
        self.symptom_map: Dict[str, int] = {}
        self.medication_map: Dict[str, int] = {}
        self.images_by_disease: Dict[int, List[int]] = {} 
        print("--- Initialisation de l'assembleur de cas cliniques ---")

    def _preload_data(self):
        print("  -> PrÃ©-chargement des dictionnaires...")
        
        diseases = self.db.query(models.Disease.id, models.Disease.code_icd10).all()
        self.disease_map = {str(code).strip(): id for id, code in diseases}
        
        symptoms = self.db.query(models.Symptom.id, models.Symptom.nom).all()
        self.symptom_map = {nom: id for id, nom in symptoms}

        meds = self.db.query(models.Medication.id, models.Medication.nom_commercial).all()
        self.medication_map = {nom: id for id, nom in meds}

        # Images
        images = self.db.query(models.ImageMedicale.id, models.ImageMedicale.pathologie_id).filter(models.ImageMedicale.pathologie_id != None).all()
        for img_id, path_id in images:
            if path_id not in self.images_by_disease:
                self.images_by_disease[path_id] = []
            self.images_by_disease[path_id].append(img_id)

        # CSVs
        self.df_diagnoses = pd.read_csv(
            self.paths['diagnoses_icd'],
            usecols=['hadm_id', 'icd9_code', 'seq_num'],
            dtype={'icd9_code': str}
        )
        
        self.df_labitems = pd.read_csv(self.paths['d_labitems'], usecols=['itemid', 'label'])
        self.itemid_to_label = pd.Series(self.df_labitems.label.values, index=self.df_labitems.itemid).to_dict()

    def run(self):
        self._preload_data()

        admissions_path = self.paths.get('admissions')
        if not admissions_path: return

        print("\nğŸš€ DÃ©marrage de l'assemblage des cas cliniques...")
        df_admissions = pd.read_csv(admissions_path)
        
        # --- AgrÃ©gation Labos ---
        print("  -> AgrÃ©gation des rÃ©sultats de laboratoire...")
        labevents_chunk_iterator = pd.read_csv(self.paths['labevents'], chunksize=100000, usecols=['hadm_id', 'itemid', 'valuenum', 'valueuom', 'flag'])
        admission_labs: Dict[int, Dict[str, Any]] = {}
        for chunk in labevents_chunk_iterator:
            chunk['valuenum'].fillna(0, inplace=True)
            chunk['valueuom'].fillna('', inplace=True)
            chunk['flag'].fillna('', inplace=True)
            abnormal_events = chunk[chunk['flag'] == 'abnormal'].dropna(subset=['hadm_id'])
            for _, event in abnormal_events.iterrows():
                hadm_id = int(event['hadm_id'])
                if hadm_id not in admission_labs: admission_labs[hadm_id] = {}
                symptom_name = self.itemid_to_label.get(event['itemid'])
                if symptom_name and symptom_name not in admission_labs[hadm_id]:
                    admission_labs[hadm_id][symptom_name] = {
                        "nom": symptom_name, "valeur": event['valuenum'], "unite": event['valueuom']
                    }
        
        # --- AgrÃ©gation MÃ©dicaments ---
        print("  -> AgrÃ©gation des prescriptions mÃ©dicamenteuses...")
        prescriptions_path = self.paths.get('prescriptions')
        admission_meds: Dict[int, List[Dict[str, Any]]] = {}
        if prescriptions_path:
            presc_chunk_iterator = pd.read_csv(prescriptions_path, chunksize=50000, usecols=['hadm_id', 'drug', 'dose_val_rx', 'dose_unit_rx'], dtype=str)
            for chunk in presc_chunk_iterator:
                chunk = chunk.dropna(subset=['hadm_id', 'drug'])
                for _, row in chunk.iterrows():
                    hadm_id = int(float(row['hadm_id']))
                    if hadm_id not in admission_meds: admission_meds[hadm_id] = []
                    drug_name = str(row['drug']).strip()
                    med_id = self.medication_map.get(drug_name)
                    if med_id:
                        admission_meds[hadm_id].append({
                            "medicament_id": med_id, "nom": drug_name, "dose": f"{row['dose_val_rx']} {row['dose_unit_rx']}"
                        })

        # --- Assemblage ---
        new_cases = []
        existing_case_codes = {c[0] for c in self.db.query(models.ClinicalCase.code_fultang).all()}

        for _, admission in df_admissions.iterrows():
            hadm_id = admission['hadm_id']
            case_code = f"MIMIC_{hadm_id}"

            if case_code in existing_case_codes: continue

            diagnoses_for_admission = self.df_diagnoses[self.df_diagnoses['hadm_id'] == hadm_id].sort_values('seq_num')
            if diagnoses_for_admission.empty: continue

            main_diag_id = None
            secondary_diag_ids = []
            for _, diag_row in diagnoses_for_admission.iterrows():
                raw_diag_code = str(diag_row['icd9_code']).strip()
                normalized_diag_code = raw_diag_code.lstrip('0')
                if not normalized_diag_code and raw_diag_code.isnumeric(): normalized_diag_code = '0'
                elif not normalized_diag_code: normalized_diag_code = raw_diag_code
                diag_id = self.disease_map.get(normalized_diag_code) or self.disease_map.get(raw_diag_code)

                if diag_id:
                    if diag_row['seq_num'] == 1:
                        main_diag_id = diag_id
                    else:
                        secondary_diag_ids.append(diag_id)
            
            if not main_diag_id: continue

            # SymptÃ´mes
            lab_results_dict = admission_labs.get(hadm_id, {})
            lab_results_list = list(lab_results_dict.values())
            symptomes_patient = []
            symptoms_text_list = [] # Pour le vecteur
            
            for lab_res in lab_results_list:
                symptom_id = self.symptom_map.get(lab_res['nom'])
                if symptom_id:
                    symptomes_patient.append({
                        "symptome_id": symptom_id, "details": f"Valeur: {lab_res.get('valeur')} {lab_res.get('unite') or ''}".strip()
                    })
                    symptoms_text_list.append(f"{lab_res['nom']} {lab_res.get('valeur')}")

            history_text = f"Admission pour : {admission['diagnosis']}"
            presentation = {
                "histoire_maladie": history_text,
                "symptomes_patient": symptomes_patient
            }
            
            meds_list = admission_meds.get(hadm_id, [])

            # Images
            images_ids = []
            if main_diag_id in self.images_by_disease:
                available_images = self.images_by_disease[main_diag_id]
                if available_images:
                    images_ids.append(random.choice(available_images))

            # --- VECTORISATION ---
            # On vectorise l'histoire clinique combinÃ©e aux symptÃ´mes principaux
            # C'est ce texte que le RAG utilisera pour trouver des cas similaires
            full_case_text = f"{history_text}. SymptÃ´mes biologiques notables : {', '.join(symptoms_text_list[:10])}"
            vector = embedding_service.get_text_embedding(full_case_text)

            new_case = models.ClinicalCase(
                code_fultang=case_code,
                pathologie_principale_id=main_diag_id,
                pathologies_secondaires_ids=secondary_diag_ids,
                presentation_clinique=presentation,
                donnees_paracliniques={"lab_results": lab_results_list},
                medicaments_prescrits=meds_list,
                images_associees_ids=images_ids,
                niveau_difficulte=2 + len(secondary_diag_ids),
                embedding_texte=vector # <-- AJOUT
            )
            new_cases.append(new_case)

        print(f"  -> {len(new_cases)} cas cliniques assemblÃ©s.")

        if new_cases:
            try:
                self.db.bulk_save_objects(new_cases)
                self.db.commit()
                print(f"âœ¨ Chargement de {len(new_cases)} nouveaux cas cliniques rÃ©ussi.")

                print("\n--- AperÃ§u des 10 premiers cas cliniques chargÃ©s ---")
                first_10_cases = self.db.query(models.ClinicalCase).order_by(models.ClinicalCase.id.desc()).limit(10).all()
                for i, case_from_db in enumerate(reversed(first_10_cases)):
                    disease_name = case_from_db.pathologie_principale.nom_fr if case_from_db.pathologie_principale else "Inconnue"
                    # VÃ©rifier si le vecteur est prÃ©sent (pour le log)
                    has_vector = "OUI" if case_from_db.embedding_texte is not None else "NON"
                    
                    print(f"\n[{i+1}] Cas: {case_from_db.code_fultang}")
                    print(f"    Pathologie: {disease_name}")
                    print(f"    Vecteur IA gÃ©nÃ©rÃ©: {has_vector}") # <-- Affichage validation

            except Exception as e:
                print(f"âŒ Erreur lors du chargement des cas : {e}")
                self.db.rollback()
        else:
            print("âœ¨ Aucun nouveau cas clinique Ã  ajouter.")

=== Fichier: ./datasets/assembler/__init__.py ===



=== Fichier: ./datasets/assembler/enrichment_engine.py ===



=== Fichier: ./datasets/base_integrator.py ===

from abc import ABC, abstractmethod
from sqlalchemy.orm import Session

class BaseIntegrator(ABC):
    """
    Classe de base abstraite (blueprint) pour tous les intÃ©grateurs de datasets.
    
    Elle impose une structure ETL (Extract, Transform, Load) cohÃ©rente pour
    garantir que chaque script d'importation fonctionne de la mÃªme maniÃ¨re.
    """

    def __init__(self, db_session: Session, dataset_path: str):
        """
        Initialise l'intÃ©grateur avec une session de base de donnÃ©es et le chemin
        vers le dataset.
        
        :param db_session: La session SQLAlchemy pour interagir avec la BDD.
        :param dataset_path: Le chemin vers le dossier ou le fichier du dataset.
        """
        self.db = db_session
        self.path = dataset_path
        print(f"--- Initialisation de {self.__class__.__name__} ---")
        print(f"Source des donnÃ©es : {self.path}")

    @abstractmethod
    def extract(self):
        """
        Ã‰tape d'Extraction (E) : Lire les donnÃ©es depuis la source.
        
        Cette mÃ©thode DOIT Ãªtre implÃ©mentÃ©e par chaque sous-classe.
        Elle doit retourner un itÃ©rateur qui produit des lots (chunks) de donnÃ©es
        (par exemple, un TextFileReader de pandas).
        """
        pass

    @abstractmethod
    def transform(self, data_chunk: any):
        """
        Ã‰tape de Transformation (T) : Nettoyer, mapper et prÃ©parer les donnÃ©es.
        
        Cette mÃ©thode DOIT Ãªtre implÃ©mentÃ©e par chaque sous-classe.
        Elle prend un lot de donnÃ©es extraites et retourne une liste d'objets
        SQLAlchemy prÃªts Ã  Ãªtre insÃ©rÃ©s.
        """
        pass

    @abstractmethod
    def load(self, transformed_data: list):
        """
        Ã‰tape de Chargement (L) : InsÃ©rer les donnÃ©es transformÃ©es en BDD.
        
        Cette mÃ©thode DOIT Ãªtre implÃ©mentÃ©e par chaque sous-classe.
        """
        pass

    def run(self):
        """
        Orchestre le processus ETL complet.
        
        Cette mÃ©thode est dÃ©jÃ  implÃ©mentÃ©e et ne devrait pas Ãªtre modifiÃ©e.
        Elle appelle successivement extract, transform, et load pour chaque lot.
        """
        print(f"\nğŸš€ DÃ©marrage du processus ETL pour {self.__class__.__name__}...")
        
        try:
            extracted_data_iterator = self.extract()
            
            total_items_loaded = 0
            chunk_count = 0
            for chunk in extracted_data_iterator:
                chunk_count += 1
                print(f"  [{chunk_count}] Extraction d'un lot de {len(chunk)} lignes.")
                
                transformed_chunk = self.transform(chunk)
                
                if transformed_chunk:
                    print(f"    -> Transformation rÃ©ussie : {len(transformed_chunk)} objets prÃªts Ã  Ãªtre chargÃ©s.")
                    self.load(transformed_chunk)
                    total_items_loaded += len(transformed_chunk)
                else:
                    print("    -> Aucun nouvel objet Ã  charger dans ce lot.")
            
            print(f"\nâœ¨ Processus ETL terminÃ©. {total_items_loaded} objets uniques chargÃ©s au total.")
        except FileNotFoundError:
            print(f"âŒ ERREUR: Le fichier ou dossier du dataset n'a pas Ã©tÃ© trouvÃ© Ã  l'emplacement : {self.path}")
        except Exception as e:
            print(f"âŒ ERREUR inattendue pendant le processus ETL : {e}")
            # En production, on utiliserait un logger plus sophistiquÃ©.

=== Fichier: ./testchat.py ===

import requests
import json
from datetime import datetime
import time
import uuid

# Configuration
BASE_URL = "https://expert-cmck.onrender.com"
API_BASE = f"{BASE_URL}/api/v1"
OUTPUT_FILE = f"test_simulation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    END = '\033[0m'

class SimulationTester:
    def __init__(self, filename):
        self.filename = filename
        self.file = open(filename, 'w', encoding='utf-8')
        self.test_count = 0
        self.success_count = 0
        self.fail_count = 0
        self.session_data = {}
        
    def write(self, message, color=None):
        """Ã‰crit dans le fichier et affiche Ã  l'Ã©cran"""
        self.file.write(message + '\n')
        self.file.flush()
        
        if color:
            print(f"{color}{message}{Colors.END}")
        else:
            print(message)
    
    def section(self, title):
        separator = '='*100
        self.write(f"\n{separator}")
        self.write(f"  {title}")
        self.write(separator)
    
    def test_header(self, method, endpoint, description):
        self.test_count += 1
        header = f"\n{'â”€'*100}\nTEST #{self.test_count}: {method} {endpoint}\nDescription: {description}\n{'â”€'*100}"
        self.write(header, Colors.CYAN)
    
    def log_request(self, method, url, data=None, params=None):
        self.write(f"\nğŸ“¤ REQUÃŠTE:", Colors.BLUE)
        self.write(f"   MÃ©thode: {method}")
        self.write(f"   URL: {url}")
        if params:
            self.write(f"   ParamÃ¨tres: {json.dumps(params, indent=6, ensure_ascii=False)}")
        if data:
            self.write(f"   DonnÃ©es envoyÃ©es:")
            self.write(json.dumps(data, indent=6, ensure_ascii=False))
    
    def log_response(self, response, show_full=True):
        self.write(f"\nğŸ“¥ RÃ‰PONSE:", Colors.BLUE)
        self.write(f"   Status Code: {response.status_code}")
        self.write(f"   Temps de rÃ©ponse: {response.elapsed.total_seconds():.2f}s")
        
        try:
            data = response.json()
            if show_full:
                self.write(f"   DonnÃ©es reÃ§ues:")
                self.write(json.dumps(data, indent=6, ensure_ascii=False))
            else:
                if isinstance(data, list):
                    self.write(f"   Type: Liste de {len(data)} Ã©lÃ©ments")
                    if len(data) > 0:
                        self.write(f"   Premier Ã©lÃ©ment:")
                        self.write(json.dumps(data[0], indent=6, ensure_ascii=False))
        except:
            self.write(f"   RÃ©ponse texte: {response.text[:1000]}")
    
    def mark_success(self, message=""):
        self.success_count += 1
        self.write(f"\nâœ… SUCCÃˆS: {message}", Colors.GREEN)
    
    def mark_failure(self, message=""):
        self.fail_count += 1
        self.write(f"\nâŒ Ã‰CHEC: {message}", Colors.RED)
    
    def summary(self):
        self.section("RÃ‰SUMÃ‰ DES TESTS DE SIMULATION")
        self.write(f"Total de tests: {self.test_count}")
        self.write(f"SuccÃ¨s: {self.success_count}", Colors.GREEN)
        self.write(f"Ã‰checs: {self.fail_count}", Colors.RED)
        self.write(f"Taux de rÃ©ussite: {(self.success_count/self.test_count*100):.1f}%" if self.test_count > 0 else "N/A")
    
    def close(self):
        self.file.close()

# Instance globale
tester = None

# =============================================================================
# TESTS DE SIMULATION - WORKFLOW COMPLET
# =============================================================================

def test_start_simulation_session():
    """DÃ©marrer une nouvelle session de simulation"""
    tester.test_header("POST", "/api/v1/simulation/sessions/start", 
                      "DÃ©marrer une session de simulation")
    
    data = {
        "learner_id": 1,  # ID d'un apprenant existant
        "category": "Infectiologie"
    }
    
    tester.log_request("POST", f"{API_BASE}/simulation/sessions/start", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/start", 
                               json=data, timeout=60)
        tester.log_response(response)
        
        if response.status_code == 201:
            result = response.json()
            tester.session_data['session_id'] = result['session_id']
            tester.session_data['session_type'] = result.get('session_type')
            tester.session_data['clinical_case'] = result.get('clinical_case', {})
            
            tester.mark_success(f"Session crÃ©Ã©e avec ID: {result['session_id']}, Type: {result.get('session_type')}")
            
            # Afficher les dÃ©tails du cas clinique
            if 'clinical_case' in result:
                case = result['clinical_case']
                tester.write(f"\nğŸ“‹ CAS CLINIQUE ASSIGNÃ‰:", Colors.MAGENTA)
                tester.write(f"   Code: {case.get('code_fultang')}")
                tester.write(f"   Niveau difficultÃ©: {case.get('niveau_difficulte')}")
                tester.write(f"   Pathologie: {case.get('pathologie_principale', {}).get('nom_fr')}")
                
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 201")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_chat_message_1_greeting():
    """Message 1: Apprenant salue le patient + RÃ©ponse du patient"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    clinical_case = tester.session_data.get('clinical_case', {})
    
    tester.test_header("POST", f"/api/v1/chat/sessions/{session_id}/messages", 
                      "Message 1: Ã‰change de salutations")
    
    # 1. MESSAGE DE L'APPRENANT
    apprenant_data = {
        "sender": "Apprenant",
        "content": "Bonjour Monsieur/Madame, je suis l'Ã©tudiant en mÃ©decine qui va vous consulter aujourd'hui. Comment puis-je vous aider ?",
        "message_metadata": {
            "message_type": "greeting",
            "consultation_phase": "accueil"
        }
    }
    
    try:
        tester.write(f"\nğŸ’¬ Ã‰CHANGE #1:", Colors.MAGENTA)
        tester.write(f"   ğŸ‘¨â€âš•ï¸ Apprenant: {apprenant_data['content']}", Colors.CYAN)
        
        # Envoyer message apprenant
        response = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                               json=apprenant_data, timeout=30)
        
        if response.status_code != 201:
            tester.mark_failure(f"Ã‰chec envoi message apprenant: {response.status_code}")
            return False
        
        time.sleep(0.5)
        
        # 2. RÃ‰PONSE DU PATIENT (GÃ‰NÃ‰RÃ‰E PAR LE TEST - SIMULANT L'IA)
        # RÃ©cupÃ©rer les symptÃ´mes du cas clinique pour une rÃ©ponse cohÃ©rente
        histoire = clinical_case.get('presentation_clinique', {}).get('histoire_maladie', '')
        
        patient_response = f"Bonjour docteur. Je ne me sens pas bien depuis quelques jours. {histoire}"
        
        patient_data = {
            "sender": "Patient",
            "content": patient_response,
            "message_metadata": {
                "message_type": "response",
                "consultation_phase": "accueil",
                "generated_by": "test_script"  # Pour traÃ§abilitÃ©
            }
        }
        
        tester.write(f"   ğŸ¤’ Patient: {patient_data['content']}", Colors.GREEN)
        
        # Envoyer rÃ©ponse patient
        patient_post = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                                    json=patient_data, timeout=30)
        
        if patient_post.status_code != 201:
            tester.mark_failure(f"Ã‰chec envoi rÃ©ponse patient: {patient_post.status_code}")
            return False
        
        tester.mark_success("Dialogue initial Ã©tabli (Apprenant + Patient)")
        return True
        
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_chat_message_2_chief_complaint():
    """Message 2: Question sur le motif de consultation + RÃ©ponse patient"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    clinical_case = tester.session_data.get('clinical_case', {})
    
    tester.test_header("POST", f"/api/v1/chat/sessions/{session_id}/messages", 
                      "Message 2: Motif de consultation")
    
    # 1. QUESTION DE L'APPRENANT
    apprenant_data = {
        "sender": "Apprenant",
        "content": "Qu'est-ce qui vous amÃ¨ne aujourd'hui ? Pouvez-vous me dÃ©crire ce que vous ressentez ?",
        "message_metadata": {
            "message_type": "question",
            "consultation_phase": "anamnese",
            "question_category": "chief_complaint"
        }
    }
    
    try:
        tester.write(f"\nğŸ’¬ Ã‰CHANGE #2:", Colors.MAGENTA)
        tester.write(f"   ğŸ‘¨â€âš•ï¸ Apprenant: {apprenant_data['content']}", Colors.CYAN)
        
        response = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                               json=apprenant_data, timeout=30)
        
        if response.status_code != 201:
            tester.mark_failure(f"Ã‰chec envoi question: {response.status_code}")
            return False
        
        time.sleep(0.5)
        
        # 2. RÃ‰PONSE DU PATIENT (BASÃ‰E SUR LE CAS CLINIQUE)
        symptomes = clinical_case.get('presentation_clinique', {}).get('symptomes_patient', [])
        
        # Construire une rÃ©ponse rÃ©aliste
        patient_response = "VoilÃ , j'ai de la fiÃ¨vre depuis 2-3 jours, autour de 38-39Â°C. "
        
        # Ajouter des symptÃ´mes du cas
        if len(symptomes) > 0:
            patient_response += "Je me sens trÃ¨s fatiguÃ© et j'ai des douleurs. "
        
        patient_response += "C'est pour Ã§a que je suis venu vous consulter."
        
        patient_data = {
            "sender": "Patient",
            "content": patient_response,
            "message_metadata": {
                "message_type": "response",
                "consultation_phase": "anamnese",
                "generated_by": "test_script"
            }
        }
        
        tester.write(f"   ğŸ¤’ Patient: {patient_data['content']}", Colors.GREEN)
        
        patient_post = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                                    json=patient_data, timeout=30)
        
        if patient_post.status_code != 201:
            tester.mark_failure(f"Ã‰chec rÃ©ponse patient: {patient_post.status_code}")
            return False
        
        tester.mark_success("Motif de consultation exprimÃ© par le patient")
        return True
        
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_chat_message_3_symptom_details():
    """Message 3: Approfondissement des symptÃ´mes + RÃ©ponse patient"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    
    tester.test_header("POST", f"/api/v1/chat/sessions/{session_id}/messages", 
                      "Message 3: CaractÃ©risation des symptÃ´mes")
    
    # 1. QUESTIONS DÃ‰TAILLÃ‰ES DE L'APPRENANT
    apprenant_data = {
        "sender": "Apprenant",
        "content": "Depuis quand avez-vous ces symptÃ´mes ? Est-ce que la douleur est constante ou intermittente ? Y a-t-il quelque chose qui l'aggrave ou la soulage ?",
        "message_metadata": {
            "message_type": "question",
            "consultation_phase": "anamnese",
            "question_category": "symptom_characterization"
        }
    }
    
    try:
        tester.write(f"\nğŸ’¬ Ã‰CHANGE #3:", Colors.MAGENTA)
        tester.write(f"   ğŸ‘¨â€âš•ï¸ Apprenant: {apprenant_data['content']}", Colors.CYAN)
        
        response = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                               json=apprenant_data, timeout=30)
        
        if response.status_code != 201:
            tester.mark_failure(f"Ã‰chec: {response.status_code}")
            return False
        
        time.sleep(0.5)
        
        # 2. RÃ‰PONSE DÃ‰TAILLÃ‰E DU PATIENT
        patient_response = """Ã‡a a commencÃ© il y a 3 jours environ. Au dÃ©but c'Ã©tait juste une lÃ©gÃ¨re gÃªne, 
mais depuis hier Ã§a s'est aggravÃ©. La douleur est plutÃ´t constante, mais elle augmente quand je bouge 
ou quand j'urine. Le paracÃ©tamol que j'ai pris ne m'a pas vraiment soulagÃ©."""
        
        patient_data = {
            "sender": "Patient",
            "content": patient_response,
            "message_metadata": {
                "message_type": "response",
                "consultation_phase": "anamnese",
                "details_provided": ["chronologie", "caractere", "facteurs_aggravants", "traitement_essaye"],
                "generated_by": "test_script"
            }
        }
        
        tester.write(f"   ğŸ¤’ Patient: {patient_data['content']}", Colors.GREEN)
        
        patient_post = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                                    json=patient_data, timeout=30)
        
        if patient_post.status_code != 201:
            tester.mark_failure(f"Ã‰chec rÃ©ponse patient: {patient_post.status_code}")
            return False
        
        tester.mark_success("AnamnÃ¨se dÃ©taillÃ©e obtenue")
        return True
        
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_action_1_vital_signs():
    """Action 1: Demande des paramÃ¨tres vitaux"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/actions", 
                      "Action 1: Prise des paramÃ¨tres vitaux")
    
    data = {
        "action_type": "parametres_vitaux",
        "action_name": "Prise des constantes",
        "justification": "Ã‰valuation de l'Ã©tat gÃ©nÃ©ral du patient et recherche de signes de gravitÃ© avant tout examen approfondi"
    }
    
    tester.log_request("POST", f"{API_BASE}/simulation/sessions/{session_id}/actions", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/{session_id}/actions", 
                               json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.write(f"\nğŸ”¬ RÃ‰SULTATS:", Colors.MAGENTA)
            if 'result' in result:
                tester.write(json.dumps(result['result'], indent=6, ensure_ascii=False))
            tester.mark_success("ParamÃ¨tres vitaux obtenus avec feedback")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_chat_message_4_medical_history():
    """Message 4: Questions sur les antÃ©cÃ©dents + RÃ©ponse patient"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    clinical_case = tester.session_data.get('clinical_case', {})
    
    tester.test_header("POST", f"/api/v1/chat/sessions/{session_id}/messages", 
                      "Message 4: AntÃ©cÃ©dents mÃ©dicaux")
    
    # 1. QUESTION ANTÃ‰CÃ‰DENTS
    apprenant_data = {
        "sender": "Apprenant",
        "content": "Avez-vous des antÃ©cÃ©dents mÃ©dicaux particuliers ? Prenez-vous des mÃ©dicaments rÃ©guliÃ¨rement ? Y a-t-il des maladies dans votre famille ?",
        "message_metadata": {
            "message_type": "question",
            "consultation_phase": "anamnese",
            "question_category": "medical_history"
        }
    }
    
    try:
        tester.write(f"\nğŸ’¬ Ã‰CHANGE #4:", Colors.MAGENTA)
        tester.write(f"   ğŸ‘¨â€âš•ï¸ Apprenant: {apprenant_data['content']}", Colors.CYAN)
        
        response = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                               json=apprenant_data, timeout=30)
        
        if response.status_code != 201:
            tester.mark_failure(f"Ã‰chec: {response.status_code}")
            return False
        
        time.sleep(0.5)
        
        # 2. RÃ‰PONSE DU PATIENT (avec pathologies secondaires si disponibles)
        pathologies_secondaires = clinical_case.get('pathologies_secondaires', [])
        
        if len(pathologies_secondaires) > 0:
            patient_response = """J'ai du diabÃ¨te depuis 5 ans, je prends du Metformine. 
J'ai aussi de l'hypertension, contrÃ´lÃ©e avec de l'Amlodipine. Mon pÃ¨re avait des problÃ¨mes cardiaques."""
        else:
            patient_response = """Non, je n'ai pas d'antÃ©cÃ©dents particuliers. Je ne prends pas de mÃ©dicaments 
rÃ©guliÃ¨rement, juste du paracÃ©tamol quand j'ai mal. Dans ma famille, il n'y a rien de notable."""
        
        patient_data = {
            "sender": "Patient",
            "content": patient_response,
            "message_metadata": {
                "message_type": "response",
                "consultation_phase": "anamnese",
                "antecedents_revealed": True,
                "generated_by": "test_script"
            }
        }
        
        tester.write(f"   ğŸ¤’ Patient: {patient_data['content']}", Colors.GREEN)
        
        patient_post = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                                    json=patient_data, timeout=30)
        
        if patient_post.status_code != 201:
            tester.mark_failure(f"Ã‰chec rÃ©ponse patient: {patient_post.status_code}")
            return False
        
        tester.mark_success("AntÃ©cÃ©dents mÃ©dicaux collectÃ©s")
        return True
        
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_action_2_blood_test():
    """Action 2: Demande d'examen sanguin"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/actions", 
                      "Action 2: Demande d'examen sanguin (NFS)")
    
    data = {
        "action_type": "examen_complementaire",
        "action_name": "NumÃ©ration Formule Sanguine (NFS)",
        "justification": "Suspicion d'une infection compte tenu des symptÃ´mes prÃ©sentÃ©s. La NFS permettra d'Ã©valuer la prÃ©sence d'une inflammation (augmentation des GB) et de rechercher une anÃ©mie"
    }
    
    tester.log_request("POST", f"{API_BASE}/simulation/sessions/{session_id}/actions", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/{session_id}/actions", 
                               json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.write(f"\nğŸ”¬ RÃ‰SULTATS EXAMEN:", Colors.MAGENTA)
            if 'result' in result:
                tester.write(json.dumps(result['result'], indent=6, ensure_ascii=False))
            tester.mark_success("RÃ©sultats de NFS obtenus avec feedback")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_action_3_inappropriate_exam():
    """Action 3: Demande d'examen inappropriÃ© (pour tester le feedback nÃ©gatif)"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/actions", 
                      "Action 3: Demande d'examen inappropriÃ© (IRM cÃ©rÃ©brale)")
    
    data = {
        "action_type": "examen_complementaire",
        "action_name": "IRM cÃ©rÃ©brale",
        "justification": "Pour vÃ©rifier"
    }
    
    tester.log_request("POST", f"{API_BASE}/simulation/sessions/{session_id}/actions", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/{session_id}/actions", 
                               json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.write(f"\nâš ï¸  FEEDBACK SUR ACTION:", Colors.YELLOW)
            if 'feedback' in result:
                tester.write(f"   {result['feedback']}")
            tester.mark_success("Feedback nÃ©gatif reÃ§u pour examen inappropriÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_request_hint_1():
    """Demande d'indice simple"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/request-hint", 
                      "Demande d'indice (type: simple)")
    
    tester.log_request("POST", f"{API_BASE}/simulation/sessions/{session_id}/request-hint")
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/{session_id}/request-hint", 
                               timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.write(f"\nğŸ’¡ INDICE REÃ‡U:", Colors.MAGENTA)
            tester.write(f"   Type: {result.get('hint_type')}")
            tester.write(f"   Contenu: {result.get('content')}")
            tester.mark_success("Indice reÃ§u avec succÃ¨s")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_action_4_consult_image():
    """Action 4: Consultation d'image mÃ©dicale (si disponible)"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    # VÃ©rifier si le cas clinique a des images
    clinical_case = tester.session_data.get('clinical_case', {})
    has_images = len(clinical_case.get('images_associees_ids', [])) > 0
    
    if not has_images:
        tester.write("â„¹ï¸  Aucune image disponible pour ce cas, test ignorÃ©", Colors.BLUE)
        return True
    
    session_id = tester.session_data['session_id']
    tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/actions", 
                      "Action 4: Consultation de l'image mÃ©dicale")
    
    data = {
        "action_type": "consulter_image",
        "action_name": "Consulter radiographie/Ã©chographie",
        "justification": "Analyse des rÃ©sultats d'imagerie pour complÃ©ter le diagnostic clinique"
    }
    
    tester.log_request("POST", f"{API_BASE}/simulation/sessions/{session_id}/actions", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/{session_id}/actions", 
                               json=data, timeout=30)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            tester.mark_success("Image consultÃ©e avec feedback")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_chat_message_5_summary():
    """Message 5: RÃ©sumÃ© de la consultation + Confirmation patient"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    
    tester.test_header("POST", f"/api/v1/chat/sessions/{session_id}/messages", 
                      "Message 5: SynthÃ¨se et confirmation")
    
    # 1. SYNTHÃˆSE DE L'APPRENANT
    apprenant_data = {
        "sender": "Apprenant",
        "content": "D'accord, laissez-moi rÃ©sumer. Vous prÃ©sentez des symptÃ´mes depuis 3 jours, avec de la fiÃ¨vre et des douleurs qui s'aggravent. Les examens montrent une inflammation. Je vais maintenant Ã©tablir mon diagnostic.",
        "message_metadata": {
            "message_type": "summary",
            "consultation_phase": "synthese"
        }
    }
    
    try:
        tester.write(f"\nğŸ’¬ Ã‰CHANGE #5:", Colors.MAGENTA)
        tester.write(f"   ğŸ‘¨â€âš•ï¸ Apprenant: {apprenant_data['content']}", Colors.CYAN)
        
        response = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                               json=apprenant_data, timeout=30)
        
        if response.status_code != 201:
            tester.mark_failure(f"Ã‰chec: {response.status_code}")
            return False
        
        time.sleep(0.5)
        
        # 2. CONFIRMATION DU PATIENT
        patient_response = "Oui c'est exactement Ã§a. J'espÃ¨re que vous pourrez m'aider."
        
        patient_data = {
            "sender": "Patient",
            "content": patient_response,
            "message_metadata": {
                "message_type": "confirmation",
                "consultation_phase": "synthese",
                "generated_by": "test_script"
            }
        }
        
        tester.write(f"   ğŸ¤’ Patient: {patient_data['content']}", Colors.GREEN)
        
        patient_post = requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                                    json=patient_data, timeout=30)
        
        if patient_post.status_code != 201:
            tester.mark_failure(f"Ã‰chec rÃ©ponse patient: {patient_post.status_code}")
            return False
        
        tester.mark_success("SynthÃ¨se validÃ©e par le patient - PrÃªt pour diagnostic")
        return True
        
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_get_chat_history():
    """RÃ©cupÃ©rer l'historique complet du chat"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    tester.test_header("GET", f"/api/v1/chat/sessions/{session_id}/messages", 
                      "RÃ©cupÃ©ration de l'historique complet du chat")
    
    tester.log_request("GET", f"{API_BASE}/chat/sessions/{session_id}/messages")
    
    try:
        response = requests.get(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                              timeout=30)
        tester.log_response(response, show_full=False)
        
        if response.status_code == 200:
            data = response.json()
            tester.write(f"\nğŸ’¬ HISTORIQUE COMPLET DE LA CONSULTATION:", Colors.MAGENTA)
            tester.write(f"   Nombre total de messages: {len(data)}")
            
            # Compter les messages par type
            apprenant_msgs = [m for m in data if m.get('sender') == 'Apprenant']
            patient_msgs = [m for m in data if m.get('sender') == 'Patient']
            
            tester.write(f"   ğŸ‘¨â€âš•ï¸ Messages de l'apprenant: {len(apprenant_msgs)}", Colors.CYAN)
            tester.write(f"   ğŸ¤’ Messages du patient: {len(patient_msgs)}", Colors.GREEN)
            
            # Afficher toute la conversation
            tester.write(f"\nğŸ“œ TRANSCRIPTION COMPLÃˆTE:", Colors.BLUE)
            for i, msg in enumerate(data, 1):
                sender_icon = "ğŸ‘¨â€âš•ï¸" if msg['sender'] == "Apprenant" else "ğŸ¤’"
                sender_color = Colors.CYAN if msg['sender'] == "Apprenant" else Colors.GREEN
                timestamp = msg.get('timestamp', 'N/A')
                content = msg['content'][:200] + "..." if len(msg['content']) > 200 else msg['content']
                
                tester.write(f"\n   [{i}] {sender_icon} {msg['sender']} ({timestamp}):", sender_color)
                tester.write(f"       {content}")
            
            # VÃ©rification critique
            if len(patient_msgs) == 0:
                tester.write(f"\nâš ï¸  PROBLÃˆME CRITIQUE: Le patient virtuel n'a pas rÃ©pondu aux questions!", Colors.RED)
                tester.write(f"      Cela rend la simulation inutilisable.", Colors.RED)
                tester.mark_failure(f"0 rÃ©ponses patient dÃ©tectÃ©es sur {len(apprenant_msgs)} questions")
                return False
            elif len(patient_msgs) < len(apprenant_msgs):
                ratio = len(patient_msgs) / len(apprenant_msgs) * 100
                tester.write(f"\nâš ï¸  ATTENTION: Seulement {ratio:.0f}% des questions ont reÃ§u une rÃ©ponse", Colors.YELLOW)
                tester.mark_success(f"Historique rÃ©cupÃ©rÃ©: {len(data)} messages (conversation partielle)")
            else:
                tester.mark_success(f"Historique rÃ©cupÃ©rÃ©: {len(data)} messages (conversation complÃ¨te)")
            
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_submit_diagnosis_correct():
    """Soumission d'un diagnostic correct"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    clinical_case = tester.session_data.get('clinical_case', {})
    
    # RÃ©cupÃ©rer la pathologie principale du cas
    pathologie_id = clinical_case.get('pathologie_principale_id')
    
    if not pathologie_id:
        tester.write("âš ï¸  Pas de pathologie principale dans le cas, test ignorÃ©", Colors.YELLOW)
        return False
    
    tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/submit", 
                      "Soumission du diagnostic final (correct)")
    
    # Extraire les IDs des mÃ©dicaments (pas les objets complets)
    medicaments_prescrits = clinical_case.get('medicaments_prescrits', [])
    medication_ids = []
    
    if medicaments_prescrits:
        for med in medicaments_prescrits[:3]:  # Prendre les 3 premiers
            if isinstance(med, dict) and 'medicament_id' in med:
                medication_ids.append(med['medicament_id'])
            elif isinstance(med, int):
                medication_ids.append(med)
    
    # DonnÃ©es de soumission avec format CORRECT (liste d'IDs uniquement)
    data = {
        "diagnosed_pathology_id": pathologie_id,
        "prescribed_medication_ids": medication_ids  # âœ… LISTE D'ENTIERS UNIQUEMENT
    }
    
    tester.write(f"\nğŸ“‹ DIAGNOSTIC SOUMIS:", Colors.BLUE)
    tester.write(f"   Pathologie ID: {pathologie_id}")
    tester.write(f"   MÃ©dicaments IDs: {medication_ids}")
    
    tester.log_request("POST", f"{API_BASE}/simulation/sessions/{session_id}/submit", data=data)
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/{session_id}/submit", 
                               json=data, timeout=60)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            
            tester.write(f"\nğŸ“Š Ã‰VALUATION FINALE:", Colors.MAGENTA)
            evaluation = result.get('evaluation', {})
            
            score_diagnostic = evaluation.get('score_diagnostic', 0)
            score_therapeutique = evaluation.get('score_therapeutique', 0)
            score_demarche = evaluation.get('score_demarche', 0)
            score_total = evaluation.get('score_total', 0)
            
            # Affichage avec barre de progression visuelle
            def progress_bar(score, max_score=10):
                filled = int((score / max_score) * 20)
                bar = "â–ˆ" * filled + "â–‘" * (20 - filled)
                return f"[{bar}] {score}/{max_score}"
            
            tester.write(f"   ğŸ¯ Score Diagnostic:      {progress_bar(score_diagnostic)}", 
                        Colors.GREEN if score_diagnostic >= 8 else Colors.YELLOW)
            tester.write(f"   ğŸ’Š Score ThÃ©rapeutique:   {progress_bar(score_therapeutique)}", 
                        Colors.GREEN if score_therapeutique >= 8 else Colors.YELLOW)
            tester.write(f"   ğŸ©º Score DÃ©marche:        {progress_bar(score_demarche)}", 
                        Colors.GREEN if score_demarche >= 8 else Colors.YELLOW)
            
            tester.write(f"\n   â­ SCORE TOTAL: {score_total}/30", 
                        Colors.GREEN if score_total >= 24 else Colors.YELLOW if score_total >= 18 else Colors.RED)
            
            tester.write(f"\nğŸ“ FEEDBACK GLOBAL:", Colors.CYAN)
            feedback_lines = result.get('feedback_global', '').split('\n')
            for line in feedback_lines[:5]:  # Premiers 5 lignes
                if line.strip():
                    tester.write(f"   {line}")
            
            tester.write(f"\nğŸ¯ RECOMMANDATION:", Colors.BLUE)
            recommendation = result.get('recommendation_next_step', '')
            tester.write(f"   {recommendation}")
            
            # DÃ©terminer le niveau de rÃ©ussite
            if score_total >= 24:
                tester.mark_success(f"ğŸ‰ Excellent diagnostic! Score: {score_total}/30")
            elif score_total >= 18:
                tester.mark_success(f"âœ… Bon diagnostic. Score: {score_total}/30")
            else:
                tester.mark_success(f"âš ï¸  Diagnostic soumis mais score faible: {score_total}/30")
            
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_start_and_submit_wrong_diagnosis():
    """ScÃ©nario complet avec diagnostic incorrect"""
    tester.section("SCÃ‰NARIO 2: SESSION AVEC DIAGNOSTIC INCORRECT")
    
    # DÃ©marrer une nouvelle session
    tester.test_header("POST", "/api/v1/simulation/sessions/start", 
                      "Nouvelle session pour test diagnostic incorrect")
    
    data = {
        "learner_id": 1,
        "category": "Cardiologie"
    }
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/start", 
                               json=data, timeout=60)
        
        if response.status_code != 201:
            tester.mark_failure("Impossible de dÃ©marrer la session")
            return False
        
        result = response.json()
        session_id = result['session_id']
        clinical_case = result.get('clinical_case', {})
        
        tester.mark_success(f"Session crÃ©Ã©e: {session_id}")
        
        # Quelques messages rapides
        messages = [
            "Bonjour, que puis-je faire pour vous ?",
            "Depuis combien de temps avez-vous ces symptÃ´mes ?"
        ]
        
        for msg in messages:
            msg_data = {
                "sender": "Apprenant",
                "content": msg,
                "message_metadata": {"type": "question"}
            }
            requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                        json=msg_data, timeout=30)
        
        # Soumettre un MAUVAIS diagnostic
        tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/submit", 
                          "Soumission d'un diagnostic INCORRECT")
        
        # Prendre une pathologie diffÃ©rente de celle du cas
        wrong_pathology_id = clinical_case.get('pathologie_principale_id', 1) + 100
        
        wrong_data = {
            "diagnosed_pathology_id": wrong_pathology_id,
            "prescribed_medication_ids": []
        }
        
        tester.log_request("POST", f"{API_BASE}/simulation/sessions/{session_id}/submit", 
                         data=wrong_data)
        
        response = requests.post(f"{API_BASE}/simulation/sessions/{session_id}/submit", 
                               json=wrong_data, timeout=60)
        tester.log_response(response)
        
        if response.status_code == 200:
            result = response.json()
            evaluation = result.get('evaluation', {})
            
            tester.write(f"\nğŸ“Š Ã‰VALUATION (DIAGNOSTIC INCORRECT):", Colors.YELLOW)
            tester.write(f"   Score Diagnostic: {evaluation.get('score_diagnostic')}/10")
            tester.write(f"   Score ThÃ©rapeutique: {evaluation.get('score_therapeutique')}/10")
            tester.write(f"   Score DÃ©marche: {evaluation.get('score_demarche')}/10")
            tester.write(f"   SCORE TOTAL: {evaluation.get('score_total')}/30")
            
            tester.mark_success("Diagnostic incorrect dÃ©tectÃ© avec feedback appropriÃ©")
            return True
        else:
            tester.mark_failure(f"Code {response.status_code} attendu 200")
            return False
            
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_multiple_hint_requests():
    """Test de demandes multiples d'indices"""
    if 'session_id' not in tester.session_data:
        tester.write("âš ï¸  Aucune session active, test ignorÃ©", Colors.YELLOW)
        return False
    
    session_id = tester.session_data['session_id']
    tester.section("TEST DES DIFFÃ‰RENTS TYPES D'INDICES")
    
    hint_count = 0
    for i in range(3):  # Demander 3 indices
        tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/request-hint", 
                          f"Demande d'indice #{i+1}")
        
        try:
            response = requests.post(f"{API_BASE}/simulation/sessions/{session_id}/request-hint", 
                                   timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                hint_count += 1
                
                tester.write(f"\nğŸ’¡ INDICE #{hint_count}:", Colors.CYAN)
                tester.write(f"   Type: {result.get('hint_type')}")
                tester.write(f"   Contenu: {result.get('content')[:200]}...")
                
                tester.mark_success(f"Indice #{hint_count} reÃ§u")
                time.sleep(1)  # Petite pause entre les requÃªtes
            else:
                tester.mark_failure(f"Ã‰chec demande indice #{i+1}")
                
        except Exception as e:
            tester.mark_failure(f"Exception: {str(e)}")
    
    return hint_count > 0


def test_session_formative_evaluation():
    """Test d'une session d'Ã©valuation formative complÃ¨te"""
    tester.section("SCÃ‰NARIO 3: SESSION D'Ã‰VALUATION FORMATIVE")
    
    tester.test_header("POST", "/api/v1/simulation/sessions/start", 
                      "DÃ©marrage session formative")
    
    data = {
        "learner_id": 1,
        "category": "PÃ©diatrie"
    }
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/start", 
                               json=data, timeout=60)
        
        if response.status_code != 201:
            tester.mark_failure("Impossible de dÃ©marrer la session formative")
            return False
        
        result = response.json()
        session_id = result['session_id']
        session_type = result.get('session_type')
        
        tester.write(f"\nğŸ“š TYPE DE SESSION: {session_type}", Colors.MAGENTA)
        tester.mark_success(f"Session formative crÃ©Ã©e: {session_id}")
        
        # Simuler une consultation formative complÃ¨te
        
        # 1. Messages initiaux
        consultation_flow = [
            ("Bonjour, je suis l'Ã©tudiant. Racontez-moi ce qui vous amÃ¨ne.", "greeting"),
            ("Depuis quand prÃ©sentez-vous ces symptÃ´mes ?", "timeline"),
            ("Avez-vous des antÃ©cÃ©dents mÃ©dicaux ?", "history"),
        ]
        
        for content, phase in consultation_flow:
            msg_data = {
                "sender": "Apprenant",
                "content": content,
                "message_metadata": {"phase": phase}
            }
            requests.post(f"{API_BASE}/chat/sessions/{session_id}/messages", 
                        json=msg_data, timeout=30)
            time.sleep(0.5)
        
        # 2. Actions cliniques
        actions = [
            {
                "action_type": "parametres_vitaux",
                "action_name": "Constantes vitales",
                "justification": "Ã‰valuation initiale de l'Ã©tat du patient"
            },
            {
                "action_type": "examen_complementaire",
                "action_name": "CRP et NFS",
                "justification": "Recherche de syndrome inflammatoire"
            }
        ]
        
        for action in actions:
            action_response = requests.post(
                f"{API_BASE}/simulation/sessions/{session_id}/actions", 
                json=action, 
                timeout=30
            )
            if action_response.status_code == 200:
                result = action_response.json()
                tester.write(f"   Action '{action['action_name']}': {result.get('feedback', 'OK')[:100]}", 
                           Colors.GREEN)
        
        # 3. Demander un indice
        hint_response = requests.post(
            f"{API_BASE}/simulation/sessions/{session_id}/request-hint", 
            timeout=30
        )
        if hint_response.status_code == 200:
            hint = hint_response.json()
            tester.write(f"\nğŸ’¡ Indice formatif reÃ§u: {hint.get('hint_type')}", Colors.CYAN)
        
        # 4. Soumettre diagnostic
        submit_data = {
            "diagnosed_pathology_id": result.get('clinical_case', {}).get('pathologie_principale_id', 1),
            "prescribed_medication_ids": []
        }
        
        submit_response = requests.post(
            f"{API_BASE}/simulation/sessions/{session_id}/submit",
            json=submit_data,
            timeout=60
        )
        
        if submit_response.status_code == 200:
            evaluation = submit_response.json()
            scores = evaluation.get('evaluation', {})
            
            tester.write(f"\nğŸ“Š Ã‰VALUATION FORMATIVE:", Colors.MAGENTA)
            tester.write(f"   Diagnostic: {scores.get('score_diagnostic')}/10")
            tester.write(f"   ThÃ©rapeutique: {scores.get('score_therapeutique')}/10")
            tester.write(f"   DÃ©marche: {scores.get('score_demarche')}/10")
            tester.write(f"   Total: {scores.get('score_total')}/30")
            
            tester.mark_success("Session formative complÃ©tÃ©e avec Ã©valuation dÃ©taillÃ©e")
            return True
        else:
            tester.mark_failure("Ã‰chec soumission formative")
            return False
            
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False


def test_edge_cases():
    """Test de cas limites et gestion d'erreurs"""
    tester.section("TESTS DE CAS LIMITES ET GESTION D'ERREURS")
    
    # Test 1: Session inexistante
    tester.test_header("POST", "/api/v1/chat/sessions/00000000-0000-0000-0000-000000000000/messages", 
                      "Test avec session_id invalide")
    
    invalid_session_data = {
        "sender": "Apprenant",
        "content": "Test",
        "message_metadata": {}
    }
    
    try:
        response = requests.post(
            f"{API_BASE}/chat/sessions/00000000-0000-0000-0000-000000000000/messages",
            json=invalid_session_data,
            timeout=30
        )
        
        if response.status_code == 404:
            tester.mark_success("Erreur 404 correctement retournÃ©e pour session invalide")
        else:
            tester.mark_failure(f"Code {response.status_code} au lieu de 404")
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
    
    # Test 2: Action sans justification
    if 'session_id' in tester.session_data:
        session_id = tester.session_data['session_id']
        
        tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/actions", 
                          "Test action sans justification")
        
        no_justification_data = {
            "action_type": "examen_complementaire",
            "action_name": "Scanner thoracique",
            "justification": ""  # Justification vide
        }
        
        try:
            response = requests.post(
                f"{API_BASE}/simulation/sessions/{session_id}/actions",
                json=no_justification_data,
                timeout=30
            )
            
            if response.status_code in [200, 422]:  # 422 pour validation error
                result = response.json()
                if 'feedback' in result:
                    tester.write(f"   Feedback: {result['feedback'][:200]}", Colors.YELLOW)
                tester.mark_success("Gestion appropriÃ©e de la justification manquante")
            else:
                tester.mark_failure(f"Code inattendu: {response.status_code}")
        except Exception as e:
            tester.mark_failure(f"Exception: {str(e)}")
    
    # Test 3: Soumission sans diagnostic
    if 'session_id' in tester.session_data:
        session_id = tester.session_data['session_id']
        
        tester.test_header("POST", f"/api/v1/simulation/sessions/{session_id}/submit", 
                          "Test soumission sans pathologie")
        
        incomplete_data = {
            "diagnosed_pathology_id": None,
            "prescribed_medication_ids": []
        }
        
        try:
            response = requests.post(
                f"{API_BASE}/simulation/sessions/{session_id}/submit",
                json=incomplete_data,
                timeout=30
            )
            
            if response.status_code in [400, 422]:
                tester.mark_success("Validation correcte des donnÃ©es incomplÃ¨tes")
            else:
                tester.mark_failure(f"Code {response.status_code} au lieu de 400/422")
        except Exception as e:
            tester.mark_failure(f"Exception: {str(e)}")


# =============================================================================
# FONCTION PRINCIPALE
# =============================================================================

def main():
    global tester
    tester = SimulationTester(OUTPUT_FILE)
    
    tester.section("TEST COMPLET DES ROUTES DE SIMULATION STI MEDICAL")
    tester.write(f"URL: {BASE_URL}")
    tester.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    tester.write(f"Fichier de sortie: {OUTPUT_FILE}")
    
    print(f"\n{Colors.CYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print(f"â•‘  TEST DES ROUTES DE SIMULATION - WORKFLOW COMPLET             â•‘")
    print(f"â•‘  Simulation d'une consultation mÃ©dicale complÃ¨te              â•‘")
    print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.END}\n")
    
    try:
        # =================================================================
        # SCÃ‰NARIO 1: SESSION COMPLÃˆTE AVEC DIAGNOSTIC CORRECT
        # =================================================================
        tester.section("SCÃ‰NARIO 1: CONSULTATION COMPLÃˆTE AVEC DIAGNOSTIC CORRECT")
        
        # 1. DÃ©marrer la session
        if not test_start_simulation_session():
            tester.write("\nâš ï¸  Impossible de continuer sans session active", Colors.RED)
            return
        
        time.sleep(1)
        
        # 2. Flux de consultation avec messages
        test_chat_message_1_greeting()
        time.sleep(0.5)
        
        test_chat_message_2_chief_complaint()
        time.sleep(0.5)
        
        test_chat_message_3_symptom_details()
        time.sleep(0.5)
        
        # 3. Actions cliniques
        test_action_1_vital_signs()
        time.sleep(0.5)
        
        test_chat_message_4_medical_history()
        time.sleep(0.5)
        
        test_action_2_blood_test()
        time.sleep(0.5)
        
        # 4. Test d'action inappropriÃ©e
        test_action_3_inappropriate_exam()
        time.sleep(0.5)
        
        # 5. Demande d'indice
        test_request_hint_1()
        time.sleep(0.5)
        
        # 6. Consultation d'image (si disponible)
        test_action_4_consult_image()
        time.sleep(0.5)
        
        # 7. RÃ©sumÃ© avant diagnostic
        test_chat_message_5_summary()
        time.sleep(0.5)
        
        # 8. RÃ©cupÃ©rer historique complet
        test_get_chat_history()
        time.sleep(0.5)
        
        # 9. Soumission du diagnostic correct
        test_submit_diagnosis_correct()
        
        # =================================================================
        # SCÃ‰NARIO 2: DIAGNOSTIC INCORRECT
        # =================================================================
        time.sleep(2)
        test_start_and_submit_wrong_diagnosis()
        
        # =================================================================
        # SCÃ‰NARIO 3: DEMANDES MULTIPLES D'INDICES
        # =================================================================
        time.sleep(2)
        test_multiple_hint_requests()
        
        # =================================================================
        # SCÃ‰NARIO 4: SESSION FORMATIVE
        # =================================================================
        time.sleep(2)
        test_session_formative_evaluation()
        
        # =================================================================
        # TESTS DE CAS LIMITES
        # =================================================================
        time.sleep(2)
        test_edge_cases()
        
        # =================================================================
        # RÃ‰SUMÃ‰ FINAL
        # =================================================================
        tester.summary()
        
    except KeyboardInterrupt:
        tester.write("\n\nâš ï¸  Tests interrompus par l'utilisateur", Colors.YELLOW)
        tester.summary()
    except Exception as e:
        tester.write(f"\n\nâŒ ERREUR CRITIQUE: {str(e)}", Colors.RED)
        import traceback
        tester.write(traceback.format_exc())
        tester.summary()
    finally:
        tester.close()
        print(f"\n{Colors.GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"â•‘  TESTS TERMINÃ‰S                                                â•‘")
        print(f"â•‘  RÃ©sultats sauvegardÃ©s dans: {OUTPUT_FILE:30s} â•‘")
        print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.END}\n")


if __name__ == "__main__":
    main()

=== Fichier: ./testtutor.py ===

import requests
import json
from datetime import datetime

# Configuration
TUTOR_BASE_URL = "https://tutor-docker-sti.onrender.com"
OUTPUT_FILE = f"discovery_tutor_routes_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    END = '\033[0m'

def print_color(message, color=None, end='\n'):
    if color:
        print(f"{color}{message}{Colors.END}", end=end)
    else:
        print(message, end=end)

def test_endpoint(base_url, endpoint, method="GET", data=None):
    """Test un endpoint et retourne le rÃ©sultat"""
    url = f"{base_url}{endpoint}"
    try:
        if method == "GET":
            response = requests.get(url, timeout=10)
        elif method == "POST":
            response = requests.post(url, json=data if data else {}, timeout=10)
        else:
            response = requests.request(method, url, timeout=10)
        
        return {
            "status": response.status_code,
            "success": response.status_code < 400,
            "response": response.text[:200] if response.text else "Empty",
            "time": response.elapsed.total_seconds()
        }
    except Exception as e:
        return {
            "status": "ERROR",
            "success": False,
            "response": str(e)[:200],
            "time": 0
        }

def discover_routes():
    """DÃ©couvre les routes disponibles"""
    
    print_color("\n" + "="*100, Colors.CYAN)
    print_color("DÃ‰COUVERTE DES ROUTES API TUTEUR", Colors.CYAN)
    print_color("="*100, Colors.CYAN)
    print_color(f"\nğŸ“ URL de base: {TUTOR_BASE_URL}", Colors.BLUE)
    print_color(f"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", Colors.BLUE)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        
        def log(message):
            f.write(message + '\n')
            f.flush()
        
        log("="*100)
        log(f"DÃ‰COUVERTE DES ROUTES API TUTEUR - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        log("="*100)
        log(f"\nURL de base: {TUTOR_BASE_URL}\n")
        
        # Liste des endpoints Ã  tester
        endpoints_to_test = [
            # Racine
            ("GET", "/", "Racine de l'API"),
            ("GET", "/docs", "Documentation Swagger"),
            ("GET", "/openapi.json", "OpenAPI spec"),
            
            # API v1
            ("GET", "/api/v1", "Base API v1"),
            ("GET", "/api/v1/docs", "Docs API v1"),
            ("GET", "/api/v1/openapi.json", "OpenAPI v1"),
            
            # Routes selon la doc fournie
            ("POST", "/api/v1/decide", "Decide endpoint"),
            ("POST", "/api/v1/session/start", "Start session"),
            ("POST", "/api/v1/hint", "Request hint"),
            ("POST", "/api/v1/answer", "Submit answer"),
            ("POST", "/api/v1/case/end", "End case"),
            ("POST", "/api/v1/case/next", "Get next case"),
            ("GET", "/api/v1/session/1/1038", "Get session info"),
            ("GET", "/api/v1/sessions/learner/1", "Get learner sessions"),
            
            # Autres variations possibles
            ("GET", "/health", "Health check"),
            ("GET", "/api/health", "API Health check"),
            ("GET", "/api/v1/health", "API v1 Health"),
            ("GET", "/tutor", "Tutor endpoint"),
            ("GET", "/api/tutor", "API Tutor"),
            ("GET", "/api/v1/tutor", "API v1 Tutor"),
        ]
        
        print_color("\nğŸ” Test des endpoints...\n", Colors.YELLOW)
        log("\n" + "â”€"*100)
        log("RÃ‰SULTATS DES TESTS")
        log("â”€"*100 + "\n")
        
        available = []
        not_found = []
        errors = []
        
        for method, endpoint, description in endpoints_to_test:
            print_color(f"Testing {method:6} {endpoint:40} ", Colors.BLUE, end='')
            
            result = test_endpoint(TUTOR_BASE_URL, endpoint, method)
            
            log(f"\n{method} {endpoint}")
            log(f"Description: {description}")
            log(f"Status: {result['status']}")
            log(f"Response: {result['response']}")
            log(f"Time: {result['time']:.2f}s")
            
            if result['success']:
                print_color("âœ… DISPONIBLE", Colors.GREEN)
                available.append((method, endpoint, description, result['status']))
            elif result['status'] == 404:
                print_color("âŒ 404 Not Found", Colors.RED)
                not_found.append((method, endpoint, description))
            elif result['status'] == 405:
                print_color("âš ï¸  405 Method Not Allowed", Colors.YELLOW)
                not_found.append((method, endpoint, description))
            else:
                print_color(f"âš ï¸  {result['status']}", Colors.YELLOW)
                errors.append((method, endpoint, description, result['status']))
        
        # RÃ©sumÃ©
        print_color("\n" + "="*100, Colors.CYAN)
        print_color("RÃ‰SUMÃ‰ DE LA DÃ‰COUVERTE", Colors.CYAN)
        print_color("="*100, Colors.CYAN)
        
        log("\n" + "="*100)
        log("RÃ‰SUMÃ‰")
        log("="*100)
        
        summary = f"""
ğŸ“Š Statistiques:
   â€¢ Endpoints testÃ©s: {len(endpoints_to_test)}
   â€¢ Disponibles: {len(available)}
   â€¢ Non trouvÃ©s (404): {len(not_found)}
   â€¢ Erreurs: {len(errors)}
"""
        print_color(summary, Colors.BLUE)
        log(summary)
        
        if available:
            print_color("\nâœ… ENDPOINTS DISPONIBLES:", Colors.GREEN)
            log("\nâœ… ENDPOINTS DISPONIBLES:")
            for method, endpoint, desc, status in available:
                msg = f"   {method:6} {endpoint:40} â†’ {status} - {desc}"
                print_color(msg, Colors.GREEN)
                log(msg)
        
        if errors:
            print_color("\nâš ï¸  ENDPOINTS AVEC ERREURS:", Colors.YELLOW)
            log("\nâš ï¸  ENDPOINTS AVEC ERREURS:")
            for method, endpoint, desc, status in errors:
                msg = f"   {method:6} {endpoint:40} â†’ {status} - {desc}"
                print_color(msg, Colors.YELLOW)
                log(msg)
        
        # Tester la racine pour voir s'il y a un message
        print_color("\nğŸ” Test dÃ©taillÃ© de la racine:", Colors.CYAN)
        log("\nğŸ” Test dÃ©taillÃ© de la racine:")
        
        try:
            response = requests.get(TUTOR_BASE_URL, timeout=10)
            print_color(f"\nStatus: {response.status_code}", Colors.BLUE)
            print_color(f"Response:", Colors.BLUE)
            print_color(response.text[:500], Colors.YELLOW)
            
            log(f"\nRacine ({TUTOR_BASE_URL}):")
            log(f"Status: {response.status_code}")
            log(f"Headers: {dict(response.headers)}")
            log(f"Response:\n{response.text}")
        except Exception as e:
            print_color(f"Erreur: {str(e)}", Colors.RED)
            log(f"Erreur: {str(e)}")
        
        # Recommandations
        print_color("\nğŸ’¡ RECOMMANDATIONS:", Colors.CYAN)
        log("\nğŸ’¡ RECOMMANDATIONS:")
        
        recommendations = """
1. Si /docs ou /openapi.json est disponible, consultez la documentation Swagger
2. VÃ©rifiez que l'API Tuteur est bien dÃ©ployÃ©e sur Render
3. Les routes peuvent avoir un prÃ©fixe diffÃ©rent (ex: /tutor/api/v1/...)
4. L'API peut nÃ©cessiter une authentification (API Key, JWT)
5. Contactez l'Ã©quipe de dÃ©veloppement pour confirmer les routes exactes
"""
        print_color(recommendations, Colors.YELLOW)
        log(recommendations)
        
        log("\n" + "="*100)
        log(f"Rapport complet sauvegardÃ© dans: {OUTPUT_FILE}")
        log(f"Date fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        log("="*100)
    
    print_color(f"\nğŸ“„ Rapport complet: {OUTPUT_FILE}", Colors.GREEN)
    print_color("="*100 + "\n", Colors.CYAN)

if __name__ == "__main__":
    try:
        discover_routes()
    except KeyboardInterrupt:
        print_color("\n\nâš ï¸  DÃ©couverte interrompue", Colors.YELLOW)
    except Exception as e:
        print_color(f"\n\nâŒ ERREUR: {str(e)}", Colors.RED)
        import traceback
        traceback.print_exc()

=== Fichier: ./apply_associations_api.py ===

import requests
import json
import csv
import io
from datetime import datetime
import time

# ==============================================================================
# CONFIGURATION
# ==============================================================================
BASE_URL = "https://expert-cmck.onrender.com/api/v1"
OUTPUT_FILE = f"application_associations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

# Seuil de score minimum pour qu'une association soit appliquÃ©e
SCORE_THRESHOLD = 10

# Les donnÃ©es CSV extraites du rapport
CSV_DATA = """case_id,pathologie_id,pathologie_name,image_id,image_type,score,type_association
1041,25579,"Closed fracture of surgical neck of humerus",198,"Radio Ã‰paule",40,PROPOSITION
1041,25579,"Closed fracture of surgical neck of humerus",203,"Radio Coude",20,PROPOSITION
1041,25579,"Closed fracture of surgical neck of humerus",204,"Radio Coude",20,PROPOSITION
1043,19789,"Intracerebral hemorrhage",199,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1043,19789,"Intracerebral hemorrhage",233,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1044,19759,"Congestive heart failure, unspecified",200,"Radio Thorax",40,PROPOSITION
1044,19759,"Congestive heart failure, unspecified",201,"Radio Thorax",20,PROPOSITION
1044,19759,"Congestive heart failure, unspecified",202,"Radio Thorax",20,PROPOSITION
1046,25597,"Other closed fracture of lower end of humerus",198,"Radio Ã‰paule",20,PROPOSITION
1046,25597,"Other closed fracture of lower end of humerus",203,"Radio Coude",20,PROPOSITION
1046,25597,"Other closed fracture of lower end of humerus",204,"Radio Coude",20,PROPOSITION
1047,17069,"Toxic multinodular goiter without mention of thyrotoxic crisis or storm",205,"Ã‰cho ThyroÃ¯de",30,PROPOSITION
1047,17069,"Toxic multinodular goiter without mention of thyrotoxic crisis or storm",206,"Ã‰cho ThyroÃ¯de",30,PROPOSITION
1048,19795,"Occlusion and stenosis of carotid artery without mention of cerebral infarction",207,"Echo-Doppler",30,PROPOSITION
1048,19795,"Occlusion and stenosis of carotid artery without mention of cerebral infarction",208,"Echo-Doppler",30,PROPOSITION
1048,19795,"Occlusion and stenosis of carotid artery without mention of cerebral infarction",209,"Echo-Doppler",30,PROPOSITION
1050,26912,"Infection and inflammatory reaction due to other internal orthopedic device, implant, and graft",210,"Radio",20,PROPOSITION
1050,26912,"Infection and inflammatory reaction due to other internal orthopedic device, implant, and graft",211,"Radio",20,PROPOSITION
1051,19596,"Unspecified hypertensive heart disease with heart failure",200,"Radio Thorax",30,PROPOSITION
1051,19596,"Unspecified hypertensive heart disease with heart failure",201,"Radio Thorax",30,PROPOSITION
1051,19596,"Unspecified hypertensive heart disease with heart failure",202,"Radio Thorax",30,PROPOSITION
1058,21090,"Cirrhosis of liver without mention of alcohol",219,"Ã‰cho Abdo",20,PROPOSITION
1058,21090,"Cirrhosis of liver without mention of alcohol",270,"Ã‰cho Abdo",20,PROPOSITION
1059,21090,"Cirrhosis of liver without mention of alcohol",219,"Ã‰cho Abdo",20,PROPOSITION
1059,21090,"Cirrhosis of liver without mention of alcohol",270,"Ã‰cho Abdo",20,PROPOSITION
1060,19759,"Congestive heart failure, unspecified",200,"Radio Thorax",40,PROPOSITION
1060,19759,"Congestive heart failure, unspecified",201,"Radio Thorax",20,PROPOSITION
1060,19759,"Congestive heart failure, unspecified",202,"Radio Thorax",20,PROPOSITION
1061,23049,"Closed fracture of base of skull with subarachnoid, subdural, and extradural hemorrhage, with prolonged [more than 24 hours] loss of consciousness, without return to pre-existing conscious level",221,"Scanner CÃ©rÃ©bral",30,PROPOSITION
1061,23049,"Closed fracture of base of skull with subarachnoid, subdural, and extradural hemorrhage, with prolonged [more than 24 hours] loss of consciousness, without return to pre-existing conscious level",235,"Scanner CÃ©rÃ©bral",20,PROPOSITION
1071,19789,"Intracerebral hemorrhage",199,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1071,19789,"Intracerebral hemorrhage",233,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1076,24386,"Other open skull fracture with subarachnoid, subdural, and extradural hemorrhage, with prolonged [more than 24 hours] loss of consciousness, without return to pre-existing conscious level",235,"Scanner CÃ©rÃ©bral",30,PROPOSITION
1076,24386,"Other open skull fracture with subarachnoid, subdural, and extradural hemorrhage, with prolonged [more than 24 hours] loss of consciousness, without return to pre-existing conscious level",221,"Scanner CÃ©rÃ©bral",20,PROPOSITION
1081,19759,"Congestive heart failure, unspecified",200,"Radio Thorax",40,PROPOSITION
1081,19759,"Congestive heart failure, unspecified",201,"Radio Thorax",20,PROPOSITION
1081,19759,"Congestive heart failure, unspecified",202,"Radio Thorax",20,PROPOSITION
1083,19759,"Congestive heart failure, unspecified",200,"Radio Thorax",40,PROPOSITION
1083,19759,"Congestive heart failure, unspecified",201,"Radio Thorax",20,PROPOSITION
1083,19759,"Congestive heart failure, unspecified",202,"Radio Thorax",20,PROPOSITION
1086,21128,"Acute cholecystitis",242,"Ã‰cho Abdo",40,PROPOSITION
1087,21334,"Chronic or unspecified duodenal ulcer with hemorrhage, without mention of obstruction",243,"Gastroscopie",20,PROPOSITION
1087,21334,"Chronic or unspecified duodenal ulcer with hemorrhage, without mention of obstruction",244,"Gastroscopie",20,PROPOSITION
1087,21334,"Chronic or unspecified duodenal ulcer with hemorrhage, without mention of obstruction",245,"Gastroscopie",20,PROPOSITION
1089,22193,"Closed fracture of intertrochanteric section of neck of femur",198,"Radio Ã‰paule",20,PROPOSITION
1089,22193,"Closed fracture of intertrochanteric section of neck of femur",246,"Radio Bassin",20,PROPOSITION
1097,21140,"Cholangitis",255,"Scanner/Ã‰cho",30,PROPOSITION
1097,21140,"Cholangitis",256,"Scanner/Ã‰cho",30,PROPOSITION
1099,24405,"Subarachnoid hemorrhage following injury without mention of open intracranial wound, with loss of consciousness of unspecified duration",257,"Scanner CÃ©rÃ©bral",40,PROPOSITION
1104,19764,"Acute on chronic systolic heart failure",200,"Radio Thorax",20,PROPOSITION
1104,19764,"Acute on chronic systolic heart failure",201,"Radio Thorax",20,PROPOSITION
1104,19764,"Acute on chronic systolic heart failure",202,"Radio Thorax",20,PROPOSITION
1106,21302,"Tracheoesophageal fistula",260,"Transit",40,PROPOSITION
1108,21128,"Acute cholecystitis",242,"Ã‰cho Abdo",40,PROPOSITION
1113,27653,"Ventilator associated pneumonia",261,"Radio Thorax",50,PROPOSITION
1129,27723,"Closed fracture of first cervical vertebra",247,"Scanner Rachis",20,PROPOSITION
1130,19762,"Acute systolic heart failure",200,"Radio Thorax",20,PROPOSITION
1130,19762,"Acute systolic heart failure",201,"Radio Thorax",20,PROPOSITION
1130,19762,"Acute systolic heart failure",202,"Radio Thorax",20,PROPOSITION
"""

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    END = '\033[0m'

def print_color(message, color=None):
    """Affiche un message en couleur"""
    if color:
        print(f"{color}{message}{Colors.END}")
    else:
        print(message)

def get_clinical_case(case_id):
    """RÃ©cupÃ¨re un cas clinique complet"""
    try:
        response = requests.get(f"{BASE_URL}/clinical-cases/{case_id}", timeout=30)
        if response.status_code == 200:
            return response.json()
        else:
            print_color(f"   âš ï¸ Erreur {response.status_code} pour le cas {case_id}", Colors.YELLOW)
            return None
    except Exception as e:
        print_color(f"   âŒ Exception lors de la rÃ©cupÃ©ration du cas {case_id}: {str(e)}", Colors.RED)
        return None

def update_image_pathology(image_id, pathologie_id):
    """Met Ã  jour la pathologie associÃ©e Ã  une image"""
    try:
        data = {"pathologie_id": pathologie_id}
        response = requests.patch(
            f"{BASE_URL}/media/images/{image_id}",
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            return True, "OK"
        else:
            return False, f"HTTP {response.status_code}"
    except Exception as e:
        return False, str(e)

def update_clinical_case(case_id, images_associees_ids):
    """Met Ã  jour les images associÃ©es Ã  un cas clinique"""
    try:
        data = {"images_associees_ids": images_associees_ids}
        response = requests.patch(
            f"{BASE_URL}/clinical-cases/{case_id}",
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            return True, "OK"
        else:
            return False, f"HTTP {response.status_code}"
    except Exception as e:
        return False, str(e)

def apply_associations():
    """Script principal pour lire le CSV et appliquer les associations via API"""
    
    print_color("\n" + "="*100, Colors.CYAN)
    print_color("APPLICATION DES ASSOCIATIONS VIA API", Colors.CYAN)
    print_color("="*100, Colors.CYAN)
    print_color(f"\nğŸ¯ Seuil de score minimum: {SCORE_THRESHOLD}", Colors.BLUE)
    print_color(f"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", Colors.BLUE)
    print_color("-" * 100, Colors.CYAN)
    
    csv_file = io.StringIO(CSV_DATA)
    reader = csv.DictReader(csv_file)
    
    # Grouper les associations par cas clinique
    associations_by_case = {}
    for row in reader:
        case_id = int(row['case_id'])
        pathologie_id = int(row['pathologie_id'])
        image_id = int(row['image_id'])
        score = int(row['score'])
        
        if score < SCORE_THRESHOLD:
            continue
        
        if case_id not in associations_by_case:
            associations_by_case[case_id] = {
                'pathologie_id': pathologie_id,
                'images': []
            }
        
        associations_by_case[case_id]['images'].append({
            'image_id': image_id,
            'score': score
        })
    
    print_color(f"\nğŸ“Š Statistiques initiales:", Colors.YELLOW)
    print_color(f"   â€¢ {len(associations_by_case)} cas cliniques Ã  traiter", Colors.BLUE)
    total_images = sum(len(v['images']) for v in associations_by_case.values())
    print_color(f"   â€¢ {total_images} images Ã  associer", Colors.BLUE)
    
    # Ouvrir le fichier de log
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as log_file:
        
        def log(message):
            log_file.write(message + '\n')
            log_file.flush()
        
        log("="*100)
        log(f"APPLICATION DES ASSOCIATIONS - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        log("="*100)
        log(f"\nSeuil de score: {SCORE_THRESHOLD}")
        log(f"Cas Ã  traiter: {len(associations_by_case)}")
        log(f"Images Ã  associer: {total_images}\n")
        
        # Statistiques
        stats = {
            'cases_processed': 0,
            'cases_success': 0,
            'cases_failed': 0,
            'images_updated': 0,
            'images_failed': 0,
            'already_associated': 0
        }
        
        # Traiter chaque cas
        for idx, (case_id, data) in enumerate(associations_by_case.items(), 1):
            pathologie_id = data['pathologie_id']
            images = data['images']
            
            print_color(f"\n{'â”€'*100}", Colors.CYAN)
            print_color(f"[{idx}/{len(associations_by_case)}] CAS #{case_id}", Colors.CYAN)
            print_color(f"{'â”€'*100}", Colors.CYAN)
            
            log(f"\n{'â”€'*100}")
            log(f"CAS #{case_id} - Pathologie #{pathologie_id}")
            log(f"{'â”€'*100}")
            
            # RÃ©cupÃ©rer le cas actuel
            print_color(f"   ğŸ“¥ RÃ©cupÃ©ration du cas clinique...", Colors.BLUE)
            case = get_clinical_case(case_id)
            
            if not case:
                print_color(f"   âŒ Impossible de rÃ©cupÃ©rer le cas {case_id}", Colors.RED)
                log(f"âŒ ERREUR: Cas non trouvÃ©")
                stats['cases_failed'] += 1
                continue
            
            stats['cases_processed'] += 1
            
            # RÃ©cupÃ©rer les images actuellement associÃ©es
            current_images = case.get('images_associees_ids', []) or []
            new_images = list(current_images)  # Copie
            
            print_color(f"   ğŸ“‹ Images actuellement associÃ©es: {len(current_images)}", Colors.BLUE)
            log(f"Images actuelles: {current_images}")
            
            # Traiter chaque image
            images_to_add = []
            for img_data in images:
                image_id = img_data['image_id']
                score = img_data['score']
                
                print_color(f"\n   ğŸ–¼ï¸  Image #{image_id} (Score: {score})", Colors.MAGENTA)
                log(f"\n   Image #{image_id} (Score: {score})")
                
                # 1. Mettre Ã  jour la pathologie de l'image
                print_color(f"      â†’ Mise Ã  jour pathologie_id...", Colors.BLUE)
                success, message = update_image_pathology(image_id, pathologie_id)
                
                if success:
                    print_color(f"      âœ… Pathologie associÃ©e Ã  l'image", Colors.GREEN)
                    log(f"      âœ… Image {image_id}: pathologie_id = {pathologie_id}")
                    stats['images_updated'] += 1
                else:
                    print_color(f"      âŒ Ã‰chec: {message}", Colors.RED)
                    log(f"      âŒ Erreur pathologie: {message}")
                    stats['images_failed'] += 1
                    continue
                
                # 2. Ajouter Ã  la liste si pas dÃ©jÃ  prÃ©sente
                if image_id not in new_images:
                    new_images.append(image_id)
                    images_to_add.append(image_id)
                    print_color(f"      â• Image ajoutÃ©e Ã  la liste d'association", Colors.GREEN)
                    log(f"      â• Image {image_id} ajoutÃ©e")
                else:
                    print_color(f"      â„¹ï¸  Image dÃ©jÃ  associÃ©e au cas", Colors.YELLOW)
                    log(f"      â„¹ï¸  Image {image_id} dÃ©jÃ  prÃ©sente")
                    stats['already_associated'] += 1
                
                # Pause pour Ã©viter de surcharger l'API
                time.sleep(0.2)
            
            # 3. Mettre Ã  jour le cas clinique si de nouvelles images
            if images_to_add:
                print_color(f"\n   ğŸ’¾ Mise Ã  jour du cas clinique...", Colors.BLUE)
                print_color(f"      Images Ã  ajouter: {images_to_add}", Colors.BLUE)
                log(f"\n   Mise Ã  jour cas {case_id}")
                log(f"   Nouvelles images: {images_to_add}")
                log(f"   Total images aprÃ¨s: {new_images}")
                
                success, message = update_clinical_case(case_id, new_images)
                
                if success:
                    print_color(f"   âœ… Cas clinique mis Ã  jour avec succÃ¨s!", Colors.GREEN)
                    log(f"   âœ… Cas mis Ã  jour avec succÃ¨s")
                    stats['cases_success'] += 1
                else:
                    print_color(f"   âŒ Ã‰chec mise Ã  jour: {message}", Colors.RED)
                    log(f"   âŒ Erreur mise Ã  jour cas: {message}")
                    stats['cases_failed'] += 1
            else:
                print_color(f"\n   â„¹ï¸  Aucune nouvelle image Ã  ajouter", Colors.YELLOW)
                log(f"   â„¹ï¸  Pas de nouvelles images")
                stats['cases_success'] += 1
            
            # Pause entre chaque cas
            time.sleep(0.5)
        
        # RÃ©sumÃ© final
        print_color(f"\n{'='*100}", Colors.CYAN)
        print_color("RÃ‰SUMÃ‰ DE L'OPÃ‰RATION", Colors.CYAN)
        print_color(f"{'='*100}", Colors.CYAN)
        
        log(f"\n{'='*100}")
        log("RÃ‰SUMÃ‰ FINAL")
        log(f"{'='*100}")
        
        summary = f"""
ğŸ“Š Cas cliniques:
   â€¢ TraitÃ©s: {stats['cases_processed']}
   â€¢ SuccÃ¨s: {stats['cases_success']}
   â€¢ Ã‰checs: {stats['cases_failed']}

ğŸ–¼ï¸  Images:
   â€¢ Mises Ã  jour: {stats['images_updated']}
   â€¢ Ã‰checs: {stats['images_failed']}
   â€¢ DÃ©jÃ  associÃ©es: {stats['already_associated']}

âœ… Taux de rÃ©ussite: {(stats['cases_success']/max(stats['cases_processed'],1)*100):.1f}%
"""
        print_color(summary, Colors.GREEN)
        log(summary)
        
        log(f"\n{'='*100}")
        log(f"Fichier de log: {OUTPUT_FILE}")
        log(f"Date fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        log(f"{'='*100}")
    
    print_color(f"\nğŸ“„ Rapport complet sauvegardÃ© dans: {OUTPUT_FILE}", Colors.CYAN)
    print_color(f"{'='*100}\n", Colors.CYAN)

if __name__ == "__main__":
    try:
        apply_associations()
    except KeyboardInterrupt:
        print_color("\n\nâš ï¸  Script interrompu par l'utilisateur", Colors.YELLOW)
    except Exception as e:
        print_color(f"\n\nâŒ ERREUR CRITIQUE: {str(e)}", Colors.RED)
        import traceback
        traceback.print_exc()

=== Fichier: ./test.py ===

import requests
import json
from datetime import datetime
from collections import defaultdict

# Configuration
BASE_URL = "https://expert-cmck.onrender.com/api/v1"
OUTPUT_FILE = f"associations_cas_patho_images_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    END = '\033[0m'

def print_color(message, color=None):
    """Affiche un message en couleur"""
    if color:
        print(f"{color}{message}{Colors.END}")
    else:
        print(message)

def fetch_all_paginated(endpoint, params_base=None, show_progress=True):
    """RÃ©cupÃ¨re toutes les donnÃ©es paginÃ©es d'un endpoint"""
    all_data = []
    skip = 0
    limit = 100
    page = 1
    
    while True:
        try:
            params = params_base.copy() if params_base else {}
            params.update({"skip": skip, "limit": limit})
            
            response = requests.get(f"{BASE_URL}/{endpoint}", params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                if not data or len(data) == 0:
                    break
                
                all_data.extend(data)
                
                if show_progress:
                    print_color(f"      Page {page}: +{len(data)} items (Total: {len(all_data)})", Colors.BLUE)
                
                # Si on a reÃ§u moins que la limite, c'est la derniÃ¨re page
                if len(data) < limit:
                    break
                
                skip += limit
                page += 1
            else:
                print_color(f"   âŒ Erreur HTTP {response.status_code}", Colors.RED)
                break
        except Exception as e:
            print_color(f"   âŒ Erreur: {str(e)}", Colors.RED)
            break
    
    return all_data

def get_case_details(case_id):
    """RÃ©cupÃ¨re les dÃ©tails complets d'un cas clinique"""
    try:
        response = requests.get(f"{BASE_URL}/clinical-cases/{case_id}", timeout=30)
        if response.status_code == 200:
            return response.json()
    except:
        pass
    return None

def normalize_text(text):
    """Normalise le texte pour la comparaison"""
    if not text:
        return ""
    return text.lower().strip()

def calculate_match_score(disease_name, image_description, image_type, image_subtype):
    """Calcule un score de correspondance entre une pathologie et une image"""
    score = 0
    disease_lower = normalize_text(disease_name)
    desc_lower = normalize_text(image_description)
    type_lower = normalize_text(image_type)
    subtype_lower = normalize_text(image_subtype)
    
    # Mots-clÃ©s importants dans le nom de la pathologie
    disease_keywords = disease_lower.split()
    
    # VÃ©rifier les correspondances dans la description
    for keyword in disease_keywords:
        if len(keyword) > 3:  # Ignorer les mots courts
            if keyword in desc_lower:
                score += 10
            if keyword in type_lower:
                score += 15
            if keyword in subtype_lower:
                score += 15
    
    # Bonus si correspondance exacte
    if disease_lower in desc_lower or desc_lower in disease_lower:
        score += 20
    
    return score

def main():
    print_color("\n" + "="*100, Colors.CYAN)
    print_color("ASSOCIATION CAS CLINIQUES â†’ PATHOLOGIES â†’ IMAGES", Colors.CYAN)
    print_color("="*100, Colors.CYAN)
    
    # 1. RÃ©cupÃ©rer toutes les donnÃ©es
    print_color("\nğŸ“¥ Ã‰TAPE 1: RÃ©cupÃ©ration des donnÃ©es...", Colors.YELLOW)
    
    print_color("   â†’ RÃ©cupÃ©ration des cas cliniques...", Colors.BLUE)
    clinical_cases = fetch_all_paginated("clinical-cases")
    print_color(f"   âœ“ {len(clinical_cases)} cas cliniques rÃ©cupÃ©rÃ©s", Colors.GREEN)
    
    print_color("   â†’ RÃ©cupÃ©ration des pathologies...", Colors.BLUE)
    diseases = fetch_all_paginated("diseases")
    print_color(f"   âœ“ {len(diseases)} pathologies rÃ©cupÃ©rÃ©es", Colors.GREEN)
    
    print_color("   â†’ RÃ©cupÃ©ration des images mÃ©dicales...", Colors.BLUE)
    images = fetch_all_paginated("media/images")
    print_color(f"   âœ“ {len(images)} images rÃ©cupÃ©rÃ©es", Colors.GREEN)
    
    # 2. CrÃ©er des dictionnaires pour accÃ¨s rapide
    diseases_dict = {d['id']: d for d in diseases}
    images_by_pathology = defaultdict(list)
    unassigned_images = []
    
    for img in images:
        if img.get('pathologie_id'):
            images_by_pathology[img['pathologie_id']].append(img)
        else:
            unassigned_images.append(img)
    
    # 3. Analyse et associations
    print_color("\nğŸ” Ã‰TAPE 2: Analyse et associations...", Colors.YELLOW)
    
    associations = []
    pathologies_in_cases = set()
    cases_without_images = []
    
    for case in clinical_cases:
        case_id = case['id']
        pathologie_id = case.get('pathologie_principale', {}).get('id') if isinstance(case.get('pathologie_principale'), dict) else None
        
        if not pathologie_id:
            continue
        
        pathologies_in_cases.add(pathologie_id)
        pathologie = diseases_dict.get(pathologie_id)
        
        if not pathologie:
            continue
        
        pathologie_name = pathologie.get('nom_fr', 'N/A')
        nb_images = case.get('nb_images', 0)
        
        # Cas avec images dÃ©jÃ  associÃ©es
        if nb_images > 0:
            # RÃ©cupÃ©rer les dÃ©tails du cas pour avoir les IDs des images
            case_details = get_case_details(case_id)
            if case_details and case_details.get('images_associees'):
                for img in case_details['images_associees']:
                    associations.append({
                        'type': 'EXISTANT',
                        'case_id': case_id,
                        'case_code': case.get('code_fultang', 'N/A'),
                        'pathologie_id': pathologie_id,
                        'pathologie_name': pathologie_name,
                        'image_id': img['id'],
                        'image_type': img.get('type_examen', 'N/A'),
                        'image_subtype': img.get('sous_type', 'N/A'),
                        'image_url': img.get('fichier_url', 'N/A'),
                        'score': 100  # Score parfait pour association existante
                    })
        
        # Chercher des images dÃ©jÃ  associÃ©es Ã  cette pathologie
        if pathologie_id in images_by_pathology:
            for img in images_by_pathology[pathologie_id]:
                # VÃ©rifier si cette image n'est pas dÃ©jÃ  dans les associations existantes
                already_associated = any(
                    a['case_id'] == case_id and a['image_id'] == img['id'] 
                    for a in associations
                )
                
                if not already_associated:
                    associations.append({
                        'type': 'PATHOLOGIE_DIRECTE',
                        'case_id': case_id,
                        'case_code': case.get('code_fultang', 'N/A'),
                        'pathologie_id': pathologie_id,
                        'pathologie_name': pathologie_name,
                        'image_id': img['id'],
                        'image_type': img.get('type_examen', 'N/A'),
                        'image_subtype': img.get('sous_type', 'N/A'),
                        'image_url': img.get('fichier_url', 'N/A'),
                        'score': 90  # Score trÃ¨s Ã©levÃ©
                    })
        
        # Chercher des correspondances dans les images non assignÃ©es
        if nb_images == 0:  # Seulement pour les cas sans images
            cases_without_images.append({
                'case_id': case_id,
                'case_code': case.get('code_fultang', 'N/A'),
                'pathologie_id': pathologie_id,
                'pathologie_name': pathologie_name
            })
            
            best_matches = []
            for img in unassigned_images:
                score = calculate_match_score(
                    pathologie_name,
                    img.get('description', ''),
                    img.get('type_examen', ''),
                    img.get('sous_type', '')
                )
                
                if score > 10:  # Seuil minimum
                    best_matches.append({
                        'type': 'PROPOSITION',
                        'case_id': case_id,
                        'case_code': case.get('code_fultang', 'N/A'),
                        'pathologie_id': pathologie_id,
                        'pathologie_name': pathologie_name,
                        'image_id': img['id'],
                        'image_type': img.get('type_examen', 'N/A'),
                        'image_subtype': img.get('sous_type', 'N/A'),
                        'image_description': img.get('description', 'N/A'),
                        'image_url': img.get('fichier_url', 'N/A'),
                        'score': score
                    })
            
            # Garder les 3 meilleures propositions
            best_matches.sort(key=lambda x: x['score'], reverse=True)
            associations.extend(best_matches[:3])
    
    # 4. Propositions pour pathologies sans cas cliniques mais avec images
    print_color("\nğŸ” Ã‰TAPE 3: Propositions pour autres pathologies...", Colors.YELLOW)
    
    other_pathologies_with_images = []
    for pathologie_id, imgs in images_by_pathology.items():
        if pathologie_id not in pathologies_in_cases:
            pathologie = diseases_dict.get(pathologie_id)
            if pathologie:
                other_pathologies_with_images.append({
                    'pathologie_id': pathologie_id,
                    'pathologie_name': pathologie.get('nom_fr', 'N/A'),
                    'pathologie_code': pathologie.get('code_icd10', 'N/A'),
                    'nb_images': len(imgs),
                    'images': imgs
                })
    
    # 5. Ã‰criture du rapport
    print_color("\nğŸ“ Ã‰TAPE 4: GÃ©nÃ©ration du rapport...", Colors.YELLOW)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        # En-tÃªte
        separator = "="*100
        f.write(separator + '\n')
        f.write("RAPPORT D'ASSOCIATION: CAS CLINIQUES â†’ PATHOLOGIES â†’ IMAGES\n")
        f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(separator + '\n')
        
        # Statistiques globales
        f.write(f"\nğŸ“Š STATISTIQUES GLOBALES\n")
        f.write("-" * 100 + '\n')
        f.write(f"Total cas cliniques: {len(clinical_cases)}\n")
        f.write(f"Cas avec pathologie principale: {len([c for c in clinical_cases if c.get('pathologie_principale')])}\n")
        f.write(f"Pathologies uniques dans les cas: {len(pathologies_in_cases)}\n")
        f.write(f"Cas sans images: {len(cases_without_images)}\n")
        f.write(f"Total d'images: {len(images)}\n")
        f.write(f"Images non assignÃ©es: {len(unassigned_images)}\n")
        f.write(f"Associations trouvÃ©es/proposÃ©es: {len(associations)}\n")
        
        # Section 1: Associations existantes
        existing = [a for a in associations if a['type'] == 'EXISTANT']
        f.write(f"\n\n{'='*100}\n")
        f.write(f"SECTION 1: ASSOCIATIONS EXISTANTES ({len(existing)})\n")
        f.write(f"{'='*100}\n")
        
        if existing:
            for idx, assoc in enumerate(existing, 1):
                f.write(f"\n{idx}. Cas #{assoc['case_id']} ({assoc['case_code']})\n")
                f.write(f"   â†’ Pathologie #{assoc['pathologie_id']}: {assoc['pathologie_name']}\n")
                f.write(f"   â†’ Image #{assoc['image_id']}: {assoc['image_type']}")
                if assoc['image_subtype'] != 'N/A':
                    f.write(f" - {assoc['image_subtype']}")
                f.write(f"\n   â†’ URL: {assoc['image_url']}\n")
                f.write(f"   âœ… SCORE: {assoc['score']}/100 (Association confirmÃ©e)\n")
        else:
            f.write("\nâš ï¸  Aucune association existante trouvÃ©e\n")
        
        # Section 2: Associations directes par pathologie
        direct = [a for a in associations if a['type'] == 'PATHOLOGIE_DIRECTE']
        f.write(f"\n\n{'='*100}\n")
        f.write(f"SECTION 2: IMAGES LIÃ‰ES Ã€ LA PATHOLOGIE (Ã€ ASSOCIER) ({len(direct)})\n")
        f.write(f"{'='*100}\n")
        
        if direct:
            for idx, assoc in enumerate(direct, 1):
                f.write(f"\n{idx}. Cas #{assoc['case_id']} ({assoc['case_code']})\n")
                f.write(f"   â†’ Pathologie #{assoc['pathologie_id']}: {assoc['pathologie_name']}\n")
                f.write(f"   â†’ Image #{assoc['image_id']}: {assoc['image_type']}")
                if assoc['image_subtype'] != 'N/A':
                    f.write(f" - {assoc['image_subtype']}")
                f.write(f"\n   â†’ URL: {assoc['image_url']}\n")
                f.write(f"   ğŸ”— SCORE: {assoc['score']}/100 (Image dÃ©jÃ  liÃ©e Ã  cette pathologie)\n")
        else:
            f.write("\nâš ï¸  Aucune image directement liÃ©e aux pathologies des cas\n")
        
        # Section 3: Propositions intelligentes
        propositions = [a for a in associations if a['type'] == 'PROPOSITION']
        f.write(f"\n\n{'='*100}\n")
        f.write(f"SECTION 3: PROPOSITIONS D'ASSOCIATIONS ({len(propositions)})\n")
        f.write(f"{'='*100}\n")
        
        if propositions:
            current_case = None
            for idx, assoc in enumerate(sorted(propositions, key=lambda x: (x['case_id'], -x['score'])), 1):
                if current_case != assoc['case_id']:
                    current_case = assoc['case_id']
                    f.write(f"\n{'â”€'*100}\n")
                    f.write(f"CAS #{assoc['case_id']} ({assoc['case_code']})\n")
                    f.write(f"Pathologie: {assoc['pathologie_name']}\n")
                    f.write(f"{'â”€'*100}\n")
                
                f.write(f"\n   Proposition #{idx}:\n")
                f.write(f"   â†’ Image #{assoc['image_id']}: {assoc['image_type']}")
                if assoc['image_subtype'] != 'N/A':
                    f.write(f" - {assoc['image_subtype']}")
                f.write(f"\n   â†’ Description: {assoc['image_description']}\n")
                f.write(f"   â†’ URL: {assoc['image_url']}\n")
                f.write(f"   ğŸ’¡ SCORE: {assoc['score']}/100 (Correspondance suggÃ©rÃ©e)\n")
        else:
            f.write("\nâš ï¸  Aucune proposition d'association trouvÃ©e\n")
        
        # Section 4: Autres pathologies avec images (sans cas cliniques)
        f.write(f"\n\n{'='*100}\n")
        f.write(f"SECTION 4: PATHOLOGIES AVEC IMAGES (SANS CAS CLINIQUE) ({len(other_pathologies_with_images)})\n")
        f.write(f"{'='*100}\n")
        
        if other_pathologies_with_images:
            for idx, patho in enumerate(other_pathologies_with_images, 1):
                f.write(f"\n{idx}. Pathologie #{patho['pathologie_id']}: {patho['pathologie_name']}\n")
                f.write(f"   Code ICD-10: {patho['pathologie_code']}\n")
                f.write(f"   Nombre d'images: {patho['nb_images']}\n")
                for img_idx, img in enumerate(patho['images'][:5], 1):  # Max 5 images
                    f.write(f"   â†’ Image #{img['id']}: {img.get('type_examen', 'N/A')}")
                    if img.get('sous_type'):
                        f.write(f" - {img['sous_type']}")
                    f.write(f"\n")
                if patho['nb_images'] > 5:
                    f.write(f"   ... et {patho['nb_images'] - 5} autres images\n")
        
        # RÃ©sumÃ© des actions recommandÃ©es
        f.write(f"\n\n{'='*100}\n")
        f.write("RÃ‰SUMÃ‰ ET ACTIONS RECOMMANDÃ‰ES\n")
        f.write(f"{'='*100}\n")
        f.write(f"\nâœ… {len(existing)} associations dÃ©jÃ  en place\n")
        f.write(f"ğŸ”— {len(direct)} images Ã  associer directement (mÃªme pathologie)\n")
        f.write(f"ğŸ’¡ {len(propositions)} propositions d'associations intelligentes\n")
        f.write(f"ğŸ“‹ {len(other_pathologies_with_images)} pathologies avec images (potentiel pour nouveaux cas)\n")
        
        # Format CSV pour import
        f.write(f"\n\n{'='*100}\n")
        f.write("FORMAT CSV POUR IMPORT\n")
        f.write(f"{'='*100}\n")
        f.write("\ncase_id,pathologie_id,pathologie_name,image_id,image_type,score,type_association\n")
        
        for assoc in sorted(associations, key=lambda x: (x['case_id'], -x['score'])):
            f.write(f"{assoc['case_id']},{assoc['pathologie_id']},\"{assoc['pathologie_name']}\",")
            f.write(f"{assoc['image_id']},\"{assoc['image_type']}\",{assoc['score']},{assoc['type']}\n")
    
    print_color(f"\nâœ… Rapport gÃ©nÃ©rÃ© avec succÃ¨s!", Colors.GREEN)
    print_color(f"ğŸ“„ Fichier: {OUTPUT_FILE}", Colors.CYAN)
    print_color(f"\nğŸ“Š RÃ©sumÃ©:", Colors.YELLOW)
    print_color(f"   â€¢ {len(existing)} associations existantes", Colors.GREEN)
    print_color(f"   â€¢ {len(direct)} images liÃ©es Ã  la pathologie", Colors.BLUE)
    print_color(f"   â€¢ {len(propositions)} propositions intelligentes", Colors.MAGENTA)
    print_color(f"   â€¢ {len(other_pathologies_with_images)} pathologies avec images (sans cas)", Colors.YELLOW)
    print_color(f"\n{'='*100}\n", Colors.CYAN)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print_color("\n\nâš ï¸  Analyse interrompue", Colors.YELLOW)
    except Exception as e:
        print_color(f"\n\nâŒ ERREUR: {str(e)}", Colors.RED)
        import traceback
        traceback.print_exc()

=== Fichier: ./testend.py ===

import requests
import json
from datetime import datetime
import time

# Configuration
BASE_URL ="http://127.0.0.1:8000/"
API_BASE = f"{BASE_URL}/api/v1"
OUTPUT_FILE = f"test_progression_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    END = '\033[0m'

class ProgressionTester:
    def __init__(self, filename):
        self.filename = filename
        self.file = open(filename, 'w', encoding='utf-8')
        self.test_count = 0
        self.success_count = 0
        self.fail_count = 0
        self.learner_id = 7  # ID de l'apprenant test
        self.category = "Urgences"
        self.sessions_history = []
        
    def write(self, message, color=None):
        self.file.write(message + '\n')
        self.file.flush()
        if color:
            print(f"{color}{message}{Colors.END}")
        else:
            print(message)
    
    def section(self, title):
        separator = '='*100
        self.write(f"\n{separator}")
        self.write(f"  {title}")
        self.write(separator)
    
    def test_header(self, description):
        self.test_count += 1
        header = f"\n{'â”€'*100}\nTEST #{self.test_count}: {description}\n{'â”€'*100}"
        self.write(header, Colors.CYAN)
    
    def mark_success(self, message=""):
        self.success_count += 1
        self.write(f"âœ… SUCCÃˆS: {message}", Colors.GREEN)
    
    def mark_failure(self, message=""):
        self.fail_count += 1
        self.write(f"âŒ Ã‰CHEC: {message}", Colors.RED)
    
    def mark_warning(self, message=""):
        self.write(f"âš ï¸  ATTENTION: {message}", Colors.YELLOW)
    
    def summary(self):
        self.section("RÃ‰SUMÃ‰ DES TESTS DE PROGRESSION")
        self.write(f"Total de tests: {self.test_count}")
        self.write(f"SuccÃ¨s: {self.success_count}", Colors.GREEN)
        self.write(f"Ã‰checs: {self.fail_count}", Colors.RED)
        self.write(f"Taux de rÃ©ussite: {(self.success_count/self.test_count*100):.1f}%" if self.test_count > 0 else "N/A")
    
    def close(self):
        self.file.close()

tester = None

# =============================================================================
# TEST 1: VÃ‰RIFICATION REPRISE DE SESSION
# =============================================================================

def test_session_resume():
    """VÃ©rifier si la sÃ©lection d'une catÃ©gorie reprend la derniÃ¨re session non terminÃ©e"""
    tester.test_header("Reprise de session non terminÃ©e")
    
    tester.write(f"\nğŸ“‹ TEST: SÃ©lection de catÃ©gorie '{tester.category}'", Colors.BLUE)
    tester.write(f"   Comportement attendu: Reprendre la derniÃ¨re session non terminÃ©e")
    
    data = {
        "learner_id": tester.learner_id,
        "category": tester.category
    }
    
    try:
        # PremiÃ¨re session
        response1 = requests.post(f"{API_BASE}/simulation/sessions/start", json=data, timeout=30)
        
        if response1.status_code == 201:
            session1 = response1.json()
            session1_id = session1['session_id']
            tester.sessions_history.append(session1)
            
            tester.write(f"\n   Session 1 crÃ©Ã©e: {session1_id}")
            tester.write(f"   Type: {session1.get('session_type')}")
            tester.write(f"   Cas clinique: {session1.get('clinical_case', {}).get('code_fultang')}")
            tester.write(f"   Niveau difficultÃ©: {session1.get('clinical_case', {}).get('niveau_difficulte')}")
            
            time.sleep(2)
            
            # DeuxiÃ¨me tentative SANS terminer la premiÃ¨re
            tester.write(f"\n   â³ Nouvelle demande de session SANS terminer la premiÃ¨re...", Colors.YELLOW)
            response2 = requests.post(f"{API_BASE}/simulation/sessions/start", json=data, timeout=30)
            
            if response2.status_code == 201:
                session2 = response2.json()
                session2_id = session2['session_id']
                
                if session1_id == session2_id:
                    tester.mark_success("âœ… Session existante reprise (mÃªme ID)")
                    return True
                else:
                    tester.write(f"\n   Session 2 crÃ©Ã©e: {session2_id}")
                    tester.write(f"   Type: {session2.get('session_type')}")
                    
                    tester.mark_warning("Nouvelle session crÃ©Ã©e au lieu de reprendre l'existante")
                    tester.write(f"      Attendu: {session1_id}")
                    tester.write(f"      Obtenu: {session2_id}")
                    return False
            else:
                tester.mark_failure(f"Erreur lors de la 2Ã¨me demande: {response2.status_code}")
                return False
        else:
            tester.mark_failure(f"Impossible de crÃ©er la session initiale: {response1.status_code}")
            return False
            
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TEST 2: CYCLE FORMATIF (3 sessions)
# =============================================================================

def test_formative_cycle():
    """Tester le cycle de 3 Ã©valuations formatives"""
    tester.section("CYCLE DE 3 Ã‰VALUATIONS FORMATIVES")
    
    formative_sessions = []
    
    for i in range(1, 4):
        tester.test_header(f"Session Formative #{i}/3")
        
        data = {
            "learner_id": tester.learner_id,
            "category": tester.category
        }
        
        try:
            response = requests.post(f"{API_BASE}/simulation/sessions/start", json=data, timeout=30)
            
            if response.status_code == 201:
                session = response.json()
                session_type = session.get('session_type')
                session_id = session['session_id']
                niveau = session.get('clinical_case', {}).get('niveau_difficulte')
                
                formative_sessions.append(session)
                
                tester.write(f"\nğŸ“Š Session {i}:")
                tester.write(f"   ID: {session_id}")
                tester.write(f"   Type: {session_type}")
                tester.write(f"   Niveau difficultÃ©: {niveau}/30")
                
                # VÃ©rifier que c'est bien formatif pour les 3 premiÃ¨res
                if session_type == "formatif" or session_type == "formative":
                    tester.write(f"   âœ… Type correct: {session_type}", Colors.GREEN)
                else:
                    tester.mark_warning(f"Type attendu 'formatif', obtenu '{session_type}'")
                
                # Simuler une complÃ©tion rapide (sans vraiment faire la session)
                tester.write(f"\n   ğŸ”„ Simulation de complÃ©tion de la session...")
                # Note: On devrait submit mais Ã§a crashe, donc on marque juste
                
                time.sleep(1)
                tester.mark_success(f"Session formative {i}/3 crÃ©Ã©e")
            else:
                tester.mark_failure(f"Ã‰chec crÃ©ation session {i}: {response.status_code}")
                return False
                
        except Exception as e:
            tester.mark_failure(f"Exception session {i}: {str(e)}")
            return False
    
    # VÃ©rifier que les 3 sessions ont des cas diffÃ©rents
    tester.write(f"\nğŸ” VÃ‰RIFICATION: Cas cliniques diffÃ©rents?", Colors.MAGENTA)
    codes = [s.get('clinical_case', {}).get('code_fultang') for s in formative_sessions]
    niveaux = [s.get('clinical_case', {}).get('niveau_difficulte') for s in formative_sessions]
    
    tester.write(f"   Cas 1: {codes[0]} (niveau {niveaux[0]})")
    tester.write(f"   Cas 2: {codes[1]} (niveau {niveaux[1]})")
    tester.write(f"   Cas 3: {codes[2]} (niveau {niveaux[2]})")
    
    if len(set(codes)) == 3:
        tester.mark_success("3 cas cliniques diffÃ©rents âœ…")
    else:
        tester.mark_warning("Certains cas se rÃ©pÃ¨tent")
    
    return True

# =============================================================================
# TEST 3: SESSION SOMMATIVE APRÃˆS 3 FORMATIVES
# =============================================================================

def test_summative_after_formatives():
    """VÃ©rifier qu'une session sommative est proposÃ©e aprÃ¨s 3 formatives"""
    tester.test_header("Session Sommative aprÃ¨s 3 Formatives")
    
    tester.write(f"\nğŸ“‹ AprÃ¨s 3 sessions formatives, la 4Ã¨me devrait Ãªtre SOMMATIVE", Colors.BLUE)
    
    data = {
        "learner_id": tester.learner_id,
        "category": tester.category
    }
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/start", json=data, timeout=30)
        
        if response.status_code == 201:
            session = response.json()
            session_type = session.get('session_type')
            session_id = session['session_id']
            clinical_case = session.get('clinical_case', {})
            
            tester.write(f"\nğŸ“Š Session 4 (Sommative attendue):")
            tester.write(f"   ID: {session_id}")
            tester.write(f"   Type: {session_type}")
            tester.write(f"   Cas: {clinical_case.get('code_fultang')}")
            tester.write(f"   Niveau: {clinical_case.get('niveau_difficulte')}/30")
            
            if session_type == "sommatif" or session_type == "summative":
                tester.mark_success(f"âœ… Session SOMMATIVE correctement dÃ©clenchÃ©e")
                
                # VÃ©rifier que le cas fait partie des 3 prÃ©cÃ©dents (formatifs)
                tester.write(f"\nğŸ” Le cas sommative est-il parmi les 3 cas formatifs?")
                # (nÃ©cessiterait de stocker les IDs des cas formatifs)
                
                return True, session
            else:
                tester.mark_failure(f"Type attendu 'sommatif', obtenu '{session_type}'")
                return False, None
        else:
            tester.mark_failure(f"Ã‰chec: {response.status_code}")
            return False, None
            
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False, None

# =============================================================================
# TEST 4: PROGRESSION AVEC NOTE > 12/20
# =============================================================================

def test_progression_success():
    """Simuler une note > 12/20 et vÃ©rifier la progression niveau +3"""
    tester.test_header("Progression avec succÃ¨s (note > 12/20)")
    
    tester.write(f"\nğŸ“Š SIMULATION: Note sommative = 15/20 (> 12)", Colors.GREEN)
    tester.write(f"   Comportement attendu:")
    tester.write(f"   - Passer au niveau de difficultÃ© +3")
    tester.write(f"   - Nouvelle phase formative (3 sessions)")
    
    # Note: Comme le submit crashe, on ne peut pas vraiment tester
    # Mais on peut vÃ©rifier la logique attendue
    
    tester.write(f"\nâš ï¸  TEST LIMITÃ‰: Impossible de soumettre rÃ©ellement (bug end_time)", Colors.YELLOW)
    tester.write(f"   VÃ©rification thÃ©orique de la logique:")
    
    niveau_actuel = 15  # Exemple
    niveau_attendu = niveau_actuel + 3
    
    tester.write(f"\n   Si niveau actuel = {niveau_actuel}/30")
    tester.write(f"   Alors niveau suivant = {niveau_attendu}/30")
    
    # Tenter de dÃ©marrer une nouvelle session et voir le niveau
    data = {
        "learner_id": tester.learner_id,
        "category": tester.category
    }
    
    try:
        response = requests.post(f"{API_BASE}/simulation/sessions/start", json=data, timeout=30)
        
        if response.status_code == 201:
            session = response.json()
            nouveau_niveau = session.get('clinical_case', {}).get('niveau_difficulte')
            
            tester.write(f"\nğŸ“‹ Nouvelle session crÃ©Ã©e:")
            tester.write(f"   Niveau obtenu: {nouveau_niveau}/30")
            
            # On ne peut pas vraiment vÃ©rifier sans avoir fait le submit
            tester.mark_warning("Impossible de vÃ©rifier la progression rÃ©elle sans soumission fonctionnelle")
            return True
        else:
            tester.mark_failure(f"Erreur: {response.status_code}")
            return False
            
    except Exception as e:
        tester.mark_failure(f"Exception: {str(e)}")
        return False

# =============================================================================
# TEST 5: RÃ‰TROGRADATION AVEC NOTE < 12/20
# =============================================================================

def test_retrogradation_failure():
    """Simuler une note < 12/20 et vÃ©rifier la rÃ©trogradation"""
    tester.test_header("RÃ©trogradation avec Ã©chec (note < 12/20)")
    
    tester.write(f"\nğŸ“Š SIMULATION: Note sommative = 8/20 (< 12)", Colors.RED)
    tester.write(f"   Comportement attendu:")
    tester.write(f"   - Rester au mÃªme niveau de difficultÃ©")
    tester.write(f"   - Recommencer cycle formatif (3 sessions)")
    tester.write(f"   - Nouvelle session sommative aprÃ¨s")
    
    tester.write(f"\nâš ï¸  TEST LIMITÃ‰: Impossible de soumettre (bug end_time)", Colors.YELLOW)
    
    tester.mark_warning("FonctionnalitÃ© non testable sans correction du bug de soumission")
    return False

# =============================================================================
# TEST 6: Ã‰CHELLE DE NOTATION
# =============================================================================

def test_scoring_scale():
    """VÃ©rifier l'Ã©chelle de notation et conversion"""
    tester.test_header("VÃ©rification de l'Ã©chelle de notation")
    
    tester.write(f"\nğŸ“Š Ã‰CHELLES ATTENDUES:", Colors.BLUE)
    tester.write(f"   Niveau de difficultÃ©: 0-30")
    tester.write(f"   Note finale: 0-20")
    tester.write(f"   Seuil de rÃ©ussite: 12/20 (60%)")
    
    tester.write(f"\nğŸ” VÃ‰RIFICATION DANS LES LOGS PRÃ‰CÃ‰DENTS:")
    tester.write(f"   Score calculÃ©: 14.0")
    tester.write(f"   âŒ Ã‰chelle incorrecte! Le score est sur 30, pas sur 20")
    
    tester.write(f"\nğŸ“ PROBLÃˆME DÃ‰TECTÃ‰:", Colors.YELLOW)
    tester.write(f"   Le systÃ¨me calcule un score sur 30 points:")
    tester.write(f"   - score_diagnostic: /10")
    tester.write(f"   - score_therapeutique: /10")
    tester.write(f"   - score_demarche: /10")
    tester.write(f"   TOTAL: /30")
    
    tester.write(f"\n   Mais devrait Ãªtre sur /20 selon vos specs!")
    
    tester.write(f"\nğŸ’¡ CONVERSION NÃ‰CESSAIRE:")
    tester.write(f"   score_sur_20 = (score_sur_30 / 30) * 20")
    tester.write(f"   Exemple: 14/30 = (14/30)*20 = 9.33/20")
    
    tester.mark_warning("Ã‰chelle de notation incorrecte (30 au lieu de 20)")
    return False

# =============================================================================
# TEST 7: RECOMMANDATION NEXT_STEP
# =============================================================================

def test_recommendation_logic():
    """VÃ©rifier la logique de recommandation aprÃ¨s Ã©valuation"""
    tester.test_header("Logique de recommandation post-Ã©valuation")
    
    tester.write(f"\nğŸ“‹ RECOMMANDATIONS ATTENDUES:", Colors.BLUE)
    
    scenarios = [
        {"note": 18, "attendu": "Progresser niveau +3, nouvelle phase formative"},
        {"note": 15, "attendu": "Progresser niveau +3, nouvelle phase formative"},
        {"note": 12, "attendu": "Progresser niveau +3, nouvelle phase formative (limite)"},
        {"note": 11, "attendu": "Recommencer cycle formatif au mÃªme niveau"},
        {"note": 8, "attendu": "Recommencer cycle formatif au mÃªme niveau"},
        {"note": 5, "attendu": "Recommencer cycle formatif au mÃªme niveau"},
    ]
    
    for scenario in scenarios:
        note = scenario["note"]
        attendu = scenario["attendu"]
        statut = "âœ… RÃ‰USSITE" if note >= 12 else "âŒ Ã‰CHEC"
        
        tester.write(f"\n   Note: {note}/20 â†’ {statut}")
        tester.write(f"   Recommandation: {attendu}")
    
    tester.write(f"\nâš ï¸  IMPOSSIBLE Ã€ TESTER: Bug de soumission empÃªche validation", Colors.YELLOW)
    tester.mark_warning("Logique de recommandation non vÃ©rifiable")
    return False

# =============================================================================
# TEST 8: SUIVI DE PROGRESSION PAR CATÃ‰GORIE
# =============================================================================

def test_category_progression_tracking():
    """VÃ©rifier le suivi de progression par catÃ©gorie"""
    tester.test_header("Suivi de progression par catÃ©gorie")
    
    categories = ["Infectiologie", "Cardiologie", "PÃ©diatrie"]
    
    tester.write(f"\nğŸ“Š TEST: Progression indÃ©pendante par catÃ©gorie", Colors.BLUE)
    tester.write(f"   L'apprenant devrait avoir un niveau diffÃ©rent dans chaque catÃ©gorie")
    
    for cat in categories:
        data = {
            "learner_id": tester.learner_id,
            "category": cat
        }
        
        try:
            response = requests.post(f"{API_BASE}/simulation/sessions/start", json=data, timeout=30)
            
            if response.status_code == 201:
                session = response.json()
                niveau = session.get('clinical_case', {}).get('niveau_difficulte')
                session_type = session.get('session_type')
                
                tester.write(f"\n   {cat}:")
                tester.write(f"   - Niveau: {niveau}/30")
                tester.write(f"   - Type session: {session_type}")
                
                time.sleep(1)
            else:
                tester.write(f"\n   {cat}: Erreur {response.status_code}")
                
        except Exception as e:
            tester.write(f"\n   {cat}: Exception {str(e)}")
    
    tester.mark_warning("VÃ©rification partielle - Niveaux affichÃ©s mais progression non confirmÃ©e")
    return True

# =============================================================================
# FONCTION PRINCIPALE
# =============================================================================

def main():
    global tester
    tester = ProgressionTester(OUTPUT_FILE)
    
    tester.section("TEST DU WORKFLOW DE PROGRESSION PÃ‰DAGOGIQUE")
    tester.write(f"URL: {BASE_URL}")
    tester.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    tester.write(f"Apprenant ID: {tester.learner_id}")
    tester.write(f"CatÃ©gorie testÃ©e: {tester.category}")
    
    tester.write(f"\nğŸ“‹ LOGIQUE ATTENDUE:", Colors.MAGENTA)
    tester.write(f"1. SÃ©lection catÃ©gorie â†’ Reprend session non terminÃ©e OU nouvelle session")
    tester.write(f"2. Phase FORMATIVE: 3 sessions d'apprentissage")
    tester.write(f"3. Phase SOMMATIVE: 1 session d'Ã©valuation (cas alÃ©atoire parmi les 3 formatifs)")
    tester.write(f"4. Si note â‰¥ 12/20 â†’ Niveau +3, nouvelle phase formative")
    tester.write(f"5. Si note < 12/20 â†’ MÃªme niveau, recommencer cycle formatif")
    tester.write(f"6. Progression indÃ©pendante par catÃ©gorie")
    
    try:
        # Test 1: Reprise de session
        test_session_resume()
        time.sleep(2)
        
        # Test 2: Cycle formatif
        test_formative_cycle()
        time.sleep(2)
        
        # Test 3: Session sommative
        test_summative_after_formatives()
        time.sleep(2)
        
        # Test 4: Progression succÃ¨s
        test_progression_success()
        time.sleep(2)
        
        # Test 5: RÃ©trogradation
        test_retrogradation_failure()
        time.sleep(1)
        
        # Test 6: Ã‰chelle notation
        test_scoring_scale()
        time.sleep(1)
        
        # Test 7: Recommandations
        test_recommendation_logic()
        time.sleep(1)
        
        # Test 8: Suivi par catÃ©gorie
        test_category_progression_tracking()
        
        # RÃ©sumÃ©
        tester.summary()
        
        # Analyse finale
        tester.section("ANALYSE DE L'IMPLÃ‰MENTATION")
        
        tester.write(f"\nğŸ” FONCTIONNALITÃ‰S DÃ‰TECTÃ‰ES:", Colors.BLUE)
        tester.write(f"âœ… CrÃ©ation de sessions par catÃ©gorie")
        tester.write(f"âœ… Attribution de cas cliniques avec niveaux de difficultÃ©")
        tester.write(f"âœ… Types de session (test/formatif/sommatif)")
        tester.write(f"âŒ Reprise automatique de session non terminÃ©e")
        tester.write(f"âŒ Cycle automatique 3 formatifs â†’ 1 sommatif")
        tester.write(f"âŒ Progression automatique niveau +3")
        tester.write(f"âŒ RÃ©trogradation si Ã©chec")
        tester.write(f"âŒ Conversion score 30 â†’ 20")
        
        tester.write(f"\nğŸš¨ BLOQUEURS MAJEURS:", Colors.RED)
        tester.write(f"1. Bug end_time empÃªche toute soumission")
        tester.write(f"2. Impossible de tester la progression rÃ©elle")
        tester.write(f"3. Ã‰chelle de notation incorrecte (30 vs 20)")
        tester.write(f"4. Logique de workflow non observable")
        
    except KeyboardInterrupt:
        tester.write("\n\nâš ï¸  Tests interrompus par l'utilisateur", Colors.YELLOW)
    except Exception as e:
        tester.write(f"\n\nâŒ ERREUR CRITIQUE: {str(e)}", Colors.RED)
        import traceback
        tester.write(traceback.format_exc())
    finally:
        tester.summary()
        tester.close()
        print(f"\n{Colors.GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print(f"â•‘  TESTS TERMINÃ‰S                                                â•‘")
        print(f"â•‘  RÃ©sultats: {OUTPUT_FILE:46s} â•‘")
        print(f"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.END}\n")

if __name__ == "__main__":
    main()

