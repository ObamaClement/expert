

### FILE: ./app/main.py

from fastapi import FastAPI
from .api.v1 import symptoms,diseases,medications,media,clinical_cases,expert_strategies,diagnostic

app = FastAPI(
    title="STI Medical Expert Module",
    description="Base de connaissances et moteur de raisonnement pour le STI médical.",
    version="0.1.0"
)


app.include_router(symptoms.router, prefix="/api/v1")
app.include_router(diseases.router, prefix="/api/v1")
app.include_router(medications.router, prefix="/api/v1")
app.include_router(media.router, prefix="/api/v1")
app.include_router(clinical_cases.router, prefix="/api/v1")
app.include_router(expert_strategies.router, prefix="/api/v1")
app.include_router(diagnostic.router, prefix="/api/v1")

@app.get("/")
def read_root():
    """
    Endpoint racine pour vérifier que le service est en ligne.
    """
    return {"status": "Service is running"}

### FILE: ./app/core/cognitive_diagnosis.py



### FILE: ./app/core/prerequisite_graph.py



### FILE: ./app/core/htn_planner.py



### FILE: ./app/core/integrity_validator.py



### FILE: ./app/core/__init__.py



### FILE: ./app/core/q_matrix_solver.py



### FILE: ./app/core/reasoning_engine.py

from typing import List, Dict, Any

def evaluate_condition(condition: Dict[str, Any], facts: Dict[str, Any]) -> bool:
    """
    Évalue une seule condition par rapport à un ensemble de faits.
    Version très simple pour commencer.
    """
    fact_type = condition.get("fact")
    fact_value = condition.get("value")
    operator = condition.get("operator")

    if fact_type == "symptom" and operator == "present":
        return fact_value in facts.get("symptoms", [])
    
    if fact_type == "context" and operator == "is":
        return fact_value in facts.get("context", [])
    
    # Ajouter d'autres logiques d'évaluation ici plus tard (ex: age > 65)
    
    return False


def forward_chaining_engine(rules: List[Dict[str, Any]], facts: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Moteur de raisonnement simple en chaînage avant.

    :param rules: Une liste de règles, où chaque règle est un dictionnaire
                  avec les clés 'conditions' et 'actions'.
    :param facts: Un dictionnaire représentant les faits connus sur le patient
                  (ex: {"symptoms": ["Fièvre", "Toux"], "context": ["zone_endemique"]}).
    :return: Une liste de toutes les actions des règles qui ont été déclenchées.
    """
    triggered_actions = []

    for rule in rules:
        conditions = rule.get("conditions", {})
        
        # Pour l'instant, nous ne gérons que l'opérateur "AND"
        if conditions.get("operator") == "AND":
            all_conditions_met = True
            for condition in conditions.get("rules", []):
                if not evaluate_condition(condition, facts):
                    all_conditions_met = False
                    break  # Inutile de vérifier les autres conditions de cette règle
            
            if all_conditions_met:
                # Toutes les conditions sont remplies, on ajoute les actions
                triggered_actions.extend(rule.get("actions", []))

    return triggered_actions

"""""
# Ajoutez ce bloc à la fin du fichier pour tester
if __name__ == "__main__":
    # Définir une règle de test (copiée de notre exemple précédent)
    test_rule = {
        "code_regle": "DIAG_PALU_SIMPLE_01",
        "conditions": {
            "operator": "AND",
            "rules": [
                {"fact": "symptom", "value": "Fièvre", "operator": "present"},
                {"fact": "context", "value": "zone_endemique", "operator": "is"}
            ]
        },
        "actions": [
            {"action": "add_hypothesis", "pathology": "Paludisme simple", "confidence": 0.7}
        ]
    }
    
    # Définir des faits qui devraient déclencher la règle
    patient_facts = {
        "symptoms": ["Fièvre", "Toux"],
        "context": ["zone_endemique"]
    }
    
    print("Test du moteur de raisonnement...")
    conclusions = forward_chaining_engine(rules=[test_rule], facts=patient_facts)
    
    print(f"Faits: {patient_facts}")
    print(f"Règles: {[test_rule['code_regle']]}")
    print(f"Conclusions: {conclusions}")
    
    # Vérification du test
    assert len(conclusions) == 1
    assert conclusions[0]['pathology'] == 'Paludisme simple'
    print("\n✅ Test réussi !")
    
    """

### FILE: ./app/core/knowledge_graph.py



### FILE: ./app/ml/embeddings.py



### FILE: ./app/ml/__init__.py



### FILE: ./app/ml/clustering.py



### FILE: ./app/ml/recommendation.py



### FILE: ./app/ml/similarity.py



### FILE: ./app/schemas/symptom.py

from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from datetime import datetime

# ==============================================================================
# Schéma de Base
# ==============================================================================
class SymptomBase(BaseModel):
    """
    Schéma de base pour un symptôme.
    Contient les champs communs à la création et à la lecture.
    """
    nom: str
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    type_symptome: Optional[str] = None
    description: Optional[str] = None
    questions_anamnese: Optional[Dict[str, Any]] = None
    signes_alarme: bool = False


# ==============================================================================
# Schéma pour la Création (ce que l'API attend dans un POST)
# ==============================================================================
class SymptomCreate(SymptomBase):
    """
    Schéma utilisé pour créer un nouveau symptôme via l'API.
    Hérite de SymptomBase et n'ajoute aucun champ supplémentaire pour l'instant.
    """
    pass


# ==============================================================================
# Schéma pour la Mise à Jour (ce que l'API attend dans un PATCH)
# ==============================================================================
class SymptomUpdate(BaseModel):
    """
    Schéma utilisé pour mettre à jour un symptôme existant.
    Tous les champs sont optionnels pour permettre des mises à jour partielles.
    """
    nom: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    type_symptome: Optional[str] = None
    description: Optional[str] = None
    questions_anamnese: Optional[Dict[str, Any]] = None
    signes_alarme: Optional[bool] = None


# ==============================================================================
# Schéma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class Symptom(SymptomBase):
    """
    Schéma complet pour représenter un symptôme, y compris les champs
    générés par la base de données comme 'id' et 'created_at'.
    Ce sera le modèle de réponse de l'API.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        """
        Configuration pour Pydantic.
        'from_attributes = True' (anciennement 'orm_mode') permet au modèle Pydantic
        de lire les données directement depuis un objet SQLAlchemy.
        C'est le lien magique entre notre modèle de BDD et notre schéma d'API.
        """
        from_attributes = True

### FILE: ./app/schemas/medication.py

from pydantic import BaseModel
from typing import Optional, Dict, Any
from datetime import datetime

# ==============================================================================
# Schéma de Base
# ==============================================================================
class MedicationBase(BaseModel):
    """
    Schéma de base pour un médicament, contenant les champs modifiables.
    """
    dci: str
    nom_commercial: Optional[str] = None
    classe_therapeutique: Optional[str] = None
    forme_galenique: Optional[str] = None
    dosage: Optional[str] = None
    voie_administration: Optional[str] = None
    mecanisme_action: Optional[str] = None
    indications: Optional[Dict[str, Any]] = None
    contre_indications: Optional[Dict[str, Any]] = None
    effets_secondaires: Optional[Dict[str, Any]] = None
    interactions_medicamenteuses: Optional[Dict[str, Any]] = None
    precautions_emploi: Optional[str] = None
    posologie_standard: Optional[Dict[str, Any]] = None
    disponibilite_cameroun: Optional[str] = None
    cout_moyen_fcfa: Optional[int] = None
    statut_prescription: Optional[str] = None


# ==============================================================================
# Schéma pour la Création
# ==============================================================================
class MedicationCreate(MedicationBase):
    """
    Schéma utilisé pour créer un nouveau médicament.
    'dci' est le seul champ strictement requis.
    """
    pass


# ==============================================================================
# Schéma pour la Mise à Jour
# ==============================================================================
class MedicationUpdate(BaseModel):
    """
    Schéma pour la mise à jour partielle d'un médicament.
    """
    dci: Optional[str] = None
    nom_commercial: Optional[str] = None
    classe_therapeutique: Optional[str] = None
    # ... (tous les autres champs de MedicationBase en optionnel)
    forme_galenique: Optional[str] = None
    dosage: Optional[str] = None
    voie_administration: Optional[str] = None
    mecanisme_action: Optional[str] = None
    indications: Optional[Dict[str, Any]] = None
    contre_indications: Optional[Dict[str, Any]] = None
    effets_secondaires: Optional[Dict[str, Any]] = None
    interactions_medicamenteuses: Optional[Dict[str, Any]] = None
    precautions_emploi: Optional[str] = None
    posologie_standard: Optional[Dict[str, Any]] = None
    disponibilite_cameroun: Optional[str] = None
    cout_moyen_fcfa: Optional[int] = None
    statut_prescription: Optional[str] = None


# ==============================================================================
# Schéma pour la Lecture (Réponse API)
# ==============================================================================
class Medication(MedicationBase):
    """
    Schéma complet pour représenter un médicament en réponse d'API.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

### FILE: ./app/schemas/clinical_case.py

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date
from decimal import Decimal

# Importer les autres schémas pour les réponses imbriquées
from .disease import Disease
from .media import ImageMedicale
from .symptom import Symptom






# --- NOUVEAUX SOUS-SCHÉMAS ---
class SymptomInCase(BaseModel):
    symptome_id: int
    details: str # Ex: "Fièvre élevée (40°C) apparue brutalement il y a 48h"

class PresentationClinique(BaseModel):
    histoire_maladie: str
    symptomes_patient: List[SymptomInCase]
    antecedents: Optional[Dict[str, Any]] = None
# ==============================================================================
# Schéma de Base et de Création
# ==============================================================================
class ClinicalCaseBase(BaseModel):
    """
    Schéma de base pour un cas clinique, contenant les champs éditables.
    """
    code_fultang: str = Field(..., description="Identifiant unique (Fultang ou synthétique)")
    pathologie_principale_id: Optional[int] = None
    pathologies_secondaires_ids: Optional[List[int]] = []
    presentation_clinique: PresentationClinique
    donnees_paracliniques: Optional[Dict[str, Any]] = None
    evolution_patient: Optional[str] = None
    images_associees_ids: Optional[List[int]] = []
    sons_associes_ids: Optional[List[int]] = []
    medicaments_prescrits: Optional[List[Dict[str, Any]]] = []
    niveau_difficulte: int = Field(default=3, ge=1, le=5)
    duree_estimee_resolution_min: Optional[int] = None
    objectifs_apprentissage: Optional[List[str]] = []
    competences_requises: Optional[Dict[str, Any]] = {}


class ClinicalCaseCreate(ClinicalCaseBase):
    """
    Schéma utilisé pour créer un nouveau cas clinique via l'API.
    """
    pass


# ==============================================================================
# Schéma pour la Mise à Jour
# ==============================================================================
class ClinicalCaseUpdate(BaseModel):
    """
    Schéma pour la mise à jour partielle d'un cas clinique.
    """
    code_fultang: Optional[str] = None
    pathologie_principale_id: Optional[int] = None
    presentation_clinique: Optional[Dict[str, Any]] = None
    donnees_paracliniques: Optional[Dict[str, Any]] = None
    evolution_patient: Optional[str] = None
    images_associees_ids: Optional[List[int]] = None
    sons_associes_ids: Optional[List[int]] = None
    medicaments_prescrits: Optional[List[Dict[str, Any]]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=5)
    duree_estimee_resolution_min: Optional[int] = None
    objectifs_apprentissage: Optional[List[str]] = None
    competences_requises: Optional[Dict[str, Any]] = None
    valide_expert: Optional[bool] = None
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# Schémas pour la Lecture (Réponse API)
# ==============================================================================
class ClinicalCaseSimple(BaseModel):
    """
    Schéma simplifié pour les listes de cas cliniques.
    """
    id: int
    code_fultang: str
    niveau_difficulte: int
    pathologie_principale: Optional[Disease] = None # Affiche l'objet maladie complet
    nb_images: int
    nb_sons: int

    class Config:
        from_attributes = True


# --- NOUVEAU SCHÉMA DE LECTURE ENRICHI ---
class SymptomDetailInCase(BaseModel):
    symptome: Symptom # L'objet symptôme complet
    details: str # Les détails spécifiques au cas

class PresentationCliniqueDetail(BaseModel):
    histoire_maladie: str
    symptomes_patient: List[SymptomDetailInCase]
    antecedents: Optional[Dict[str, Any]] = None


class ClinicalCase(ClinicalCaseBase):
    id: int
    created_at: datetime
    updated_at: datetime
    
    pathologie_principale: Optional[Disease] = None
    pathologies_secondaires: List[Disease] = [] # <- AJOUTER
    images_associees: List[ImageMedicale] = []
    
    # --- ENRICHISSEMENT DE LA PRÉSENTATION CLINIQUE ---
    presentation_clinique_detail: Optional[PresentationCliniqueDetail] = None

    class Config:
        from_attributes = True



### FILE: ./app/schemas/relations.py

from pydantic import BaseModel, Field
from typing import Any, Dict, Optional
from decimal import Decimal

# Importer les schémas de base pour l'affichage
from .symptom import Symptom
from .disease import Disease
from .medication import Medication


# ==============================================================================
# Schéma de Base et de Création pour l'Association
# ==============================================================================
class PathologieSymptomeBase(BaseModel):
    """
    Schéma de base pour l'association Pathologie-Symptôme.
    Contient les champs nécessaires pour créer ou mettre à jour le lien.
    """
    pathologie_id: int
    symptome_id: int
    probabilite: Optional[Decimal] = Field(None, ge=0, le=1)
    sensibilite: Optional[Decimal] = Field(None, ge=0, le=1)
    specificite: Optional[Decimal] = Field(None, ge=0, le=1)
    phase_maladie: Optional[str] = None
    frequence: Optional[str] = None
    est_pathognomonique: bool = False
    importance_diagnostique: Optional[int] = Field(None, ge=1, le=5)

class PathologieSymptomeCreate(PathologieSymptomeBase):
    """
    Schéma utilisé spécifiquement pour créer une nouvelle association.
    """
    pass


# ==============================================================================
# Schémas pour la Lecture (Réponse de l'API)
# ==============================================================================
class PathologieSymptome(PathologieSymptomeBase):
    """
    Schéma complet pour la réponse de l'API, incluant l'ID de l'association.
    """
    id: int

    class Config:
        from_attributes = True


class SymptomForDiseaseDetail(BaseModel):
    """
    Schéma pour afficher les détails d'un symptôme DANS le contexte d'une pathologie.
    """
    symptome: Symptom
    probabilite: Optional[Decimal]
    importance_diagnostique: Optional[int]
    est_pathognomonique: bool

    class Config:
        from_attributes = True


class DiseaseForSymptomDetail(BaseModel):
    """
    Schéma pour afficher les détails d'une pathologie DANS le contexte d'un symptôme
    (utile pour le diagnostic différentiel).
    """
    pathologie: Disease
    probabilite: Optional[Decimal]
    importance_diagnostique: Optional[int]

    class Config:
        from_attributes = True



# Contenu à AJOUTER à la fin de app/schemas/relations.py

# Importer le schéma de base pour l'affichage


# ==============================================================================
# Schémas pour l'Association Traitement-Pathologie
# ==============================================================================
class TraitementPathologieBase(BaseModel):
    pathologie_id: int
    medicament_id: int
    type_traitement: Optional[str] = None
    ligne_traitement: Optional[int] = None
    indication_precise: Optional[str] = None
    efficacite_taux: Optional[Decimal] = Field(None, ge=0, le=100)
    duree_traitement_jours: Optional[int] = None
    posologie_detaillee: Optional[Dict[str, Any]] = None
    niveau_preuve: Optional[str] = None
    guidelines_source: Optional[str] = None
    rang_preference: Optional[int] = 99

class TraitementPathologieCreate(TraitementPathologieBase):
    pass

class TraitementPathologie(TraitementPathologieBase):
    id: int
    class Config:
        from_attributes = True

class MedicationForDiseaseDetail(BaseModel):
    """
    Schéma pour afficher les détails d'un médicament DANS le contexte d'une pathologie.
    """
    medicament: Medication
    type_traitement: Optional[str]
    ligne_traitement: Optional[int]
    rang_preference: Optional[int]
    
    class Config:
        from_attributes = True

# ==============================================================================
# Schémas pour l'Association Traitement-Symptôme
# ==============================================================================
class TraitementSymptomeBase(BaseModel):
    symptome_id: int
    medicament_id: int
    efficacite: Optional[str] = None
    rapidite_action: Optional[str] = None
    posologie_recommandee: Optional[str] = None
    rang_preference: Optional[int] = 99

class TraitementSymptomeCreate(TraitementSymptomeBase):
    pass

class TraitementSymptome(TraitementSymptomeBase):
    id: int
    class Config:
        from_attributes = True

class MedicationForSymptomDetail(BaseModel):
    """
    Schéma pour afficher les détails d'un médicament DANS le contexte d'un symptôme.
    """
    medicament: Medication
    efficacite: Optional[str]
    rang_preference: Optional[int]

    class Config:
        from_attributes = True

### FILE: ./app/schemas/__init__.py

from .symptom import SymptomCreate,SymptomBase,SymptomUpdate, Symptom
from .disease import DiseaseCreate,DiseaseBase,DiseaseUpdate, Disease
from . import relations
from .medication import MedicationCreate,MedicationBase,MedicationUpdate, Medication
from .media import ImageMedicaleBase,ImageMedicaleUpdate, ImageMedicale
from .clinical_case import ClinicalCaseCreate,ClinicalCaseBase,ClinicalCaseUpdate, ClinicalCase
from .expert_strategy import ExpertStrategyCreate,ExpertStrategyBase,ExpertStrategyUpdate, ExpertStrategy

### FILE: ./app/schemas/expert_strategy.py

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date
from decimal import Decimal

# ==============================================================================
# Schéma de Base
# ==============================================================================
class ExpertStrategyBase(BaseModel):
    """
    Schéma de base pour une règle/stratégie experte.
    """
    code_regle: str = Field(..., max_length=50)
    categorie: str
    priorite: int = Field(default=5, ge=1, le=10)
    conditions: Dict[str, Any]
    actions: List[Dict[str, Any]]
    description_naturelle: Optional[str] = None
    justification_medicale: Optional[str] = None
    expert_auteur: Optional[str] = None
    date_validation: Optional[date] = None
    est_active: bool = True


# ==============================================================================
# Schéma pour la Création
# ==============================================================================
class ExpertStrategyCreate(ExpertStrategyBase):
    """
    Schéma utilisé pour créer une nouvelle règle.
    """
    pass


# ==============================================================================
# Schéma pour la Mise à Jour
# ==============================================================================
class ExpertStrategyUpdate(BaseModel):
    """
    Schéma pour la mise à jour partielle d'une règle.
    """
    code_regle: Optional[str] = Field(None, max_length=50)
    categorie: Optional[str] = None
    priorite: Optional[int] = Field(None, ge=1, le=10)
    conditions: Optional[Dict[str, Any]] = None
    actions: Optional[List[Dict[str, Any]]] = None
    description_naturelle: Optional[str] = None
    justification_medicale: Optional[str] = None
    expert_auteur: Optional[str] = None
    date_validation: Optional[date] = None
    est_active: Optional[bool] = None


# ==============================================================================
# Schéma pour la Lecture (Réponse API)
# ==============================================================================
class ExpertStrategy(ExpertStrategyBase):
    """
    Schéma complet pour représenter une règle en réponse d'API.
    """
    id: int
    nb_activations: int
    taux_succes: Optional[Decimal] = None
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

### FILE: ./app/schemas/response.py



### FILE: ./app/schemas/media.py

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, date

# ==============================================================================
# Schéma de Base pour les Métadonnées d'une Image
# ==============================================================================
class ImageMedicaleBase(BaseModel):
    """
    Schéma de base contenant les métadonnées modifiables d'une image médicale.
    """
    type_examen: str
    sous_type: Optional[str] = None
    pathologie_id: Optional[int] = None
    description: Optional[str] = None
    signes_radiologiques: Optional[Dict[str, Any]] = None
    annotations: Optional[List[Dict[str, Any]]] = None
    interpretation_experte: Optional[str] = None
    diagnostic_differentiel: Optional[List[str]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=5)
    qualite_image: Optional[int] = Field(None, ge=1, le=5)
    valide_expert: Optional[bool] = False
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# Schéma pour la Mise à Jour des Métadonnées
# ==============================================================================
class ImageMedicaleUpdate(BaseModel):
    """
    Schéma pour la mise à jour partielle des métadonnées d'une image.
    Tous les champs sont optionnels.
    """
    type_examen: Optional[str] = None
    sous_type: Optional[str] = None
    pathologie_id: Optional[int] = None
    description: Optional[str] = None
    signes_radiologiques: Optional[Dict[str, Any]] = None
    annotations: Optional[List[Dict[str, Any]]] = None
    interpretation_experte: Optional[str] = None
    diagnostic_differentiel: Optional[List[str]] = None
    niveau_difficulte: Optional[int] = Field(None, ge=1, le=5)
    qualite_image: Optional[int] = Field(None, ge=1, le=5)
    valide_expert: Optional[bool] = None
    expert_validateur: Optional[str] = None
    date_validation: Optional[date] = None


# ==============================================================================
# Schéma pour la Lecture (Réponse API)
# ==============================================================================
class ImageMedicale(ImageMedicaleBase):
    """
    Schéma complet pour représenter les métadonnées d'une image en réponse d'API.
    """
    id: int
    fichier_url: str
    fichier_miniature_url: Optional[str] = None
    format_image: Optional[str] = None
    taille_ko: Optional[int] = None
    resolution: Optional[str] = None
    created_at: datetime

    class Config:
        from_attributes = True

# Nous ajouterons les schémas pour SonMedical ici plus tard.

### FILE: ./app/schemas/disease.py

from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime
from decimal import Decimal

# ==============================================================================
# Schéma de Base
# ==============================================================================
class DiseaseBase(BaseModel):
    """
    Schéma de base pour une pathologie, contenant les champs modifiables.
    """
    nom_fr: str
    code_icd10: str
    nom_en: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    prevalence_cameroun: Optional[Decimal] = Field(None, ge=0, le=100)
    niveau_gravite: Optional[int] = Field(None, ge=1, le=5)
    description: Optional[str] = None
    physiopathologie: Optional[str] = None
    evolution_naturelle: Optional[str] = None
    complications: Optional[Dict[str, Any]] = None
    facteurs_risque: Optional[Dict[str, Any]] = None
    prevention: Optional[str] = None


# ==============================================================================
# Schéma pour la Création (ce que l'API attend dans un POST)
# ==============================================================================
class DiseaseCreate(DiseaseBase):
    """
    Schéma utilisé pour créer une nouvelle pathologie.
    """
    pass


# ==============================================================================
# Schéma pour la Mise à Jour (ce que l'API attend dans un PATCH)
# ==============================================================================
class DiseaseUpdate(BaseModel):
    """
    Schéma pour la mise à jour partielle d'une pathologie.
    Tous les champs sont optionnels.
    """
    nom_fr: Optional[str] = None
    code_icd10: Optional[str] = None
    nom_en: Optional[str] = None
    nom_local: Optional[str] = None
    categorie: Optional[str] = None
    prevalence_cameroun: Optional[Decimal] = Field(None, ge=0, le=100)
    niveau_gravite: Optional[int] = Field(None, ge=1, le=5)
    description: Optional[str] = None
    physiopathologie: Optional[str] = None
    evolution_naturelle: Optional[str] = None
    complications: Optional[Dict[str, Any]] = None
    facteurs_risque: Optional[Dict[str, Any]] = None
    prevention: Optional[str] = None


# ==============================================================================
# Schéma pour la Lecture (ce que l'API renvoie)
# ==============================================================================
class Disease(DiseaseBase):
    """
    Schéma complet pour représenter une pathologie en réponse d'API.
    Inclut les champs non modifiables comme 'id' et les horodatages.
    """
    id: int
    created_at: datetime
    updated_at: datetime

    class Config:
        """
        Permet la conversion automatique depuis un objet SQLAlchemy.
        """
        from_attributes = True

### FILE: ./app/schemas/diagnostic.py



### FILE: ./app/schemas/base.py



### FILE: ./app/schemas/request.py



### FILE: ./app/api/v1/__init__.py



### FILE: ./app/api/v1/q_matrix.py



### FILE: ./app/api/v1/fultang.py



### FILE: ./app/api/v1/media.py

from fastapi import (
    APIRouter,
    Depends,
    HTTPException,
    status,
    UploadFile,
    File,
    Form
)
from sqlalchemy.orm import Session
from typing import List, Optional

from ... import schemas, models
from ...services import media_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/media",
    tags=["Media"]
)


@router.post("/images/upload", response_model=schemas.media.ImageMedicale, status_code=status.HTTP_201_CREATED)
async def upload_image_medicale(
    file: UploadFile = File(..., description="Le fichier image à uploader"),
    type_examen: str = Form(..., description="Type d'examen (ex: Radiographie)"),
    sous_type: Optional[str] = Form(None, description="Sous-type (ex: Thorax)"),
    pathologie_id: Optional[int] = Form(None, description="ID de la pathologie associée"),
    description: Optional[str] = Form(None, description="Description de l'image"),
    db: Session = Depends(get_db)
):
    """
    Uploade une image médicale et crée l'enregistrement de ses métadonnées.
    """
    # Vérifier le type de fichier si nécessaire
    if not file.content_type.startswith("image/"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Le fichier uploadé n'est pas une image."
        )

    db_image = await media_service.create_image_medicale(
        db=db,
        file=file,
        type_examen=type_examen,
        sous_type=sous_type,
        pathologie_id=pathologie_id,
        description=description
    )
    return db_image


@router.get("/images", response_model=List[schemas.media.ImageMedicale])
def read_all_images_metadata(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    Récupère une liste des métadonnées de toutes les images médicales.
    """
    images = media_service.get_all_images_medicales(db, skip=skip, limit=limit)
    return images


@router.get("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def read_image_metadata(image_id: int, db: Session = Depends(get_db)):
    """
    Récupère les métadonnées d'une image médicale spécifique par son ID.
    """
    db_image = media_service.get_image_medicale_by_id(db, image_id=image_id)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvée.")
    return db_image


@router.patch("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def update_image_metadata(
    image_id: int,
    metadata_update: schemas.media.ImageMedicaleUpdate,
    db: Session = Depends(get_db)
):
    """
    Met à jour les métadonnées d'une image médicale existante.
    """
    db_image = media_service.update_image_medicale_metadata(db, image_id=image_id, image_update=metadata_update)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvée.")
    return db_image


@router.delete("/images/{image_id}", response_model=schemas.media.ImageMedicale)
def delete_image(image_id: int, db: Session = Depends(get_db)):
    """
    Supprime une image médicale (métadonnées et fichier physique).
    """
    db_image = media_service.delete_image_medicale(db, image_id=image_id)
    if db_image is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Image non trouvée.")
    return db_image

### FILE: ./app/api/v1/expert_strategies.py

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import expert_strategy_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/expert-strategies",
    tags=["Expert Strategies"]
)


@router.post("/", response_model=schemas.expert_strategy.ExpertStrategy, status_code=status.HTTP_201_CREATED)
def create_expert_strategy(strategy_data: schemas.expert_strategy.ExpertStrategyCreate, db: Session = Depends(get_db)):
    """
    Crée une nouvelle règle/stratégie experte.
    """
    db_strategy = expert_strategy_service.get_strategy_by_code(db, code=strategy_data.code_regle)
    if db_strategy:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Une règle avec le code '{strategy_data.code_regle}' existe déjà."
        )
    return expert_strategy_service.create_strategy(db=db, strategy=strategy_data)


@router.get("/", response_model=List[schemas.expert_strategy.ExpertStrategy])
def read_all_expert_strategies(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    Récupère une liste de toutes les règles expertes.
    """
    strategies = expert_strategy_service.get_all_strategies(db, skip=skip, limit=limit)
    return strategies


@router.get("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def read_expert_strategy(strategy_id: int, db: Session = Depends(get_db)):
    """
    Récupère une règle experte par son ID.
    """
    db_strategy = expert_strategy_service.get_strategy_by_id(db, strategy_id=strategy_id)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Règle non trouvée.")
    return db_strategy


@router.patch("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def update_expert_strategy(strategy_id: int, strategy_data: schemas.expert_strategy.ExpertStrategyUpdate, db: Session = Depends(get_db)):
    """
    Met à jour une règle experte.
    """
    db_strategy = expert_strategy_service.update_strategy(db, strategy_id=strategy_id, strategy_update=strategy_data)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Règle non trouvée.")
    return db_strategy


@router.delete("/{strategy_id}", response_model=schemas.expert_strategy.ExpertStrategy)
def delete_expert_strategy(strategy_id: int, db: Session = Depends(get_db)):
    """
    Supprime une règle experte.
    """
    db_strategy = expert_strategy_service.delete_strategy(db, strategy_id=strategy_id)
    if db_strategy is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Règle non trouvée.")
    return db_strategy

### FILE: ./app/api/v1/learning_paths.py



### FILE: ./app/api/v1/diseases.py

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import disease_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/diseases",
    tags=["Diseases"]
)


@router.post("/", response_model=schemas.disease.Disease, status_code=status.HTTP_201_CREATED)
def create_disease(disease_data: schemas.disease.DiseaseCreate, db: Session = Depends(get_db)):
    """
    Crée une nouvelle pathologie.
    Vérifie l'unicité du code CIM-10.
    """
    db_disease = disease_service.get_disease_by_icd10(db, icd10_code=disease_data.code_icd10)
    if db_disease:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Une pathologie avec le code CIM-10 '{disease_data.code_icd10}' existe déjà."
        )
    return disease_service.create_disease(db=db, disease=disease_data)


@router.get("/", response_model=List[schemas.disease.Disease])
def read_diseases(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    Récupère une liste de pathologies.
    """
    diseases = disease_service.get_all_diseases(db, skip=skip, limit=limit)
    return diseases


@router.get("/{disease_id}", response_model=schemas.disease.Disease)
def read_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    Récupère une pathologie par son ID.
    """
    db_disease = disease_service.get_disease_by_id(db, disease_id=disease_id)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvée.")
    return db_disease


@router.patch("/{disease_id}", response_model=schemas.disease.Disease)
def update_disease(disease_id: int, disease_data: schemas.disease.DiseaseUpdate, db: Session = Depends(get_db)):
    """
    Met à jour une pathologie.
    """
    db_disease = disease_service.update_disease(db, disease_id=disease_id, disease_update=disease_data)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvée.")
    return db_disease


@router.delete("/{disease_id}", response_model=schemas.disease.Disease)
def delete_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    Supprime une pathologie.
    """
    db_disease = disease_service.delete_disease(db, disease_id=disease_id)
    if db_disease is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Pathologie non trouvée.")
    return db_disease

# Contenu à AJOUTER à la fin de app/api/v1/diseases.py

@router.post(
    "/{disease_id}/symptoms",
    response_model=schemas.relations.PathologieSymptome,
    status_code=status.HTTP_201_CREATED,
    tags=["Disease-Symptom Relations"] # Un nouveau tag pour l'organisation
)
def add_symptom_to_disease(
    disease_id: int, 
    association_data: schemas.relations.PathologieSymptomeCreate, 
    db: Session = Depends(get_db)
):
    """
    Associe un symptôme à une pathologie avec des attributs de relation
    (probabilité, importance, etc.).
    """
    # Assurer la cohérence des IDs
    if disease_id != association_data.pathologie_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="L'ID de la pathologie dans l'URL ne correspond pas à celui dans le corps de la requête."
        )
    
    try:
        return disease_service.add_symptom_to_disease(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=str(e))


@router.get(
    "/{disease_id}/symptoms",
    response_model=List[schemas.relations.SymptomForDiseaseDetail],
    tags=["Disease-Symptom Relations"]
)
def get_symptoms_for_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    Récupère la liste de tous les symptômes associés à une pathologie,
    avec les détails de la relation et les détails du symptôme lui-même.
    """
    associations = disease_service.get_symptoms_for_disease(db, disease_id=disease_id)
    if not associations:
        # Ce n'est pas une erreur, la maladie peut simplement n'avoir aucun symptôme associé pour l'instant
        return []
    
    # Transformer les données pour correspondre au schéma de réponse attendu
    response = []
    for assoc in associations:
        response.append({
            "symptome": assoc.symptome, # L'objet Symptom complet
            "probabilite": assoc.probabilite,
            "importance_diagnostique": assoc.importance_diagnostique,
            "est_pathognomonique": assoc.est_pathognomonique
        })
    return response


# Contenu à AJOUTER à la fin de app/api/v1/diseases.py

@router.post(
    "/{disease_id}/treatments",
    response_model=schemas.relations.TraitementPathologie,
    status_code=status.HTTP_201_CREATED,
    tags=["Therapeutic Relations"]
)
def add_treatment_to_disease(
    disease_id: int, 
    association_data: schemas.relations.TraitementPathologieCreate, 
    db: Session = Depends(get_db)
):
    """
    Associe un médicament à une pathologie en tant que traitement.
    """
    if disease_id != association_data.pathologie_id:
        raise HTTPException(status_code=400, detail="Incohérence des IDs de pathologie.")
    
    try:
        return disease_service.add_treatment_to_disease(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get(
    "/{disease_id}/treatments",
    response_model=List[schemas.relations.MedicationForDiseaseDetail],
    tags=["Therapeutic Relations"]
)
def get_treatments_for_disease(disease_id: int, db: Session = Depends(get_db)):
    """
    Récupère la liste des traitements recommandés pour une pathologie.
    """
    associations = disease_service.get_treatments_for_disease(db, disease_id=disease_id)
    return [
        {
            "medicament": assoc.medicament,
            "type_traitement": assoc.type_traitement,
            "ligne_traitement": assoc.ligne_traitement,
            "rang_preference": assoc.rang_preference,
        }
        for assoc in associations
    ]

### FILE: ./app/api/v1/diagnostic.py

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List, Dict, Any

from ...services import diagnostic_engine
from ...dependencies import get_db

router = APIRouter(
    prefix="/diagnostic-engine",
    tags=["Diagnostic Engine"]
)


@router.post("/run", response_model=List[Dict[str, Any]])
def run_diagnostic_engine(
    patient_facts: diagnostic_engine.DiagnosticInput,
    db: Session = Depends(get_db)
):
    """
    Exécute le moteur de raisonnement sur un ensemble de faits patient.

    Prend en entrée une liste de symptômes et de contextes, et retourne
    une liste d'actions/conclusions basées sur les règles expertes actives
    dans le système.
    """
    if not patient_facts.symptoms:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="La liste des symptômes ne peut pas être vide."
        )

    conclusions = diagnostic_engine.run_diagnostic(db=db, patient_facts=patient_facts)
    
    return conclusions

### FILE: ./app/api/v1/clinical_cases.py

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import clinical_case_service, media_service, symptom_service, disease_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/clinical-cases",
    tags=["Clinical Cases"]
)


@router.post("/", response_model=schemas.clinical_case.ClinicalCase, status_code=status.HTTP_201_CREATED)
def create_clinical_case(case_data: schemas.clinical_case.ClinicalCaseCreate, db: Session = Depends(get_db)):
    """
    Crée un nouveau cas clinique.
    """
    db_case_by_code = clinical_case_service.get_case_by_code(db, code=case_data.code_fultang)
    if db_case_by_code:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Un cas avec le code '{case_data.code_fultang}' existe déjà."
        )
    try:
        # Le service create_case retournera un objet SQLAlchemy
        db_case = clinical_case_service.create_case(db=db, case=case_data)
        # La conversion vers le schéma Pydantic se fait automatiquement par FastAPI
        return db_case
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))


@router.get("/", response_model=List[schemas.clinical_case.ClinicalCaseSimple])
def read_all_clinical_cases(skip: int = 0, limit: int = 25, db: Session = Depends(get_db)):
    """
    Récupère une liste simplifiée de cas cliniques.
    """
    cases = clinical_case_service.get_all_cases(db, skip=skip, limit=limit)
    
    # La conversion vers le schéma Pydantic gère automatiquement la construction de la réponse
    # en utilisant les relations SQLAlchemy et les configurations 'from_attributes'.
    # Cependant, pour des champs calculés comme 'nb_images', nous devons construire la réponse manuellement.
    response = []
    for case in cases:
        case_simple = schemas.clinical_case.ClinicalCaseSimple(
            id=case.id,
            code_fultang=case.code_fultang,
            niveau_difficulte=case.niveau_difficulte,
            pathologie_principale=case.pathologie_principale,
            nb_images=len(case.images_associees_ids) if case.images_associees_ids else 0,
            nb_sons=len(case.sons_associes_ids) if case.sons_associes_ids else 0,
        )
        response.append(case_simple)
    return response


@router.get("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def read_clinical_case(case_id: int, db: Session = Depends(get_db)):
    """
    Récupère un cas clinique complet par son ID, avec tous les objets liés.
    """
    db_case = clinical_case_service.get_case_by_id(db, case_id=case_id)
    
    if db_case is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Cas clinique non trouvé.")
    
    # --- LOGIQUE D'ENRICHISSEMENT ---
    
    # 1. Enrichir avec les objets images complets
    images = []
    if db_case.images_associees_ids:
        for img_id in db_case.images_associees_ids:
            img = media_service.get_image_medicale_by_id(db, image_id=img_id)
            if img:
                images.append(img)
    
    # 2. Enrichir avec les objets pathologies secondaires complets
    pathologies_secondaires = []
    if db_case.pathologies_secondaires_ids:
        for p_id in db_case.pathologies_secondaires_ids:
            p_obj = disease_service.get_disease_by_id(db, disease_id=p_id)
            if p_obj:
                pathologies_secondaires.append(p_obj)

    # 3. Enrichir la présentation clinique avec les objets symptômes complets
    symptomes_details_in_case = []
    presentation_clinique_dict = db_case.presentation_clinique or {}
    if 'symptomes_patient' in presentation_clinique_dict:
        for sympt_in_case in presentation_clinique_dict['symptomes_patient']:
            sympt_obj = symptom_service.get_symptom_by_id(db, symptom_id=sympt_in_case['symptome_id'])
            if sympt_obj:
                symptomes_details_in_case.append({
                    "symptome": sympt_obj,
                    "details": sympt_in_case.get('details', '')
                })
    
    presentation_clinique_detail = {
        "histoire_maladie": presentation_clinique_dict.get('histoire_maladie', ''),
        "symptomes_patient": symptomes_details_in_case,
        "antecedents": presentation_clinique_dict.get('antecedents')
    }

    # --- CONSTRUCTION DE LA RÉPONSE FINALE ---
    
    # Convertir l'objet SQLAlchemy de base en dictionnaire
    case_dict = db_case.__dict__
    
    # Ajouter/Remplacer les champs enrichis
    case_dict['images_associees'] = images
    case_dict['pathologies_secondaires'] = pathologies_secondaires
    case_dict['presentation_clinique_detail'] = presentation_clinique_detail
    
    # Valider le dictionnaire complet avec le schéma Pydantic pour une sérialisation correcte
    validated_response = schemas.clinical_case.ClinicalCase.model_validate(case_dict, from_attributes=True)

    return validated_response


@router.patch("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def update_clinical_case(case_id: int, case_data: schemas.clinical_case.ClinicalCaseUpdate, db: Session = Depends(get_db)):
    """
    Met à jour un cas clinique.
    """
    db_case = clinical_case_service.update_case(db, case_id=case_id, case_update=case_data)
    if db_case is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Cas clinique non trouvé.")
    # La conversion vers le schéma de réponse se fait automatiquement
    return db_case


@router.delete("/{case_id}", response_model=schemas.clinical_case.ClinicalCase)
def delete_clinical_case(case_id: int, db: Session = Depends(get_db)):
    """
    Supprime un cas clinique.
    """
    db_case = clinical_case_service.delete_case(db, case_id=case_id)
    if db_case is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Cas clinique non trouvé.")
    # La conversion vers le schéma de réponse se fait automatiquement
    return db_case

### FILE: ./app/api/v1/knowledge_graph.py



### FILE: ./app/api/v1/medications.py

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import medication_service
from ...dependencies import get_db

router = APIRouter(
    prefix="/medications",
    tags=["Medications"]
)


@router.post("/", response_model=schemas.medication.Medication, status_code=status.HTTP_201_CREATED)
def create_medication(medication_data: schemas.medication.MedicationCreate, db: Session = Depends(get_db)):
    """
    Crée un nouveau médicament.
    Vérifie l'unicité du DCI (Dénomination Commune Internationale).
    """
    db_medication = medication_service.get_medication_by_dci(db, dci=medication_data.dci)
    if db_medication:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Un médicament avec le DCI '{medication_data.dci}' existe déjà."
        )
    return medication_service.create_medication(db=db, medication=medication_data)


@router.get("/", response_model=List[schemas.medication.Medication])
def read_medications(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    Récupère une liste de médicaments.
    """
    medications = medication_service.get_all_medications(db, skip=skip, limit=limit)
    return medications


@router.get("/{medication_id}", response_model=schemas.medication.Medication)
def read_medication(medication_id: int, db: Session = Depends(get_db)):
    """
    Récupère un médicament par son ID.
    """
    db_medication = medication_service.get_medication_by_id(db, medication_id=medication_id)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Médicament non trouvé.")
    return db_medication


@router.patch("/{medication_id}", response_model=schemas.medication.Medication)
def update_medication(medication_id: int, medication_data: schemas.medication.MedicationUpdate, db: Session = Depends(get_db)):
    """
    Met à jour un médicament.
    """
    db_medication = medication_service.update_medication(db, medication_id=medication_id, medication_update=medication_data)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Médicament non trouvé.")
    return db_medication


@router.delete("/{medication_id}", response_model=schemas.medication.Medication)
def delete_medication(medication_id: int, db: Session = Depends(get_db)):
    """
    Supprime un médicament.
    """
    db_medication = medication_service.delete_medication(db, medication_id=medication_id)
    if db_medication is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Médicament non trouvé.")
    return db_medication

### FILE: ./app/api/v1/symptoms.py

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List

from ... import schemas, models
from ...services import symptom_service
from ...dependencies import get_db

# Création d'un nouveau routeur.
# C'est comme une mini-application FastAPI que l'on pourra inclure dans notre app principale.
router = APIRouter(
    prefix="/symptoms",  # Toutes les routes de ce fichier commenceront par /symptoms
    tags=["Symptoms"]      # Groupe les routes dans la documentation interactive
)


@router.post("/", response_model=schemas.Symptom, status_code=status.HTTP_201_CREATED)
def create_symptom(symptom: schemas.SymptomCreate, db: Session = Depends(get_db)):
    """
    Crée un nouveau symptôme.
    """
    # Vérifie si un symptôme avec le même nom existe déjà
    db_symptom = symptom_service.get_symptom_by_name(db, name=symptom.nom)
    if db_symptom:
        raise HTTPException(status_code=400, detail="Un symptôme avec ce nom existe déjà.")
    
    return symptom_service.create_symptom(db=db, symptom=symptom)


@router.get("/", response_model=List[schemas.Symptom])
def read_symptoms(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    """
    Récupère une liste de symptômes.
    """
    symptoms = symptom_service.get_all_symptoms(db, skip=skip, limit=limit)
    return symptoms


@router.get("/{symptom_id}", response_model=schemas.Symptom)
def read_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    Récupère un symptôme par son ID.
    """
    db_symptom = symptom_service.get_symptom_by_id(db, symptom_id=symptom_id)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="Symptôme non trouvé.")
    return db_symptom


@router.patch("/{symptom_id}", response_model=schemas.Symptom)
def update_symptom(symptom_id: int, symptom: schemas.SymptomUpdate, db: Session = Depends(get_db)):
    """
    Met à jour un symptôme.
    """
    db_symptom = symptom_service.update_symptom(db, symptom_id=symptom_id, symptom_update=symptom)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="Symptôme non trouvé.")
    return db_symptom


@router.delete("/{symptom_id}", response_model=schemas.Symptom)
def delete_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    Supprime un symptôme.
    """
    db_symptom = symptom_service.delete_symptom(db, symptom_id=symptom_id)
    if db_symptom is None:
        raise HTTPException(status_code=404, detail="Symptôme non trouvé.")
    return db_symptom

# Contenu à AJOUTER à la fin de app/api/v1/symptoms.py

@router.get(
    "/{symptom_id}/diseases",
    response_model=List[schemas.relations.DiseaseForSymptomDetail],
    tags=["Disease-Symptom Relations"]
)
def get_diseases_for_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    Récupère la liste de toutes les pathologies pouvant présenter ce symptôme
    (utile pour le diagnostic différentiel).
    """
    associations = symptom_service.get_diseases_for_symptom(db, symptom_id=symptom_id)
    if not associations:
        return []
        
    response = []
    for assoc in associations:
        response.append({
            "pathologie": assoc.pathologie,
            "probabilite": assoc.probabilite,
            "importance_diagnostique": assoc.importance_diagnostique
        })
    return response



# Contenu à AJOUTER à la fin de app/api/v1/symptoms.py

@router.post(
    "/{symptom_id}/treatments",
    response_model=schemas.relations.TraitementSymptome,
    status_code=status.HTTP_201_CREATED,
    tags=["Therapeutic Relations"]
)
def add_treatment_to_symptom(
    symptom_id: int,
    association_data: schemas.relations.TraitementSymptomeCreate,
    db: Session = Depends(get_db)
):
    """
    Associe un médicament à un symptôme pour un traitement symptomatique.
    """
    if symptom_id != association_data.symptome_id:
        raise HTTPException(status_code=400, detail="Incohérence des IDs de symptôme.")
    
    try:
        return symptom_service.add_treatment_to_symptom(db=db, association_data=association_data)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get(
    "/{symptom_id}/treatments",
    response_model=List[schemas.relations.MedicationForSymptomDetail],
    tags=["Therapeutic Relations"]
)
def get_treatments_for_symptom(symptom_id: int, db: Session = Depends(get_db)):
    """
    Récupère la liste des traitements pour un symptôme spécifique.
    """
    associations = symptom_service.get_treatments_for_symptom(db, symptom_id=symptom_id)
    return [
        {
            "medicament": assoc.medicament,
            "efficacite": assoc.efficacite,
            "rang_preference": assoc.rang_preference,
        }
        for assoc in associations
    ]

### FILE: ./app/api/__init__.py



### FILE: ./app/database.py

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from .config import settings

# L'objet 'engine' est le point d'entrée principal pour communiquer avec la BDD.
engine = create_engine(
    settings.DATABASE_URL,
    # pool_pre_ping=True # Option utile en production
)

# La 'SessionLocal' est une "usine" à sessions de base de données.
# Chaque fois que nous aurons besoin de parler à la BDD, nous demanderons une session à cette usine.
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

### FILE: ./app/models/tutor_models.py

from sqlalchemy import Column, Integer, String, Text, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean
from sqlalchemy.orm import relationship
from sqlalchemy.dialects.postgresql import UUID
from .base import Base

class LearningPath(Base):
    __tablename__ = "learning_paths"

    id = Column(Integer, primary_key=True, index=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    
    algorithme_recommandation = Column(String(100))
    ordered_case_ids = Column(JSON, comment="Liste ordonnée des IDs des cas") 
    progression = Column(Float, default=0.0)
    status = Column(String(50), default="in_progress")
    created_at = Column(TIMESTAMP, server_default=text("now()"))

    learner = relationship("Learner")


class TutorDecision(Base):
    __tablename__ = "tutor_decisions"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    trigger_event_id = Column(Integer, ForeignKey("interaction_logs.id"), nullable=True)
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    strategy_used = Column(String(100)) # Socratique, Scaffolding...
    action_choisie = Column(String(100)) # Hint, Encouragement
    intervention_content = Column(Text)
    rationale = Column(JSON) # Pourquoi j'ai fait ça ?
    succes_intervention = Column(Boolean, nullable=True)

    session = relationship("SimulationSession", back_populates="tutor_decisions")


class TutorStrategiesHistory(Base):
    __tablename__ = "tutor_strategies_history"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    strategy_name = Column(String(100))
    relevance_score = Column(Float)


class TutorScaffoldingState(Base):
    __tablename__ = "tutor_scaffolding_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    competence_cible_id = Column(Integer, ForeignKey("competences_cliniques.id"))
    current_level = Column(Integer, default=0)
    indices_deja_donnes = Column(JSON)


class TutorSocraticState(Base):
    __tablename__ = "tutor_socratic_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    tactic_used = Column(String(100))
    target_concept = Column(String(255))
    step_in_dialogue = Column(Integer)


class TutorMotivationalState(Base):
    __tablename__ = "tutor_motivational_state"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    intervention_type = Column(String(100))
    emotional_state_before = Column(JSON)


class TutorFeedbackLog(Base):
    __tablename__ = "tutor_feedback_logs"
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    feedback_type = Column(String(50))
    content = Column(Text)

### FILE: ./app/models/symptom.py

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    Boolean,
    JSON,
    TIMESTAMP,
    text
)
from pgvector.sqlalchemy import Vector
from sqlalchemy.orm import relationship

from .base import Base


class Symptom(Base):
    """
    Modèle SQLAlchemy pour la table des symptômes.

    Cette table est le catalogue central de tous les symptômes connus par le système expert.
    Elle inclut des informations détaillées pour permettre un raisonnement clinique fin
    et des recherches sémantiques.
    """
    __tablename__ = "symptomes"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et Catégorisation ---
    nom = Column(String(255), nullable=False, unique=True, index=True)
    nom_local = Column(String(255), comment="Nom vernaculaire ou local, ex: 'Ntou-tou' pour la toux")
    categorie = Column(String(100), index=True, comment="Catégorie fonctionnelle (ex: Respiratoire, Neurologique, Digestif)")
    type_symptome = Column(String(50), comment="Type de symptôme (ex: Subjectif, Objectif, Signe clinique)")

    # --- Description et Contexte Clinique ---
    description = Column(Text, comment="Description détaillée du symptôme et de sa signification clinique.")
    questions_anamnese = Column(JSON, comment="Liste structurée de questions pour explorer ce symptôme (ex: PQRST)")
    signes_alarme = Column(Boolean, default=False, nullable=False, comment="Indique si ce symptôme est un signe de gravité ('red flag')")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche sémantique (ex: BioBERT)")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    # Relation vers la table d'association 'pathologie_symptomes'
    # 'back_populates' assure la synchronisation de la relation des deux côtés.
    # 'cascade' signifie que si un symptôme est supprimé, ses associations le seront aussi.
    pathologies = relationship(
        "PathologieSymptome",
        back_populates="symptome",
        cascade="all, delete-orphan"
    )
    traitements = relationship(
        "TraitementSymptome",
        back_populates="symptome",
        cascade="all, delete-orphan"
    )

    def __repr__(self) -> str:
        return f"<Symptom(id={self.id}, nom='{self.nom}')>"

### FILE: ./app/models/medication.py

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    text
)
from pgvector.sqlalchemy import Vector
from sqlalchemy.orm import relationship
from .base import Base


class Medication(Base):
    """
    Modèle SQLAlchemy pour la table des médicaments.

    Cette table est le catalogue central de tous les médicaments connus par le système,
    incluant des informations pharmacologiques et contextuelles (disponibilité, coût).
    """
    __tablename__ = "medicaments"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification ---
    nom_commercial = Column(String(255), index=True)
    dci = Column(String(255), nullable=False, index=True, comment="Dénomination Commune Internationale")
    
    # --- Classification et Formulation ---
    classe_therapeutique = Column(String(255), index=True)
    forme_galenique = Column(String(100), comment="Ex: Comprimé, Sirop, Injectable")
    dosage = Column(String(100))
    voie_administration = Column(String(100), comment="Ex: Orale, IV, IM, Cutanée")

    # --- Informations Pharmacologiques ---
    mecanisme_action = Column(Text)
    indications = Column(JSON)
    contre_indications = Column(JSON)
    effets_secondaires = Column(JSON)
    interactions_medicamenteuses = Column(JSON)
    precautions_emploi = Column(Text)
    posologie_standard = Column(JSON, comment="Posologie standard par âge, poids, indication")

    # --- Contexte Local (Cameroun) ---
    disponibilite_cameroun = Column(String(50), comment="Ex: Urbain, Rural, CHU_uniquement")
    cout_moyen_fcfa = Column(Integer)
    statut_prescription = Column(String(50), comment="Ex: Prescription_obligatoire, OTC")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche de médicaments similaires")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    traitements_pathologies = relationship("TraitementPathologie", back_populates="medicament")
    traitements_symptomes = relationship("TraitementSymptome", back_populates="medicament")

    def __repr__(self) -> str:
        return f"<Medication(id={self.id}, dci='{self.dci}')>"

### FILE: ./app/models/clinical_case.py

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    ForeignKey,
    ARRAY,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class ClinicalCase(Base):
    """
    Modèle SQLAlchemy pour la table des cas cliniques enrichis.
    C'est l'objet central utilisé pour les scénarios d'apprentissage.
    """
    __tablename__ = "cas_cliniques_enrichis"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et Intégrité ---
    code_fultang = Column(String(100), unique=True, index=True, comment="Identifiant unique provenant de Fultang (ou synthétique)")
    hash_integrite = Column(String(64), nullable=True, comment="SHA-256 pour la preuve d'intégrité des données brutes")

    # --- Liaisons aux Connaissances de Base ---
    pathologie_principale_id = Column(Integer, ForeignKey("pathologies.id"), nullable=True, index=True)
    # pathologie_secondaires_ids = Column(ARRAY(Integer), comment="Liste d'IDs de pathologies comorbides")


    pathologies_secondaires_ids = Column(ARRAY(Integer), comment="Liste d'IDs de pathologies comorbides ou secondaires")

    # --- Données du Scénario ---
    donnees_brutes = Column(JSON, nullable=True, comment="Données originales (ex: de Fultang) avant traitement")
    presentation_clinique = Column(JSON, nullable=False, comment="Histoire du patient, symptômes présentés, etc.")
    donnees_paracliniques = Column(JSON, comment="Résultats des examens pour ce cas spécifique")
    evolution_patient = Column(Text, comment="Description de l'évolution du patient pendant le cas")
    
    # --- Liaisons Multimédia ---
    images_associees_ids = Column(ARRAY(Integer), comment="Liste des IDs des images de la table 'images_medicales'")
    sons_associes_ids = Column(ARRAY(Integer), comment="Liste des IDs des sons de la table 'sons_medicaux'")

    # --- Liaisons Thérapeutiques ---
    # ordonnance_utilisee_id = Column(Integer, ForeignKey("ordonnances_types.id"), nullable=True)
    medicaments_prescrits = Column(JSON, comment="Liste des médicaments prescrits dans ce cas")

    # --- Métadonnées Pédagogiques ---
    niveau_difficulte = Column(Integer, default=3, comment="Difficulté du cas (1-5)")
    duree_estimee_resolution_min = Column(Integer, comment="Temps estimé pour résoudre le cas")
    objectifs_apprentissage = Column(JSON, comment="Liste des compétences à acquérir")
    competences_requises = Column(JSON, comment="Mapping Q-Matrix pour ce cas")

    # --- Validation ---
    valide_expert = Column(Boolean, default=False)
    
    # AJOUTER CETTE LIGNE : La Clé Étrangère
    expert_validateur = relationship("ExpertUser", back_populates="cas_valides")
    #expert_validateur = Column(String(255))
    date_validation = Column(Date)
    qualite_donnees = Column(Integer, comment="Qualité des données sources (1-5)")

    # --- Métriques d'Utilisation ---
    nb_utilisations = Column(Integer, default=0)
    note_moyenne_apprenants = Column(DECIMAL(3, 2))
    taux_succes_diagnostic = Column(DECIMAL(5, 2))
    
    # --- Intelligence Artificielle ---
    embedding_texte = Column(Vector(384), nullable=True, comment="Embedding de la description textuelle du cas")
    embedding_global = Column(Vector(1536), nullable=True, comment="Embedding multimodal fusionné (texte+image+son)")
    
    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    pathologie_principale = relationship("Disease")

    

    def __repr__(self) -> str:
        return f"<ClinicalCase(id={self.id}, code='{self.code_fultang}')>"

### FILE: ./app/models/learner_models.py

from sqlalchemy import Column, Integer, String, Float, ForeignKey, JSON, TIMESTAMP, text, Boolean
from sqlalchemy.orm import relationship
from .base import Base

class Learner(Base):
    __tablename__ = "learners"

    id = Column(Integer, primary_key=True, index=True)
    matricule = Column(String(50), unique=True, index=True)
    nom = Column(String(255))
    email = Column(String(255), unique=True, index=True)
    niveau_etudes = Column(String(50)) # Med 3, Interne...
    specialite_visee = Column(String(100))
    langue_preferee = Column(String(10), default="fr")
    date_inscription = Column(TIMESTAMP, server_default=text("now()"))

    # Relations
    competency_mastery = relationship("LearnerCompetencyMastery", back_populates="learner")
    misconceptions = relationship("LearnerMisconception", back_populates="learner")
    sessions = relationship("SimulationSession", back_populates="learner")


class LearnerCompetencyMastery(Base):
    __tablename__ = "learner_competency_mastery"

    id = Column(Integer, primary_key=True, index=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    mastery_level = Column(Float, default=0.0) # Probabilité BKT (0-1)
    confidence = Column(Float, default=0.0) # Certitude du système
    last_practice_date = Column(TIMESTAMP)
    nb_success = Column(Integer, default=0)
    nb_failures = Column(Integer, default=0)
    streak_correct = Column(Integer, default=0)

    learner = relationship("Learner", back_populates="competency_mastery")
    competence = relationship("Competence") # Lien vers Module Expert


class LearnerCognitiveProfile(Base):
    __tablename__ = "learner_cognitive_profiles"

    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"), unique=True)
    
    vitesse_assimilation = Column(Float)
    capacite_memoire_travail = Column(Float)
    tendance_impulsivite = Column(Float) # 0 (Réfléchi) - 1 (Impulsif)
    prefer_visual = Column(Boolean, default=False)
    
    learner = relationship("Learner")


class LearnerMisconception(Base):
    __tablename__ = "learner_misconceptions"

    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    
    type_erreur = Column(String(255)) # ex: "Confond Virus/Bactérie"
    frequence_apparition = Column(Integer, default=1)
    resistance_correction = Column(Float, default=0.0) # 0-1
    detected_at = Column(TIMESTAMP, server_default=text("now()"))
    
    learner = relationship("Learner", back_populates="misconceptions")


class LearnerGoal(Base):
    __tablename__ = "learner_goals"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    type_objectif = Column(String(100))
    domaine_cible = Column(String(100))
    date_limite = Column(TIMESTAMP)
    statut = Column(String(50)) # en_cours, atteint, abandonne


class LearnerPreference(Base):
    __tablename__ = "learner_preferences"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    cle = Column(String(100))
    valeur = Column(String(255))


class LearnerAchievement(Base):
    __tablename__ = "learner_achievements"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    badge_id = Column(String(100))
    date_obtention = Column(TIMESTAMP, server_default=text("now()"))


class LearnerStrategy(Base):
    __tablename__ = "learner_strategies"
    id = Column(Integer, primary_key=True)
    learner_id = Column(Integer, ForeignKey("learners.id"))
    strategy_name = Column(String(100)) # ex: "Gaming", "Help Seeking"
    frequency = Column(Integer)
    effectiveness = Column(Float)

### FILE: ./app/models/relations.py

from sqlalchemy import (
    JSON,
    Column,
    Integer,
    ForeignKey,
    DECIMAL,
    String,
    Boolean,
    Text
)
from sqlalchemy.orm import relationship

from .base import Base


class PathologieSymptome(Base):
    """
    Modèle de la table d'association entre Pathologies et Symptômes.

    Cette table matérialise la relation "plusieurs-à-plusieurs" et permet de stocker
    des informations contextuelles sur le lien, telles que la probabilité
    d'apparition, la spécificité, etc.
    """
    __tablename__ = "pathologie_symptomes"

    id = Column(Integer, primary_key=True)

    # --- Clés Étrangères ---
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=False)
    symptome_id = Column(Integer, ForeignKey("symptomes.id"), nullable=False)

    # --- Attributs de la Relation ---
    probabilite = Column(DECIMAL(5, 4), comment="Probabilité d'apparition du symptôme pour cette pathologie P(symptôme|pathologie)")
    sensibilite = Column(DECIMAL(5, 4))
    specificite = Column(DECIMAL(5, 4))
    phase_maladie = Column(String(50), comment="Phase de la maladie où le symptôme apparaît (ex: Précoce, Tardive)")
    frequence = Column(String(50), comment="Fréquence d'apparition (ex: Constant, Fréquent, Occasionnel)")
    est_pathognomonique = Column(Boolean, default=False, comment="Si True, ce symptôme seul suffit presque à poser le diagnostic")
    importance_diagnostique = Column(Integer, comment="Échelle de 1 à 5 sur l'importance de ce symptôme pour le diagnostic")

    # --- Relations Inverses (Back-population) ---
    # Permet d'accéder à l'objet parent directement depuis une instance de cette classe.
    # ex: mon_association.pathologie -> renvoie l'objet Disease
    pathologie = relationship("Disease", back_populates="symptomes")
    symptome = relationship("Symptom", back_populates="pathologies")

    def __repr__(self) -> str:
        return f"<PathologieSymptome(pathologie_id={self.pathologie_id}, symptome_id={self.symptome_id})>"
    

# Contenu à AJOUTER à la fin de app/models/relations.py

class TraitementPathologie(Base):
    """
    Table d'association pour les traitements spécifiques aux pathologies.
    """
    __tablename__ = "traitements_pathologies"

    id = Column(Integer, primary_key=True)
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=False)
    medicament_id = Column(Integer, ForeignKey("medicaments.id"), nullable=False)

    type_traitement = Column(String(50), comment="Ex: Premiere_intention, Alternative, Adjuvant")
    ligne_traitement = Column(Integer, comment="Ex: 1ère ligne, 2e ligne")
    indication_precise = Column(Text)
    efficacite_taux = Column(DECIMAL(5, 2), comment="Taux de succès en %")
    duree_traitement_jours = Column(Integer)
    posologie_detaillee = Column(JSON)
    niveau_preuve = Column(String(50), comment="Grade de recommandation (A, B, C)")
    guidelines_source = Column(String(255), comment="Source (OMS, MINSANTE Cameroun, etc.)")
    rang_preference = Column(Integer, default=99)

    pathologie = relationship("Disease", back_populates="traitements")
    medicament = relationship("Medication", back_populates="traitements_pathologies")


class TraitementSymptome(Base):
    """
    Table d'association pour les traitements symptomatiques.
    """
    __tablename__ = "traitements_symptomes"

    id = Column(Integer, primary_key=True)
    symptome_id = Column(Integer, ForeignKey("symptomes.id"), nullable=False)
    medicament_id = Column(Integer, ForeignKey("medicaments.id"), nullable=False)

    efficacite = Column(String(50), comment="Ex: Tres_efficace, Efficace, Modere")
    rapidite_action = Column(String(100), comment="Ex: Immediate, <30min")
    posologie_recommandee = Column(Text)
    rang_preference = Column(Integer, default=99)
    
    symptome = relationship("Symptom", back_populates="traitements")
    medicament = relationship("Medication", back_populates="traitements_symptomes")




### FILE: ./app/models/tracking_models.py

from sqlalchemy import Column, Integer, String, Float, ForeignKey, JSON, TIMESTAMP, Text, text, Boolean, BigInteger
from sqlalchemy.orm import relationship
from sqlalchemy.dialects.postgresql import UUID
import uuid
from .base import Base

class SimulationSession(Base):
    __tablename__ = "simulation_sessions"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    learner_id = Column(Integer, ForeignKey("learners.id"), nullable=False)
    cas_clinique_id = Column(Integer, ForeignKey("cas_cliniques_enrichis.id"), nullable=False)
    
    start_time = Column(TIMESTAMP, server_default=text("now()"))
    end_time = Column(TIMESTAMP)
    score_final = Column(Float)
    temps_total = Column(Integer) # secondes
    cout_virtuel_genere = Column(Integer)
    statut = Column(String(50), default="en_cours") # en_cours, termine, abandonne
    raison_fin = Column(String(100))

    # État courant du jeu (pour reprise)
    current_stage = Column(String(50)) # anamnèse, examen...
    context_state = Column(JSON) # État interne du patient virtuel

    learner = relationship("Learner", back_populates="sessions")
    cas_clinique = relationship("ClinicalCase")
    
    # Relations
    logs = relationship("InteractionLog", back_populates="session")
    messages = relationship("ChatMessage", back_populates="session")
    tutor_decisions = relationship("TutorDecision", back_populates="session")


class InteractionLog(Base):
    __tablename__ = "interaction_logs"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    action_category = Column(String(50)) # Anamnèse, Examen...
    action_type = Column(String(100)) # PoseQuestion, ClicImage
    action_content = Column(JSON)
    response_latency = Column(Integer) # ms
    charge_cognitive_estimee = Column(Float)
    est_pertinent = Column(Boolean)
    
    session = relationship("SimulationSession", back_populates="logs")


class ChatMessage(Base):
    __tablename__ = "chat_messages"

    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    sender = Column(String(50)) # student, patient, tutor
    content = Column(Text)
    intention_detectee = Column(String(100))
    sentiment_analyse = Column(String(50))
    message_metadata = Column(JSON) # tokens, model used...

    session = relationship("SimulationSession", back_populates="messages")


class LearnerAffectiveState(Base):
    __tablename__ = "learner_affective_states"

    id = Column(Integer, primary_key=True)
    session_id = Column(UUID(as_uuid=True), ForeignKey("simulation_sessions.id"))
    timestamp = Column(TIMESTAMP, server_default=text("now()"))
    
    stress_level = Column(Float) # 0-100
    confidence_level = Column(Float)
    motivation_level = Column(Float)
    frustration_level = Column(Float)

### FILE: ./app/models/prerequisite.py

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    ForeignKey,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship

from .base import Base


class Competence(Base):
    """
    Modèle SQLAlchemy pour les compétences cliniques (Knowledge Components).
    """
    __tablename__ = "competences_cliniques"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification ---
    code_competence = Column(String(50), unique=True, nullable=False, index=True, comment="Code unique (ex: 'ANAMNESE_DOULEUR')")
    nom = Column(String(255), nullable=False)
    categorie = Column(String(100), index=True, comment="Ex: Anamnese, Examen_physique, Raisonnement, Technique")
    
    # --- Pédagogie ---
    niveau_bloom = Column(Integer, comment="Niveau dans la taxonomie de Bloom (1-6)")
    description = Column(Text)
    objectifs_apprentissage = Column(JSON, comment="Liste détaillée des objectifs")
    criteres_maitrise = Column(JSON, comment="Critères pour valider la compétence")
    
    # --- Hiérarchie (Parent/Enfant) ---
    parent_competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=True)
    ordre_apprentissage = Column(Integer, default=0)

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # --- Relations ---
    children = relationship("Competence", 
                          back_populates="parent",
                          cascade="all, delete-orphan")
    
    parent = relationship("Competence", 
                        back_populates="children",
                        remote_side=[id])

    # Relation vers les prérequis
    prerequis = relationship(
        "Competence",
        secondary="prerequis_competences",
        primaryjoin="Competence.id==prerequis_competences.c.competence_id",
        secondaryjoin="Competence.id==prerequis_competences.c.prerequis_id",
        backref="est_prerequis_pour"
    )

    def __repr__(self) -> str:
        return f"<Competence(code='{self.code_competence}', nom='{self.nom}')>"


class PrerequisCompetence(Base):
    """
    Table d'association pour le graphe de prérequis entre compétences.
    Permet de dire : "Pour apprendre A, il faut d'abord maîtriser B".
    """
    __tablename__ = "prerequis_competences"

    id = Column(Integer, primary_key=True)
    
    # La compétence cible (Celle qu'on veut apprendre)
    competence_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    # La compétence prérequise (Celle qu'on doit déjà avoir)
    prerequis_id = Column(Integer, ForeignKey("competences_cliniques.id"), nullable=False)
    
    # --- Métadonnées de la relation ---
    type_relation = Column(String(50), default="STRICT", comment="STRICT, RECOMMANDE, SUPPORTIF")
    force_relation = Column(DECIMAL(3, 2), default=1.0, comment="Force du lien (0-1)")

    def __repr__(self) -> str:
        return f"<Prerequis(target={self.competence_id}, needed={self.prerequis_id})>"

### FILE: ./app/models/__init__.py

from .base import Base
from .symptom import Symptom
from .disease import Disease
from .medication import Medication
from .media import ImageMedicale
from .clinical_case import ClinicalCase
from .expert_strategy import ExpertStrategy
from .relations import PathologieSymptome, TraitementPathologie, TraitementSymptome
from .prerequisite import Competence, PrerequisCompetence

# --- AJOUTER CES LIGNES SI ELLES MANQUENT ---
from .learner_models import (
    Learner, LearnerCompetencyMastery, LearnerCognitiveProfile, 
    LearnerMisconception, LearnerGoal, LearnerPreference, 
    LearnerAchievement, LearnerStrategy
)
from .tracking_models import (
    SimulationSession, InteractionLog, ChatMessage, LearnerAffectiveState
)
from .tutor_models import (
    LearningPath, TutorDecision, TutorStrategiesHistory, 
    TutorScaffoldingState, TutorSocraticState, TutorMotivationalState, 
    TutorFeedbackLog
)
from .expert_user import ExpertUser

### FILE: ./app/models/expert_user.py

from sqlalchemy import Column, Integer, String, Text, Boolean, TIMESTAMP, text
from sqlalchemy.orm import relationship
from .base import Base

class ExpertUser(Base):
    __tablename__ = "experts"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String(255), unique=True, index=True, nullable=False)
    hashed_password = Column(String(255), nullable=False)
    nom_complet = Column(String(255))
    specialite = Column(String(100))
    hopital_affiliation = Column(String(255))
    role = Column(String(50), default="validateur") # superadmin, validateur, contributeur
    
    last_login = Column(TIMESTAMP)
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # Relation avec les cas cliniques validés
    cas_valides = relationship("ClinicalCase", back_populates="expert_validateur")

### FILE: ./app/models/expert_strategy.py

from sqlalchemy import (
    DECIMAL,
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    text
)
from sqlalchemy.orm import relationship

from .base import Base


class ExpertStrategy(Base):
    """
    Modèle SQLAlchemy pour la table des règles de production (stratégies expertes).
    
    Cette table stocke la logique IF-THEN du système expert.
    """
    __tablename__ = "regles_production"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et Métadonnées ---
    code_regle = Column(String(50), unique=True, nullable=False, index=True)
    categorie = Column(String(100), index=True, comment="Ex: DIAGNOSTIC, THERAPEUTIQUE, PEDAGOGIQUE, ALERTE")
    priorite = Column(Integer, default=5, comment="Priorité d'exécution (1-10), 10 étant le plus prioritaire")
    
    # --- Structure de la Règle (IF-THEN) ---
    conditions = Column(JSON, nullable=False, comment="Partie 'IF' de la règle, structurée en JSON")
    # Exemple de 'conditions':
    # {
    #   "operator": "AND",
    #   "rules": [
    #     {"fact": "symptom", "value": "Fièvre", "operator": "present"},
    #     {"fact": "symptom", "value": "Toux", "operator": "present"},
    #     {"fact": "age", "value": 65, "operator": "greater_than"}
    #   ]
    # }

    actions = Column(JSON, nullable=False, comment="Partie 'THEN' de la règle, structurée en JSON")
    # Exemple d' 'actions':
    # [
    #   {"action": "add_hypothesis", "pathology": "Pneumonie", "confidence": 0.8},
    #   {"action": "recommend_exam", "exam": "Radio Thorax", "urgency": "high"}
    # ]

    # --- Documentation et Validation ---
    description_naturelle = Column(Text, comment="Description de la règle en langage naturel")
    justification_medicale = Column(Text, comment="Source ou justification clinique de la règle")
    expert_auteur = Column(String(255))
    date_validation = Column(Date)
    est_active = Column(Boolean, default=True, nullable=False)

    # --- Métriques ---
    nb_activations = Column(Integer, default=0)
    taux_succes = Column(DECIMAL(5, 4))

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    def __repr__(self) -> str:
        return f"<ExpertStrategy(id={self.id}, code='{self.code_regle}')>"

### FILE: ./app/models/media.py

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    Boolean,
    Date,
    ForeignKey,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class ImageMedicale(Base):
    """
    Modèle SQLAlchemy pour la table des images médicales.
    Catalogue toutes les images (radios, scanners, etc.) avec leurs métadonnées.
    """
    __tablename__ = "images_medicales"

    id = Column(Integer, primary_key=True, index=True)

    # --- Classification et Liaison ---
    type_examen = Column(String(100), nullable=False, index=True, comment="Ex: Radiographie, Échographie, Scanner")
    sous_type = Column(String(100), comment="Ex: Thorax, Abdomen, Crâne")
    pathologie_id = Column(Integer, ForeignKey("pathologies.id"), nullable=True, index=True)

    # --- Gestion du Fichier ---
    fichier_url = Column(String(500), nullable=False, comment="URL vers le fichier (S3, stockage local, etc.)")
    fichier_miniature_url = Column(String(500), comment="URL vers une version miniature de l'image")
    format_image = Column(String(20), comment="Ex: DICOM, PNG, JPEG")
    taille_ko = Column(Integer)
    resolution = Column(String(50))

    # --- Métadonnées Cliniques ---
    description = Column(Text, comment="Description générale de l'image ou du cas")
    signes_radiologiques = Column(JSON, comment="Signes spécifiques visibles (ex: opacité, épanchement)")
    annotations = Column(JSON, comment="Coordonnées et descriptions de zones d'intérêt")
    interpretation_experte = Column(Text, comment="Compte-rendu d'un radiologue expert")
    diagnostic_differentiel = Column(JSON, comment="Autres diagnostics possibles basés sur l'image")

    # --- Métadonnées Pédagogiques ---
    niveau_difficulte = Column(Integer, comment="Difficulté d'interprétation de l'image (1-5)")
    qualite_image = Column(Integer, comment="Qualité technique de l'image (1-5)")

    # --- Intelligence Artificielle ---
    embedding_vision = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche par similarité visuelle")

    # --- Validation et Horodatage ---
    valide_expert = Column(Boolean, default=False)
    expert_validateur = Column(String(255))
    date_validation = Column(Date)
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))

    # --- Relations ---
    # Permet d'accéder à l'objet Pathologie depuis une ImageMedicale
    pathologie = relationship("Disease") # Nous n'avons pas besoin de back_populates ici pour l'instant

    def __repr__(self) -> str:
        return f"<ImageMedicale(id={self.id}, type='{self.type_examen}')>"


### FILE: ./app/models/knowledge_version.py



### FILE: ./app/models/disease.py

from sqlalchemy import (
    Column,
    Integer,
    String,
    Text,
    JSON,
    TIMESTAMP,
    DECIMAL,
    text
)
from sqlalchemy.orm import relationship
from pgvector.sqlalchemy import Vector

from .base import Base


class Disease(Base):
    """
    Modèle SQLAlchemy pour la table des pathologies (maladies).

    Cette table contient toutes les informations détaillées sur chaque maladie
    connue par le système, y compris le contexte local, les caractéristiques
    cliniques et les vecteurs pour l'IA.
    """
    __tablename__ = "pathologies"

    id = Column(Integer, primary_key=True, index=True)

    # --- Identification et Classification ---
    code_icd10 = Column(String(20), unique=True, index=True, comment="Code international de la maladie (CIM-10)")
    nom_fr = Column(String(255), nullable=False, index=True)
    nom_en = Column(String(255))
    nom_local = Column(String(255), comment="Noms locaux ou courants au Cameroun")
    categorie = Column(String(100), index=True, comment="Ex: Infectieuse, Chronique, Parasitaire")

    # --- Données Cliniques et Épidémiologiques ---
    prevalence_cameroun = Column(DECIMAL(5, 2), comment="Prévalence en % dans le contexte camerounais")
    niveau_gravite = Column(Integer, comment="Échelle de 1 (bénin) à 5 (critique)")
    description = Column(Text)
    physiopathologie = Column(Text, comment="Mécanisme de la maladie")
    evolution_naturelle = Column(Text, comment="Comment la maladie évolue sans traitement")
    complications = Column(JSON, comment="Complications possibles")
    facteurs_risque = Column(JSON, comment="Facteurs de risque associés")
    prevention = Column(Text, comment="Mesures de prévention")

    # --- Intelligence Artificielle ---
    embedding_vector = Column(Vector(384), nullable=True, comment="Vecteur d'embedding pour la recherche sémantique")

    # --- Horodatage ---
    created_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"))
    updated_at = Column(TIMESTAMP, nullable=False, server_default=text("now()"), onupdate=text("now()"))

    # --- Relations ---
    # Nous préparons le terrain pour la future relation avec les symptômes.
    # Pour l'instant, elle reste en commentaire pour éviter les erreurs d'import circulaire.
    symptomes = relationship(
         "PathologieSymptome",
         back_populates="pathologie",
         cascade="all, delete-orphan"
    
     )
    
    traitements = relationship(
        "TraitementPathologie",
        back_populates="pathologie",
        cascade="all, delete-orphan"
    )

    def __repr__(self) -> str:
        return f"<Disease(id={self.id}, nom_fr='{self.nom_fr}')>"

### FILE: ./app/models/diagnostic.py



### FILE: ./app/models/base.py

from sqlalchemy.orm import declarative_base

# Cette instance de 'declarative_base' est le catalogue central où SQLAlchemy
# enregistrera toutes les classes de modèles que nous définirons.
# C'est ce que Alembic utilisera pour comparer l'état de notre code
# avec l'état de la base de données.
Base = declarative_base()

### FILE: ./app/__init__.py



### FILE: ./app/services/fultang_integration/extractor.py



### FILE: ./app/services/fultang_integration/validator.py



### FILE: ./app/services/fultang_integration/__init__.py



### FILE: ./app/services/fultang_integration/anonymizer.py



### FILE: ./app/services/fultang_integration/case_generator.py



### FILE: ./app/services/__init__.py



### FILE: ./app/services/learning_path_service.py



### FILE: ./app/services/medication_service.py

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_medication_by_id(db: Session, medication_id: int) -> Optional[models.Medication]:
    """
    Récupère un médicament par son ID.
    """
    return db.query(models.Medication).filter(models.Medication.id == medication_id).first()

def get_medication_by_dci(db: Session, dci: str) -> Optional[models.Medication]:
    """
    Récupère un médicament par son DCI (Dénomination Commune Internationale).
    """
    return db.query(models.Medication).filter(models.Medication.dci == dci).first()

def get_all_medications(db: Session, skip: int = 0, limit: int = 100) -> List[models.Medication]:
    """
    Récupère une liste de tous les médicaments avec pagination.
    """
    return db.query(models.Medication).offset(skip).limit(limit).all()

def create_medication(db: Session, medication: schemas.MedicationCreate) -> models.Medication:
    """
    Crée un nouveau médicament dans la base de données.
    """
    medication_data = medication.model_dump()
    db_medication = models.Medication(**medication_data)
    
    db.add(db_medication)
    db.commit()
    db.refresh(db_medication)
    
    return db_medication

def update_medication(db: Session, medication_id: int, medication_update: schemas.MedicationUpdate) -> Optional[models.Medication]:
    """
    Met à jour un médicament existant.
    """
    db_medication = get_medication_by_id(db, medication_id)
    if not db_medication:
        return None

    update_data = medication_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_medication, key, value)
        
    db.commit()
    db.refresh(db_medication)
    
    return db_medication

def delete_medication(db: Session, medication_id: int) -> Optional[models.Medication]:
    """
    Supprime un médicament de la base de données.
    """
    db_medication = get_medication_by_id(db, medication_id)
    if not db_medication:
        return None

    db.delete(db_medication)
    db.commit()
    
    return db_medication




# Contenu à AJOUTER à la fin de app/services/medication_service.py

def get_diseases_treated_by_medication(db: Session, medication_id: int) -> List[models.TraitementPathologie]:
    """
    Récupère toutes les pathologies traitées par un médicament.
    """
    return db.query(models.TraitementPathologie).filter(models.TraitementPathologie.medicament_id == medication_id).all()


def get_symptoms_treated_by_medication(db: Session, medication_id: int) -> List[models.TraitementSymptome]:
    """
    Récupère tous les symptômes traités par un médicament.
    """
    return db.query(models.TraitementSymptome).filter(models.TraitementSymptome.medicament_id == medication_id).all()

### FILE: ./app/services/media_service.py

import os
import shutil
from sqlalchemy.orm import Session
from typing import List, Optional
from fastapi import UploadFile

from .. import models, schemas

# Définir le chemin de base pour le stockage.
# Plus tard, cela pourrait pointer vers un service cloud comme S3.
STORAGE_PATH = "storage/media/images"


async def save_upload_file(upload_file: UploadFile, destination: str) -> None:
    """
    Fonction utilitaire pour sauvegarder un fichier uploadé sur le disque.
    """
    try:
        # Assurer que le dossier de destination existe
        os.makedirs(os.path.dirname(destination), exist_ok=True)
        with open(destination, "wb") as buffer:
            # Lire le contenu du fichier par morceaux pour ne pas surcharger la mémoire
            shutil.copyfileobj(upload_file.file, buffer)
    finally:
        await upload_file.close()


async def create_image_medicale(
    db: Session,
    file: UploadFile,
    type_examen: str,
    sous_type: Optional[str] = None,
    pathologie_id: Optional[int] = None,
    description: Optional[str] = None
) -> models.ImageMedicale:
    """
    Crée une nouvelle entrée pour une image médicale.
    1. Sauvegarde le fichier sur le disque.
    2. Crée l'enregistrement correspondant en base de données.
    """
    # Définir le chemin de sauvegarde du fichier
    file_path = os.path.join(STORAGE_PATH, file.filename)
    
    # Sauvegarder le fichier physique
    await save_upload_file(file, file_path)

    # Créer l'objet SQLAlchemy avec les métadonnées
    db_image = models.ImageMedicale(
        type_examen=type_examen,
        sous_type=sous_type,
        pathologie_id=pathologie_id,
        description=description,
        fichier_url=file_path, # Stocke le chemin d'accès
        format_image=file.content_type,
        taille_ko=file.size // 1024 if file.size else None,
        # Les autres champs (embedding, etc.) seront remplis plus tard
    )
    
    db.add(db_image)
    db.commit()
    db.refresh(db_image)
    
    return db_image


def get_image_medicale_by_id(db: Session, image_id: int) -> Optional[models.ImageMedicale]:
    """
    Récupère une image médicale par son ID.
    """
    return db.query(models.ImageMedicale).filter(models.ImageMedicale.id == image_id).first()


def get_all_images_medicales(db: Session, skip: int = 0, limit: int = 100) -> List[models.ImageMedicale]:
    """
    Récupère une liste de toutes les images médicales avec pagination.
    """
    return db.query(models.ImageMedicale).offset(skip).limit(limit).all()


def update_image_medicale_metadata(
    db: Session,
    image_id: int,
    image_update: schemas.ImageMedicaleUpdate
) -> Optional[models.ImageMedicale]:
    """
    Met à jour les métadonnées d'une image médicale existante.
    """
    db_image = get_image_medicale_by_id(db, image_id)
    if not db_image:
        return None

    update_data = image_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_image, key, value)
        
    db.commit()
    db.refresh(db_image)
    
    return db_image


def delete_image_medicale(db: Session, image_id: int) -> Optional[models.ImageMedicale]:
    """
    Supprime une image médicale.
    1. Supprime l'enregistrement de la base de données.
    2. Supprime le fichier physique du disque.
    """
    db_image = get_image_medicale_by_id(db, image_id)
    if not db_image:
        return None

    # Supprimer le fichier physique s'il existe
    if db_image.fichier_url and os.path.exists(db_image.fichier_url):
        os.remove(db_image.fichier_url)

    db.delete(db_image)
    db.commit()
    
    return db_image

### FILE: ./app/services/symptom_service.py

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas
from ..utils.exceptions import NotFoundException # Nous créerons ce fichier plus tard


def get_symptom_by_id(db: Session, symptom_id: int) -> Optional[models.Symptom]:
    """
    Récupère un symptôme par son ID.
    """
    return db.query(models.Symptom).filter(models.Symptom.id == symptom_id).first()


def get_symptom_by_name(db: Session, name: str) -> Optional[models.Symptom]:
    """
    Récupère un symptôme par son nom.
    """
    return db.query(models.Symptom).filter(models.Symptom.nom == name).first()


def get_all_symptoms(db: Session, skip: int = 0, limit: int = 100) -> List[models.Symptom]:
    """
    Récupère une liste de tous les symptômes avec pagination.
    """
    return db.query(models.Symptom).offset(skip).limit(limit).all()


def create_symptom(db: Session, symptom: schemas.SymptomCreate) -> models.Symptom:
    """
    Crée un nouveau symptôme dans la base de données.
    
    Prend un schéma Pydantic 'SymptomCreate' en entrée, le convertit en
    modèle SQLAlchemy 'Symptom' et l'ajoute à la base de données.
    """
    # Convertit le schéma Pydantic en dictionnaire
    symptom_data = symptom.model_dump()
    
    # Crée une instance du modèle SQLAlchemy
    db_symptom = models.Symptom(**symptom_data)
    
    # Ajoute l'instance à la session de la base de données
    db.add(db_symptom)
    # Valide la transaction pour l'écrire en base
    db.commit()
    # Rafraîchit l'instance pour obtenir les valeurs générées par la BDD (comme l'ID)
    db.refresh(db_symptom)
    
    return db_symptom


def update_symptom(db: Session, symptom_id: int, symptom_update: schemas.SymptomUpdate) -> Optional[models.Symptom]:
    """
    Met à jour un symptôme existant.
    """
    db_symptom = get_symptom_by_id(db, symptom_id)
    if not db_symptom:
        # Plus tard, nous lèverons une exception personnalisée
        # raise NotFoundException(detail=f"Symptom with id {symptom_id} not found")
        return None

    # Convertit le schéma Pydantic en dictionnaire, en excluant les valeurs non définies
    update_data = symptom_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_symptom, key, value)
        
    db.commit()
    db.refresh(db_symptom)
    
    return db_symptom


def delete_symptom(db: Session, symptom_id: int) -> Optional[models.Symptom]:
    """
    Supprime un symptôme de la base de données.
    """
    db_symptom = get_symptom_by_id(db, symptom_id)
    if not db_symptom:
        # raise NotFoundException(detail=f"Symptom with id {symptom_id} not found")
        return None

    db.delete(db_symptom)
    db.commit()
    
    return db_symptom

def get_diseases_for_symptom(db: Session, symptom_id: int) -> List[models.PathologieSymptome]:
    """
    Récupère toutes les pathologies associées à un symptôme (diagnostic différentiel).
    """
    return db.query(models.PathologieSymptome).filter(models.PathologieSymptome.symptome_id == symptom_id).all()





def add_treatment_to_symptom(db: Session, association_data: schemas.relations.TraitementSymptomeCreate) -> models.TraitementSymptome:
    """
    Associe un médicament à un symptôme en tant que traitement symptomatique.
    """
    db_symptom = get_symptom_by_id(db, symptom_id=association_data.symptome_id)
    from . import medication_service
    db_medication = medication_service.get_medication_by_id(db, medication_id=association_data.medicament_id)

    if not db_symptom or not db_medication:
        raise ValueError("Symptôme ou Médicament non trouvé.")

    association = models.TraitementSymptome(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_treatments_for_symptom(db: Session, symptom_id: int) -> List[models.TraitementSymptome]:
    """
    Récupère tous les traitements associés à un symptôme.
    """
    return db.query(models.TraitementSymptome).filter(models.TraitementSymptome.symptome_id == symptom_id).all()

### FILE: ./app/services/clinical_case_service.py

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

# Importer les autres services dont nous aurons besoin
from . import disease_service
from . import media_service


def get_case_by_id(db: Session, case_id: int) -> Optional[models.ClinicalCase]:
    """
    Récupère un cas clinique par son ID.
    """
    return db.query(models.ClinicalCase).filter(models.ClinicalCase.id == case_id).first()


def get_case_by_code(db: Session, code: str) -> Optional[models.ClinicalCase]:
    """
    Récupère un cas clinique par son code Fultang ou synthétique.
    """
    return db.query(models.ClinicalCase).filter(models.ClinicalCase.code_fultang == code).first()


def get_all_cases(db: Session, skip: int = 0, limit: int = 100) -> List[models.ClinicalCase]:
    """
    Récupère une liste de tous les cas cliniques avec pagination.
    """
    return db.query(models.ClinicalCase).offset(skip).limit(limit).all()


def create_case(db: Session, case: schemas.ClinicalCaseCreate) -> models.ClinicalCase:
    """
    Crée un nouveau cas clinique dans la base de données.
    """
    # Vérifier que la pathologie principale existe, si elle est fournie
    if case.pathologie_principale_id:
        db_disease = disease_service.get_disease_by_id(db, disease_id=case.pathologie_principale_id)
        if not db_disease:
            raise ValueError(f"La pathologie avec l'ID {case.pathologie_principale_id} n'existe pas.")

    # Vérifier que les images associées existent, si elles sont fournies
    if case.images_associees_ids:
        for img_id in case.images_associees_ids:
            db_image = media_service.get_image_medicale_by_id(db, image_id=img_id)
            if not db_image:
                raise ValueError(f"L'image avec l'ID {img_id} n'existe pas.")

    case_data = case.model_dump()
    db_case = models.ClinicalCase(**case_data)
    
    db.add(db_case)
    db.commit()
    db.refresh(db_case)
    
    return db_case


def update_case(db: Session, case_id: int, case_update: schemas.ClinicalCaseUpdate) -> Optional[models.ClinicalCase]:
    """
    Met à jour un cas clinique existant.
    """
    db_case = get_case_by_id(db, case_id)
    if not db_case:
        return None

    update_data = case_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_case, key, value)
        
    db.commit()
    db.refresh(db_case)
    
    return db_case


def delete_case(db: Session, case_id: int) -> Optional[models.ClinicalCase]:
    """
    Supprime un cas clinique de la base de données.
    Note : Ne supprime pas les entités associées (maladies, images...).
    """
    db_case = get_case_by_id(db, case_id)
    if not db_case:
        return None

    db.delete(db_case)
    db.commit()
    
    return db_case

### FILE: ./app/services/expert_strategy_service.py

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_strategy_by_id(db: Session, strategy_id: int) -> Optional[models.ExpertStrategy]:
    """
    Récupère une règle par son ID.
    """
    return db.query(models.ExpertStrategy).filter(models.ExpertStrategy.id == strategy_id).first()

def get_strategy_by_code(db: Session, code: str) -> Optional[models.ExpertStrategy]:
    """
    Récupère une règle par son code unique.
    """
    return db.query(models.ExpertStrategy).filter(models.ExpertStrategy.code_regle == code).first()

def get_all_strategies(db: Session, skip: int = 0, limit: int = 100) -> List[models.ExpertStrategy]:
    """
    Récupère une liste de toutes les règles avec pagination.
    """
    return db.query(models.ExpertStrategy).offset(skip).limit(limit).all()

def get_active_strategies_by_category(db: Session, category: str) -> List[models.ExpertStrategy]:
    """
    Récupère toutes les règles actives pour une catégorie donnée, triées par priorité.
    Cette fonction sera très utile pour le moteur de raisonnement.
    """
    return db.query(models.ExpertStrategy).filter(
        models.ExpertStrategy.categorie == category,
        models.ExpertStrategy.est_active == True
    ).order_by(models.ExpertStrategy.priorite.desc()).all()


def create_strategy(db: Session, strategy: schemas.ExpertStrategyCreate) -> models.ExpertStrategy:
    """
    Crée une nouvelle règle dans la base de données.
    """
    strategy_data = strategy.model_dump()
    db_strategy = models.ExpertStrategy(**strategy_data)
    
    db.add(db_strategy)
    db.commit()
    db.refresh(db_strategy)
    
    return db_strategy

def update_strategy(db: Session, strategy_id: int, strategy_update: schemas.ExpertStrategyUpdate) -> Optional[models.ExpertStrategy]:
    """
    Met à jour une règle existante.
    """
    db_strategy = get_strategy_by_id(db, strategy_id)
    if not db_strategy:
        return None

    update_data = strategy_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_strategy, key, value)
        
    db.commit()
    db.refresh(db_strategy)
    
    return db_strategy

def delete_strategy(db: Session, strategy_id: int) -> Optional[models.ExpertStrategy]:
    """
    Supprime une règle de la base de données.
    """
    db_strategy = get_strategy_by_id(db, strategy_id)
    if not db_strategy:
        return None

    db.delete(db_strategy)
    db.commit()
    
    return db_strategy

### FILE: ./app/services/embedding_service.py

from sentence_transformers import SentenceTransformer
import logging

# Configuration du logging
logger = logging.getLogger(__name__)

class EmbeddingService:
    """
    Service pour générer des embeddings (vecteurs) à partir de texte.
    Utilise le modèle 'all-MiniLM-L6-v2' qui est un excellent compromis
    rapidité/qualité pour l'anglais et le français technique.
    """
    
    _instance = None
    _model = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(EmbeddingService, cls).__new__(cls)
            logger.info("Initialisation du modèle d'embedding...")
            # Chargement du modèle. On essaie sans le préfixe 'sentence-transformers/'
            # Si cela échoue encore, nous essaierons une autre approche.
            try:
                cls._model = SentenceTransformer('all-MiniLM-L6-v2')
            except Exception as e:
                logger.error(f"Erreur chargement modèle 'all-MiniLM-L6-v2': {e}")
                # Tentative de repli explicite
                cls._model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
            
            logger.info("Modèle d'embedding chargé avec succès.")
        return cls._instance

    def get_text_embedding(self, text: str) -> list:
        """
        Génère un vecteur d'embedding pour une chaîne de caractères donnée.
        
        :param text: Le texte à vectoriser.
        :return: Une liste de flottants (le vecteur).
        """
        if not text or not isinstance(text, str):
            return None
            
        try:
            # Le modèle retourne un numpy array, on le convertit en liste simple
            # pour qu'il soit compatible avec pgvector et JSON.
            embedding = self._model.encode(text)
            return embedding.tolist()
        except Exception as e:
            logger.error(f"Erreur lors de la vectorisation du texte : {e}")
            return None

# Instance globale prête à l'emploi
embedding_service = EmbeddingService()

### FILE: ./app/services/diagnostic_engine.py

from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional

from .. import models
from ..core import reasoning_engine
from . import expert_strategy_service

# Pour le typage, nous pouvons définir un schéma simple ici
from pydantic import BaseModel

class DiagnosticInput(BaseModel):
    """
    Schéma simple pour les données d'entrée du moteur de diagnostic.
    """
    symptoms: List[str]
    context: List[str] = []
    age: Optional[int] = None
    # ... d'autres faits pertinents pourraient être ajoutés ici


def run_diagnostic(db: Session, patient_facts: DiagnosticInput) -> List[Dict[str, Any]]:
    """
    Orchestre le processus de diagnostic.

    1. Récupère les règles de diagnostic actives depuis la base de données.
    2. Formate les faits du patient.
    3. Appelle le moteur de raisonnement.
    4. Retourne les actions/conclusions.
    """
    # 1. Récupérer les règles
    # On utilise la fonction 'intelligente' que nous avions créée dans le service des stratégies
    diagnostic_rules_db = expert_strategy_service.get_active_strategies_by_category(
        db, category="DIAGNOSTIC"
    )

    if not diagnostic_rules_db:
        return []

    # Convertir les objets SQLAlchemy en dictionnaires simples pour le moteur de logique pure
    rules_list = [
        {
            "code_regle": rule.code_regle,
            "conditions": rule.conditions,
            "actions": rule.actions,
        }
        for rule in diagnostic_rules_db
    ]

    # 2. Formater les faits (déjà au bon format grâce à Pydantic)
    facts_dict = patient_facts.model_dump()

    # 3. Appeler le moteur de raisonnement
    conclusions = reasoning_engine.forward_chaining_engine(
        rules=rules_list,
        facts=facts_dict
    )

    # 4. Retourner les conclusions
    return conclusions

### FILE: ./app/services/q_matrix_service.py



### FILE: ./app/services/disease_service.py

from sqlalchemy.orm import Session
from typing import List, Optional

from .. import models, schemas

def get_disease_by_id(db: Session, disease_id: int) -> Optional[models.Disease]:
    """
    Récupère une pathologie par son ID.
    """
    return db.query(models.Disease).filter(models.Disease.id == disease_id).first()

def get_disease_by_icd10(db: Session, icd10_code: str) -> Optional[models.Disease]:
    """
    Récupère une pathologie par son code CIM-10.
    """
    return db.query(models.Disease).filter(models.Disease.code_icd10 == icd10_code).first()

def get_all_diseases(db: Session, skip: int = 0, limit: int = 100) -> List[models.Disease]:
    """
    Récupère une liste de toutes les pathologies avec pagination.
    """
    return db.query(models.Disease).offset(skip).limit(limit).all()

def create_disease(db: Session, disease: schemas.DiseaseCreate) -> models.Disease:
    """
    Crée une nouvelle pathologie dans la base de données.
    """
    disease_data = disease.model_dump()
    db_disease = models.Disease(**disease_data)
    
    db.add(db_disease)
    db.commit()
    db.refresh(db_disease)
    
    return db_disease

def update_disease(db: Session, disease_id: int, disease_update: schemas.DiseaseUpdate) -> Optional[models.Disease]:
    """
    Met à jour une pathologie existante.
    """
    db_disease = get_disease_by_id(db, disease_id)
    if not db_disease:
        return None

    update_data = disease_update.model_dump(exclude_unset=True)
    
    for key, value in update_data.items():
        setattr(db_disease, key, value)
        
    db.commit()
    db.refresh(db_disease)
    
    return db_disease

def delete_disease(db: Session, disease_id: int) -> Optional[models.Disease]:
    """
    Supprime une pathologie de la base de données.
    """
    db_disease = get_disease_by_id(db, disease_id)
    if not db_disease:
        return None

    db.delete(db_disease)
    db.commit()
    
    return db_disease

def add_symptom_to_disease(db: Session, association_data: schemas.relations.PathologieSymptomeCreate) -> models.PathologieSymptome:
    """
    Associe un symptôme à une pathologie avec des attributs de relation.
    """
    # Vérifier que la pathologie et le symptôme existent
    db_disease = get_disease_by_id(db, disease_id=association_data.pathologie_id)
    # Nous aurons besoin d'importer le symptom_service pour cette vérification
    from . import symptom_service
    db_symptom = symptom_service.get_symptom_by_id(db, symptom_id=association_data.symptome_id)

    if not db_disease or not db_symptom:
        # Idéalement, lever une exception plus spécifique
        raise ValueError("Pathologie ou Symptôme non trouvé.")

    # Créer l'objet d'association
    association = models.PathologieSymptome(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_symptoms_for_disease(db: Session, disease_id: int) -> List[models.PathologieSymptome]:
    """
    Récupère tous les symptômes associés à une pathologie, avec les détails de la relation.
    """
    return db.query(models.PathologieSymptome).filter(models.PathologieSymptome.pathologie_id == disease_id).all()


def add_treatment_to_disease(db: Session, association_data: schemas.relations.TraitementPathologieCreate) -> models.TraitementPathologie:
    """
    Associe un médicament à une pathologie en tant que traitement.
    """
    db_disease = get_disease_by_id(db, disease_id=association_data.pathologie_id)
    from . import medication_service
    db_medication = medication_service.get_medication_by_id(db, medication_id=association_data.medicament_id)

    if not db_disease or not db_medication:
        raise ValueError("Pathologie ou Médicament non trouvé.")

    association = models.TraitementPathologie(**association_data.model_dump())
    
    db.add(association)
    db.commit()
    db.refresh(association)
    
    return association


def get_treatments_for_disease(db: Session, disease_id: int) -> List[models.TraitementPathologie]:
    """
    Récupère tous les traitements associés à une pathologie.
    """
    return db.query(models.TraitementPathologie).filter(models.TraitementPathologie.pathologie_id == disease_id).all()

### FILE: ./app/dependencies.py

# app/dependencies.py
from .database import SessionLocal

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

### FILE: ./app/middleware/logging_middleware.py



### FILE: ./app/middleware/__init__.py



### FILE: ./app/middleware/error_handler.py



### FILE: ./app/middleware/cors_middleware.py



### FILE: ./app/config.py

from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    """
    Classe pour gérer la configuration de l'application.
    Les variables sont chargées depuis le fichier .env.
    """
    DATABASE_URL: str

    class Config:
        env_file = ".env"

settings = Settings()

### FILE: ./app/utils/anonymization.py



### FILE: ./app/utils/__init__.py



### FILE: ./app/utils/formatters.py



### FILE: ./app/utils/crypto.py



### FILE: ./app/utils/validators.py



### FILE: ./app/utils/exceptions.py

# app/utils/exceptions.py

class NotFoundException(Exception):
    """
    Exception personnalisée à lever lorsque'une ressource n'est pas trouvée
    dans la base de données.
    """
    def __init__(self, detail: str):
        self.detail = detail

### FILE: ./app/utils/logging.py



### FILE: ./setup.py



### FILE: ./llm_integration/prompt_templates/patient_simulation.py



### FILE: ./llm_integration/prompt_templates/__init__.py



### FILE: ./llm_integration/prompt_templates/diagnostic_guidance.py



### FILE: ./llm_integration/prompt_templates/feedback_generation.py



### FILE: ./llm_integration/rag/__init__.py



### FILE: ./llm_integration/rag/response_generator.py



### FILE: ./llm_integration/rag/context_builder.py



### FILE: ./llm_integration/rag/retriever.py



### FILE: ./llm_integration/__init__.py



### FILE: ./llm_integration/training/conversation_extractor.py



### FILE: ./llm_integration/training/__init__.py



### FILE: ./llm_integration/training/dataset_preparation.py



### FILE: ./llm_integration/training/finetuning_pipeline.py



### FILE: ./llm_integration/conversation/__init__.py



### FILE: ./llm_integration/conversation/patient_agent.py



### FILE: ./llm_integration/conversation/dialogue_manager.py



### FILE: ./llm_integration/conversation/tutor_agent.py



### FILE: ./alembic/env.py

import os
import sys
from logging.config import fileConfig

from sqlalchemy import engine_from_config
from sqlalchemy import pool

from alembic import context

# --- MODIFICATION 1: Chargement de l'environnement ---
from dotenv import load_dotenv

# Ajoute la racine du projet au chemin de recherche de Python
sys.path.insert(0, os.path.realpath(os.path.join(os.path.dirname(__file__), '..')))
# Charge le fichier .env qui se trouve à la racine du projet
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))
# -----------------------------------------------------


# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)


# --- MODIFICATION 2: Importation des Modèles ---
# Importer la 'Base' depuis notre application
from app.models.base import Base

# --- IMPORT DE TOUS LES MODÈLES POUR ALEMBIC ---
# Module Expert
from app.models.symptom import Symptom
from app.models.disease import Disease
from app.models.medication import Medication
from app.models.media import ImageMedicale
from app.models.relations import PathologieSymptome, TraitementPathologie, TraitementSymptome
from app.models.clinical_case import ClinicalCase
from app.models.expert_strategy import ExpertStrategy
from app.models.expert_user import ExpertUser
from app.models.prerequisite import Competence, PrerequisCompetence

# Module Apprenant
from app.models.learner_models import (
    Learner, LearnerCompetencyMastery, LearnerCognitiveProfile, 
    LearnerMisconception, LearnerGoal, LearnerPreference, 
    LearnerAchievement, LearnerStrategy
)

# Module Suivi (Tracking)
from app.models.tracking_models import (
    SimulationSession, InteractionLog, ChatMessage, LearnerAffectiveState
)

# Module Tuteur
from app.models.tutor_models import (
    LearningPath, TutorDecision, TutorStrategiesHistory, 
    TutorScaffoldingState, TutorSocraticState, TutorMotivationalState, 
    TutorFeedbackLog
)
# --------------------------------------------------

target_metadata = Base.metadata


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = os.environ.get('DATABASE_URL')
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    # --- MODIFICATION 3: Configuration de l'Engine ---
    configuration = config.get_section(config.config_ini_section)
    configuration['sqlalchemy.url'] = os.environ.get('DATABASE_URL')
    
    connectable = engine_from_config(
        configuration,
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    # -------------------------------------------------

    with connectable.connect() as connection:
        context.configure(
            connection=connection, target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

### FILE: ./alembic/versions/7108003f9629_add_cas_symptomes_association_and_.py

"""Add cas_symptomes association and update models

Revision ID: 7108003f9629
Revises: 4f66bc9b6081
Create Date: 2025-11-07 10:04:10.734115+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '7108003f9629'
down_revision = '4f66bc9b6081'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('cas_symptomes')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_symptomes',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('cas_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('symptome_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('details_contextuels', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True, comment="Description narrative du symptôme dans ce cas (ex: 'Fièvre à 40°C depuis 3 jours')"),
    sa.ForeignKeyConstraint(['cas_id'], ['cas_cliniques_enrichis.id'], name=op.f('cas_symptomes_cas_id_fkey')),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], name=op.f('cas_symptomes_symptome_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('cas_symptomes_pkey'))
    )
    # ### end Alembic commands ###


### FILE: ./alembic/versions/994203ee2537_add_cas_symptomes_association_table.py

"""Add cas_symptomes association table

Revision ID: 994203ee2537
Revises: a6bc48307908
Create Date: 2025-11-07 09:49:25.031773+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '994203ee2537'
down_revision = 'a6bc48307908'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('cas_id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('details_contextuels', sa.JSON(), nullable=True, comment="Description narrative du symptôme dans ce cas (ex: 'Fièvre à 40°C depuis 3 jours')"),
    sa.ForeignKeyConstraint(['cas_id'], ['cas_cliniques_enrichis.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire générale du patient, antécédents, etc. (SANS la liste des symptômes)',
               existing_comment='Histoire du patient, symptômes présentés, etc.',
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire du patient, symptômes présentés, etc.',
               existing_comment='Histoire générale du patient, antécédents, etc. (SANS la liste des symptômes)',
               existing_nullable=False)
    op.drop_table('cas_symptomes')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/bc127903e3d2_add_expert_validateur_id_to_clinicalcase.py

"""Add expert_validateur_id to ClinicalCase

Revision ID: bc127903e3d2
Revises: 16068309bdb8
Create Date: 2025-12-25 00:23:58.911118+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'bc127903e3d2'
down_revision = '16068309bdb8'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('expert_validateur_id', sa.Integer(), nullable=True))
    op.create_foreign_key(None, 'cas_cliniques_enrichis', 'experts', ['expert_validateur_id'], ['id'])
    op.drop_column('cas_cliniques_enrichis', 'expert_validateur')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('expert_validateur', sa.VARCHAR(length=255), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'cas_cliniques_enrichis', type_='foreignkey')
    op.drop_column('cas_cliniques_enrichis', 'expert_validateur_id')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/bc4cda91a030_add_learner_tracking_and_tutor_tables.py

"""Add Learner, Tracking and Tutor tables

Revision ID: bc4cda91a030
Revises: afeac86179db
Create Date: 2025-12-19 10:03:40.038591+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'bc4cda91a030'
down_revision = 'afeac86179db'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###


### FILE: ./alembic/versions/a6bc48307908_create_clinical_cases_table.py

"""Create clinical_cases table

Revision ID: a6bc48307908
Revises: b2699b90c4a9
Create Date: 2025-11-07 09:29:53.852125+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'a6bc48307908'
down_revision = 'b2699b90c4a9'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cas_cliniques_enrichis',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_fultang', sa.String(length=100), nullable=True, comment='Identifiant unique provenant de Fultang (ou synthétique)'),
    sa.Column('hash_integrite', sa.String(length=64), nullable=True, comment="SHA-256 pour la preuve d'intégrité des données brutes"),
    sa.Column('pathologie_principale_id', sa.Integer(), nullable=True),
    sa.Column('donnees_brutes', sa.JSON(), nullable=True, comment='Données originales (ex: de Fultang) avant traitement'),
    sa.Column('presentation_clinique', sa.JSON(), nullable=False, comment='Histoire du patient, symptômes présentés, etc.'),
    sa.Column('donnees_paracliniques', sa.JSON(), nullable=True, comment='Résultats des examens pour ce cas spécifique'),
    sa.Column('evolution_patient', sa.Text(), nullable=True, comment="Description de l'évolution du patient pendant le cas"),
    sa.Column('images_associees_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste des IDs des images de la table 'images_medicales'"),
    sa.Column('sons_associes_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste des IDs des sons de la table 'sons_medicaux'"),
    sa.Column('medicaments_prescrits', sa.JSON(), nullable=True, comment='Liste des médicaments prescrits dans ce cas'),
    sa.Column('niveau_difficulte', sa.Integer(), nullable=True, comment='Difficulté du cas (1-5)'),
    sa.Column('duree_estimee_resolution_min', sa.Integer(), nullable=True, comment='Temps estimé pour résoudre le cas'),
    sa.Column('objectifs_apprentissage', sa.JSON(), nullable=True, comment='Liste des compétences à acquérir'),
    sa.Column('competences_requises', sa.JSON(), nullable=True, comment='Mapping Q-Matrix pour ce cas'),
    sa.Column('valide_expert', sa.Boolean(), nullable=True),
    sa.Column('expert_validateur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('qualite_donnees', sa.Integer(), nullable=True, comment='Qualité des données sources (1-5)'),
    sa.Column('nb_utilisations', sa.Integer(), nullable=True),
    sa.Column('note_moyenne_apprenants', sa.DECIMAL(precision=3, scale=2), nullable=True),
    sa.Column('taux_succes_diagnostic', sa.DECIMAL(precision=5, scale=2), nullable=True),
    sa.Column('embedding_texte', pgvector.sqlalchemy.vector.VECTOR(dim=384), nullable=True, comment='Embedding de la description textuelle du cas'),
    sa.Column('embedding_global', pgvector.sqlalchemy.vector.VECTOR(dim=1536), nullable=True, comment='Embedding multimodal fusionné (texte+image+son)'),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['pathologie_principale_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_cas_cliniques_enrichis_code_fultang'), 'cas_cliniques_enrichis', ['code_fultang'], unique=True)
    op.create_index(op.f('ix_cas_cliniques_enrichis_id'), 'cas_cliniques_enrichis', ['id'], unique=False)
    op.create_index(op.f('ix_cas_cliniques_enrichis_pathologie_principale_id'), 'cas_cliniques_enrichis', ['pathologie_principale_id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_cas_cliniques_enrichis_pathologie_principale_id'), table_name='cas_cliniques_enrichis')
    op.drop_index(op.f('ix_cas_cliniques_enrichis_id'), table_name='cas_cliniques_enrichis')
    op.drop_index(op.f('ix_cas_cliniques_enrichis_code_fultang'), table_name='cas_cliniques_enrichis')
    op.drop_table('cas_cliniques_enrichis')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/4f66bc9b6081_add_cas_symptomes_association_and_.py

"""Add cas_symptomes association and update models

Revision ID: 4f66bc9b6081
Revises: 994203ee2537
Create Date: 2025-11-07 10:03:23.727581+00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '4f66bc9b6081'
down_revision = '994203ee2537'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire du patient, symptômes présentés, etc.',
               existing_comment='Histoire générale du patient, antécédents, etc. (SANS la liste des symptômes)',
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('cas_cliniques_enrichis', 'presentation_clinique',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Histoire générale du patient, antécédents, etc. (SANS la liste des symptômes)',
               existing_comment='Histoire du patient, symptômes présentés, etc.',
               existing_nullable=False)
    # ### end Alembic commands ###


### FILE: ./alembic/versions/de1d3372f456_add_secondary_pathologies_to_clinical_.py

"""Add secondary pathologies to clinical cases

Revision ID: de1d3372f456
Revises: 7108003f9629
Create Date: 2025-11-07 13:38:16.973024+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'de1d3372f456'
down_revision = '7108003f9629'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('cas_cliniques_enrichis', sa.Column('pathologies_secondaires_ids', sa.ARRAY(sa.Integer()), nullable=True, comment="Liste d'IDs de pathologies comorbides ou secondaires"))
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('cas_cliniques_enrichis', 'pathologies_secondaires_ids')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/f29ac6884d1c_create_medications_table.py

"""Create medications table

Revision ID: f29ac6884d1c
Revises: 8e5b38bb2891
Create Date: 2025-11-06 20:17:47.401019+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'f29ac6884d1c'
down_revision = '8e5b38bb2891'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('medicaments',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('nom_commercial', sa.String(length=255), nullable=True),
    sa.Column('dci', sa.String(length=255), nullable=False, comment='Dénomination Commune Internationale'),
    sa.Column('classe_therapeutique', sa.String(length=255), nullable=True),
    sa.Column('forme_galenique', sa.String(length=100), nullable=True, comment='Ex: Comprimé, Sirop, Injectable'),
    sa.Column('dosage', sa.String(length=100), nullable=True),
    sa.Column('voie_administration', sa.String(length=100), nullable=True, comment='Ex: Orale, IV, IM, Cutanée'),
    sa.Column('mecanisme_action', sa.Text(), nullable=True),
    sa.Column('indications', sa.JSON(), nullable=True),
    sa.Column('contre_indications', sa.JSON(), nullable=True),
    sa.Column('effets_secondaires', sa.JSON(), nullable=True),
    sa.Column('interactions_medicamenteuses', sa.JSON(), nullable=True),
    sa.Column('precautions_emploi', sa.Text(), nullable=True),
    sa.Column('posologie_standard', sa.JSON(), nullable=True, comment='Posologie standard par âge, poids, indication'),
    sa.Column('disponibilite_cameroun', sa.String(length=50), nullable=True, comment='Ex: Urbain, Rural, CHU_uniquement'),
    sa.Column('cout_moyen_fcfa', sa.Integer(), nullable=True),
    sa.Column('statut_prescription', sa.String(length=50), nullable=True, comment='Ex: Prescription_obligatoire, OTC'),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=384), nullable=True, comment="Vecteur d'embedding pour la recherche de médicaments similaires"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_medicaments_classe_therapeutique'), 'medicaments', ['classe_therapeutique'], unique=False)
    op.create_index(op.f('ix_medicaments_dci'), 'medicaments', ['dci'], unique=False)
    op.create_index(op.f('ix_medicaments_id'), 'medicaments', ['id'], unique=False)
    op.create_index(op.f('ix_medicaments_nom_commercial'), 'medicaments', ['nom_commercial'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_medicaments_nom_commercial'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_id'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_dci'), table_name='medicaments')
    op.drop_index(op.f('ix_medicaments_classe_therapeutique'), table_name='medicaments')
    op.drop_table('medicaments')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/8e5b38bb2891_create_symptoms_table.py

"""Create symptoms table

Revision ID: 8e5b38bb2891
Revises: 6eb5a7dba20c
Create Date: 2025-11-06 19:31:00.822591+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '8e5b38bb2891'
down_revision = '6eb5a7dba20c'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('pathologie_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('pathologie_id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('probabilite', sa.DECIMAL(precision=5, scale=4), nullable=True, comment="Probabilité d'apparition du symptôme pour cette pathologie P(symptôme|pathologie)"),
    sa.Column('sensibilite', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('specificite', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('phase_maladie', sa.String(length=50), nullable=True, comment='Phase de la maladie où le symptôme apparaît (ex: Précoce, Tardive)'),
    sa.Column('frequence', sa.String(length=50), nullable=True, comment="Fréquence d'apparition (ex: Constant, Fréquent, Occasionnel)"),
    sa.Column('est_pathognomonique', sa.Boolean(), nullable=True, comment='Si True, ce symptôme seul suffit presque à poser le diagnostic'),
    sa.Column('importance_diagnostique', sa.Integer(), nullable=True, comment="Échelle de 1 à 5 sur l'importance de ce symptôme pour le diagnostic"),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('pathologie_symptomes')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/4b1e2599b918_initial_empty_migration.py

"""Initial empty migration

Revision ID: 4b1e2599b918
Revises: 
Create Date: 2025-11-06 11:09:36.525928+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '4b1e2599b918'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    pass


def downgrade():
    pass


### FILE: ./alembic/versions/b2699b90c4a9_create_media_table.py

"""Create media table

Revision ID: b2699b90c4a9
Revises: 9aed193ba8b7
Create Date: 2025-11-07 07:45:54.209466+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = 'b2699b90c4a9'
down_revision = '9aed193ba8b7'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('images_medicales',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('type_examen', sa.String(length=100), nullable=False, comment='Ex: Radiographie, Échographie, Scanner'),
    sa.Column('sous_type', sa.String(length=100), nullable=True, comment='Ex: Thorax, Abdomen, Crâne'),
    sa.Column('pathologie_id', sa.Integer(), nullable=True),
    sa.Column('fichier_url', sa.String(length=500), nullable=False, comment='URL vers le fichier (S3, stockage local, etc.)'),
    sa.Column('fichier_miniature_url', sa.String(length=500), nullable=True, comment="URL vers une version miniature de l'image"),
    sa.Column('format_image', sa.String(length=20), nullable=True, comment='Ex: DICOM, PNG, JPEG'),
    sa.Column('taille_ko', sa.Integer(), nullable=True),
    sa.Column('resolution', sa.String(length=50), nullable=True),
    sa.Column('description', sa.Text(), nullable=True, comment="Description générale de l'image ou du cas"),
    sa.Column('signes_radiologiques', sa.JSON(), nullable=True, comment='Signes spécifiques visibles (ex: opacité, épanchement)'),
    sa.Column('annotations', sa.JSON(), nullable=True, comment="Coordonnées et descriptions de zones d'intérêt"),
    sa.Column('interpretation_experte', sa.Text(), nullable=True, comment="Compte-rendu d'un radiologue expert"),
    sa.Column('diagnostic_differentiel', sa.JSON(), nullable=True, comment="Autres diagnostics possibles basés sur l'image"),
    sa.Column('niveau_difficulte', sa.Integer(), nullable=True, comment="Difficulté d'interprétation de l'image (1-5)"),
    sa.Column('qualite_image', sa.Integer(), nullable=True, comment="Qualité technique de l'image (1-5)"),
    sa.Column('embedding_vision', pgvector.sqlalchemy.vector.VECTOR(dim=384), nullable=True, comment="Vecteur d'embedding pour la recherche par similarité visuelle"),
    sa.Column('valide_expert', sa.Boolean(), nullable=True),
    sa.Column('expert_validateur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_images_medicales_id'), 'images_medicales', ['id'], unique=False)
    op.create_index(op.f('ix_images_medicales_pathologie_id'), 'images_medicales', ['pathologie_id'], unique=False)
    op.create_index(op.f('ix_images_medicales_type_examen'), 'images_medicales', ['type_examen'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_images_medicales_type_examen'), table_name='images_medicales')
    op.drop_index(op.f('ix_images_medicales_pathologie_id'), table_name='images_medicales')
    op.drop_index(op.f('ix_images_medicales_id'), table_name='images_medicales')
    op.drop_table('images_medicales')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/afeac86179db_create_competencies_and_prerequisites_.py

"""Create competencies and prerequisites tables

Revision ID: afeac86179db
Revises: 03d192a5f522
Create Date: 2025-11-29 20:23:29.605930+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'afeac86179db'
down_revision = '03d192a5f522'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('competences_cliniques',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_competence', sa.String(length=50), nullable=False, comment="Code unique (ex: 'ANAMNESE_DOULEUR')"),
    sa.Column('nom', sa.String(length=255), nullable=False),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: Anamnese, Examen_physique, Raisonnement, Technique'),
    sa.Column('niveau_bloom', sa.Integer(), nullable=True, comment='Niveau dans la taxonomie de Bloom (1-6)'),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('objectifs_apprentissage', sa.JSON(), nullable=True, comment='Liste détaillée des objectifs'),
    sa.Column('criteres_maitrise', sa.JSON(), nullable=True, comment='Critères pour valider la compétence'),
    sa.Column('parent_competence_id', sa.Integer(), nullable=True),
    sa.Column('ordre_apprentissage', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['parent_competence_id'], ['competences_cliniques.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_competences_cliniques_categorie'), 'competences_cliniques', ['categorie'], unique=False)
    op.create_index(op.f('ix_competences_cliniques_code_competence'), 'competences_cliniques', ['code_competence'], unique=True)
    op.create_index(op.f('ix_competences_cliniques_id'), 'competences_cliniques', ['id'], unique=False)
    op.create_table('prerequis_competences',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('competence_id', sa.Integer(), nullable=False),
    sa.Column('prerequis_id', sa.Integer(), nullable=False),
    sa.Column('type_relation', sa.String(length=50), nullable=True, comment='STRICT, RECOMMANDE, SUPPORTIF'),
    sa.Column('force_relation', sa.DECIMAL(precision=3, scale=2), nullable=True, comment='Force du lien (0-1)'),
    sa.ForeignKeyConstraint(['competence_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['prerequis_id'], ['competences_cliniques.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('prerequis_competences')
    op.drop_index(op.f('ix_competences_cliniques_id'), table_name='competences_cliniques')
    op.drop_index(op.f('ix_competences_cliniques_code_competence'), table_name='competences_cliniques')
    op.drop_index(op.f('ix_competences_cliniques_categorie'), table_name='competences_cliniques')
    op.drop_table('competences_cliniques')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/7995e67f8833_create_symptoms_table.py

"""Create symptoms table

Revision ID: 7995e67f8833
Revises: 4b1e2599b918
Create Date: 2025-11-06 12:48:47.725270+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '7995e67f8833'
down_revision = '4b1e2599b918'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('nom', sa.String(length=255), nullable=False),
    sa.Column('nom_local', sa.String(length=255), nullable=True, comment="Nom vernaculaire ou local, ex: 'Ntou-tou' pour la toux"),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Catégorie fonctionnelle (ex: Respiratoire, Neurologique, Digestif)'),
    sa.Column('type_symptome', sa.String(length=50), nullable=True, comment='Type de symptôme (ex: Subjectif, Objectif, Signe clinique)'),
    sa.Column('description', sa.Text(), nullable=True, comment='Description détaillée du symptôme et de sa signification clinique.'),
    sa.Column('questions_anamnese', sa.JSON(), nullable=True, comment='Liste structurée de questions pour explorer ce symptôme (ex: PQRST)'),
    sa.Column('signes_alarme', sa.Boolean(), nullable=False, comment="Indique si ce symptôme est un signe de gravité ('red flag')"),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=384), nullable=True, comment="Vecteur d'embedding pour la recherche sémantique (ex: BioBERT)"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_symptomes_categorie'), 'symptomes', ['categorie'], unique=False)
    op.create_index(op.f('ix_symptomes_id'), 'symptomes', ['id'], unique=False)
    op.create_index(op.f('ix_symptomes_nom'), 'symptomes', ['nom'], unique=True)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_symptomes_nom'), table_name='symptomes')
    op.drop_index(op.f('ix_symptomes_id'), table_name='symptomes')
    op.drop_index(op.f('ix_symptomes_categorie'), table_name='symptomes')
    op.drop_table('symptomes')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/16068309bdb8_add_learner_tracking_tutor_and_.py

"""Add Learner, Tracking, Tutor and ExpertUser tables

Revision ID: 16068309bdb8
Revises: bc4cda91a030
Create Date: 2025-12-23 02:00:58.044928+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '16068309bdb8'
down_revision = 'bc4cda91a030'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('experts',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('email', sa.String(length=255), nullable=False),
    sa.Column('hashed_password', sa.String(length=255), nullable=False),
    sa.Column('nom_complet', sa.String(length=255), nullable=True),
    sa.Column('specialite', sa.String(length=100), nullable=True),
    sa.Column('hopital_affiliation', sa.String(length=255), nullable=True),
    sa.Column('role', sa.String(length=50), nullable=True),
    sa.Column('last_login', sa.TIMESTAMP(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_experts_email'), 'experts', ['email'], unique=True)
    op.create_index(op.f('ix_experts_id'), 'experts', ['id'], unique=False)
    op.create_table('learners',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('matricule', sa.String(length=50), nullable=True),
    sa.Column('nom', sa.String(length=255), nullable=True),
    sa.Column('email', sa.String(length=255), nullable=True),
    sa.Column('niveau_etudes', sa.String(length=50), nullable=True),
    sa.Column('specialite_visee', sa.String(length=100), nullable=True),
    sa.Column('langue_preferee', sa.String(length=10), nullable=True),
    sa.Column('date_inscription', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learners_email'), 'learners', ['email'], unique=True)
    op.create_index(op.f('ix_learners_id'), 'learners', ['id'], unique=False)
    op.create_index(op.f('ix_learners_matricule'), 'learners', ['matricule'], unique=True)
    op.create_table('learner_achievements',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('badge_id', sa.String(length=100), nullable=True),
    sa.Column('date_obtention', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_cognitive_profiles',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('vitesse_assimilation', sa.Float(), nullable=True),
    sa.Column('capacite_memoire_travail', sa.Float(), nullable=True),
    sa.Column('tendance_impulsivite', sa.Float(), nullable=True),
    sa.Column('prefer_visual', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('learner_id')
    )
    op.create_table('learner_competency_mastery',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('competence_id', sa.Integer(), nullable=False),
    sa.Column('mastery_level', sa.Float(), nullable=True),
    sa.Column('confidence', sa.Float(), nullable=True),
    sa.Column('last_practice_date', sa.TIMESTAMP(), nullable=True),
    sa.Column('nb_success', sa.Integer(), nullable=True),
    sa.Column('nb_failures', sa.Integer(), nullable=True),
    sa.Column('streak_correct', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['competence_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learner_competency_mastery_id'), 'learner_competency_mastery', ['id'], unique=False)
    op.create_table('learner_goals',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('type_objectif', sa.String(length=100), nullable=True),
    sa.Column('domaine_cible', sa.String(length=100), nullable=True),
    sa.Column('date_limite', sa.TIMESTAMP(), nullable=True),
    sa.Column('statut', sa.String(length=50), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_misconceptions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('type_erreur', sa.String(length=255), nullable=True),
    sa.Column('frequence_apparition', sa.Integer(), nullable=True),
    sa.Column('resistance_correction', sa.Float(), nullable=True),
    sa.Column('detected_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_preferences',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('cle', sa.String(length=100), nullable=True),
    sa.Column('valeur', sa.String(length=255), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learner_strategies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=True),
    sa.Column('strategy_name', sa.String(length=100), nullable=True),
    sa.Column('frequency', sa.Integer(), nullable=True),
    sa.Column('effectiveness', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('learning_paths',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('algorithme_recommandation', sa.String(length=100), nullable=True),
    sa.Column('ordered_case_ids', sa.JSON(), nullable=True, comment='Liste ordonnée des IDs des cas'),
    sa.Column('progression', sa.Float(), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_learning_paths_id'), 'learning_paths', ['id'], unique=False)
    op.create_table('simulation_sessions',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('learner_id', sa.Integer(), nullable=False),
    sa.Column('cas_clinique_id', sa.Integer(), nullable=False),
    sa.Column('start_time', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('end_time', sa.TIMESTAMP(), nullable=True),
    sa.Column('score_final', sa.Float(), nullable=True),
    sa.Column('temps_total', sa.Integer(), nullable=True),
    sa.Column('cout_virtuel_genere', sa.Integer(), nullable=True),
    sa.Column('statut', sa.String(length=50), nullable=True),
    sa.Column('raison_fin', sa.String(length=100), nullable=True),
    sa.Column('current_stage', sa.String(length=50), nullable=True),
    sa.Column('context_state', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['cas_clinique_id'], ['cas_cliniques_enrichis.id'], ),
    sa.ForeignKeyConstraint(['learner_id'], ['learners.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('chat_messages',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('sender', sa.String(length=50), nullable=True),
    sa.Column('content', sa.Text(), nullable=True),
    sa.Column('intention_detectee', sa.String(length=100), nullable=True),
    sa.Column('sentiment_analyse', sa.String(length=50), nullable=True),
    sa.Column('message_metadata', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_chat_messages_id'), 'chat_messages', ['id'], unique=False)
    op.create_table('interaction_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('action_category', sa.String(length=50), nullable=True),
    sa.Column('action_type', sa.String(length=100), nullable=True),
    sa.Column('action_content', sa.JSON(), nullable=True),
    sa.Column('response_latency', sa.Integer(), nullable=True),
    sa.Column('charge_cognitive_estimee', sa.Float(), nullable=True),
    sa.Column('est_pertinent', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_interaction_logs_id'), 'interaction_logs', ['id'], unique=False)
    op.create_table('learner_affective_states',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('stress_level', sa.Float(), nullable=True),
    sa.Column('confidence_level', sa.Float(), nullable=True),
    sa.Column('motivation_level', sa.Float(), nullable=True),
    sa.Column('frustration_level', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('tutor_feedback_logs',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('feedback_type', sa.String(length=50), nullable=True),
    sa.Column('content', sa.Text(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_feedback_logs_id'), 'tutor_feedback_logs', ['id'], unique=False)
    op.create_table('tutor_motivational_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('intervention_type', sa.String(length=100), nullable=True),
    sa.Column('emotional_state_before', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_motivational_state_id'), 'tutor_motivational_state', ['id'], unique=False)
    op.create_table('tutor_scaffolding_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('competence_cible_id', sa.Integer(), nullable=True),
    sa.Column('current_level', sa.Integer(), nullable=True),
    sa.Column('indices_deja_donnes', sa.JSON(), nullable=True),
    sa.ForeignKeyConstraint(['competence_cible_id'], ['competences_cliniques.id'], ),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_scaffolding_state_id'), 'tutor_scaffolding_state', ['id'], unique=False)
    op.create_table('tutor_socratic_state',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('tactic_used', sa.String(length=100), nullable=True),
    sa.Column('target_concept', sa.String(length=255), nullable=True),
    sa.Column('step_in_dialogue', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_socratic_state_id'), 'tutor_socratic_state', ['id'], unique=False)
    op.create_table('tutor_strategies_history',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('strategy_name', sa.String(length=100), nullable=True),
    sa.Column('relevance_score', sa.Float(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_strategies_history_id'), 'tutor_strategies_history', ['id'], unique=False)
    op.create_table('tutor_decisions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('session_id', sa.UUID(), nullable=True),
    sa.Column('trigger_event_id', sa.Integer(), nullable=True),
    sa.Column('timestamp', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=True),
    sa.Column('strategy_used', sa.String(length=100), nullable=True),
    sa.Column('action_choisie', sa.String(length=100), nullable=True),
    sa.Column('intervention_content', sa.Text(), nullable=True),
    sa.Column('rationale', sa.JSON(), nullable=True),
    sa.Column('succes_intervention', sa.Boolean(), nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['simulation_sessions.id'], ),
    sa.ForeignKeyConstraint(['trigger_event_id'], ['interaction_logs.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tutor_decisions_id'), 'tutor_decisions', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_tutor_decisions_id'), table_name='tutor_decisions')
    op.drop_table('tutor_decisions')
    op.drop_index(op.f('ix_tutor_strategies_history_id'), table_name='tutor_strategies_history')
    op.drop_table('tutor_strategies_history')
    op.drop_index(op.f('ix_tutor_socratic_state_id'), table_name='tutor_socratic_state')
    op.drop_table('tutor_socratic_state')
    op.drop_index(op.f('ix_tutor_scaffolding_state_id'), table_name='tutor_scaffolding_state')
    op.drop_table('tutor_scaffolding_state')
    op.drop_index(op.f('ix_tutor_motivational_state_id'), table_name='tutor_motivational_state')
    op.drop_table('tutor_motivational_state')
    op.drop_index(op.f('ix_tutor_feedback_logs_id'), table_name='tutor_feedback_logs')
    op.drop_table('tutor_feedback_logs')
    op.drop_table('learner_affective_states')
    op.drop_index(op.f('ix_interaction_logs_id'), table_name='interaction_logs')
    op.drop_table('interaction_logs')
    op.drop_index(op.f('ix_chat_messages_id'), table_name='chat_messages')
    op.drop_table('chat_messages')
    op.drop_table('simulation_sessions')
    op.drop_index(op.f('ix_learning_paths_id'), table_name='learning_paths')
    op.drop_table('learning_paths')
    op.drop_table('learner_strategies')
    op.drop_table('learner_preferences')
    op.drop_table('learner_misconceptions')
    op.drop_table('learner_goals')
    op.drop_index(op.f('ix_learner_competency_mastery_id'), table_name='learner_competency_mastery')
    op.drop_table('learner_competency_mastery')
    op.drop_table('learner_cognitive_profiles')
    op.drop_table('learner_achievements')
    op.drop_index(op.f('ix_learners_matricule'), table_name='learners')
    op.drop_index(op.f('ix_learners_id'), table_name='learners')
    op.drop_index(op.f('ix_learners_email'), table_name='learners')
    op.drop_table('learners')
    op.drop_index(op.f('ix_experts_id'), table_name='experts')
    op.drop_index(op.f('ix_experts_email'), table_name='experts')
    op.drop_table('experts')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/6eb5a7dba20c_create_symptoms_table.py

"""Create symptoms table

Revision ID: 6eb5a7dba20c
Revises: 7995e67f8833
Create Date: 2025-11-06 19:20:35.224401+00:00

"""
from alembic import op
import sqlalchemy as sa
import pgvector

# revision identifiers, used by Alembic.
revision = '6eb5a7dba20c'
down_revision = '7995e67f8833'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('pathologies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_icd10', sa.String(length=20), nullable=True, comment='Code international de la maladie (CIM-10)'),
    sa.Column('nom_fr', sa.String(length=255), nullable=False),
    sa.Column('nom_en', sa.String(length=255), nullable=True),
    sa.Column('nom_local', sa.String(length=255), nullable=True, comment='Noms locaux ou courants au Cameroun'),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: Infectieuse, Chronique, Parasitaire'),
    sa.Column('prevalence_cameroun', sa.DECIMAL(precision=5, scale=2), nullable=True, comment='Prévalence en % dans le contexte camerounais'),
    sa.Column('niveau_gravite', sa.Integer(), nullable=True, comment='Échelle de 1 (bénin) à 5 (critique)'),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('physiopathologie', sa.Text(), nullable=True, comment='Mécanisme de la maladie'),
    sa.Column('evolution_naturelle', sa.Text(), nullable=True, comment='Comment la maladie évolue sans traitement'),
    sa.Column('complications', sa.JSON(), nullable=True, comment='Complications possibles'),
    sa.Column('facteurs_risque', sa.JSON(), nullable=True, comment='Facteurs de risque associés'),
    sa.Column('prevention', sa.Text(), nullable=True, comment='Mesures de prévention'),
    sa.Column('embedding_vector', pgvector.sqlalchemy.vector.VECTOR(dim=384), nullable=True, comment="Vecteur d'embedding pour la recherche sémantique"),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_pathologies_categorie'), 'pathologies', ['categorie'], unique=False)
    op.create_index(op.f('ix_pathologies_code_icd10'), 'pathologies', ['code_icd10'], unique=True)
    op.create_index(op.f('ix_pathologies_id'), 'pathologies', ['id'], unique=False)
    op.create_index(op.f('ix_pathologies_nom_fr'), 'pathologies', ['nom_fr'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_pathologies_nom_fr'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_id'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_code_icd10'), table_name='pathologies')
    op.drop_index(op.f('ix_pathologies_categorie'), table_name='pathologies')
    op.drop_table('pathologies')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/9aed193ba8b7_create_therapeutic_relations_tables.py

"""Create therapeutic relations tables

Revision ID: 9aed193ba8b7
Revises: f29ac6884d1c
Create Date: 2025-11-06 20:44:30.949745+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '9aed193ba8b7'
down_revision = 'f29ac6884d1c'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('traitements_pathologies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('pathologie_id', sa.Integer(), nullable=False),
    sa.Column('medicament_id', sa.Integer(), nullable=False),
    sa.Column('type_traitement', sa.String(length=50), nullable=True, comment='Ex: Premiere_intention, Alternative, Adjuvant'),
    sa.Column('ligne_traitement', sa.Integer(), nullable=True, comment='Ex: 1ère ligne, 2e ligne'),
    sa.Column('indication_precise', sa.Text(), nullable=True),
    sa.Column('efficacite_taux', sa.DECIMAL(precision=5, scale=2), nullable=True, comment='Taux de succès en %'),
    sa.Column('duree_traitement_jours', sa.Integer(), nullable=True),
    sa.Column('posologie_detaillee', sa.JSON(), nullable=True),
    sa.Column('niveau_preuve', sa.String(length=50), nullable=True, comment='Grade de recommandation (A, B, C)'),
    sa.Column('guidelines_source', sa.String(length=255), nullable=True, comment='Source (OMS, MINSANTE Cameroun, etc.)'),
    sa.Column('rang_preference', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['medicament_id'], ['medicaments.id'], ),
    sa.ForeignKeyConstraint(['pathologie_id'], ['pathologies.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('traitements_symptomes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('symptome_id', sa.Integer(), nullable=False),
    sa.Column('medicament_id', sa.Integer(), nullable=False),
    sa.Column('efficacite', sa.String(length=50), nullable=True, comment='Ex: Tres_efficace, Efficace, Modere'),
    sa.Column('rapidite_action', sa.String(length=100), nullable=True, comment='Ex: Immediate, <30min'),
    sa.Column('posologie_recommandee', sa.Text(), nullable=True),
    sa.Column('rang_preference', sa.Integer(), nullable=True),
    sa.ForeignKeyConstraint(['medicament_id'], ['medicaments.id'], ),
    sa.ForeignKeyConstraint(['symptome_id'], ['symptomes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('traitements_symptomes')
    op.drop_table('traitements_pathologies')
    # ### end Alembic commands ###


### FILE: ./alembic/versions/03d192a5f522_add_expert_intelligence.py

"""Add expert intelligence

Revision ID: 03d192a5f522
Revises: de1d3372f456
Create Date: 2025-11-07 14:06:32.502322+00:00

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '03d192a5f522'
down_revision = 'de1d3372f456'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('regles_production',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code_regle', sa.String(length=50), nullable=False),
    sa.Column('categorie', sa.String(length=100), nullable=True, comment='Ex: DIAGNOSTIC, THERAPEUTIQUE, PEDAGOGIQUE, ALERTE'),
    sa.Column('priorite', sa.Integer(), nullable=True, comment="Priorité d'exécution (1-10), 10 étant le plus prioritaire"),
    sa.Column('conditions', sa.JSON(), nullable=False, comment="Partie 'IF' de la règle, structurée en JSON"),
    sa.Column('actions', sa.JSON(), nullable=False, comment="Partie 'THEN' de la règle, structurée en JSON"),
    sa.Column('description_naturelle', sa.Text(), nullable=True, comment='Description de la règle en langage naturel'),
    sa.Column('justification_medicale', sa.Text(), nullable=True, comment='Source ou justification clinique de la règle'),
    sa.Column('expert_auteur', sa.String(length=255), nullable=True),
    sa.Column('date_validation', sa.Date(), nullable=True),
    sa.Column('est_active', sa.Boolean(), nullable=False),
    sa.Column('nb_activations', sa.Integer(), nullable=True),
    sa.Column('taux_succes', sa.DECIMAL(precision=5, scale=4), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.TIMESTAMP(), server_default=sa.text('now()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_regles_production_categorie'), 'regles_production', ['categorie'], unique=False)
    op.create_index(op.f('ix_regles_production_code_regle'), 'regles_production', ['code_regle'], unique=True)
    op.create_index(op.f('ix_regles_production_id'), 'regles_production', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_regles_production_id'), table_name='regles_production')
    op.drop_index(op.f('ix_regles_production_code_regle'), table_name='regles_production')
    op.drop_index(op.f('ix_regles_production_categorie'), table_name='regles_production')
    op.drop_table('regles_production')
    # ### end Alembic commands ###


### FILE: ./scripts/run_dataset_import.py

import sys
import os

# Le sys.path.insert n'est plus nécessaire si on lance avec 'python -m'
# Mais on le garde au cas où, en le sécurisant
if __name__ == "__main__" and __package__ is None:
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from datasets.integrators.mimic3_dics_integrator import MIMIC3DictionariesIntegrator
from datasets.integrators.mimic3_integrator import MIMIC3RelationsIntegrator
from datasets.assembler.case_assembler import CaseAssembler
from datasets.integrators.manual_images_integrator import ManualImagesIntegrator

# --- CONFIGURATION DES CHEMINS D'ACCÈS ---
MIMIC_BASE_PATH = "/home/clement/Téléchargements/archive (1)/mimic-iii-clinical-database-demo-1.4"
SOURCE_IMAGES_DIR = "/home/clement/Téléchargements/imgradio" 
MAPPING_CSV_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'datasets/mapping/images_mapping.csv'))

MIMIC_FILES_PATHS = {
    "d_icd_diagnoses": os.path.join(MIMIC_BASE_PATH, "D_ICD_DIAGNOSES.csv"),
    "d_labitems": os.path.join(MIMIC_BASE_PATH, "D_LABITEMS.csv"),
    "d_items": os.path.join(MIMIC_BASE_PATH, "D_ITEMS.csv"),
    "prescriptions": os.path.join(MIMIC_BASE_PATH, "PRESCRIPTIONS.csv"),
    "diagnoses_icd": os.path.join(MIMIC_BASE_PATH, "DIAGNOSES_ICD.csv"),
    "labevents": os.path.join(MIMIC_BASE_PATH, "LABEVENTS.csv"),
    "admissions": os.path.join(MIMIC_BASE_PATH, "ADMISSIONS.csv"),
}

def check_paths(paths: dict):
    all_found = True
    for key, path in paths.items():
        if not os.path.exists(path):
            print(f"❌ ERREUR: Fichier non trouvé pour '{key}': {path}")
            all_found = False
    return all_found

def main():
    print("--- Démarrage du script d'importation complet ---")
    
    if not check_paths(MIMIC_FILES_PATHS):
        print("\nAttention: Fichiers MIMIC manquants.")
        # On continue quand même pour tester les autres intégrateurs si besoin
    
    db_session = SessionLocal()
    
    try:
        print("\n" + "="*50)
        print("ÉTAPE 1: PEUPLEMENT DES DICTIONNAIRES")
        dics_integrator = MIMIC3DictionariesIntegrator(db_session=db_session, paths=MIMIC_FILES_PATHS)
        dics_integrator.run_all()

        print("\n" + "="*50)
        print("ÉTAPE 2: CRÉATION DES RELATIONS")
        relations_integrator = MIMIC3RelationsIntegrator(db_session=db_session, paths=MIMIC_FILES_PATHS)
        relations_integrator.run()

        print("\n" + "="*50)
        print("ÉTAPE 3: ASSEMBLAGE DES CAS CLINIQUES")
        case_assembler = CaseAssembler(db_session=db_session, paths=MIMIC_FILES_PATHS)
        case_assembler.run()

        print("\n" + "="*50)
        print("ÉTAPE 4: IMPORTATION DES IMAGES MANUELLES")
        if not os.path.exists(MAPPING_CSV_PATH):
            print(f"❌ ERREUR: Fichier de mapping non trouvé : {MAPPING_CSV_PATH}")
        else:
            images_integrator = ManualImagesIntegrator(
                db_session=db_session,
                mapping_csv_path=MAPPING_CSV_PATH,
                source_images_dir="" 
            )
            images_integrator.run()

    except Exception as e:
        print(f"\n❌ UNE ERREUR CRITIQUE EST SURVENUE : {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        print("\nFermeture de la session de base de données.")
        db_session.close()

if __name__ == "__main__":
    main()

### FILE: ./scripts/run_assembler.py



### FILE: ./scripts/generate_q_matrix.py

import sys
import os

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app import models

def generate_matrix():
    db = SessionLocal()
    print("--- Génération de la Q-Matrix (Lien Cas <-> Compétences) ---")

    # 1. Charger toutes les compétences pour avoir leurs IDs et codes
    competencies = db.query(models.Competence).all()
    comp_map = {c.code_competence: c.id for c in competencies}
    
    if not comp_map:
        print("❌ Aucune compétence trouvée. Veuillez lancer populate_competencies.py d'abord.")
        return

    # 2. Récupérer tous les cas cliniques
    cases = db.query(models.ClinicalCase).all()
    print(f"Traitement de {len(cases)} cas cliniques...")

    count_updated = 0
    for case in cases:
        required_skills = {} # Dictionnaire pour stocker les compétences requises {code: id}

        # --- RÈGLES D'ATTRIBUTION DES COMPÉTENCES ---

        # Règle 1 : Socle commun (Tout cas nécessite ces bases)
        # Bloom 1-2
        common_skills = ["IDENTIFIER_MOTIF", "EMPATHIE", "ANAMNESE_HISTOIRE"]
        for code in common_skills:
            if code in comp_map:
                required_skills[code] = comp_map[code]

        # Règle 2 : Si le cas a des symptômes biologiques (Labo)
        # Bloom 4
        if case.donnees_paracliniques and "lab_results" in case.donnees_paracliniques:
            if len(case.donnees_paracliniques["lab_results"]) > 0:
                if "INTERPRETATION_BIOLOGIE" in comp_map:
                    required_skills["INTERPRETATION_BIOLOGIE"] = comp_map["INTERPRETATION_BIOLOGIE"]

        # Règle 3 : Si le cas a des images
        # Bloom 4
        if case.images_associees_ids and len(case.images_associees_ids) > 0:
            if "INTERPRETATION_IMAGERIE" in comp_map:
                required_skills["INTERPRETATION_IMAGERIE"] = comp_map["INTERPRETATION_IMAGERIE"]

        # Règle 4 : Si le cas a des médicaments prescrits
        # Bloom 6
        if case.medicaments_prescrits and len(case.medicaments_prescrits) > 0:
            if "PRESCRIPTION_THERAPEUTIQUE" in comp_map:
                required_skills["PRESCRIPTION_THERAPEUTIQUE"] = comp_map["PRESCRIPTION_THERAPEUTIQUE"]
        
        # Règle 5 : Compétences de Raisonnement (Toujours nécessaires pour un cas complet)
        # Bloom 4-5
        reasoning_skills = ["GENERATION_HYPOTHESES", "DIAGNOSTIC_DIFFERENTIEL", "SYNTHESE_CLINIQUE"]
        for code in reasoning_skills:
            if code in comp_map:
                required_skills[code] = comp_map[code]

        # --- MISE À JOUR DU CAS ---
        
        # On sauvegarde le résultat sous forme de JSON { "CODE_COMPETENCE": ID_COMPETENCE }
        case.competences_requises = required_skills
        
        # On calcule un niveau de difficulté suggéré basé sur la richesse du cas
        # Base: 1. +1 si labo, +1 si images, +1 si médicaments, +1 si comorbidités
        difficulty = 1
        if "INTERPRETATION_BIOLOGIE" in required_skills: difficulty += 1
        if "INTERPRETATION_IMAGERIE" in required_skills: difficulty += 1
        if "PRESCRIPTION_THERAPEUTIQUE" in required_skills: difficulty += 1
        if case.pathologies_secondaires_ids: difficulty += 1
        
        case.niveau_difficulte = min(difficulty, 5) # Max 5

        count_updated += 1

    db.commit()
    db.close()
    print(f"✨ Terminé. {count_updated} cas cliniques mis à jour avec leur Q-Matrix.")

if __name__ == "__main__":
    generate_matrix()

### FILE: ./scripts/backup_restore.py



### FILE: ./scripts/populate_from_datasets.py



### FILE: ./scripts/migrate_fultang_data.py



### FILE: ./scripts/export_training_data.py



### FILE: ./scripts/check_relations.py

import sys
import os
from sqlalchemy import inspect

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import engine
# Importez tous les modèles pour être sûr qu'ils sont enregistrés
from app import models 

def check_db_relations():
    inspector = inspect(engine)
    table_names = inspector.get_table_names()
    
    print(f"\n--- AUDIT DE LA BASE DE DONNÉES ({len(table_names)} tables trouvées) ---\n")
    
    # 1. Vérification des Tables
    print("📋 LISTE DES TABLES :")
    for table in sorted(table_names):
        print(f"  - {table}")
        
    print("\n🔗 VÉRIFICATION DES RELATIONS (Clés Étrangères) :")
    
    # 2. Vérification des Clés Étrangères
    relations_found = 0
    for table_name in sorted(table_names):
        fks = inspector.get_foreign_keys(table_name)
        if fks:
            print(f"\n  TABLE '{table_name}' est liée à :")
            for fk in fks:
                referred_table = fk.get('referred_table')
                constrained_columns = fk['constrained_columns'] # La colonne source (ex: learner_id)
                referred_columns = fk['referred_columns'] # La colonne cible (ex: id)
                
                print(f"    -> {referred_table} (via {constrained_columns[0]} -> {referred_columns[0]})")
                relations_found += 1
    
    print(f"\n✨ Total de {relations_found} relations de clé étrangère trouvées.")
    
    if relations_found > 10: # On en attend beaucoup
        print("✅ La structure relationnelle semble riche et interconnectée.")
    else:
        print("⚠️ Attention : Peu de relations trouvées. Vérifiez vos modèles.")

if __name__ == "__main__":
    check_db_relations()

### FILE: ./scripts/validate_cases.py



### FILE: ./scripts/init_db.py



### FILE: ./scripts/populate_competencies.py

import sys
import os

# Ajoute la racine du projet au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import SessionLocal
from app import models

def populate():
    db = SessionLocal()
    print("--- Peuplement des Compétences Cliniques (Structure Consultation & Bloom) ---")

    # ---------------------------------------------------------
    # 1. Compétences Racines (Les Grandes Étapes de la Consultation)
    # ---------------------------------------------------------
    root_skills = [
        {"code": "RELATION", "nom": "1. Accueil et Relation Patient", "cat": "Communication", "bloom": 2},
        {"code": "ANAMNESE", "nom": "2. Anamnèse (Interrogatoire)", "cat": "Enquête", "bloom": 3},
        {"code": "EXAMEN_PHYSIQUE", "nom": "3. Examen Clinique", "cat": "Observation", "bloom": 3},
        {"code": "RAISONNEMENT", "nom": "4. Raisonnement Diagnostique", "cat": "Raisonnement", "bloom": 4},
        {"code": "PARACLINIQUE", "nom": "5. Examens Complémentaires", "cat": "Investigation", "bloom": 4},
        {"code": "SYNTHESE", "nom": "6. Diagnostic et Explication", "cat": "Synthèse", "bloom": 5},
        {"code": "PRISE_EN_CHARGE", "nom": "7. Traitement et Suivi", "cat": "Action", "bloom": 6},
    ]

    roots = {}
    for skill in root_skills:
        existing = db.query(models.Competence).filter(models.Competence.code_competence == skill["code"]).first()
        if not existing:
            new_skill = models.Competence(
                code_competence=skill["code"],
                nom=skill["nom"],
                categorie=skill["cat"],
                niveau_bloom=skill["bloom"],
                description=f"Compétence racine pour l'étape : {skill['nom']}"
            )
            db.add(new_skill)
            db.commit()
            db.refresh(new_skill)
            roots[skill["code"]] = new_skill
            print(f"✅ Racine créée : {skill['nom']} (Bloom {skill['bloom']})")
        else:
            roots[skill["code"]] = existing
            print(f"ℹ️ Racine existante : {skill['nom']}")

    # ---------------------------------------------------------
    # 2. Sous-Compétences Spécifiques (Détails opératoires)
    # ---------------------------------------------------------
    specific_skills = [
        # 1. Accueil
        {"code": "IDENTIFIER_MOTIF", "nom": "Identifier le motif de consultation", "parent": "RELATION", "bloom": 1},
        {"code": "EMPATHIE", "nom": "Communication empathique", "parent": "RELATION", "bloom": 2},

        # 2. Anamnèse
        {"code": "ANAMNESE_HISTOIRE", "nom": "Caractériser l'histoire de la maladie (PQRST)", "parent": "ANAMNESE", "bloom": 3},
        {"code": "ANAMNESE_ANTECEDENTS", "nom": "Recueillir les antécédents (perso/famille)", "parent": "ANAMNESE", "bloom": 2},
        {"code": "ANAMNESE_TRAITEMENTS", "nom": "Recenser traitements et allergies", "parent": "ANAMNESE", "bloom": 2},
        {"code": "ANAMNESE_MODE_VIE", "nom": "Identifier les facteurs de mode de vie", "parent": "ANAMNESE", "bloom": 2},

        # 3. Examen Physique
        {"code": "SIGNES_VITAUX", "nom": "Mesurer et interpréter les constantes", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},
        {"code": "EXAMEN_CIBLE", "nom": "Réaliser l'examen physique ciblé", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},
        {"code": "RECONNAISSANCE_SIGNES", "nom": "Reconnaître les signes physiques d'alerte", "parent": "EXAMEN_PHYSIQUE", "bloom": 3},

        # 4. Raisonnement
        {"code": "GENERATION_HYPOTHESES", "nom": "Formuler des hypothèses diagnostiques", "parent": "RAISONNEMENT", "bloom": 4},
        {"code": "DIAGNOSTIC_DIFFERENTIEL", "nom": "Mener un diagnostic différentiel", "parent": "RAISONNEMENT", "bloom": 5},

        # 5. Paraclinique
        {"code": "PRESCRIPTION_PERTINENTE", "nom": "Prescrire les examens pertinents", "parent": "PARACLINIQUE", "bloom": 5},
        {"code": "INTERPRETATION_BIOLOGIE", "nom": "Interpréter les résultats biologiques", "parent": "PARACLINIQUE", "bloom": 4},
        {"code": "INTERPRETATION_IMAGERIE", "nom": "Interpréter l'imagerie médicale", "parent": "PARACLINIQUE", "bloom": 4},

        # 6. Synthèse
        {"code": "SYNTHESE_CLINIQUE", "nom": "Intégrer les données pour conclure", "parent": "SYNTHESE", "bloom": 5},
        {"code": "ANNONCE_DIAGNOSTIC", "nom": "Expliquer le diagnostic au patient", "parent": "SYNTHESE", "bloom": 3},

        # 7. Prise en charge
        {"code": "PRESCRIPTION_THERAPEUTIQUE", "nom": "Établir le plan thérapeutique", "parent": "PRISE_EN_CHARGE", "bloom": 6},
        {"code": "EDUCATION_PATIENT", "nom": "Éduquer le patient sur sa maladie", "parent": "PRISE_EN_CHARGE", "bloom": 3},
        {"code": "SUIVI_EVOLUTION", "nom": "Planifier le suivi et la surveillance", "parent": "PRISE_EN_CHARGE", "bloom": 5},
    ]

    created_skills = {}
    for skill in specific_skills:
        existing = db.query(models.Competence).filter(models.Competence.code_competence == skill["code"]).first()
        if not existing:
            parent = roots.get(skill["parent"])
            new_skill = models.Competence(
                code_competence=skill["code"],
                nom=skill["nom"],
                categorie=parent.categorie if parent else "Autre",
                parent_competence_id=parent.id if parent else None,
                niveau_bloom=skill["bloom"],
                description=f"Sous-compétence de : {parent.nom if parent else 'Racine'}"
            )
            db.add(new_skill)
            db.commit()
            db.refresh(new_skill)
            created_skills[skill["code"]] = new_skill
            print(f"  -> Sous-compétence créée : {skill['nom']} (Bloom {skill['bloom']})")
        else:
            created_skills[skill["code"]] = existing

    # ---------------------------------------------------------
    # 3. Création des Prérequis (Le Graphe de Dépendance)
    # ---------------------------------------------------------
    # Logique : "Pour faire B, il faut savoir faire A"
    prerequisites = [
        # Logique interne à l'Anamnèse
        ("ANAMNESE_HISTOIRE", "IDENTIFIER_MOTIF"), # On ne peut pas creuser l'histoire si on n'a pas le motif
        
        # Logique Anamnèse -> Examen
        ("EXAMEN_CIBLE", "ANAMNESE_HISTOIRE"), # L'examen est guidé par l'histoire
        
        # Logique vers Raisonnement
        ("GENERATION_HYPOTHESES", "ANAMNESE_HISTOIRE"),
        ("GENERATION_HYPOTHESES", "SIGNES_VITAUX"),
        
        # Logique vers Paraclinique
        ("PRESCRIPTION_PERTINENTE", "GENERATION_HYPOTHESES"), # On prescrit pour tester une hypothèse
        
        # Logique vers Synthèse
        ("SYNTHESE_CLINIQUE", "INTERPRETATION_BIOLOGIE"),
        ("SYNTHESE_CLINIQUE", "DIAGNOSTIC_DIFFERENTIEL"),
        
        # Logique vers Traitement (Le sommet)
        ("PRESCRIPTION_THERAPEUTIQUE", "SYNTHESE_CLINIQUE"), # Pas de traitement sans diagnostic
        ("EDUCATION_PATIENT", "SYNTHESE_CLINIQUE"),
    ]

    for target_code, req_code in prerequisites:
        target = created_skills.get(target_code)
        req = created_skills.get(req_code)

        if target and req:
            # Vérifier si le lien existe déjà
            link_exists = db.query(models.PrerequisCompetence).filter(
                models.PrerequisCompetence.competence_id == target.id,
                models.PrerequisCompetence.prerequis_id == req.id
            ).first()

            if not link_exists:
                new_link = models.PrerequisCompetence(
                    competence_id=target.id,
                    prerequis_id=req.id,
                    type_relation="STRICT"
                )
                db.add(new_link)
                print(f"    🔗 Prérequis créé : {req.nom} -> {target.nom}")

    db.commit()
    db.close()
    print("✨ Peuplement des compétences pédagogiques terminé.")

if __name__ == "__main__":
    populate()

### FILE: ./testembedding.py

from app.services.embedding_service import embedding_service

text = "Pneumonie avec fièvre élevée"
vector = embedding_service.get_text_embedding(text)

print(f"Texte : {text}")
print(f"Taille du vecteur : {len(vector)}")
print(f"Aperçu : {vector[:5]}...")

### FILE: ./tests/conftest.py



### FILE: ./tests/fixtures/__init__.py



### FILE: ./tests/__init__.py



### FILE: ./tests/integration/__init__.py



### FILE: ./tests/unit/__init__.py



### FILE: ./datasets/integrators/open_medic_integrator.py



### FILE: ./datasets/integrators/physionet_integrator.py



### FILE: ./datasets/integrators/open_bio_integrator.py



### FILE: ./datasets/integrators/__init__.py



### FILE: ./datasets/integrators/eicu_integrator.py



### FILE: ./datasets/integrators/chexpert_integrator.py



### FILE: ./datasets/integrators/mimic3_symptom_relation_integrator.py



### FILE: ./datasets/integrators/manual_images_integrator.py

import pandas as pd
import os
import shutil
from sqlalchemy.orm import Session
from typing import List

from app import models
from ..base_integrator import BaseIntegrator

# Chemin relatif où vous avez mis vos images
STORAGE_REL_PATH = "storage/media/images" 

class ManualImagesIntegrator(BaseIntegrator):
    """
    Intégrateur pour cataloguer les images manuelles déjà présentes dans le dossier storage.
    """

    def __init__(self, db_session: Session, mapping_csv_path: str, source_images_dir: str = None):
        super().__init__(db_session, mapping_csv_path)
        self.storage_dir = os.path.abspath(STORAGE_REL_PATH)
        print(f"--- Initialisation de l'intégrateur d'images ---")
        print(f"Dossier des images : {self.storage_dir}")

    def extract(self):
        """Lit le fichier de mapping."""
        return pd.read_csv(self.path, chunksize=1000)

    def transform(self, data_chunk: pd.DataFrame) -> List[dict]:
        """Prépare les données."""
        actions = []
        for _, row in data_chunk.iterrows():
            filename = str(row['filename']).strip()
            file_path = os.path.join(self.storage_dir, filename)
            
            if not os.path.exists(file_path):
                print(f"⚠️ Fichier manquant dans storage : {filename}")
                continue

            # Nettoyage et parsing des IDs
            raw_ids = str(row['cas_ids'])
            cas_ids_str = raw_ids.replace('"', '').replace("'", "")
            cas_ids = []
            for x in cas_ids_str.split(','):
                x = x.strip()
                if x.isdigit():
                    cas_ids.append(int(x))
            
            # Log de débogage
            # print(f"[DEBUG] Image {filename} -> IDs cibles : {cas_ids}")

            actions.append({
                "filename": filename,
                "file_path": file_path,
                "cas_ids": cas_ids,
                "type_examen": row['type_examen'],
                "description": row['description']
            })
        return actions

    def load(self, actions: List[dict]):
        """Crée les entrées en base."""
        for action in actions:
            filename = action['filename']
            file_url = os.path.join(STORAGE_REL_PATH, filename)
            
            existing_img = self.db.query(models.ImageMedicale).filter(
                models.ImageMedicale.fichier_url == file_url
            ).first()

            if not existing_img:
                new_image = models.ImageMedicale(
                    type_examen=action['type_examen'],
                    description=action['description'],
                    fichier_url=file_url,
                    format_image=filename.split('.')[-1].lower()
                )
                self.db.add(new_image)
                self.db.flush()
                image_id = new_image.id
                print(f"    -> Image cataloguée : {filename} (ID: {image_id})")
            else:
                image_id = existing_img.id

            # Lier aux Cas Cliniques
            for case_id_csv in action['cas_ids']: 
                
                # Pour chaque ID de la liste, on applique le décalage
                case_id_db = case_id_csv + 908  
                
                # On cherche le cas correspondant en base
                case = self.db.query(models.ClinicalCase).filter(models.ClinicalCase.id == case_id_db).first()
                if case:
                    # ... (le reste du code utilise 'case', donc c'est bon)
                    if case.images_associees_ids is None:
                        case.images_associees_ids = []
                    
                    current_ids = list(case.images_associees_ids)
                    if image_id not in current_ids:
                        current_ids.append(image_id)
                        case.images_associees_ids = current_ids
                        print(f"       -> ✅ Liée au cas {case_id_db} ({case.code_fultang})")

        try:
            self.db.commit()
        except Exception as e:
            print(f"❌ Erreur commit : {e}")
            self.db.rollback()

### FILE: ./datasets/integrators/mimic3_integrator.py

import pandas as pd
from sqlalchemy.orm import Session
from typing import Dict, Set

from app import models

class MIMIC3RelationsIntegrator:
    """
    Intégrateur pour déduire et créer les relations entre pathologies,
    symptômes et médicaments avec des probabilités réelles (basées sur les patients uniques).
    """

    def __init__(self, db_session: Session, paths: Dict[str, str]):
        self.db = db_session
        self.paths = paths
        self.disease_map: Dict[str, int] = {}
        self.symptom_map: Dict[str, int] = {}
        self.medication_map: Dict[str, int] = {}
        print("--- Initialisation de l'intégrateur de relations MIMIC-III ---")

    def _preload_dictionaries(self):
        print("  -> Pré-chargement des dictionnaires...")
        diseases = self.db.query(models.Disease.id, models.Disease.code_icd10).all()
        self.disease_map = {str(code).strip(): id for id, code in diseases}
        
        symptoms = self.db.query(models.Symptom.id, models.Symptom.nom).all()
        self.symptom_map = {nom: id for id, nom in symptoms}

        meds = self.db.query(models.Medication.id, models.Medication.nom_commercial).all()
        self.medication_map = {nom: id for id, nom in meds}

    def run(self):
        self._preload_dictionaries()

        # --- Étape 1: Carte des diagnostics et COMPTAGE ---
        print("\n🚀 Étape 1: Carte des diagnostics et calcul des totaux...")
        diagnoses_path = self.paths.get('diagnoses_icd')
        if not diagnoses_path: return
            
        admissions_diagnoses = {}
        disease_counts: Dict[str, int] = {} 

        df_diag = pd.read_csv(diagnoses_path, usecols=['hadm_id', 'icd9_code'], dtype={'icd9_code': str})
        for _, row in df_diag.iterrows():
            hadm_id = row['hadm_id']
            icd9_code = str(row['icd9_code']).strip()
            
            normalized_code = icd9_code.lstrip('0')
            if not normalized_code and icd9_code.isnumeric(): normalized_code = '0'
            elif not normalized_code: normalized_code = icd9_code

            if normalized_code in self.disease_map:
                code_to_use = normalized_code
            elif icd9_code in self.disease_map:
                code_to_use = icd9_code
            else:
                continue

            if hadm_id not in admissions_diagnoses:
                admissions_diagnoses[hadm_id] = set()
            
            if code_to_use not in admissions_diagnoses[hadm_id]:
                admissions_diagnoses[hadm_id].add(code_to_use)
                disease_counts[code_to_use] = disease_counts.get(code_to_use, 0) + 1
        
        print(f"  -> Carte construite. {len(disease_counts)} maladies différentes trouvées.")

        # --- Étape 2: Analyse des résultats (CORRECTION LOGIQUE) ---
        print("\n🚀 Étape 2: Analyse des résultats de laboratoire anormaux...")
        labevents_path = self.paths.get('labevents')
        d_labitems_path = self.paths.get('d_labitems')
        if not labevents_path or not d_labitems_path: return

        df_labitems = pd.read_csv(d_labitems_path, usecols=['itemid', 'label'])
        itemid_to_label = pd.Series(df_labitems.label.values, index=df_labitems.itemid).to_dict()

        # CORRECTION : Utiliser un Set pour stocker les hadm_id uniques
        co_occurrences: Dict[str, Dict[str, Set[int]]] = {} 

        chunk_iterator = pd.read_csv(labevents_path, chunksize=100000, usecols=['hadm_id', 'itemid', 'flag'])
        
        for chunk in chunk_iterator:
            abnormal_events = chunk[chunk['flag'] == 'abnormal'].dropna()
            for _, event in abnormal_events.iterrows():
                hadm_id = event['hadm_id']
                itemid = event['itemid']
                diagnoses = admissions_diagnoses.get(hadm_id)
                symptom_name = itemid_to_label.get(itemid)

                if diagnoses and symptom_name and symptom_name in self.symptom_map:
                    for icd9_code in diagnoses:
                        if icd9_code not in co_occurrences:
                            co_occurrences[icd9_code] = {}
                        
                        if symptom_name not in co_occurrences[icd9_code]:
                            co_occurrences[icd9_code][symptom_name] = set() # Initialiser un Set
                        
                        # Ajouter l'ID de l'admission (les doublons sont ignorés par le Set)
                        co_occurrences[icd9_code][symptom_name].add(hadm_id)
        
        # --- Étape 3: Chargement des relations ---
        print("\n🚀 Étape 3: Chargement des relations (Probabilités réelles)...")
        new_relations = []
        
        log_limit = 10 
        current_log = 0

        for icd9_code, symptom_sets in co_occurrences.items():
            disease_id = self.disease_map.get(icd9_code)
            total_cases = disease_counts.get(icd9_code, 1)

            if not disease_id: continue

            for symptom_name, unique_patients_set in symptom_sets.items():
                symptom_id = self.symptom_map.get(symptom_name)
                if not symptom_id: continue
                
                # CORRECTION : Compter la taille du Set (nombre de patients uniques)
                unique_count = len(unique_patients_set)
                
                # Calcul correct : (Nb patients uniques avec symptôme) / (Nb total patients avec maladie)
                prob = unique_count / total_cases 
            
            # Logs de vérification
                if current_log < 120: # Augmentons la limite à 20 pour voir plus de cas
                    print(f"  [LOG] Maladie {icd9_code} (ID BDD: {disease_id})")
                    print(f"        Symptôme: {symptom_name}")
                    # Afficher clairement si c'est un cas unique ou non
                    if total_cases == 1:
                        print(f"        -> ⚠️ UN SEUL PATIENT connu pour cette maladie dans le dataset.")
                    else:
                        print(f"        -> ✅ PLUSIEURS PATIENTS ({total_cases}).")
                    
                    print(f"        -> Calcul: {unique_count}/{total_cases} = {prob:.4f}")
                    print("        --------------------------------------------------")
                    current_log += 1

                if prob > 0.05:
                    new_relations.append(models.PathologieSymptome(
                        pathologie_id=disease_id,
                        symptome_id=symptom_id,
                        probabilite=prob,
                        frequence=f"{prob*100:.1f}%",
                        importance_diagnostique=3
                    ))

        if new_relations:
            try:
                self.db.bulk_save_objects(new_relations)
                self.db.commit()
                print(f"✨ Chargement de {len(new_relations)} relations pathologie-symptôme.")
            except Exception:
                self.db.rollback()

        # --- Étape 4 & 5: Relations Thérapeutiques (Même logique de correction) ---
        print("\n🚀 Étape 4: Analyse des prescriptions...")
        prescriptions_path = self.paths.get('prescriptions')
        if not prescriptions_path: return

        # CORRECTION : Utiliser un Set pour les médicaments aussi
        med_co_occurrences: Dict[str, Dict[str, Set[int]]] = {}

        chunk_iterator = pd.read_csv(prescriptions_path, chunksize=10000, usecols=['hadm_id', 'drug'], dtype=str)
        for chunk in chunk_iterator:
            for _, row in chunk.iterrows():
                hadm_id = int(row['hadm_id']) if pd.notna(row['hadm_id']) else None
                drug_name = str(row['drug']).strip()
                diagnoses = admissions_diagnoses.get(hadm_id)
                
                if diagnoses and drug_name in self.medication_map:
                    for icd9_code in diagnoses:
                        if icd9_code not in med_co_occurrences:
                            med_co_occurrences[icd9_code] = {}
                        
                        if drug_name not in med_co_occurrences[icd9_code]:
                            med_co_occurrences[icd9_code][drug_name] = set()
                        
                        med_co_occurrences[icd9_code][drug_name].add(hadm_id)

        print("\n🚀 Étape 5: Chargement des relations thérapeutiques...")
        new_treatments = []
        for icd9_code, drug_sets in med_co_occurrences.items():
            disease_id = self.disease_map.get(icd9_code)
            total_cases = disease_counts.get(icd9_code, 1)

            if not disease_id: continue

            # Trier par nombre de patients uniques
            top_drugs = sorted(drug_sets.items(), key=lambda x: len(x[1]), reverse=True)[:10]

            for drug_name, unique_patients_set in top_drugs:
                med_id = self.medication_map.get(drug_name)
                if not med_id: continue
                
                unique_count = len(unique_patients_set)
                frequence = (unique_count / total_cases) * 100
                
                new_treatments.append(models.TraitementPathologie(
                    pathologie_id=disease_id,
                    medicament_id=med_id,
                    efficacite_taux=frequence,
                    type_traitement=f"Prescrit dans {frequence:.1f}% des cas"
                ))

        if new_treatments:
            try:
                self.db.bulk_save_objects(new_treatments)
                self.db.commit()
                print(f"✨ Chargement de {len(new_treatments)} relations thérapeutiques.")
            except Exception:
                self.db.rollback()

### FILE: ./datasets/integrators/mimic3_dics_integrator.py

import pandas as pd
from sqlalchemy.orm import Session
from typing import Dict, Set

from app import models

class MIMIC3DictionariesIntegrator:
    """
    Intégrateur spécialisé pour peupler les tables de référence (dictionnaires)
    de notre base de données à partir des fichiers correspondants de MIMIC-III.
    """

    def __init__(self, db_session: Session, paths: Dict[str, str]):
        """
        Initialise l'intégrateur avec une session de base de données et un
        dictionnaire des chemins vers les fichiers CSV nécessaires.
        """
        self.db = db_session
        self.paths = paths
        print("--- Initialisation de l'intégrateur de dictionnaires MIMIC-III ---")

    def populate_pathologies(self):
        """
        Peuple la table 'pathologies' depuis D_ICD_DIAGNOSES.csv.
        """
        print("\n🚀 Démarrage du peuplement de la table 'pathologies'...")
        path = self.paths.get('d_icd_diagnoses')
        if not path:
            print("❌ Chemin pour D_ICD_DIAGNOSES.csv non fourni. Étape ignorée.")
            return

        existing_codes = {c[0] for c in self.db.query(models.Disease.code_icd10).all()}
        print(f"  -> {len(existing_codes)} pathologies déjà en base.")
        
        chunk_iterator = pd.read_csv(
            path, 
            chunksize=5000, 
            usecols=['icd9_code', 'long_title'], 
            encoding='latin1',
            dtype={'icd9_code': str}
        )
        
        total_added = 0
        for chunk in chunk_iterator:
            new_diseases = []
            for _, row in chunk.iterrows():
                code = str(row['icd9_code']).strip()
                if code and code not in existing_codes:
                    existing_codes.add(code)
                    new_diseases.append(models.Disease(
                        code_icd10=code,
                        nom_fr=str(row['long_title']).strip()[:255],
                        categorie="Importé de MIMIC-III"
                    ))
            
            if new_diseases:
                self.db.bulk_save_objects(new_diseases)
                total_added += len(new_diseases)

        self.db.commit()
        print(f"✨ Peuplement terminé. {total_added} nouvelles pathologies ajoutées.")

    def populate_symptoms_from_items(self):
        """
        Peuple la table 'symptomes' depuis D_LABITEMS.csv et D_ITEMS.csv.
        """
        print("\n🚀 Démarrage du peuplement de la table 'symptomes'...")
        files_to_process = {
            'd_labitems': {'categorie': 'Biologique'},
            'd_items': {'categorie': 'Signe Vital/Clinique'}
        }
        
        existing_symptoms = {s[0] for s in self.db.query(models.Symptom.nom).all()}
        print(f"  -> {len(existing_symptoms)} symptômes déjà en base.")

        total_added = 0
        for key, info in files_to_process.items():
            path = self.paths.get(key)
            if not path:
                print(f"⚠️ Chemin pour {key}.csv non fourni. Étape ignorée.")
                continue
            
            print(f"  -> Traitement de {path}...")
            # Utiliser un chunksize pour éviter de charger tout le fichier en mémoire
            chunk_iterator = pd.read_csv(path, usecols=['label'], encoding='latin1', chunksize=10000)
            
            for chunk in chunk_iterator:
                new_symptoms = []
                unique_labels = chunk['label'].dropna().unique()

                for label in unique_labels:
                    clean_label = str(label).strip()
                    if clean_label and clean_label not in existing_symptoms:
                        existing_symptoms.add(clean_label)
                        new_symptoms.append(models.Symptom(
                            nom=clean_label[:255],
                            categorie=info['categorie']
                        ))
                
                if new_symptoms:
                    self.db.bulk_save_objects(new_symptoms)
                    total_added += len(new_symptoms)
        
        self.db.commit()
        print(f"✨ Peuplement terminé. {total_added} nouveaux symptômes ajoutés.")

    def populate_medications(self):
        """
        Peuple la table 'medicaments' depuis PRESCRIPTIONS.csv.
        Utilise la colonne 'drug' (nom commercial) et 'formulary_drug_cd' (comme proxy DCI pour l'instant).
        """
        print("\n🚀 Démarrage du peuplement de la table 'medicaments'...")
        path = self.paths.get('prescriptions')
        if not path:
            print("❌ Chemin pour PRESCRIPTIONS.csv non fourni. Étape ignorée.")
            return

        existing_meds = {m[0] for m in self.db.query(models.Medication.nom_commercial).all()}
        print(f"  -> {len(existing_meds)} médicaments déjà en base.")
        
        # Lecture par lots car PRESCRIPTIONS.csv peut être très gros
        chunk_iterator = pd.read_csv(
            path, 
            chunksize=10000, 
            usecols=['drug', 'drug_type', 'formulary_drug_cd', 'prod_strength', 'dose_val_rx', 'dose_unit_rx', 'route'],
            dtype=str # Tout lire en string pour éviter les erreurs de type
        )
        
        total_added = 0
        for chunk in chunk_iterator:
            new_meds = []
            # On ne garde que les noms de médicaments uniques dans ce lot
            unique_drugs = chunk.drop_duplicates(subset=['drug'])
            
            for _, row in unique_drugs.iterrows():
                drug_name = str(row['drug']).strip()
                
                if drug_name and drug_name not in existing_meds:
                    existing_meds.add(drug_name)
                    
                    # Construction de l'objet Médicament
                    # Note: Dans MIMIC, 'drug' est souvent le nom commercial.
                    # 'formulary_drug_cd' est un code interne, on l'utilise comme DCI temporaire
                    # si 'drug_name_generic' n'est pas dispo (ce qui est le cas dans la démo parfois).
                    new_meds.append(models.Medication(
                        nom_commercial=drug_name,
                        dci=str(row['formulary_drug_cd']).strip()[:255], 
                        classe_therapeutique="Importé de MIMIC-III",
                        dosage=str(row['prod_strength']).strip()[:100] if pd.notna(row['prod_strength']) else None,
                        voie_administration=str(row['route']).strip()[:100] if pd.notna(row['route']) else None,
                        disponibilite_cameroun="Inconnue"
                    ))
            
            if new_meds:
                self.db.bulk_save_objects(new_meds)
                total_added += len(new_meds)

        self.db.commit()
        print(f"✨ Peuplement terminé. {total_added} nouveaux médicaments ajoutés.")

    def run_all(self):
        """
        Exécute toutes les étapes de peuplement des dictionnaires.
        """
        self.populate_pathologies()
        self.populate_symptoms_from_items()
        self.populate_medications() # <- NOUVELLE ÉTAPE

### FILE: ./datasets/adapters/medication_adapter.py



### FILE: ./datasets/adapters/prevalence_adapter.py



### FILE: ./datasets/adapters/__init__.py



### FILE: ./datasets/adapters/cameroon_adapter.py



### FILE: ./datasets/validators/quality_checker.py



### FILE: ./datasets/validators/__init__.py



### FILE: ./datasets/validators/clinical_validator.py



### FILE: ./datasets/__init__.py



### FILE: ./datasets/assembler/intelligent_assembler.py



### FILE: ./datasets/assembler/case_assembler.py

import pandas as pd
from sqlalchemy.orm import Session
from typing import Dict, List, Any
import math
import random

from app import models
from app.services.embedding_service import embedding_service # <-- IMPORT

def clean_nan(value: Any) -> Any:
    """Remplace les valeurs NaN par None."""
    if value is None: return None
    if isinstance(value, float) and math.isnan(value): return None
    if isinstance(value, str) and value.lower() == 'nan': return None
    return value


class CaseAssembler:
    """
    Assemble des cas cliniques enrichis à partir de MIMIC-III.
    """
    def __init__(self, db_session: Session, paths: Dict[str, str]):
        self.db = db_session
        self.paths = paths
        self.disease_map: Dict[str, int] = {}
        self.symptom_map: Dict[str, int] = {}
        self.medication_map: Dict[str, int] = {}
        self.images_by_disease: Dict[int, List[int]] = {} 
        print("--- Initialisation de l'assembleur de cas cliniques ---")

    def _preload_data(self):
        print("  -> Pré-chargement des dictionnaires...")
        
        diseases = self.db.query(models.Disease.id, models.Disease.code_icd10).all()
        self.disease_map = {str(code).strip(): id for id, code in diseases}
        
        symptoms = self.db.query(models.Symptom.id, models.Symptom.nom).all()
        self.symptom_map = {nom: id for id, nom in symptoms}

        meds = self.db.query(models.Medication.id, models.Medication.nom_commercial).all()
        self.medication_map = {nom: id for id, nom in meds}

        # Images
        images = self.db.query(models.ImageMedicale.id, models.ImageMedicale.pathologie_id).filter(models.ImageMedicale.pathologie_id != None).all()
        for img_id, path_id in images:
            if path_id not in self.images_by_disease:
                self.images_by_disease[path_id] = []
            self.images_by_disease[path_id].append(img_id)

        # CSVs
        self.df_diagnoses = pd.read_csv(
            self.paths['diagnoses_icd'],
            usecols=['hadm_id', 'icd9_code', 'seq_num'],
            dtype={'icd9_code': str}
        )
        
        self.df_labitems = pd.read_csv(self.paths['d_labitems'], usecols=['itemid', 'label'])
        self.itemid_to_label = pd.Series(self.df_labitems.label.values, index=self.df_labitems.itemid).to_dict()

    def run(self):
        self._preload_data()

        admissions_path = self.paths.get('admissions')
        if not admissions_path: return

        print("\n🚀 Démarrage de l'assemblage des cas cliniques...")
        df_admissions = pd.read_csv(admissions_path)
        
        # --- Agrégation Labos ---
        print("  -> Agrégation des résultats de laboratoire...")
        labevents_chunk_iterator = pd.read_csv(self.paths['labevents'], chunksize=100000, usecols=['hadm_id', 'itemid', 'valuenum', 'valueuom', 'flag'])
        admission_labs: Dict[int, Dict[str, Any]] = {}
        for chunk in labevents_chunk_iterator:
            chunk['valuenum'].fillna(0, inplace=True)
            chunk['valueuom'].fillna('', inplace=True)
            chunk['flag'].fillna('', inplace=True)
            abnormal_events = chunk[chunk['flag'] == 'abnormal'].dropna(subset=['hadm_id'])
            for _, event in abnormal_events.iterrows():
                hadm_id = int(event['hadm_id'])
                if hadm_id not in admission_labs: admission_labs[hadm_id] = {}
                symptom_name = self.itemid_to_label.get(event['itemid'])
                if symptom_name and symptom_name not in admission_labs[hadm_id]:
                    admission_labs[hadm_id][symptom_name] = {
                        "nom": symptom_name, "valeur": event['valuenum'], "unite": event['valueuom']
                    }
        
        # --- Agrégation Médicaments ---
        print("  -> Agrégation des prescriptions médicamenteuses...")
        prescriptions_path = self.paths.get('prescriptions')
        admission_meds: Dict[int, List[Dict[str, Any]]] = {}
        if prescriptions_path:
            presc_chunk_iterator = pd.read_csv(prescriptions_path, chunksize=50000, usecols=['hadm_id', 'drug', 'dose_val_rx', 'dose_unit_rx'], dtype=str)
            for chunk in presc_chunk_iterator:
                chunk = chunk.dropna(subset=['hadm_id', 'drug'])
                for _, row in chunk.iterrows():
                    hadm_id = int(float(row['hadm_id']))
                    if hadm_id not in admission_meds: admission_meds[hadm_id] = []
                    drug_name = str(row['drug']).strip()
                    med_id = self.medication_map.get(drug_name)
                    if med_id:
                        admission_meds[hadm_id].append({
                            "medicament_id": med_id, "nom": drug_name, "dose": f"{row['dose_val_rx']} {row['dose_unit_rx']}"
                        })

        # --- Assemblage ---
        new_cases = []
        existing_case_codes = {c[0] for c in self.db.query(models.ClinicalCase.code_fultang).all()}

        for _, admission in df_admissions.iterrows():
            hadm_id = admission['hadm_id']
            case_code = f"MIMIC_{hadm_id}"

            if case_code in existing_case_codes: continue

            diagnoses_for_admission = self.df_diagnoses[self.df_diagnoses['hadm_id'] == hadm_id].sort_values('seq_num')
            if diagnoses_for_admission.empty: continue

            main_diag_id = None
            secondary_diag_ids = []
            for _, diag_row in diagnoses_for_admission.iterrows():
                raw_diag_code = str(diag_row['icd9_code']).strip()
                normalized_diag_code = raw_diag_code.lstrip('0')
                if not normalized_diag_code and raw_diag_code.isnumeric(): normalized_diag_code = '0'
                elif not normalized_diag_code: normalized_diag_code = raw_diag_code
                diag_id = self.disease_map.get(normalized_diag_code) or self.disease_map.get(raw_diag_code)

                if diag_id:
                    if diag_row['seq_num'] == 1:
                        main_diag_id = diag_id
                    else:
                        secondary_diag_ids.append(diag_id)
            
            if not main_diag_id: continue

            # Symptômes
            lab_results_dict = admission_labs.get(hadm_id, {})
            lab_results_list = list(lab_results_dict.values())
            symptomes_patient = []
            symptoms_text_list = [] # Pour le vecteur
            
            for lab_res in lab_results_list:
                symptom_id = self.symptom_map.get(lab_res['nom'])
                if symptom_id:
                    symptomes_patient.append({
                        "symptome_id": symptom_id, "details": f"Valeur: {lab_res.get('valeur')} {lab_res.get('unite') or ''}".strip()
                    })
                    symptoms_text_list.append(f"{lab_res['nom']} {lab_res.get('valeur')}")

            history_text = f"Admission pour : {admission['diagnosis']}"
            presentation = {
                "histoire_maladie": history_text,
                "symptomes_patient": symptomes_patient
            }
            
            meds_list = admission_meds.get(hadm_id, [])

            # Images
            images_ids = []
            if main_diag_id in self.images_by_disease:
                available_images = self.images_by_disease[main_diag_id]
                if available_images:
                    images_ids.append(random.choice(available_images))

            # --- VECTORISATION ---
            # On vectorise l'histoire clinique combinée aux symptômes principaux
            # C'est ce texte que le RAG utilisera pour trouver des cas similaires
            full_case_text = f"{history_text}. Symptômes biologiques notables : {', '.join(symptoms_text_list[:10])}"
            vector = embedding_service.get_text_embedding(full_case_text)

            new_case = models.ClinicalCase(
                code_fultang=case_code,
                pathologie_principale_id=main_diag_id,
                pathologies_secondaires_ids=secondary_diag_ids,
                presentation_clinique=presentation,
                donnees_paracliniques={"lab_results": lab_results_list},
                medicaments_prescrits=meds_list,
                images_associees_ids=images_ids,
                niveau_difficulte=2 + len(secondary_diag_ids),
                embedding_texte=vector # <-- AJOUT
            )
            new_cases.append(new_case)

        print(f"  -> {len(new_cases)} cas cliniques assemblés.")

        if new_cases:
            try:
                self.db.bulk_save_objects(new_cases)
                self.db.commit()
                print(f"✨ Chargement de {len(new_cases)} nouveaux cas cliniques réussi.")

                print("\n--- Aperçu des 10 premiers cas cliniques chargés ---")
                first_10_cases = self.db.query(models.ClinicalCase).order_by(models.ClinicalCase.id.desc()).limit(10).all()
                for i, case_from_db in enumerate(reversed(first_10_cases)):
                    disease_name = case_from_db.pathologie_principale.nom_fr if case_from_db.pathologie_principale else "Inconnue"
                    # Vérifier si le vecteur est présent (pour le log)
                    has_vector = "OUI" if case_from_db.embedding_texte is not None else "NON"
                    
                    print(f"\n[{i+1}] Cas: {case_from_db.code_fultang}")
                    print(f"    Pathologie: {disease_name}")
                    print(f"    Vecteur IA généré: {has_vector}") # <-- Affichage validation

            except Exception as e:
                print(f"❌ Erreur lors du chargement des cas : {e}")
                self.db.rollback()
        else:
            print("✨ Aucun nouveau cas clinique à ajouter.")

### FILE: ./datasets/assembler/__init__.py



### FILE: ./datasets/assembler/enrichment_engine.py



### FILE: ./datasets/assembler/library_builder.py



### FILE: ./datasets/base_integrator.py

from abc import ABC, abstractmethod
from sqlalchemy.orm import Session

class BaseIntegrator(ABC):
    """
    Classe de base abstraite (blueprint) pour tous les intégrateurs de datasets.
    
    Elle impose une structure ETL (Extract, Transform, Load) cohérente pour
    garantir que chaque script d'importation fonctionne de la même manière.
    """

    def __init__(self, db_session: Session, dataset_path: str):
        """
        Initialise l'intégrateur avec une session de base de données et le chemin
        vers le dataset.
        
        :param db_session: La session SQLAlchemy pour interagir avec la BDD.
        :param dataset_path: Le chemin vers le dossier ou le fichier du dataset.
        """
        self.db = db_session
        self.path = dataset_path
        print(f"--- Initialisation de {self.__class__.__name__} ---")
        print(f"Source des données : {self.path}")

    @abstractmethod
    def extract(self):
        """
        Étape d'Extraction (E) : Lire les données depuis la source.
        
        Cette méthode DOIT être implémentée par chaque sous-classe.
        Elle doit retourner un itérateur qui produit des lots (chunks) de données
        (par exemple, un TextFileReader de pandas).
        """
        pass

    @abstractmethod
    def transform(self, data_chunk: any):
        """
        Étape de Transformation (T) : Nettoyer, mapper et préparer les données.
        
        Cette méthode DOIT être implémentée par chaque sous-classe.
        Elle prend un lot de données extraites et retourne une liste d'objets
        SQLAlchemy prêts à être insérés.
        """
        pass

    @abstractmethod
    def load(self, transformed_data: list):
        """
        Étape de Chargement (L) : Insérer les données transformées en BDD.
        
        Cette méthode DOIT être implémentée par chaque sous-classe.
        """
        pass

    def run(self):
        """
        Orchestre le processus ETL complet.
        
        Cette méthode est déjà implémentée et ne devrait pas être modifiée.
        Elle appelle successivement extract, transform, et load pour chaque lot.
        """
        print(f"\n🚀 Démarrage du processus ETL pour {self.__class__.__name__}...")
        
        try:
            extracted_data_iterator = self.extract()
            
            total_items_loaded = 0
            chunk_count = 0
            for chunk in extracted_data_iterator:
                chunk_count += 1
                print(f"  [{chunk_count}] Extraction d'un lot de {len(chunk)} lignes.")
                
                transformed_chunk = self.transform(chunk)
                
                if transformed_chunk:
                    print(f"    -> Transformation réussie : {len(transformed_chunk)} objets prêts à être chargés.")
                    self.load(transformed_chunk)
                    total_items_loaded += len(transformed_chunk)
                else:
                    print("    -> Aucun nouvel objet à charger dans ce lot.")
            
            print(f"\n✨ Processus ETL terminé. {total_items_loaded} objets uniques chargés au total.")
        except FileNotFoundError:
            print(f"❌ ERREUR: Le fichier ou dossier du dataset n'a pas été trouvé à l'emplacement : {self.path}")
        except Exception as e:
            print(f"❌ ERREUR inattendue pendant le processus ETL : {e}")
            # En production, on utiliserait un logger plus sophistiqué.