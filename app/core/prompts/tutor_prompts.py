#=== Fichier: ./app/core/prompts/tutor_prompts.py ===

import logging
import json
import uuid
from typing import Dict, Any, List, Optional
from datetime import datetime

# ==============================================================================
# CONFIGURATION DU LOGGER "PROMPT-TUTOR"
# ==============================================================================
# Ce logger est d√©di√© √† la construction des prompts du Tuteur.
# Il permet de v√©rifier que le contexte p√©dagogique est correctement assembl√©.
logger = logging.getLogger("tutor_prompts")
logger.setLevel(logging.DEBUG)

if not logger.handlers:
    handler = logging.StreamHandler()
    # Format incluant le fichier et la ligne pour un d√©bogage rapide
    formatter = logging.Formatter(
        '%(asctime)s - [PROMPT-TUTOR] - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)

class TutorPromptBuilder:
    """
    Classe responsable de la construction des instructions (Prompts) pour l'IA Tuteur.
    
    R√îLE :
    Transformer une interaction brute (Question √âtudiant / R√©ponse Patient) en un
    probl√®me p√©dagogique structur√© que le LLM peut r√©soudre.
    
    PRINCIPES :
    1. Contextualisation : Le Tuteur doit conna√Ætre la pathologie r√©elle pour juger.
    2. P√©dagogie : Le Tuteur ne doit pas donner la r√©ponse, mais guider la m√©thode.
    3. Robustesse : Le format de sortie JSON est forc√© par des exemples stricts.
    """

    def __init__(self):
        logger.info("üîß Initialisation du TutorPromptBuilder")
        
        # Template principal pour l'analyse p√©dagogique
        # Con√ßu pour forcer l'IA √† r√©fl√©chir en 3 temps (M√©thode -> Interpr√©tation -> Correction)
        self.PEDAGOGICAL_ANALYSIS_TEMPLATE = """
TU ES UN PROFESSEUR DE M√âDECINE CHEVRONN√â (SUPERVISEUR CLINIQUE).
Ton r√¥le est d'analyser en temps r√©el l'interaction entre un √©tudiant en m√©decine et un patient simul√©.
Tu dois fournir un feedback p√©dagogique imm√©diat, bienveillant mais rigoureux.

--- 1. LE CONTEXTE CLINIQUE (V√âRIT√â TERRAIN - CACH√âE √Ä L'√âTUDIANT) ---
Pathologie r√©elle : {pathologie_nom}
R√©sum√© du cas : {resume_cas}
Phase th√©orique actuelle de la consultation : {phase_courante} (ex: Anamn√®se, Examen Physique...)

--- 2. L'INTERACTION √Ä ANALYSER ---
DERNI√àRE QUESTION DE L'√âTUDIANT :
"{question_etudiant}"

R√âPONSE OBTENUE DU PATIENT :
"{reponse_patient}"

--- 3. TA MISSION (ANALYSE P√âDAGOGIQUE) ---
Analyse cet √©change selon 3 axes et remplis le JSON ci-dessous.

AXE A : M√âTHODOLOGIE (Chronologie & Pertinence)
- La question est-elle pos√©e au bon moment ? (ex: Ne pas demander des examens avant d'avoir fini l'interrogatoire).
- La question est-elle pertinente pour suspecter/√©liminer la pathologie r√©elle ?
- Si l'√©tudiant saute des √©tapes, signale-le.

AXE B : INTERPR√âTATION (S√©miologie)
- Analyse la r√©ponse du patient. Quels sont les signes cliniques cl√©s (S√©miologie) pr√©sents dans sa r√©ponse ?
- Explique ce que l'√©tudiant doit d√©duire de cette r√©ponse.

AXE C : CORRECTION (L'Exemple)
- Quelle question aurais-tu pos√©e √† sa place pour √™tre plus efficace, plus empathique ou plus pr√©cis ?
- Formule cette question id√©ale entre guillemets.

--- 4. FORMAT DE SORTIE OBLIGATOIRE (JSON) ---
Tu dois r√©pondre UNIQUEMENT avec un objet JSON valide. Pas de texte avant ou apr√®s.

{{
  "chronology_check": "Analyse critique de la m√©thode (1 phrase). Indique si c'est 'Pr√©matur√©', 'Pertinent' ou 'Hors sujet'.",
  "interpretation_guide": "Guide de lecture de la r√©ponse du patient. Mets en gras les sympt√¥mes cl√©s.",
  "better_question": "La question que le professeur aurait pos√©e."
}}
"""

    def build_feedback_prompt(
        self, 
        case_data: Dict[str, Any], 
        student_msg: str,
        patient_msg: str,
        chat_history_count: int
    ) -> str:
        """
        Construit le prompt complet pour l'analyse p√©dagogique.
        
        :param case_data: Donn√©es du cas clinique (Pathologie, Description).
        :param student_msg: Le texte envoy√© par l'√©tudiant.
        :param patient_msg: Le texte r√©pondu par le patient (IA).
        :param chat_history_count: Nombre de messages pr√©c√©dents (pour estimer la phase).
        :return: Le prompt format√© pr√™t √† √™tre envoy√© au LLM.
        """
        # ID de trace pour suivre la construction de ce prompt sp√©cifique dans les logs
        trace_id = f"PRMPT-{str(uuid.uuid4())[:8]}"
        
        logger.info(f"üî® [{trace_id}] D√âBUT construction prompt TUTEUR")
        logger.debug(f"   [{trace_id}] Input √âtudiant : '{student_msg[:50]}...'")
        logger.debug(f"   [{trace_id}] Input Patient  : '{patient_msg[:50]}...'")

        try:
            # 1. Extraction et nettoyage des donn√©es du cas
            # -----------------------------------------------------------------
            pathologie_nom = self._safe_get(case_data, 'pathologie_principale.nom_fr', 'Pathologie non sp√©cifi√©e')
            
            # Construction d'un r√©sum√© contextuel √† partir des donn√©es brutes
            histoire = self._safe_get(case_data, 'presentation_clinique.histoire_maladie', '')
            
            # On logue les donn√©es sensibles (V√©rit√© Terrain) pour le debug
            logger.debug(f"   [{trace_id}] Contexte V√©rit√© : Patho='{pathologie_nom}'")

            # 2. Estimation de la phase de consultation
            # -----------------------------------------------------------------
            # Heuristique simple bas√©e sur le nombre d'√©changes
            # 0-4 messages : Accueil / Motif
            # 5-15 messages : Anamn√®se d√©taill√©e
            # >15 messages : Examen physique / Conclusion
            phase = "Ind√©termin√©e"
            if chat_history_count < 4:
                phase = "D√©but de consultation / Accueil / Motif"
            elif chat_history_count < 16:
                phase = "Anamn√®se (Histoire de la maladie & Ant√©c√©dents)"
            else:
                phase = "Examen Clinique ou Synth√®se"
            
            logger.debug(f"   [{trace_id}] Phase estim√©e : {phase} (Msg count: {chat_history_count})")

            # 3. Assemblage du Prompt
            # -----------------------------------------------------------------
            final_prompt = self.PEDAGOGICAL_ANALYSIS_TEMPLATE.format(
                pathologie_nom=pathologie_nom,
                resume_cas=histoire[:500] + "..." if len(histoire) > 500 else histoire,
                phase_courante=phase,
                question_etudiant=student_msg,
                reponse_patient=patient_msg
            )

            # 4. Validation et Logging final
            # -----------------------------------------------------------------
            prompt_length = len(final_prompt)
            logger.info(f"   ‚úÖ [{trace_id}] Prompt TUTEUR construit avec succ√®s ({prompt_length} chars).")
            
            # DUMP DU PROMPT COMPLET (Niveau DEBUG)
            # C'est ici qu'on v√©rifie si l'IA a toutes les infos pour bien juger.
            logger.debug(f"\n{'='*20} [{trace_id}] CONTENU DU PROMPT TUTEUR {'='*20}")
            logger.debug(final_prompt)
            logger.debug(f"{'='*60}\n")
            
            return final_prompt

        except Exception as e:
            logger.error(f"   ‚ùå [{trace_id}] Erreur critique construction prompt : {str(e)}")
            import traceback
            logger.debug(traceback.format_exc())
            # En cas d'erreur, on retourne un prompt de secours minimaliste
            return self._get_fallback_prompt(student_msg, patient_msg)

    def _safe_get(self, data: Dict, path: str, default: Any = None) -> Any:
        """
        R√©cup√®re une valeur dans un dictionnaire imbriqu√© via une cha√Æne point√©e.
        Ex: 'pathologie_principale.nom_fr'
        """
        keys = path.split('.')
        current = data
        try:
            for key in keys:
                if isinstance(current, dict):
                    current = current.get(key, {})
                else:
                    return default
            
            # Si le r√©sultat final est un dict vide (valeur par d√©faut de .get()), 
            # et que ce n'√©tait pas la valeur attendue, on renvoie default.
            if current == {} and default is not None:
                return default
            # Si current est un string/int/list valide
            return current if current else default
        except Exception:
            return default

    def _get_fallback_prompt(self, q: str, r: str) -> str:
        """Prompt de secours minimaliste en cas d'erreur de parsing des donn√©es complexes."""
        logger.warning("   ‚ö†Ô∏è Utilisation du prompt de secours (Fallback).")
        return f"""
Analyse p√©dagogique rapide.
Question: "{q}"
R√©ponse: "{r}"
Donne un feedback JSON: {{ "chronology_check": "...", "interpretation_guide": "...", "better_question": "..." }}
"""

# ==============================================================================
# SINGLETON
# ==============================================================================
# Instance unique pr√™te √† √™tre import√©e dans les services
tutor_prompt_builder = TutorPromptBuilder()