import os
from sqlalchemy.orm import Session
from openai import OpenAI
from app import models
from app.config import settings
from app.services.embedding_service import embedding_service

class MedicalRAGService:
    def __init__(self, db: Session):
        self.db = db
        # Configuration du client OpenRouter
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENAI_API_KEY"),
        )
        # Mod√®le gratuit et performant
        self.model = "mistralai/mistral-7b-instruct:free" 

    def _find_relevant_disease(self, query: str):
        """
        √âtape 1 : Recherche Vectorielle pour trouver la maladie dont parle l'utilisateur.
        """
        # 1. Vectoriser la question de l'utilisateur
        query_vector = embedding_service.get_text_embedding(query)

        # 2. Recherche par similarit√© (op√©rateur <=> de pgvector pour la distance cosinus)
        # On cherche la maladie la plus proche s√©mantiquement
        disease = self.db.query(models.Disease).order_by(
            models.Disease.embedding_vector.cosine_distance(query_vector)
        ).first()

        return disease

    def _get_structured_data(self, disease_id: int):
        """
        √âtape 2 : R√©cup√©ration SQL des donn√©es li√©es (Sympt√¥mes et Traitements).
        C'est ici que votre base relationnelle brille !
        """
        # R√©cup√©rer les sympt√¥mes li√©s (top 10 par probabilit√©)
        symptoms = self.db.query(models.PathologieSymptome).filter(
            models.PathologieSymptome.pathologie_id == disease_id
        ).order_by(models.PathologieSymptome.probabilite.desc()).limit(10).all()

        # R√©cup√©rer les traitements li√©s (top 5 par efficacit√©)
        treatments = self.db.query(models.TraitementPathologie).filter(
            models.TraitementPathologie.pathologie_id == disease_id
        ).order_by(models.TraitementPathologie.efficacite_taux.desc()).limit(5).all()

        return symptoms, treatments

    def answer_question(self, user_query: str) -> str:
        """
        Fonction principale du RAG.
        """
        print(f"üîé Analyse de la question : '{user_query}'")

        # 1. Trouver la maladie
        disease = self._find_relevant_disease(user_query)
        
        if not disease:
            return "D√©sol√©, je ne trouve pas de pathologie correspondante dans ma base de connaissances."

        print(f"‚úÖ Maladie identifi√©e : {disease.nom_fr} (Score de similarit√© √©lev√©)")

        # 2. R√©cup√©rer les d√©tails structur√©s
        db_symptoms, db_treatments = self._get_structured_data(disease.id)

        # 3. Construire le contexte pour le LLM (Prompt Engineering)
        symptoms_text = ", ".join([f"{s.symptome.nom} ({int(s.probabilite*100)}%)" for s in db_symptoms])
        treatments_text = ", ".join([f"{t.medicament.nom_commercial} ({t.type_traitement})" for t in db_treatments])

        context = f"""
        DONN√âES M√âDICALES FIABLES (SOURCE INTERNE) :
        - Maladie : {disease.nom_fr}
        - Description : {disease.description}
        - Sympt√¥mes fr√©quents : {symptoms_text}
        - Traitements recommand√©s : {treatments_text}
        """

        system_prompt = """Tu es un assistant m√©dical expert et p√©dagogue. 
        Utilise EXCLUSIVEMENT les donn√©es fournies dans le contexte pour r√©pondre. 
        Structure ta r√©ponse clairement : 1. Ce qu'est la maladie, 2. Les sympt√¥mes, 3. Les traitements."""

        # 4. Appeler le LLM
        completion = self.client.chat.completions.create(
            extra_headers={
                "HTTP-Referer": "https://mon-app-sti.com", # Requis par OpenRouter
                "X-Title": "STI Medical Expert",
            },
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Contexte:\n{context}\n\nQuestion utilisateur : {user_query}"},
            ],
        )

        return completion.choices[0].message.content